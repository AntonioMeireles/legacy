From 5b64dc2000826365cff157de0bbeaedc21eb90d7 Mon Sep 17 00:00:00 2001
From: Dave Airlie <airlied@redhat.com>
Date: Fri, 3 Apr 2009 13:19:09 +1000
Subject: [PATCH] drm: backwards compat layer on top of F11 DRM for F10

for radeon kms
---
 drivers/gpu/drm/radeon/radeon_gem.c |  254 +++++++++++++++++++++++++++++++++++
 include/drm/drm.h                   |   39 +++---
 include/drm/drm_mode.h              |   23 ++--
 include/drm/radeon_drm.h            |   18 +++-
 4 files changed, 306 insertions(+), 28 deletions(-)

diff --git a/drivers/gpu/drm/radeon/radeon_gem.c b/drivers/gpu/drm/radeon/radeon_gem.c
index ab9c005..2fd1c5d 100644
--- a/drivers/gpu/drm/radeon/radeon_gem.c
+++ b/drivers/gpu/drm/radeon/radeon_gem.c
@@ -30,6 +30,9 @@
 static int radeon_gem_ib_init(struct drm_device *dev);
 static int radeon_gem_ib_destroy(struct drm_device *dev);
 
+static int radeon_gem_dma_bufs_init(struct drm_device *dev);
+static void radeon_gem_dma_bufs_destroy(struct drm_device *dev);
+
 int radeon_gem_init_object(struct drm_gem_object *obj)
 {
 	struct drm_radeon_gem_object *obj_priv;
@@ -721,6 +724,7 @@ int radeon_alloc_gart_objects(struct drm_device *dev)
 
 	/* init the indirect buffers */
 	radeon_gem_ib_init(dev);
+	radeon_gem_dma_bufs_init(dev);
 	return 0;
 
 }
@@ -1158,6 +1162,8 @@ void radeon_gem_mm_fini(struct drm_device *dev)
 {
 	drm_radeon_private_t *dev_priv = dev->dev_private;
 
+	radeon_gem_dma_bufs_destroy(dev);
+
 	radeon_gem_ib_destroy(dev);
 
 	mutex_lock(&dev->struct_mutex);
@@ -1583,3 +1589,251 @@ void radeon_gem_update_offsets(struct drm_device *dev, struct drm_master *master
 }
 
 
+
+#define RADEON_DMA_BUFFER_SIZE (64 * 1024)
+#define RADEON_DMA_BUFFER_COUNT (16)
+
+
+/**
+ * Cleanup after an error on one of the addbufs() functions.
+ *
+ * \param dev DRM device.
+ * \param entry buffer entry where the error occurred.
+ *
+ * Frees any pages and buffers associated with the given entry.
+ */
+static void drm_cleanup_buf_error(struct drm_device * dev,
+				  struct drm_buf_entry * entry)
+{
+	int i;
+
+	if (entry->seg_count) {
+		for (i = 0; i < entry->seg_count; i++) {
+			if (entry->seglist[i]) {
+				drm_pci_free(dev, entry->seglist[i]);
+			}
+		}
+		drm_free(entry->seglist,
+			 entry->seg_count *
+			 sizeof(*entry->seglist), DRM_MEM_SEGS);
+
+		entry->seg_count = 0;
+	}
+
+	if (entry->buf_count) {
+		for (i = 0; i < entry->buf_count; i++) {
+			if (entry->buflist[i].dev_private) {
+				drm_free(entry->buflist[i].dev_private,
+					 entry->buflist[i].dev_priv_size,
+					 DRM_MEM_BUFS);
+			}
+		}
+		drm_free(entry->buflist,
+			 entry->buf_count *
+			 sizeof(*entry->buflist), DRM_MEM_BUFS);
+
+		entry->buf_count = 0;
+	}
+}
+
+static int radeon_gem_addbufs(struct drm_device *dev)
+{
+	struct drm_radeon_private *dev_priv = dev->dev_private;
+	struct drm_device_dma *dma = dev->dma;
+	struct drm_buf_entry *entry;
+	struct drm_buf *buf;
+	unsigned long offset;
+	unsigned long agp_offset;
+	int count;
+	int order;
+	int size;
+	int alignment;
+	int page_order;
+	int total;
+	int byte_count;
+	int i;
+	struct drm_buf **temp_buflist;
+	
+	if (!dma)
+		return -EINVAL;
+
+	count = RADEON_DMA_BUFFER_COUNT;
+	order = drm_order(RADEON_DMA_BUFFER_SIZE);
+	size = 1 << order;
+
+	alignment = PAGE_ALIGN(size);
+	page_order = order - PAGE_SHIFT > 0 ? order - PAGE_SHIFT : 0;
+	total = PAGE_SIZE << page_order;
+
+	byte_count = 0;
+	agp_offset = dev_priv->mm.dma_bufs.bo->offset;
+
+	DRM_DEBUG("count:      %d\n", count);
+	DRM_DEBUG("order:      %d\n", order);
+	DRM_DEBUG("size:       %d\n", size);
+	DRM_DEBUG("agp_offset: %lu\n", agp_offset);
+	DRM_DEBUG("alignment:  %d\n", alignment);
+	DRM_DEBUG("page_order: %d\n", page_order);
+	DRM_DEBUG("total:      %d\n", total);
+
+	if (order < DRM_MIN_ORDER || order > DRM_MAX_ORDER)
+		return -EINVAL;
+	if (dev->queue_count)
+		return -EBUSY;	/* Not while in use */
+
+	spin_lock(&dev->count_lock);
+	if (dev->buf_use) {
+		spin_unlock(&dev->count_lock);
+		return -EBUSY;
+	}
+	atomic_inc(&dev->buf_alloc);
+	spin_unlock(&dev->count_lock);
+
+	mutex_lock(&dev->struct_mutex);
+	entry = &dma->bufs[order];
+	if (entry->buf_count) {
+		mutex_unlock(&dev->struct_mutex);
+		atomic_dec(&dev->buf_alloc);
+		return -ENOMEM;	/* May only call once for each order */
+	}
+
+	if (count < 0 || count > 4096) {
+		mutex_unlock(&dev->struct_mutex);
+		atomic_dec(&dev->buf_alloc);
+		return -EINVAL;
+	}
+
+	entry->buflist = drm_alloc(count * sizeof(*entry->buflist),
+				   DRM_MEM_BUFS);
+	if (!entry->buflist) {
+		mutex_unlock(&dev->struct_mutex);
+		atomic_dec(&dev->buf_alloc);
+		return -ENOMEM;
+	}
+	memset(entry->buflist, 0, count * sizeof(*entry->buflist));
+
+	entry->buf_size = size;
+	entry->page_order = page_order;
+
+	offset = 0;
+
+	while (entry->buf_count < count) {
+		buf = &entry->buflist[entry->buf_count];
+		buf->idx = dma->buf_count + entry->buf_count;
+		buf->total = alignment;
+		buf->order = order;
+		buf->used = 0;
+
+		buf->offset = (dma->byte_count + offset);
+		buf->bus_address = dev_priv->gart_vm_start + agp_offset + offset;
+		buf->address = (void *)(agp_offset + offset);
+		buf->next = NULL;
+		buf->waiting = 0;
+		buf->pending = 0;
+		init_waitqueue_head(&buf->dma_wait);
+		buf->file_priv = NULL;
+
+		buf->dev_priv_size = dev->driver->dev_priv_size;
+		buf->dev_private = drm_alloc(buf->dev_priv_size, DRM_MEM_BUFS);
+		if (!buf->dev_private) {
+			/* Set count correctly so we free the proper amount. */
+			entry->buf_count = count;
+			drm_cleanup_buf_error(dev, entry);
+			mutex_unlock(&dev->struct_mutex);
+			atomic_dec(&dev->buf_alloc);
+			return -ENOMEM;
+		}
+
+		memset(buf->dev_private, 0, buf->dev_priv_size);
+
+		DRM_DEBUG("buffer %d @ %p\n", entry->buf_count, buf->address);
+
+		offset += alignment;
+		entry->buf_count++;
+		byte_count += PAGE_SIZE << page_order;
+	}
+
+	DRM_DEBUG("byte_count: %d\n", byte_count);
+
+	temp_buflist = drm_realloc(dma->buflist,
+				   dma->buf_count * sizeof(*dma->buflist),
+				   (dma->buf_count + entry->buf_count)
+				   * sizeof(*dma->buflist), DRM_MEM_BUFS);
+	if (!temp_buflist) {
+		/* Free the entry because it isn't valid */
+		drm_cleanup_buf_error(dev, entry);
+		mutex_unlock(&dev->struct_mutex);
+		atomic_dec(&dev->buf_alloc);
+		return -ENOMEM;
+	}
+	dma->buflist = temp_buflist;
+
+	for (i = 0; i < entry->buf_count; i++) {
+		dma->buflist[i + dma->buf_count] = &entry->buflist[i];
+	}
+
+	dma->buf_count += entry->buf_count;
+	dma->seg_count += entry->seg_count;
+	dma->page_count += byte_count >> PAGE_SHIFT;
+	dma->byte_count += byte_count;
+
+	DRM_DEBUG("dma->buf_count : %d\n", dma->buf_count);
+	DRM_DEBUG("entry->buf_count : %d\n", entry->buf_count);
+
+	mutex_unlock(&dev->struct_mutex);
+
+	dma->flags = _DRM_DMA_USE_SG;
+	atomic_dec(&dev->buf_alloc);
+	return 0;
+}
+
+static int radeon_gem_dma_bufs_init(struct drm_device *dev)
+{
+	struct drm_radeon_private *dev_priv = dev->dev_private;
+	int size = RADEON_DMA_BUFFER_SIZE * RADEON_DMA_BUFFER_COUNT;
+	int ret;
+
+	ret = drm_dma_setup(dev);
+	if (ret < 0)
+		return ret;
+
+	ret = drm_buffer_object_create(dev, size, drm_bo_type_kernel,
+				       DRM_BO_FLAG_READ | DRM_BO_FLAG_WRITE | DRM_BO_FLAG_NO_EVICT |
+				       DRM_BO_FLAG_MEM_TT | DRM_BO_FLAG_MAPPABLE, 0,
+				       0, 0, &dev_priv->mm.dma_bufs.bo);
+	if (ret) {
+		DRM_ERROR("Failed to create DMA bufs\n");
+		return -ENOMEM;
+	}
+
+	ret = drm_bo_kmap(dev_priv->mm.dma_bufs.bo, 0, size >> PAGE_SHIFT,
+			  &dev_priv->mm.dma_bufs.kmap);
+	if (ret) {
+		DRM_ERROR("Failed to mmap DMA buffers\n");
+		return -ENOMEM;
+	}
+	dev_priv->mm.gart_useable -= size;
+	DRM_DEBUG("\n");
+	radeon_gem_addbufs(dev);
+
+	DRM_DEBUG("%lx %d\n", dev_priv->mm.dma_bufs.bo->map_list.hash.key, size);
+	dev->agp_buffer_token = dev_priv->mm.dma_bufs.bo->map_list.hash.key << PAGE_SHIFT;
+	dev_priv->mm.fake_agp_map.handle = dev_priv->mm.dma_bufs.kmap.virtual;
+	dev_priv->mm.fake_agp_map.size = size;
+	
+	dev->agp_buffer_map = &dev_priv->mm.fake_agp_map;
+	dev_priv->gart_buffers_offset = dev_priv->mm.dma_bufs.bo->offset + dev_priv->gart_vm_start;
+	return 0;
+}
+
+static void radeon_gem_dma_bufs_destroy(struct drm_device *dev)
+{
+
+	struct drm_radeon_private *dev_priv = dev->dev_private;
+	drm_dma_takedown(dev);
+
+	if (dev_priv->mm.dma_bufs.bo) {
+		drm_bo_kunmap(&dev_priv->mm.dma_bufs.kmap);
+		drm_bo_usage_deref_unlocked(&dev_priv->mm.dma_bufs.bo);
+	}
+}
diff --git a/include/drm/drm.h b/include/drm/drm.h
index 17a1e2c..fa02570 100644
--- a/include/drm/drm.h
+++ b/include/drm/drm.h
@@ -671,23 +671,28 @@ struct drm_gem_open {
 
 #define DRM_IOCTL_UPDATE_DRAW		DRM_IOW(0x3f, struct drm_update_draw)
 
-#define DRM_IOCTL_MODE_GETRESOURCES	DRM_IOWR(0xA0, struct drm_mode_card_res)
-#define DRM_IOCTL_MODE_GETCRTC		DRM_IOWR(0xA1, struct drm_mode_crtc)
-#define DRM_IOCTL_MODE_SETCRTC		DRM_IOWR(0xA2, struct drm_mode_crtc)
-#define DRM_IOCTL_MODE_CURSOR		DRM_IOWR(0xA3, struct drm_mode_cursor)
-#define DRM_IOCTL_MODE_GETGAMMA		DRM_IOWR(0xA4, struct drm_mode_crtc_lut)
-#define DRM_IOCTL_MODE_SETGAMMA		DRM_IOWR(0xA5, struct drm_mode_crtc_lut)
-#define DRM_IOCTL_MODE_GETENCODER	DRM_IOWR(0xA6, struct drm_mode_get_encoder)
-#define DRM_IOCTL_MODE_GETCONNECTOR	DRM_IOWR(0xA7, struct drm_mode_get_connector)
-#define DRM_IOCTL_MODE_ATTACHMODE	DRM_IOWR(0xA8, struct drm_mode_mode_cmd)
-#define DRM_IOCTL_MODE_DETACHMODE	DRM_IOWR(0xA9, struct drm_mode_mode_cmd)
-
-#define DRM_IOCTL_MODE_GETPROPERTY	DRM_IOWR(0xAA, struct drm_mode_get_property)
-#define DRM_IOCTL_MODE_SETPROPERTY	DRM_IOWR(0xAB, struct drm_mode_connector_set_property)
-#define DRM_IOCTL_MODE_GETPROPBLOB	DRM_IOWR(0xAC, struct drm_mode_get_blob)
-#define DRM_IOCTL_MODE_GETFB		DRM_IOWR(0xAD, struct drm_mode_fb_cmd)
-#define DRM_IOCTL_MODE_ADDFB		DRM_IOWR(0xAE, struct drm_mode_fb_cmd)
-#define DRM_IOCTL_MODE_RMFB		DRM_IOWR(0xAF, unsigned int)
+#define DRM_IOCTL_MODE_GETRESOURCES     DRM_IOWR(0xA0, struct drm_mode_card_res)
+#define DRM_IOCTL_MODE_GETCRTC          DRM_IOWR(0xA1, struct drm_mode_crtc)
+#define DRM_IOCTL_MODE_GETCONNECTOR        DRM_IOWR(0xA2, struct drm_mode_get_connector)
+#define DRM_IOCTL_MODE_SETCRTC          DRM_IOWR(0xA3, struct drm_mode_crtc)
+#define DRM_IOCTL_MODE_ADDFB            DRM_IOWR(0xA4, struct drm_mode_fb_cmd)
+#define DRM_IOCTL_MODE_RMFB             DRM_IOWR(0xA5, unsigned int)
+#define DRM_IOCTL_MODE_GETFB            DRM_IOWR(0xA6, struct drm_mode_fb_cmd)
+
+#define DRM_IOCTL_MODE_SETPROPERTY     DRM_IOWR(0xA7, struct drm_mode_connector_set_property)
+#define DRM_IOCTL_MODE_GETPROPBLOB     DRM_IOWR(0xA8, struct drm_mode_get_blob)
+#define DRM_IOCTL_MODE_ATTACHMODE      DRM_IOWR(0xA9, struct drm_mode_mode_cmd)
+#define DRM_IOCTL_MODE_DETACHMODE      DRM_IOWR(0xAA, struct drm_mode_mode_cmd)
+
+#define DRM_IOCTL_MODE_GETPROPERTY     DRM_IOWR(0xAB, struct drm_mode_get_property)
+#define DRM_IOCTL_MODE_CURSOR          DRM_IOWR(0xAC, struct drm_mode_cursor)
+#define DRM_IOCTL_MODE_HOTPLUG         DRM_IOWR(0xAD, struct drm_mode_hotplug)
+#define DRM_IOCTL_WAIT_HOTPLUG		DRM_IOWR(0xAE, union drm_wait_hotplug)
+
+#define DRM_IOCTL_MODE_REPLACEFB       DRM_IOWR(0xAF, struct drm_mode_fb_cmd)
+#define DRM_IOCTL_MODE_GETENCODER      DRM_IOWR(0xB0, struct drm_mode_get_encoder)
+#define DRM_IOCTL_MODE_GETGAMMA        DRM_IOWR(0xB1, struct drm_mode_crtc_lut)
+#define DRM_IOCTL_MODE_SETGAMMA        DRM_IOWR(0xB2, struct drm_mode_crtc_lut)
 
 /**
  * Device specific ioctls should only be in their respective headers
diff --git a/include/drm/drm_mode.h b/include/drm/drm_mode.h
index 601d2bd..58417e5 100644
--- a/include/drm/drm_mode.h
+++ b/include/drm/drm_mode.h
@@ -126,10 +126,11 @@ struct drm_mode_crtc {
 #define DRM_MODE_ENCODER_TVDAC	4
 
 struct drm_mode_get_encoder {
-	uint32_t encoder_id;
-	uint32_t encoder_type;
 
-	uint32_t crtc_id; /**< Id of crtc */
+	unsigned int encoder_type;
+	unsigned int encoder_id;
+
+	unsigned int crtc_id; /**< Id of crtc */
 
 	uint32_t possible_crtcs;
 	uint32_t possible_clones;
@@ -216,13 +217,15 @@ struct drm_mode_get_blob {
 };
 
 struct drm_mode_fb_cmd {
-	uint32_t fb_id;
-	uint32_t width, height;
-	uint32_t pitch;
-	uint32_t bpp;
-	uint32_t depth;
-	/* driver specific handle */
-	uint32_t handle;
+	union {
+		unsigned int fb_id;
+		unsigned int buffer_id;
+	};
+	unsigned int width, height;
+	unsigned int pitch;
+	unsigned int bpp;
+	unsigned int handle;
+	unsigned int depth;
 };
 
 struct drm_mode_mode_cmd {
diff --git a/include/drm/radeon_drm.h b/include/drm/radeon_drm.h
index f716e0a..d6a233f 100644
--- a/include/drm/radeon_drm.h
+++ b/include/drm/radeon_drm.h
@@ -514,7 +514,8 @@ typedef struct {
 #define DRM_RADEON_GEM_SET_DOMAIN 0x23
 #define DRM_RADEON_GEM_WAIT_RENDERING 0x24
 
-#define DRM_RADEON_CS       0x26
+#define DRM_RADEON_CS           0x26
+#define DRM_RADEON_CS2       0x26
 
 #define DRM_IOCTL_RADEON_CP_INIT    DRM_IOW( DRM_COMMAND_BASE + DRM_RADEON_CP_INIT, drm_radeon_init_t)
 #define DRM_IOCTL_RADEON_CP_START   DRM_IO(  DRM_COMMAND_BASE + DRM_RADEON_CP_START)
@@ -554,6 +555,7 @@ typedef struct {
 #define DRM_IOCTL_RADEON_GEM_SET_DOMAIN  DRM_IOWR(DRM_COMMAND_BASE + DRM_RADEON_GEM_SET_DOMAIN, struct drm_radeon_gem_set_domain)
 #define DRM_IOCTL_RADEON_GEM_WAIT_RENDERING DRM_IOW(DRM_COMMAND_BASE + DRM_RADEON_GEM_WAIT_RENDERING, struct drm_radeon_gem_wait_rendering) 
 #define DRM_IOCTL_RADEON_CS DRM_IOWR(DRM_COMMAND_BASE + DRM_RADEON_CS, struct drm_radeon_cs)
+#define DRM_IOCTL_RADEON_CS2 DRM_IOWR(DRM_COMMAND_BASE + DRM_RADEON_CS2, struct drm_radeon_cs2)
 
 
 typedef struct drm_radeon_init {
@@ -869,6 +871,14 @@ struct drm_radeon_gem_pwrite {
 
 /* New interface which obsolete all previous interface.
  */
+
+
+struct drm_radeon_cs_old {
+	uint32_t            dwords;
+	uint32_t            cs_id;
+	uint64_t            packets;
+};
+
 #define RADEON_CHUNK_ID_RELOCS 0x01
 #define RADEON_CHUNK_ID_IB     0x02
 #define RADEON_CHUNK_ID_OLD 0xff
@@ -886,5 +896,11 @@ struct drm_radeon_cs {
 				   cs chunks */
 };
 
+struct drm_radeon_cs2 {
+	uint32_t	num_chunks;
+	uint32_t        cs_id;
+	uint64_t	chunks; /* this points to uint64_t * which point to
+				   cs chunks */
+};
 
 #endif
-- 
1.6.0.6

