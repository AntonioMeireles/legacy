--- kernel/linux-2.6.26.3/drivers/misc/Kconfig	2008-08-20 13:11:37.000000000 -0500
+++ linux-2.6.26.3.vmtools/drivers/misc/Kconfig	2008-09-03 09:57:34.000000000 -0500
@@ -391,4 +391,34 @@ config SGI_XP
 	  this feature will allow for direct communication between SSIs
 	  based on a network adapter and DMA messaging.
 
+config VMCI
+	tristate "VMware inter-VM communication device"
+	depends on VSOCK
+	help
+	 This is a Linux kernel device driver module that drives VMware's
+	 inter-VM communication device. The device itself is backed by a
+	 PCI-based virtual hardware implementation, so hotplug or udev
+	 should load it at guest boot time in any VMs using hardware version 7.
+
+config VMMEMCTL
+	tristate "VMware Memory Control Driver"
+	help
+	 VMware Memory Control Driver.  If this kernel will be used in a VMware
+	 guest, say m here.
+
+config VMSYNC
+	tristate "VMware Sync Driver"
+	help
+	 VMware Sync Driver.  If this kernel will be used in a VMware
+	 guest, say m here.
+
+config VSOCK
+	tristate "VMware Socket driver for VMCI device"
+	help
+	 This is a Linux kernel device driver module that provides datagram and
+	 stream socket interfaces to the underlying VMCI device. The module
+	 implements a Linux socket family and one of the files in the module,
+	 vmci_sockets.h, provides the various constants and functions necessary
+	 to create and, in the case of streams, connect sockets.
+
 endif # MISC_DEVICES
--- kernel/linux-2.6.26.3/drivers/misc/Makefile	2008-08-20 13:11:37.000000000 -0500
+++ linux-2.6.26.3.vmtools/drivers/misc/Makefile	2008-09-03 09:57:34.000000000 -0500
@@ -26,3 +26,7 @@ obj-$(CONFIG_INTEL_MENLOW)	+= intel_menl
 obj-$(CONFIG_ENCLOSURE_SERVICES) += enclosure.o
 obj-$(CONFIG_KGDB_TESTS)	+= kgdbts.o
 obj-$(CONFIG_SGI_XP)		+= sgi-xp/
+obj-$(CONFIG_VMCI)		+= vmci/
+obj-$(CONFIG_VMMEMCTL)		+= vmmemctl/
+obj-$(CONFIG_VMSYNC)		+= vmsync/
+obj-$(CONFIG_VMSOCK)		+= vsock/
--- kernel/linux-2.6.26.3/drivers/misc/vmci/circList.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmci/circList.h	2008-09-03 10:01:42.000000000 -0500
@@ -0,0 +1,428 @@
+/*********************************************************
+ * Copyright (C) 1998 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ *   circList.h --
+ *
+ * macros, prototypes and struct definitions for double-linked
+ * circular lists.
+ */
+
+#ifndef _CIRCLIST_H_
+#define _CIRCLIST_H_
+
+#define INCLUDE_ALLOW_USERLEVEL
+#define INCLUDE_ALLOW_VMMON
+#define INCLUDE_ALLOW_VMCORE
+#define INCLUDE_ALLOW_MODULE
+#define INCLUDE_ALLOW_VMKERNEL
+#include "includeCheck.h"
+#include "vmware.h"
+
+typedef struct ListItem {
+   struct ListItem *prev;
+   struct ListItem *next;
+} ListItem;
+
+/* A list with no elements is a null pointer. */
+#define   LIST_ITEM_DEF(name)   \
+   ListItem * name = NULL
+
+#define   LIST_EMPTY(l)      ((l) == NULL)
+
+/* initialize list item */
+#define   INIT_LIST_ITEM(p)   \
+   do {   \
+      (p)->prev = (p)->next = (p);   \
+   } while (0)
+
+/* check if initialized */
+#define   IS_LIST_ITEM_INITIALIZED(li)   \
+   (((li) == (li)->prev) && ((li) == (li)->next))
+
+/* return first element in the list */
+#define   LIST_FIRST(l)      (l)
+#define   LIST_FIRST_CHK(l)   (l)
+
+/* return last element in the list */
+#define   LIST_LAST(l)      ((l)->prev)
+#define   LIST_LAST_CHK(l)   (LIST_EMPTY(l) ? NULL : LIST_LAST(l))
+
+/*
+ * LIST_CONTAINER - get the struct for this entry (like list_entry)
+ * @ptr: the &struct ListItem pointer.
+ * @type:   the type of the struct this is embedded in.
+ * @member: the name of the list struct within the struct.
+ */
+#define LIST_CONTAINER(ptr, type, member) \
+   ((type *)((char *)(ptr) - offsetof(type, member)))
+
+/*
+ * delete item from the list
+ */
+#define   LIST_DEL            DelListItem   
+
+/*
+ * link two lists together
+ */
+#define   LIST_SPLICE         SpliceLists
+
+/*
+ * Split a list into two lists
+ */
+#define   LIST_SPLIT          SplitLists
+
+/*
+ * Add item to front of stack. List pointer points to new head.
+ */
+#define   LIST_PUSH           PushListItem
+
+/*
+ * Add item at back of queue. List pointer only changes if list was empty.
+ */
+#define   LIST_QUEUE          QueueListItem
+
+/*
+ * Get the list size.
+ */
+#define   LIST_SIZE  	      GetListSize
+
+/*
+ * LIST_SCAN_FROM scans the list from "from" up until "until".
+ * The loop variable p should not be destroyed in the process.
+ * "from" is an element in the list where to start scanning.
+ * "until" is the element where search should stop.
+ * member is the field to use for the search - either "next" or "prev".
+ */
+#define   LIST_SCAN_FROM(p, from, until, member)   \
+   for (p = (from); (p) != NULL;   \
+      (p) = (((p)->member == (until)) ? NULL : (p)->member))
+
+/* scan the entire list (non-destructively) */ 
+#define   LIST_SCAN(p, l)   \
+   LIST_SCAN_FROM(p, LIST_FIRST(l), LIST_FIRST(l), next)
+
+
+/* scan a list backward from last element to first (non-destructively) */
+#define   LIST_SCAN_BACK(p, l)   \
+   LIST_SCAN_FROM(p, LIST_LAST_CHK(l), LIST_LAST(l), prev)
+
+/* scan the entire list where loop element may be destroyed */
+#define   LIST_SCAN_SAFE(p, pn, l)   \
+   if (!LIST_EMPTY(l))  \
+      for (p = (l), (pn) = NextListItem(p, l); (p) != NULL;   \
+           (p) = (pn), (pn) = NextListItem(p, l))
+
+/* scan the entire list backwards where loop element may be destroyed */
+#define   LIST_SCAN_BACK_SAFE(p, pn, l)   \
+   if (!LIST_EMPTY(l))  \
+      for (p = LIST_LAST(l), (pn) = PrevListItem(p, l); (p) != NULL;   \
+           (p) = (pn), (pn) = PrevListItem(p, l))
+
+
+/* function definitions */
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * NextListItem --
+ *
+ *      Returns the next member of a doubly linked list, or NULL if last.
+ *      Assumes: p is member of the list headed by head.
+ *
+ * Result
+ *      If head or p is NULL, return NULL. Otherwise,
+ *      next list member (or null if last).
+ *
+ * Side effects:
+ *      None.
+ *
+ *----------------------------------------------------------------------
+ */
+
+static INLINE ListItem *
+NextListItem(ListItem *p,        // IN
+             ListItem *head)     // IN
+{
+   if (head == NULL || p == NULL) {
+      return NULL;
+   }
+   /* both p and head are non-null */
+   p = p->next;
+   return p == head ? NULL : p;
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * PrevListItem --
+ *
+ *      Returns the prev member of a doubly linked list, or NULL if first.
+ *      Assumes: p is member of the list headed by head.
+ *
+ * Result
+ *      If head or prev is NULL, return NULL. Otherwise,
+ *      prev list member (or null if first).
+ *
+ * Side effects:
+ *      None.
+ *
+ *----------------------------------------------------------------------
+ */
+
+static INLINE ListItem *
+PrevListItem(ListItem *p,        // IN
+             ListItem *head)     // IN
+{
+   if (head == NULL || p == NULL) {
+      return NULL;
+   }
+   /* both p and head are non-null */
+   return p == head ? NULL : p->prev;
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * DelListItem --
+ *
+ *      Deletes a member of a doubly linked list, possibly modifies the
+ *      list header itself.
+ *      Assumes neither p nor headp is null and p is a member of *headp.
+ *
+ * Result
+ *      None
+ *
+ * Side effects:
+ *      Modifies *headp.
+ *
+ *----------------------------------------------------------------------
+ */
+
+static INLINE void
+DelListItem(ListItem *p,         // IN
+            ListItem **headp)    // IN/OUT
+{
+   ListItem *next;
+
+   ASSERT(p);
+   ASSERT(headp);
+
+   next = p->next;
+   if (p == next) {
+      *headp = NULL;
+   } else {
+      next->prev = p->prev;
+      p->prev->next = next;
+      if (*headp == p) {
+         *headp = next;
+      }
+   }
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * QueueListItem --
+ *
+ *      Adds a new member to the back of a doubly linked list (queue)
+ *      Assumes neither p nor headp is null and p is not a member of *headp.
+ *
+ * Result
+ *      None
+ *
+ * Side effects:
+ *      Modifies *headp.
+ *
+ *----------------------------------------------------------------------
+ */
+
+static INLINE void
+QueueListItem(ListItem *p,              // IN
+              ListItem **headp)         // IN/OUT
+{
+   ListItem *head;
+
+   head = *headp;
+   if (LIST_EMPTY(head)) {
+      INIT_LIST_ITEM(p);
+      *headp = p;
+   } else {
+      p->prev = head->prev;
+      p->next = head;
+      p->prev->next = p;
+      head->prev = p;
+   }
+}
+                                                                                
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * PushListItem --
+ *
+ *      Adds a new member to the front of a doubly linked list (stack)
+ *      Assumes neither p nor headp is null and p is not a member of *headp.
+ *
+ * Result
+ *      None
+ *
+ * Side effects:
+ *      Modifies *headp.
+ *
+ *----------------------------------------------------------------------
+ */
+
+static INLINE void
+PushListItem(ListItem *p,               // IN
+             ListItem **headp)          // IN/OUT
+{
+   QueueListItem(p, headp);
+   *headp = p;
+}
+ 
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * SpliceLists --
+ *
+ *      Make a single list {l1 l2} from {l1} and {l2} and return it.
+ *      It is okay for one or both lists to be NULL.
+ *      No checking is done. It is assumed that l1 and l2 are two
+ *      distinct lists.
+ *
+ * Result
+ *      A list { l1 l2 }.
+ *
+ * Side effects:
+ *      Modifies l1 and l2 list pointers.
+ *
+ *----------------------------------------------------------------------
+ */
+
+static INLINE ListItem *
+SpliceLists(ListItem *l1,      // IN
+            ListItem *l2)      // IN
+{
+   ListItem *l1Last, *l2Last;
+
+   if (LIST_EMPTY(l1)) {
+      return l2;
+   }
+
+   if (LIST_EMPTY(l2)) {
+      return l1;
+   }
+
+   l1Last = l1->prev;   /* last elem of l1 */
+   l2Last = l2->prev;   /* last elem of l2 */
+
+   /*
+    *    l1 -> ... -> l1Last    l2 -> ... l2Last
+    */
+   l1Last->next = l2;
+   l2->prev = l1Last;
+
+   l1->prev = l2Last;
+   l2Last->next = l1;
+
+   return l1;
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * SplitLists --
+ *
+ *      Make a list l = {l1 l2} into two separate lists {l1} and {l2}, where:
+ *      l = { ... x -> p -> ... } split into:
+ *      l1 = { ... -> x }
+ *      l2 = { p -> ... } 
+ *      Assumes neither p nor l is null and p is a member of l.
+ *      If p is the first element of l, then l1 will be NULL.
+ *
+ * Result
+ *      None.
+ *
+ * Side effects:
+ *      Sets *l1p and *l2p to the resulting two lists.
+ *      Modifies l's pointers.
+ *
+ *----------------------------------------------------------------------
+ */
+
+static INLINE void
+SplitLists(ListItem *p,         // IN
+           ListItem *l,         // IN
+           ListItem **l1p,      // OUT
+           ListItem **l2p)      // OUT
+{
+   ListItem *last;
+
+   if (p == LIST_FIRST(l)) {   /* first element */
+      *l1p = NULL;
+      *l2p = l;
+      return;
+   }
+
+   last = l->prev;
+
+   *l1p = l;
+   p->prev->next = l;
+   l->prev = p->prev;
+
+   *l2p = p;
+   p->prev = last;
+   last->next = p;
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * GetListSize --
+ *
+ *	Return the number of items in the list.
+ *
+ * Result:
+ *	The number of items in the list.
+ *
+ * Side effects:
+ *	None.
+ *
+ *----------------------------------------------------------------------
+ */
+
+static INLINE int
+GetListSize(ListItem *head) 	// IN
+{
+   ListItem *li;
+   int ret = 0;
+
+   LIST_SCAN(li, head) {
+      ret++;
+   }
+   return ret;
+}
+
+#endif /* _CIRCLIST_H_ */
--- kernel/linux-2.6.26.3/drivers/misc/vmci/compat_completion.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmci/compat_completion.h	2008-09-03 10:01:42.000000000 -0500
@@ -0,0 +1,175 @@
+/*********************************************************
+ * Copyright (C) 2004 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_COMPLETION_H__
+#   define __COMPAT_COMPLETION_H__
+
+/*
+ * The kernel's completion objects were made available for module use in 2.4.9.
+ * 
+ * Between 2.4.0 and 2.4.9, we implement completions on our own using 
+ * waitqueues and counters. This was done so that we could safely support
+ * functions like complete_all(), which cannot be implemented using semaphores.
+ *
+ * Prior to that, the waitqueue API is substantially different, and since none 
+ * of our modules that are built against older kernels need complete_all(), 
+ * we fallback on a simple semaphore-based implementation. 
+ */
+
+/* 
+ * Native completions.
+ */ 
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 4, 9)
+
+#include <linux/completion.h>
+#define compat_completion struct completion
+#define compat_init_completion(comp) init_completion(comp)
+#define COMPAT_DECLARE_COMPLETION DECLARE_COMPLETION
+#define compat_wait_for_completion(comp) wait_for_completion(comp)
+#define compat_complete(comp) complete(comp)
+
+/* complete_all() was exported in 2.6.6. */
+# if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 6)
+#  include "compat_wait.h"
+#  include "compat_list.h"
+#  include "compat_spinlock.h"
+#  include "compat_sched.h"
+#  define compat_complete_all(x)         \
+      ({                                 \
+          struct list_head *currLinks;   \
+          spin_lock(&(x)->wait.lock);    \
+          (x)->done += UINT_MAX/2;       \
+                                         \
+          list_for_each(currLinks, &(x)->wait.task_list) { \
+             wait_queue_t *currQueue = list_entry(currLinks, wait_queue_t, task_list); \
+             wake_up_process(currQueue->task); \
+          }                              \
+          spin_unlock(&(x)->wait.lock);  \
+      })
+# else
+#  define compat_complete_all complete_all
+# endif
+
+/* 
+ * Completions via waitqueues.
+ */
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(2, 4, 0)
+
+/*
+ * Kernel completions in 2.4.9 and beyond use a counter and a waitqueue, and 
+ * our implementation is quite similar. Because __wake_up_common() is not 
+ * exported, our implementations of compat_complete() and compat_complete_all()
+ * are somewhat racy: the counter is incremented outside of the waitqueue's 
+ * lock. 
+ *
+ * As a result, our completion cannot guarantee in-order wake ups. For example,
+ * suppose thread A is entering compat_complete(), thread B is sleeping inside
+ * compat_wait_for_completion(), and thread C is just now entering
+ * compat_wait_for_completion(). If Thread A is scheduled first and increments 
+ * the counter, then gets swapped out, thread C may get scheduled and will 
+ * quickly go through compat_wait_for_completion() (since done != 0) while 
+ * thread B continues to sleep, even though thread B should have been the one 
+ * to wake up.
+ */
+
+#include <asm/current.h>
+#include "compat_sched.h"
+#include "compat_list.h"
+#include <linux/smp_lock.h> // for lock_kernel()/unlock_kernel()
+#include "compat_wait.h"
+
+typedef struct compat_completion {
+   unsigned int done;
+   wait_queue_head_t wq;
+} compat_completion;
+
+#define compat_init_completion(comp) do { \
+   (comp)->done = 0; \
+   init_waitqueue_head(&(comp)->wq); \
+} while (0)
+#define COMPAT_DECLARE_COMPLETION(comp) \
+   compat_completion comp = { \
+     .done = 0, \
+     .wq = __WAIT_QUEUE_HEAD_INITIALIZER((comp).wq), \
+   }
+
+/*
+ * Locking and unlocking the kernel lock here ensures that the thread
+ * is no longer running in module code: compat_complete_and_exit
+ * performs the sequence { lock_kernel(); up(comp); compat_exit(); }, with
+ * the final unlock_kernel performed implicitly by the resident kernel
+ * in do_exit.
+ */
+#define compat_wait_for_completion(comp) do { \
+   spin_lock_irq(&(comp)->wq.lock); \
+   if (!(comp)->done) { \
+      DECLARE_WAITQUEUE(wait, current); \
+      wait.flags |= WQ_FLAG_EXCLUSIVE; \
+      __add_wait_queue_tail(&(comp)->wq, &wait); \
+      do { \
+         __set_current_state(TASK_UNINTERRUPTIBLE); \
+         spin_unlock_irq(&(comp)->wq.lock); \
+         schedule(); \
+         spin_lock_irq(&(comp)->wq.lock); \
+      } while (!(comp)->done); \
+      __remove_wait_queue(&(comp)->wq, &wait); \
+   } \
+   (comp)->done--; \
+   spin_unlock_irq(&(comp)->wq.lock); \
+   lock_kernel(); \
+   unlock_kernel(); \
+} while (0)
+
+/* XXX: I don't think I need to touch the BKL. */
+#define compat_complete(comp) do { \
+   unsigned long flags; \
+   spin_lock_irqsave(&(comp)->wq.lock, flags); \
+   (comp)->done++; \
+   spin_unlock_irqrestore(&(comp)->wq.lock, flags); \
+   wake_up(&(comp)->wq); \
+} while (0)
+
+#define compat_complete_all(comp) do { \
+   unsigned long flags; \
+   spin_lock_irqsave(&(comp)->wq.lock, flags); \
+   (comp)->done += UINT_MAX / 2; \
+   spin_unlock_irqrestore(&(comp)->wq.lock, flags); \
+   wake_up_all(&(comp)->wq); \
+} while (0)
+
+/*
+ * Completions via semaphores.
+ */ 
+#else
+
+#include "compat_semaphore.h"
+#define compat_completion struct semaphore 
+#define compat_init_completion(comp) init_MUTEX_LOCKED(comp)
+#define COMPAT_DECLARE_COMPLETION(comp) DECLARE_MUTEX_LOCKED(comp) 
+
+#define compat_wait_for_completion(comp) do { \
+   down(comp); \
+   lock_kernel(); \
+   unlock_kernel(); \
+} while (0)
+
+#define compat_complete(comp) up(comp)
+
+#endif
+
+#endif /* __COMPAT_COMPLETION_H__ */
--- kernel/linux-2.6.26.3/drivers/misc/vmci/compat_file.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmci/compat_file.h	2008-09-03 10:01:42.000000000 -0500
@@ -0,0 +1,56 @@
+/*********************************************************
+ * Copyright (C) 2002 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_FILE_H__
+#   define __COMPAT_FILE_H__
+
+
+/* The fput() API is modified in 2.2.0 --hpreg */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 2, 0)
+#   define compat_fput(_file) fput(_file)
+#else
+#   define compat_fput(_file) fput(_file, (_file)->f_inode)
+#endif
+
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 4, 0)
+#   define compat_get_file(_file) get_file(_file)
+#   define compat_file_count(_file) file_count(_file)
+#else
+#   define compat_get_file(_file) (_file)->f_count++
+#   define compat_file_count(_file) (_file)->f_count
+#endif
+
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 2, 4)
+#   define compat_filp_close(_file, _files) filp_close(_file, _files)
+#else
+static inline void compat_filp_close(struct file* filp, fl_owner_t files) {
+   if (filp->f_op && filp->f_op->flush) {
+      filp->f_op->flush(filp);
+   }
+   /*
+    * Hopefully there are no locks to release on this filp. 
+    * locks_remove_posix is not exported so we cannot use it...
+    */
+   fput(filp);
+}
+#endif
+
+
+#endif /* __COMPAT_FILE_H__ */
--- kernel/linux-2.6.26.3/drivers/misc/vmci/compat_highmem.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmci/compat_highmem.h	2008-09-03 10:01:42.000000000 -0500
@@ -0,0 +1,40 @@
+/*********************************************************
+ * Copyright (C) 2002 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_HIGHMEM_H__
+#   define __COMPAT_HIGHMEM_H__
+
+
+/*
+ *  BIGMEM  (4 GB)         support appeared in 2.3.16: kmap() API added
+ *  HIGHMEM (4 GB + 64 GB) support appeared in 2.3.23: kmap() API modified
+ *  In 2.3.27, kmap() API modified again
+ *
+ *   --hpreg
+ */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 3, 27)
+#   include <linux/highmem.h>
+#else
+/* For page_address --hpreg */
+#   include <linux/pagemap.h>
+
+#   define kmap(_page) (void*)page_address(_page)
+#   define kunmap(_page)
+#endif
+
+#endif /* __COMPAT_HIGHMEM_H__ */
--- kernel/linux-2.6.26.3/drivers/misc/vmci/compat_init.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmci/compat_init.h	2008-09-03 10:01:42.000000000 -0500
@@ -0,0 +1,38 @@
+/*********************************************************
+ * Copyright (C) 1999 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * compat_init.h: Initialization compatibility wrappers.
+ */
+
+#ifndef __COMPAT_INIT_H__
+#define __COMPAT_INIT_H__
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 2, 0)
+#include <linux/init.h>
+#endif
+
+#ifndef module_init
+#define module_init(x) int init_module(void)     { return x(); }
+#endif
+
+#ifndef module_exit
+#define module_exit(x) void cleanup_module(void) { x(); }
+#endif
+
+#endif /* __COMPAT_INIT_H__ */
--- kernel/linux-2.6.26.3/drivers/misc/vmci/compat_interrupt.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmci/compat_interrupt.h	2008-09-03 10:01:42.000000000 -0500
@@ -0,0 +1,55 @@
+/*********************************************************
+ * Copyright (C) 2003 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_INTERRUPT_H__
+#   define __COMPAT_INTERRUPT_H__
+
+
+#include <linux/interrupt.h>
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 69)
+/*
+ * We cannot just define irqreturn_t, as some 2.4.x kernels have
+ * typedef void irqreturn_t; for "increasing" backward compatibility.
+ */
+typedef void compat_irqreturn_t;
+#define COMPAT_IRQ_NONE
+#define COMPAT_IRQ_HANDLED
+#define COMPAT_IRQ_RETVAL(x)
+#else
+typedef irqreturn_t compat_irqreturn_t;
+#define COMPAT_IRQ_NONE		IRQ_NONE
+#define COMPAT_IRQ_HANDLED	IRQ_HANDLED
+#define COMPAT_IRQ_RETVAL(x)	IRQ_RETVAL(x)
+#endif
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 18)
+#define COMPAT_IRQF_DISABLED    SA_INTERRUPT
+#define COMPAT_IRQF_SHARED      SA_SHIRQ
+#else
+#define COMPAT_IRQF_DISABLED    IRQF_DISABLED
+#define COMPAT_IRQF_SHARED      IRQF_SHARED
+#endif
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 20)
+#define COMPAT_IRQ_HANDLER_ARGS(irq, devp) (int irq, void *devp, struct pt_regs *regs)
+#else
+#define COMPAT_IRQ_HANDLER_ARGS(irq, devp) (int irq, void *devp)
+#endif
+
+#endif /* __COMPAT_INTERRUPT_H__ */
--- kernel/linux-2.6.26.3/drivers/misc/vmci/compat_ioport.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmci/compat_ioport.h	2008-09-03 10:01:42.000000000 -0500
@@ -0,0 +1,63 @@
+/*********************************************************
+ * Copyright (C) 2003 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_IOPORT_H__
+#   define __COMPAT_IOPORT_H__
+
+
+#include <linux/ioport.h>
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 0)
+static inline void *
+compat_request_region(unsigned long start, unsigned long len, const char *name)
+{
+   if (check_region(start, len)) {
+      return NULL;
+   }
+   request_region(start, len, name);
+   return (void*)1;
+}
+#else
+#define compat_request_region(start, len, name) request_region(start, len, name)
+#endif
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 3, 7)
+/* mmap io support starts from 2.3.7, fail the call for kernel prior to that */
+static inline void *
+compat_request_mem_region(unsigned long start, unsigned long len, const char *name)
+{
+   return NULL;
+}
+
+static inline void
+compat_release_mem_region(unsigned long start, unsigned long len)
+{
+   return;
+}
+#else
+#define compat_request_mem_region(start, len, name) request_mem_region(start, len, name)
+#define compat_release_mem_region(start, len)       release_mem_region(start, len)
+#endif
+
+/* these two macro defs are needed by compat_pci_request_region */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 3, 15)
+#   define IORESOURCE_IO    0x00000100
+#   define IORESOURCE_MEM   0x00000200
+#endif
+
+#endif /* __COMPAT_IOPORT_H__ */
--- kernel/linux-2.6.26.3/drivers/misc/vmci/compat_kernel.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmci/compat_kernel.h	2008-09-03 10:01:42.000000000 -0500
@@ -0,0 +1,83 @@
+/*********************************************************
+ * Copyright (C) 2004 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_KERNEL_H__
+#   define __COMPAT_KERNEL_H__
+
+#include <asm/unistd.h>
+#include <linux/kernel.h>
+
+/*
+ * container_of was introduced in 2.5.28 but it's easier to check like this.
+ */
+#ifndef container_of
+#define container_of(ptr, type, member) ({			\
+        const typeof( ((type *)0)->member ) *__mptr = (ptr);	\
+        (type *)( (char *)__mptr - offsetof(type,member) );})
+#endif
+
+/*
+ * wait_for_completion and friends did not exist before 2.4.9.
+ */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 4, 9)
+
+#define compat_complete_and_exit(comp, status) complete_and_exit(comp, status)
+
+#else
+
+#include "compat_completion.h"
+
+/*
+ * Used by _syscallX macros. Note that this is global variable, so
+ * do not rely on its contents too much. As exit() is only function
+ * we use, and we never check return value from exit(), we have
+ * no problem...
+ */
+extern int errno;
+
+/*
+ * compat_exit() provides an access to the exit() function. It must 
+ * be named compat_exit(), as exit() (with different signature) is 
+ * provided by x86-64, arm and other (but not by i386).
+ */
+#define __NR_compat_exit __NR_exit
+static inline _syscall1(int, compat_exit, int, exit_code);
+
+/*
+ * See compat_wait_for_completion in compat_completion.h.
+ * compat_exit implicitly performs an unlock_kernel, in resident code,
+ * ensuring that the thread is no longer running in module code when the
+ * module is unloaded.
+ */
+#define compat_complete_and_exit(comp, status) do { \
+   lock_kernel(); \
+   compat_complete(comp); \
+   compat_exit(status); \
+} while (0)
+
+#endif
+
+/*
+ * vsnprintf became available in 2.4.10. For older kernels, just fall back on
+ * vsprintf.
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 10)
+#define vsnprintf(str, size, fmt, args) vsprintf(str, fmt, args)
+#endif
+
+#endif /* __COMPAT_KERNEL_H__ */
--- kernel/linux-2.6.26.3/drivers/misc/vmci/compat_list.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmci/compat_list.h	2008-09-03 10:01:42.000000000 -0500
@@ -0,0 +1,55 @@
+/*********************************************************
+ * Copyright (C) 2006 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_LIST_H__
+#   define __COMPAT_LIST_H__
+
+#include <linux/list.h>
+
+/*
+ * list_add_tail is with us since 2.4.0, or something like that.
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 0)
+#define list_add_tail(newe, head) do {  \
+   struct list_head *__h = (head);      \
+   __list_add((newe), __h->prev, __h);  \
+} while (0)
+#endif
+
+/*
+ * list_for_each_safe() showed up in 2.4.10, but it may be backported so we
+ * just check for its existence.
+ */
+#ifndef list_for_each_safe
+# define list_for_each_safe(pos, n, head) \
+         for (pos = (head)->next, n = pos->next; pos != (head); \
+                 pos = n, n = pos->next)
+#endif
+
+/*
+ * list_for_each_entry() showed up in 2.4.20, but it may be backported so we
+ * just check for its existence.
+ */
+#ifndef list_for_each_entry
+# define list_for_each_entry(pos, head, member) \
+         for (pos = list_entry((head)->next, typeof(*pos), member); \
+              &pos->member != (head); \
+              pos = list_entry(pos->member.next, typeof(*pos), member))
+#endif
+
+#endif /* __COMPAT_LIST_H__ */
--- kernel/linux-2.6.26.3/drivers/misc/vmci/compat_mm.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmci/compat_mm.h	2008-09-03 10:01:42.000000000 -0500
@@ -0,0 +1,134 @@
+/*********************************************************
+ * Copyright (C) 2002 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_MM_H__
+#   define __COMPAT_MM_H__
+
+
+#include <linux/mm.h>
+
+
+/* The get_page() API appeared in 2.3.7 --hpreg */
+/* Sometime during development it became function instead of macro --petr */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 0) && !defined(get_page) 
+#   define get_page(_page) atomic_inc(&(_page)->count)
+/* The __free_page() API is exported in 2.1.67 --hpreg */
+#   if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 1, 67)
+#      define put_page __free_page
+#   else
+#      include "compat_page.h"
+
+#      define page_to_phys(_page) (page_to_pfn(_page) << PAGE_SHIFT)
+#      define put_page(_page) free_page(page_to_phys(_page))
+#   endif
+#endif
+
+
+/* page_count() is 2.4.0 invention. Unfortunately unavailable in some RedHat 
+ * kernels (for example 2.4.21-4-RHEL3). */
+/* It is function since 2.6.0, and hopefully RedHat will not play silly games
+ * with mm_inline.h again... */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 0) && !defined(page_count)
+#  define page_count(page) atomic_read(&(page)->count)
+#endif
+
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 0)
+#  define compat_vm_pgoff(vma) ((vma)->vm_offset >> PAGE_SHIFT)
+
+static inline unsigned long compat_do_mmap_pgoff(struct file *file, unsigned long addr,
+   unsigned long len, unsigned long prot,
+   unsigned long flag, unsigned long pgoff)
+{
+   unsigned long ret = -EINVAL;
+
+   if (pgoff < 1 << (32 - PAGE_SHIFT)) {
+      ret = do_mmap(file, addr, len, prot, flag, pgoff << PAGE_SHIFT);
+   }
+   return ret;
+}
+
+#else
+#  define compat_vm_pgoff(vma) (vma)->vm_pgoff
+#  ifdef VMW_SKAS_MMAP
+#    define compat_do_mmap_pgoff(f, a, l, p, g, o) \
+				do_mmap_pgoff(current->mm, f, a, l, p, g, o)
+#  else
+#    define compat_do_mmap_pgoff(f, a, l, p, g, o) \
+				do_mmap_pgoff(f, a, l, p, g, o)
+#  endif
+#endif
+
+
+/* 2.2.x uses 0 instead of some define */
+#ifndef NOPAGE_SIGBUS
+#define NOPAGE_SIGBUS (0)
+#endif
+
+
+/* 2.2.x does not have HIGHMEM support */
+#ifndef GFP_HIGHUSER
+#define GFP_HIGHUSER (GFP_USER)
+#endif
+
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 0)
+
+#include "compat_page.h"
+
+static inline struct page * alloc_pages(unsigned int gfp_mask, unsigned int order)
+{
+   unsigned long addr;
+   
+   addr = __get_free_pages(gfp_mask, order);
+   if (!addr) {
+      return NULL;
+   }
+   return virt_to_page(addr);
+}
+#define alloc_page(gfp_mask) alloc_pages(gfp_mask, 0)
+
+#endif
+
+/*
+ * In 2.4.14, the logic behind the UnlockPage macro was moved to the 
+ * unlock_page() function. Later (in 2.5.12), the UnlockPage macro was removed
+ * altogether, and nowadays everyone uses unlock_page().
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 14)
+#define compat_unlock_page(page) UnlockPage(page)
+#else
+#define compat_unlock_page(page) unlock_page(page)
+#endif
+
+/*
+ * In 2.4.10, vmtruncate was changed from returning void to returning int.
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 10)
+#define compat_vmtruncate(inode, size)                                        \
+({                                                                            \
+   int result = 0;                                                            \
+   vmtruncate(inode, size);                                                   \
+   result;                                                                    \
+})
+#else
+#define compat_vmtruncate(inode, size) vmtruncate(inode, size)
+#endif
+
+
+#endif /* __COMPAT_MM_H__ */
--- kernel/linux-2.6.26.3/drivers/misc/vmci/compat_module.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmci/compat_module.h	2008-09-03 10:01:42.000000000 -0500
@@ -0,0 +1,72 @@
+/*********************************************************
+ * Copyright (C) 2007 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * compat_module.h --
+ */
+
+#ifndef __COMPAT_MODULE_H__
+#   define __COMPAT_MODULE_H__
+
+
+#include <linux/module.h>
+
+
+/*
+ * Modules wishing to use the GPL license are required to include a
+ * MODULE_LICENSE definition in their module source as of 2.4.10.
+ */
+#ifndef MODULE_LICENSE
+#define MODULE_LICENSE(license)
+#endif
+
+/*
+ * To make use of our own home-brewed MODULE_INFO, we need macros to
+ * concatenate two expressions to "__mod_", and and to convert an
+ * expression into a string. I'm sure we've got these in our codebase,
+ * but I'd rather not introduce such a dependency in a compat header.
+ */
+#ifndef __module_cat
+#define __module_cat_1(a, b) __mod_ ## a ## b
+#define __module_cat(a, b) __module_cat_1(a, b)
+#endif
+
+#ifndef __stringify
+#define __stringify_1(x) #x
+#define __stringify(x) __stringify_1(x)
+#endif
+
+/*
+ * MODULE_INFO was born in 2.5.69.
+ */
+#ifndef MODULE_INFO
+#define MODULE_INFO(tag, info)                                                \
+static const char __module_cat(tag, __LINE__)[]                               \
+  __attribute__((section(".modinfo"), unused)) = __stringify(tag) "=" info
+#endif
+
+/*
+ * MODULE_VERSION was born in 2.6.4. The earlier form appends a long "\0xxx"
+ * string to the module's version, but that was removed in 2.6.10, so we'll
+ * ignore it in our wrapper.
+ */
+#ifndef MODULE_VERSION
+#define MODULE_VERSION(_version) MODULE_INFO(version, _version)
+#endif
+
+#endif /* __COMPAT_MODULE_H__ */
--- kernel/linux-2.6.26.3/drivers/misc/vmci/compat_page.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmci/compat_page.h	2008-09-03 10:01:42.000000000 -0500
@@ -0,0 +1,75 @@
+/*********************************************************
+ * Copyright (C) 2002 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_PAGE_H__
+#   define __COMPAT_PAGE_H__
+
+
+#include <linux/mm.h>
+#include <asm/page.h>
+
+
+/* The pfn_to_page() API appeared in 2.5.14 and changed to function during 2.6.x */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 0) && !defined(pfn_to_page)
+#   define pfn_to_page(_pfn) (mem_map + (_pfn))
+#   define page_to_pfn(_page) ((_page) - mem_map)
+#endif
+
+
+/* The virt_to_page() API appeared in 2.4.0 --hpreg */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 0) && !defined(virt_to_page)
+#   define virt_to_page(_kvAddr) pfn_to_page(MAP_NR(_kvAddr))
+#endif
+
+
+/*
+ * The get_order() API appeared at some point in 2.3.x, and was then backported
+ * in 2.2.17-21mdk and in the stock 2.2.18. Because we can only detect its
+ * definition through makefile tricks, we provide our own for now --hpreg
+ */
+static inline int
+compat_get_order(unsigned long size) // IN
+{
+   int order;
+
+   size = (size - 1) >> (PAGE_SHIFT - 1);
+   order = -1;
+   do {
+      size >>= 1;
+      order++;
+   } while (size);
+
+   return order;
+}
+
+/* 
+ * BUG() was added to <asm/page.h> in 2.2.18, and was moved to <asm/bug.h>
+ * in 2.5.58.
+ * 
+ * XXX: Technically, this belongs in some sort of "compat_asm_page.h" file, but
+ * since our compatibility wrappers don't distinguish between <asm/xxx.h> and
+ * <linux/xxx.h>, putting it here is reasonable.
+ */
+#ifndef BUG
+#define BUG() do {                                                            \
+   printk("kernel BUG at %s:%d!\n", __FILE__, __LINE__);                      \
+  __asm__ __volatile__(".byte 0x0f,0x0b");                                    \
+} while (0)
+#endif
+
+#endif /* __COMPAT_PAGE_H__ */
--- kernel/linux-2.6.26.3/drivers/misc/vmci/compat_pci.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmci/compat_pci.h	2008-09-03 10:01:42.000000000 -0500
@@ -0,0 +1,590 @@
+/*********************************************************
+ * Copyright (C) 1999 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * compat_pci.h: PCI compatibility wrappers.
+ */
+
+#ifndef __COMPAT_PCI_H__
+#define __COMPAT_PCI_H__
+
+#include "compat_ioport.h"
+#include <linux/pci.h>
+#ifndef KERNEL_2_1
+#   include <linux/bios32.h>
+#endif
+
+
+/* 2.0.x has useless struct pci_dev; remap it to our own */
+#ifndef KERNEL_2_1
+#define pci_dev    vmw_pci_driver_instance
+#endif
+
+
+/* 2.0/2.2 does not have pci driver API */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 0)
+struct vmw_pci_driver_instance {
+   struct vmw_pci_driver_instance *next;
+   void                   *driver_data;
+   struct pci_driver      *pcidrv;
+#ifdef KERNEL_2_1
+   struct pci_dev         *pcidev;
+#else
+   unsigned char           bus;
+   unsigned char           devfn;
+   unsigned int            irq;
+#endif
+};
+#endif
+
+
+/* 2.0 has pcibios_* calls only...  We have to provide pci_* compatible wrappers. */
+#ifndef KERNEL_2_1
+static inline int
+pci_read_config_byte(struct pci_dev *pdev,  // IN: PCI slot
+                     unsigned char   where, // IN: Byte to read
+                     u8             *value) // OUT: Value read
+{
+   return pcibios_read_config_byte(pdev->bus, pdev->devfn, where, value);
+}
+
+static inline int
+pci_read_config_dword(struct pci_dev *pdev,  // IN: PCI slot
+                      unsigned char   where, // IN: Dword to read
+                      u32            *value) // OUT: Value read
+{
+   return pcibios_read_config_dword(pdev->bus, pdev->devfn, where, value);
+}
+
+static inline int
+pci_write_config_dword(struct pci_dev *pdev,  // IN: PCI slot
+                       unsigned char   where, // IN: Dword to write
+                       u32             value) // IN: Value to write
+{
+   return pcibios_write_config_dword(pdev->bus, pdev->devfn, where, value);
+}
+#endif
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * compat_pci_name --
+ *
+ *      Return human readable PCI slot name.  Note that some implementations
+ *      return a pointer to the static storage, so returned value may be
+ *      overwritten by subsequent calls to this function.
+ *
+ * Results:
+ *      Returns pointer to the string with slot name.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 4, 22)
+#define compat_pci_name(pdev) pci_name(pdev)
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(2, 4, 0)
+#define compat_pci_name(pdev) (pdev)->slot_name
+#elif defined(KERNEL_2_1)
+static inline const char*
+compat_pci_name(struct pci_dev* pdev)
+{
+   static char slot_name[12];
+   sprintf(slot_name, "%02X:%02X.%X", pdev->bus->number,
+           PCI_SLOT(pdev->devfn), PCI_FUNC(pdev->devfn));
+   return slot_name;
+}
+#else
+static inline const char*
+compat_pci_name(struct pci_dev* pdev)
+{
+   static char slot_name[12];
+   sprintf(slot_name, "%02X:%02X.%X", pdev->bus,
+           PCI_SLOT(pdev->devfn), PCI_FUNC(pdev->devfn));
+   return slot_name;
+}
+#endif
+
+
+/* pci_resource_start comes in 4 flavors - 2.0, 2.2, early 2.3, 2.4+ */
+#ifndef KERNEL_2_1
+static inline unsigned long
+compat_pci_resource_start(struct pci_dev *pdev,
+                          unsigned int    index)
+{
+   u32 addr;
+
+   if (pci_read_config_dword(pdev, PCI_BASE_ADDRESS_0 + index * 4, &addr)) {
+      printk(KERN_ERR "Unable to read base address %u from PCI slot %s!\n",
+             index, compat_pci_name(pdev));
+      return ~0UL;
+   }
+   if (addr & PCI_BASE_ADDRESS_SPACE) {
+      return addr & PCI_BASE_ADDRESS_IO_MASK;
+   } else {
+      return addr & PCI_BASE_ADDRESS_MEM_MASK;
+   }
+}
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(2, 3, 1)
+#   define compat_pci_resource_start(dev, index) \
+       (((dev)->base_address[index] & PCI_BASE_ADDRESS_SPACE) \
+          ? ((dev)->base_address[index] & PCI_BASE_ADDRESS_IO_MASK) \
+          : ((dev)->base_address[index] & PCI_BASE_ADDRESS_MEM_MASK))
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(2, 3, 43)
+#   define compat_pci_resource_start(dev, index) \
+       ((dev)->resource[index].start)
+#else
+#   define compat_pci_resource_start(dev, index) \
+       pci_resource_start(dev, index)
+#endif
+
+/* since 2.3.15, a new set of s/w res flags IORESOURCE_ is introduced,
+ * we fake them by returning either IORESOURCE_{IO, MEM} prior to 2.3.15 since
+ * this is what compat_pci_request_region uses
+ */
+#ifndef KERNEL_2_1
+static inline unsigned long
+compat_pci_resource_flags(struct pci_dev *pdev,
+                          unsigned int    index)
+{
+   u32 addr;
+
+   if (pci_read_config_dword(pdev, PCI_BASE_ADDRESS_0 + index * 4, &addr)) {
+      printk(KERN_ERR "Unable to read base address %u from PCI slot %s!\n",
+             index, compat_pci_name(pdev));
+      return ~0UL;
+   }
+   if (addr & PCI_BASE_ADDRESS_SPACE) {
+      return IORESOURCE_IO;
+   } else {
+      return IORESOURCE_MEM;
+   }
+}
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(2, 3, 1)
+#   define compat_pci_resource_flags(dev, index) \
+       (((dev)->base_address[index] & PCI_BASE_ADDRESS_SPACE) \
+          ? IORESOURCE_IO: IORESOURCE_MEM)
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(2, 3, 15)
+    /* IORESOURCE_xxx appeared in 2.3.15 and is set in resource[].flags */
+#   define compat_pci_resource_flags(dev, index) ((dev)->resource[index].flags)
+#else
+#   define compat_pci_resource_flags(dev, index) pci_resource_flags(dev, index)
+#endif
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 2, 18)
+static inline unsigned long
+compat_pci_resource_len(struct pci_dev *pdev,  // IN
+                        unsigned int    index) // IN
+{
+   u32 addr, mask;
+   unsigned char reg = PCI_BASE_ADDRESS_0 + index * 4;
+
+   if (pci_read_config_dword(pdev, reg, &addr) || addr == 0xFFFFFFFF) {
+      return 0;
+   }
+
+   pci_write_config_dword(pdev, reg, 0xFFFFFFFF);
+   pci_read_config_dword(pdev, reg, &mask);
+   pci_write_config_dword(pdev, reg, addr);
+
+   if (mask == 0 || mask == 0xFFFFFFFF) {
+      return 0;
+   }
+   if (addr & PCI_BASE_ADDRESS_SPACE) {
+      return 65536 - (mask & PCI_BASE_ADDRESS_IO_MASK & 0xFFFF);
+   } else {
+      return -(mask & PCI_BASE_ADDRESS_MEM_MASK);
+   }
+}
+#else
+#define compat_pci_resource_len(dev, index) pci_resource_len(dev, index)
+#endif
+
+/* pci_request_region appears in 2.4.20 */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 20)
+static inline int
+compat_pci_request_region(struct pci_dev *pdev, int bar, char *name)
+{
+   if (compat_pci_resource_len(pdev, bar) == 0) {
+      return 0;
+   }
+
+   if (compat_pci_resource_flags(pdev, bar) & IORESOURCE_IO) {
+      if (!compat_request_region(compat_pci_resource_start(pdev, bar),
+                                 compat_pci_resource_len(pdev, bar),
+                                 name)) {
+         return -EBUSY;
+      }
+   } else if (compat_pci_resource_flags(pdev, bar) & IORESOURCE_MEM) {
+      if (!compat_request_mem_region(compat_pci_resource_start(pdev, bar),
+                                     compat_pci_resource_len(pdev, bar),
+                                     name)) {
+         return -EBUSY;
+      }
+   }
+
+   return 0;
+}
+
+static inline void
+compat_pci_release_region(struct pci_dev *pdev, int bar)
+{
+   if (compat_pci_resource_len(pdev, bar) != 0) {
+      if (compat_pci_resource_flags(pdev, bar) & IORESOURCE_IO) {
+         release_region(compat_pci_resource_start(pdev, bar),
+                        compat_pci_resource_len(pdev, bar));
+      } else if (compat_pci_resource_flags(pdev, bar) & IORESOURCE_MEM) {
+         compat_release_mem_region(compat_pci_resource_start(pdev, bar),
+                                   compat_pci_resource_len(pdev, bar));
+      }
+   }
+}
+#else
+#define compat_pci_request_region(pdev, bar, name)  pci_request_region(pdev, bar, name)
+#define compat_pci_release_region(pdev, bar)        pci_release_region(pdev, bar)
+#endif
+
+/* pci_request_regions appeears in 2.4.3 */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 3)
+static inline int
+compat_pci_request_regions(struct pci_dev *pdev, char *name)
+{
+   int i;
+   
+   for (i = 0; i < 6; i++) {
+      if (compat_pci_request_region(pdev, i, name)) {
+         goto release;
+      }
+   }
+   return 0;
+
+release:
+   while (--i >= 0) {
+      compat_pci_release_region(pdev, i);
+   }
+   return -EBUSY;
+}
+static inline void
+compat_pci_release_regions(struct pci_dev *pdev)
+{
+   int i;
+   
+   for (i = 0; i < 6; i++) {
+      compat_pci_release_region(pdev, i);
+   }
+}
+#else
+#define compat_pci_request_regions(pdev, name) pci_request_regions(pdev, name)
+#define compat_pci_release_regions(pdev)       pci_release_regions(pdev)
+#endif
+
+/* pci_enable_device is available since 2.4.0 */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 0)
+#define compat_pci_enable_device(pdev) (0)
+#else
+#define compat_pci_enable_device(pdev) pci_enable_device(pdev)
+#endif
+
+
+/* pci_set_master is available since 2.2.0 */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 2, 0)
+#define compat_pci_set_master(pdev) (0)
+#else
+#define compat_pci_set_master(pdev) pci_set_master(pdev)
+#endif
+
+
+/* pci_disable_device is available since 2.4.4 */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 4)
+#define compat_pci_disable_device(pdev) do {} while (0)
+#else
+#define compat_pci_disable_device(pdev) pci_disable_device(pdev)
+#endif
+
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 0)
+/*
+ * Devices supported by particular pci driver.  While 2.4+ kernels
+ * can do match on subsystem and class too, we support match on
+ * vendor/device IDs only.
+ */
+struct pci_device_id {
+   unsigned int vendor, device;
+   unsigned long driver_data;
+};
+#define PCI_DEVICE(vend, dev)   .vendor = (vend), .device = (dev)
+
+/* PCI driver */
+struct pci_driver {
+   const char *name;
+   const struct pci_device_id *id_table;
+   int   (*probe)(struct pci_dev* dev, const struct pci_device_id* id);
+   void  (*remove)(struct pci_dev* dev);
+};
+
+
+/*
+ * Note that this is static variable.  Maybe everything below should be in
+ * separate compat_pci.c file, but currently only user of this file is vmxnet,
+ * and vmxnet has only one file, so it is fine.  Also with vmxnet all
+ * functions below are called just once, so difference between 'inline' and
+ * separate compat_pci.c should be very small.
+ */
+
+static struct vmw_pci_driver_instance *pci_driver_instances = NULL;
+
+#ifdef KERNEL_2_1
+#define vmw_pci_device(instance) (instance)->pcidev
+#else
+#define vmw_pci_device(instance) (instance)
+#endif
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * pci_register_driver --
+ *
+ *      Create driver instances for all matching PCI devices in the box.
+ *
+ * Results:
+ *      Returns 0 for success, negative error value for failure.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static inline int
+pci_register_driver(struct pci_driver *drv)
+{
+   const struct pci_device_id *chipID;
+
+   for (chipID = drv->id_table; chipID->vendor; chipID++) {
+#ifdef KERNEL_2_1
+      struct pci_dev *pdev;
+
+      for (pdev = NULL;
+           (pdev = pci_find_device(chipID->vendor, chipID->device, pdev)) != NULL; ) {
+#else
+      int adapter;
+      unsigned char bus, devfn, irq;
+
+      for (adapter = 0;
+           pcibios_find_device(chipID->vendor, chipID->device, adapter,
+                               &bus, &devfn) == 0;
+           adapter++) {
+#endif
+         struct vmw_pci_driver_instance *pdi;
+         int err;
+
+         pdi = kmalloc(sizeof *pdi, GFP_KERNEL);
+         if (!pdi) {
+            printk(KERN_ERR "Not enough memory.\n");
+            break;
+         }
+         pdi->pcidrv = drv;
+#ifdef KERNEL_2_1
+         pdi->pcidev = pdev;
+#else
+         pdi->bus = bus;
+         pdi->devfn = devfn;
+         if (pci_read_config_byte(pdi, PCI_INTERRUPT_LINE, &irq)) {
+            pdi->irq = -1;
+         } else {
+            pdi->irq = irq;
+         }
+#endif
+         pdi->driver_data = NULL;
+         pdi->next = pci_driver_instances;
+         pci_driver_instances = pdi;
+         err = drv->probe(vmw_pci_device(pdi), chipID);
+         if (err) {
+            pci_driver_instances = pdi->next;
+            kfree(pdi);
+         }
+      }
+   }
+   return 0;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * compat_pci_unregister_driver --
+ *
+ *      Shut down PCI driver - unbind all device instances from driver.
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static inline void
+pci_unregister_driver(struct pci_driver *drv)
+{
+   struct vmw_pci_driver_instance **ppdi;
+
+   ppdi = &pci_driver_instances;
+   while (1) {
+      struct vmw_pci_driver_instance *pdi = *ppdi;
+
+      if (!pdi) {
+         break;
+      }
+      if (pdi->pcidrv == drv) {
+         drv->remove(vmw_pci_device(pdi));
+         *ppdi = pdi->next;
+         kfree(pdi);
+      } else {
+         ppdi = &pdi->next;
+      }
+   }
+}
+#else
+/* provide PCI_DEVICE for early 2.4.x kernels */
+#ifndef PCI_DEVICE
+#define PCI_DEVICE(vend, dev)   .vendor = (vend), .device = (dev), \
+                                .subvendor = PCI_ANY_ID, .subdevice = PCI_ANY_ID
+#endif
+#endif
+
+
+/* provide dummy MODULE_DEVICE_TABLE for 2.0/2.2 */
+#ifndef MODULE_DEVICE_TABLE
+#define MODULE_DEVICE_TABLE(bus, devices)
+#endif
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * pci_set_drvdata --
+ *
+ *      Set per-device driver's private data.
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * pci_get_drvdata --
+ *
+ *      Retrieve per-device driver's private data.
+ *
+ * Results:
+ *      per-device driver's data previously set by pci_set_drvdata,
+ *      or NULL on failure.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+#ifndef KERNEL_2_1
+/* 2.0.x is simple, we have driver_data directly in pci_dev */
+#define pci_set_drvdata(pdev, data) do { (pdev)->driver_data = (data); } while (0)
+#define pci_get_drvdata(pdev)       (pdev)->driver_data
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 0)
+/* 2.2.x is trickier, we have to find driver instance first */
+static inline void
+pci_set_drvdata(struct pci_dev *pdev, void* data)
+{
+   struct vmw_pci_driver_instance *pdi;
+
+   for (pdi = pci_driver_instances; pdi; pdi = pdi->next) {
+      if (pdi->pcidev == pdev) {
+         pdi->driver_data = data;
+         return;
+      }
+   }
+   printk(KERN_ERR "pci_set_drvdata issued for unknown device %p\n", pdev);
+}
+
+static inline void *
+pci_get_drvdata(struct pci_dev *pdev)
+{
+   struct vmw_pci_driver_instance *pdi;
+
+   for (pdi = pci_driver_instances; pdi; pdi = pdi->next) {
+      if (pdi->pcidev == pdev) {
+         return pdi->driver_data;
+      }
+   }
+   printk(KERN_ERR "pci_get_drvdata issued for unknown device %p\n", pdev);
+   return NULL;
+}
+#endif
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,3,48)
+#   define PCI_DMA_BIDIRECTIONAL        0
+#   define PCI_DMA_TODEVICE             1
+#   define PCI_DMA_FROMDEVICE           2
+#   define PCI_DMA_NONE                 3
+#endif
+
+/*
+ * Power Management related compat wrappers.
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 10)
+#   define compat_pci_save_state(pdev)      pci_save_state((pdev), NULL)
+#   define compat_pci_restore_state(pdev)   pci_restore_state((pdev), NULL)
+#else
+#   define compat_pci_save_state(pdev)      pci_save_state((pdev))
+#   define compat_pci_restore_state(pdev)   pci_restore_state((pdev))
+#endif
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 11)
+#   define pm_message_t          u32
+#   define compat_pci_choose_state(pdev, state)  (state)
+#   define PCI_D0               0
+#   define PCI_D3hot            3
+#else
+#   define compat_pci_choose_state(pdev, state)  pci_choose_state((pdev), (state))
+#endif
+
+/* 2.6.14 changed the PCI shutdown callback */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,14)
+#   define COMPAT_PCI_SHUTDOWN(func)               .driver = { .shutdown = (func), }
+#   define COMPAT_PCI_DECLARE_SHUTDOWN(func, var)  (func)(struct device *(var))
+#   define COMPAT_PCI_TO_DEV(dev)                  (to_pci_dev(dev))
+#else
+#   define COMPAT_PCI_SHUTDOWN(func)               .shutdown = (func)
+#   define COMPAT_PCI_DECLARE_SHUTDOWN(func, var)  (func)(struct pci_dev *(var))
+#   define COMPAT_PCI_TO_DEV(dev)                  (dev)
+#endif
+
+
+#endif /* __COMPAT_PCI_H__ */
--- kernel/linux-2.6.26.3/drivers/misc/vmci/compat_pgtable.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmci/compat_pgtable.h	2008-09-03 10:01:42.000000000 -0500
@@ -0,0 +1,139 @@
+/*********************************************************
+ * Copyright (C) 2002 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_PGTABLE_H__
+#   define __COMPAT_PGTABLE_H__
+
+
+#if defined(CONFIG_PARAVIRT) && defined(CONFIG_HIGHPTE)
+#   if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 21)
+#      include <asm/paravirt.h>
+#      undef paravirt_map_pt_hook
+#      define paravirt_map_pt_hook(type, va, pfn) do {} while (0)
+#   endif
+#endif
+#include <asm/pgtable.h>
+
+
+/* pte_page() API modified in 2.3.23 to return a struct page * --hpreg */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 3, 23)
+#   define compat_pte_page pte_page
+#else
+#   include "compat_page.h"
+
+#   define compat_pte_page(_pte) virt_to_page(pte_page(_pte))
+#endif
+
+
+/* Appeared in 2.5.5 --hpreg */
+#ifndef pte_offset_map
+/*  Appeared in SuSE 8.0's 2.4.18 --hpreg */
+#   ifdef pte_offset_atomic
+#      define pte_offset_map pte_offset_atomic
+#      define pte_unmap pte_kunmap
+#   else
+#      define pte_offset_map pte_offset
+#      define pte_unmap(_pte)
+#   endif
+#endif
+
+
+/* Appeared in 2.5.74-mmX --petr */
+#ifndef pmd_offset_map
+#   define pmd_offset_map(pgd, address) pmd_offset(pgd, address)
+#   define pmd_unmap(pmd)
+#endif
+
+
+/*
+ * Appeared in 2.6.10-rc2-mm1.  Older kernels did L4 page tables as 
+ * part of pgd_offset, or they did not have L4 page tables at all.
+ * In 2.6.11 pml4 -> pgd -> pmd -> pte hierarchy was replaced by
+ * pgd -> pud -> pmd -> pte hierarchy.
+ */
+#ifdef PUD_MASK
+#   define compat_pgd_offset(mm, address)   pgd_offset(mm, address)
+#   define compat_pgd_present(pgd)          pgd_present(pgd)
+#   define compat_pud_offset(pgd, address)  pud_offset(pgd, address)
+#   define compat_pud_present(pud)          pud_present(pud)
+typedef pgd_t  compat_pgd_t;
+typedef pud_t  compat_pud_t;
+#elif defined(pml4_offset)
+#   define compat_pgd_offset(mm, address)   pml4_offset(mm, address)
+#   define compat_pgd_present(pml4)         pml4_present(pml4)
+#   define compat_pud_offset(pml4, address) pml4_pgd_offset(pml4, address)
+#   define compat_pud_present(pgd)          pgd_present(pgd)
+typedef pml4_t compat_pgd_t;
+typedef pgd_t  compat_pud_t;
+#else
+#   define compat_pgd_offset(mm, address)   pgd_offset(mm, address)
+#   define compat_pgd_present(pgd)          pgd_present(pgd)
+#   define compat_pud_offset(pgd, address)  (pgd)
+#   define compat_pud_present(pud)          (1)
+typedef pgd_t  compat_pgd_t;
+typedef pgd_t  compat_pud_t;
+#endif
+
+
+#define compat_pgd_offset_k(mm, address) pgd_offset_k(address)
+
+
+/* Introduced somewhere in 2.6.0, + backported to some 2.4 RedHat kernels */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 0) && !defined(pte_pfn)
+#   define pte_pfn(pte) page_to_pfn(compat_pte_page(pte))
+#endif
+
+
+/* A page_table_lock field is added to struct mm_struct in 2.3.10 --hpreg */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 3, 10)
+#   define compat_get_page_table_lock(_mm) (&(_mm)->page_table_lock)
+#else
+#   define compat_get_page_table_lock(_mm) NULL
+#endif
+
+
+/*
+ * Define VM_PAGE_KERNEL_EXEC for vmapping executable pages.
+ *
+ * On ia32 PAGE_KERNEL_EXEC was introduced in 2.6.8.1.  Unfortunately it accesses
+ * __PAGE_KERNEL_EXEC which is not exported for modules.  So we use
+ * __PAGE_KERNEL and just cut _PAGE_NX bit from it.
+ *
+ * For ia32 kernels before 2.6.8.1 we use PAGE_KERNEL directly, these kernels
+ * do not have noexec support.
+ *
+ * On x86-64 situation is a bit better: they always supported noexec, but
+ * before 2.6.8.1 flag was named PAGE_KERNEL_EXECUTABLE, and it was renamed
+ * to PAGE_KERNEL_EXEC when ia32 got noexec too (see above).
+ */
+#ifdef CONFIG_X86
+#ifdef _PAGE_NX
+#define VM_PAGE_KERNEL_EXEC __pgprot(__PAGE_KERNEL & ~_PAGE_NX)
+#else
+#define VM_PAGE_KERNEL_EXEC PAGE_KERNEL
+#endif
+#else
+#ifdef PAGE_KERNEL_EXECUTABLE
+#define VM_PAGE_KERNEL_EXEC PAGE_KERNEL_EXECUTABLE
+#else
+#define VM_PAGE_KERNEL_EXEC PAGE_KERNEL_EXEC
+#endif
+#endif
+
+
+#endif /* __COMPAT_PGTABLE_H__ */
--- kernel/linux-2.6.26.3/drivers/misc/vmci/compat_sched.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmci/compat_sched.h	2008-09-03 10:01:42.000000000 -0500
@@ -0,0 +1,291 @@
+/*********************************************************
+ * Copyright (C) 2002 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_SCHED_H__
+#   define __COMPAT_SCHED_H__
+
+
+#include <linux/sched.h>
+
+/* CLONE_KERNEL available in 2.5.35 and higher. */
+#ifndef CLONE_KERNEL
+#define CLONE_KERNEL CLONE_FILES | CLONE_FS | CLONE_SIGHAND
+#endif
+
+/* TASK_COMM_LEN become available in 2.6.11. */
+#ifndef TASK_COMM_LEN
+#define TASK_COMM_LEN 16
+#endif
+
+/* The capable() API appeared in 2.1.92 --hpreg */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 1, 92)
+#   define capable(_capability) suser()
+#endif
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 2, 0)
+#   define need_resched() need_resched
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 3)
+#   define need_resched() (current->need_resched)
+#endif
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 3)
+#   define cond_resched() (need_resched() ? schedule() : (void) 0)
+#endif
+
+/* Oh well.  We need yield...  Happy us! */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 20)
+#   ifdef __x86_64__
+#      define compat_yield() there_is_nothing_like_yield()
+#   else
+#      include <linux/unistd.h>
+#      include <linux/kernel.h>
+
+/*
+ * Used by _syscallX macros. Note that this is global variable, so
+ * do not rely on its contents too much. As exit() is only function
+ * we use, and we never check return value from exit(), we have
+ * no problem...
+ */
+extern int errno;
+
+/*
+ * compat_exit() provides an access to the exit() function. It must 
+ * be named compat_exit(), as exit() (with different signature) is 
+ * provided by x86-64, arm and other (but not by i386).
+ */
+#      define __NR_compat_yield __NR_sched_yield
+static inline _syscall0(int, compat_yield);
+#   endif
+#else
+#   define compat_yield() yield()
+#endif
+
+
+/*
+ * Since 2.5.34 there are two methods to enumerate tasks:
+ * for_each_process(p) { ... } which enumerates only tasks and
+ * do_each_thread(g,t) { ... } while_each_thread(g,t) which enumerates
+ *     also threads even if they share same pid.
+ */
+#ifndef for_each_process
+#   define for_each_process(p) for_each_task(p)
+#endif
+
+#ifndef do_each_thread
+#   define do_each_thread(g, t) for_each_task(g) { t = g; do
+#   define while_each_thread(g, t) while (0) }
+#endif
+
+
+/*
+ * Lock for signal mask is moving target...
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 40) && defined(CLONE_PID)
+/* 2.4.x without NPTL patches or early 2.5.x */
+#define compat_sigmask_lock sigmask_lock
+#define compat_dequeue_signal_current(siginfo_ptr) \
+   dequeue_signal(&current->blocked, (siginfo_ptr))
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 60) && !defined(INIT_SIGHAND)
+/* RedHat's 2.4.x with first version of NPTL support, or 2.5.40 to 2.5.59 */
+#define compat_sigmask_lock sig->siglock
+#define compat_dequeue_signal_current(siginfo_ptr) \
+   dequeue_signal(&current->blocked, (siginfo_ptr))
+#else
+/* RedHat's 2.4.x with second version of NPTL support, or 2.5.60+. */
+#define compat_sigmask_lock sighand->siglock
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 0)
+#define compat_dequeue_signal_current(siginfo_ptr) \
+   dequeue_signal(&current->blocked, (siginfo_ptr))
+#else
+#define compat_dequeue_signal_current(siginfo_ptr) \
+   dequeue_signal(current, &current->blocked, (siginfo_ptr))
+#endif
+#endif
+
+/*
+ * recalc_sigpending() had task argument in the past
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 29) && defined(CLONE_PID)
+/* 2.4.x without NPTL patches or early 2.5.x */
+#define compat_recalc_sigpending() recalc_sigpending(current)
+#else
+/* RedHat's 2.4.x with NPTL support, or 2.5.29+ */
+#define compat_recalc_sigpending() recalc_sigpending()
+#endif
+
+
+/*
+ * reparent_to_init() was introduced in 2.4.8.  In 2.5.38 (or possibly
+ * earlier, but later than 2.5.31) a call to it was added into
+ * daemonize(), so compat_daemonize no longer needs to call it.
+ *
+ * In 2.4.x kernels reparent_to_init() forgets to do correct refcounting
+ * on current->user. It is better to count one too many than one too few...
+ */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 4, 8) && LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 38)
+#define compat_reparent_to_init() do { \
+					reparent_to_init(); \
+					atomic_inc(&current->user->__count); \
+				  } while (0)
+#else
+#define compat_reparent_to_init() do {} while (0)
+#endif
+
+
+/*
+ * daemonize appeared in 2.2.18. Except 2.2.17-4-RH7.0, which has it too.
+ * Fortunately 2.2.17-4-RH7.0 uses versioned symbols, so we can check
+ * its existence with defined().
+ */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2, 2, 18)) && !defined(daemonize)
+static inline void daemonize(void) {
+   struct fs_struct *fs;
+
+   exit_mm(current);
+   current->session = 1;
+   current->pgrp = 1;
+   exit_fs(current);
+   fs = init_task.fs;
+   current->fs = fs;
+   atomic_inc(&fs->count);
+}
+#endif
+
+
+/*
+ * flush_signals acquires sighand->siglock since 2.5.61... Verify RH's kernels!
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 61)
+#define compat_flush_signals(task) do { \
+				      spin_lock_irq(&task->compat_sigmask_lock); \
+				      flush_signals(task); \
+				      spin_unlock_irq(&task->compat_sigmask_lock); \
+				   } while (0)
+#else
+#define compat_flush_signals(task) flush_signals(task)
+#endif
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 61)
+#define compat_allow_signal(signr) do { \
+                                      spin_lock_irq(&current->compat_sigmask_lock); \
+                                      sigdelset(&current->blocked, signr); \
+                                      compat_recalc_sigpending(); \
+                                      spin_unlock_irq(&current->compat_sigmask_lock); \
+                                   } while (0)
+#else
+#define compat_allow_signal(signr) allow_signal(signr)
+#endif
+
+/*
+ * daemonize can set process name since 2.5.61. Prior to 2.5.61, daemonize
+ * didn't block signals on our behalf.
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 61)
+#define compat_daemonize(x...)                                                \
+({                                                                            \
+   /* Beware! No snprintf here, so verify arguments! */                       \
+   sprintf(current->comm, x);                                                 \
+                                                                              \
+   /* Block all signals. */                                                   \
+   spin_lock_irq(&current->compat_sigmask_lock);                              \
+   sigfillset(&current->blocked);                                             \
+   compat_recalc_sigpending();                                                \
+   spin_unlock_irq(&current->compat_sigmask_lock);                            \
+   compat_flush_signals(current);                                             \
+                                                                              \
+   daemonize();                                                               \
+   compat_reparent_to_init();                                                 \
+})
+#else
+#define compat_daemonize(x...) daemonize(x)
+#endif
+
+
+/*
+ * set priority for specified thread. Exists on 2.6.x kernels and some
+ * 2.4.x vendor's kernels.
+ */
+#if defined(VMW_HAVE_SET_USER_NICE)
+#define compat_set_user_nice(task, n) set_user_nice((task), (n))
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 0)
+#define compat_set_user_nice(task, n) do { (task)->priority = 20 - (n); } while (0)
+#elif !defined(VMW_HAVE_SET_USER_NICE)
+#define compat_set_user_nice(task, n) do { (task)->nice = (n); } while (0)
+#endif
+
+/*
+ * try to freeze a process. For kernels 2.6.11 or newer, we know how to choose
+ * the interface. The problem is that the oldest interface, introduced in
+ * 2.5.18, was backported to 2.4.x kernels. So if we're older than 2.6.11,
+ * we'll decide what to do based on whether or not swsusp was configured
+ * for the kernel.  For kernels 2.6.20 and newer, we'll also need to include
+ * freezer.h since the try_to_freeze definition was pulled out of sched.h.
+ */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 20)
+#include <linux/freezer.h>
+#endif
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 13) || defined(VMW_TL10S64_WORKAROUND)
+#define compat_try_to_freeze() try_to_freeze()
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 11)
+#define compat_try_to_freeze() try_to_freeze(PF_FREEZE)
+#elif defined(CONFIG_SOFTWARE_SUSPEND) || defined(CONFIG_SOFTWARE_SUSPEND2)
+#include "compat_mm.h"
+#include <linux/errno.h>
+#include <linux/suspend.h>
+static inline int compat_try_to_freeze(void)  { 
+   if (current->flags & PF_FREEZE) {
+      refrigerator(PF_FREEZE); 
+      return 1;
+   } else {
+      return 0;
+   }
+}
+#else
+static inline int compat_try_to_freeze(void) { return 0; }
+#endif
+
+/*
+ * As of 2.6.23-rc1, kernel threads are no longer freezable by
+ * default. Instead, kernel threads that need to be frozen must opt-in
+ * by calling set_freezable() as soon as the thread is created.
+ */
+
+#if LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 22)
+#define compat_set_freezable() do { set_freezable(); } while (0)
+#else
+#define compat_set_freezable() do {} while (0)
+#endif
+
+/*
+ * Since 2.6.27-rc2 kill_proc() is gone... Replacement (GPL-only!)
+ * API is available since 2.6.19.  Use them from 2.6.27-rc1 up.
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 27)
+typedef int compat_pid;
+#define compat_find_get_pid(pid) (pid)
+#define compat_put_pid(pid) do { } while (0)
+#define compat_kill_pid(pid, sig, flag) kill_proc(pid, sig, flag)
+#else
+typedef struct pid * compat_pid;
+#define compat_find_get_pid(pid) find_get_pid(pid)
+#define compat_put_pid(pid) put_pid(pid)
+#define compat_kill_pid(pid, sig, flag) kill_pid(pid, sig, flag)
+#endif
+
+
+#endif /* __COMPAT_SCHED_H__ */
--- kernel/linux-2.6.26.3/drivers/misc/vmci/compat_semaphore.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmci/compat_semaphore.h	2008-09-03 10:01:42.000000000 -0500
@@ -0,0 +1,49 @@
+/*********************************************************
+ * Copyright (C) 2002 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_SEMAPHORE_H__
+#   define __COMPAT_SEMAPHORE_H__
+
+
+/* <= 2.6.25 have asm only, 2.6.26 has both, and 2.6.27-rc2+ has linux only. */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 27)
+#   include <asm/semaphore.h>
+#else
+#   include <linux/semaphore.h>
+#endif
+
+
+/*
+* The init_MUTEX_LOCKED() API appeared in 2.2.18, and is also in
+* 2.2.17-21mdk --hpreg
+*/
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 2, 18)
+   #ifndef init_MUTEX_LOCKED
+      #define init_MUTEX_LOCKED(_sem) *(_sem) = MUTEX_LOCKED
+   #endif
+   #ifndef DECLARE_MUTEX
+      #define DECLARE_MUTEX(name) struct semaphore name = MUTEX
+   #endif
+   #ifndef DECLARE_MUTEX_LOCKED
+      #define DECLARE_MUTEX_LOCKED(name) struct semaphore name = MUTEX_LOCKED
+   #endif
+#endif
+
+
+#endif /* __COMPAT_SEMAPHORE_H__ */
--- kernel/linux-2.6.26.3/drivers/misc/vmci/compat_slab.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmci/compat_slab.h	2008-09-03 10:01:42.000000000 -0500
@@ -0,0 +1,85 @@
+/*********************************************************
+ * Copyright (C) 2005 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_SLAB_H__
+#   define __COMPAT_SLAB_H__
+
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 2, 0)
+#   include <linux/slab.h>
+#else
+#   include <linux/malloc.h>
+#endif
+
+/*
+ * Before 2.6.20, kmem_cache_t was the accepted way to refer to a kmem_cache
+ * structure.  Prior to 2.6.15, this structure was called kmem_cache_s, and
+ * afterwards it was renamed to kmem_cache.  Here we keep things simple and use
+ * the accepted typedef until it became deprecated, at which point we switch
+ * over to the kmem_cache name.
+ */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 20)
+#   define compat_kmem_cache struct kmem_cache
+#else
+#   define compat_kmem_cache kmem_cache_t
+#endif
+
+/*
+ * Up to 2.6.22 kmem_cache_create has 6 arguments - name, size, alignment, flags,
+ * constructor, and destructor.  Then for some time kernel was asserting that
+ * destructor is NULL, and since 2.6.23-pre1 kmem_cache_create takes only 5
+ * arguments - destructor is gone.
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 22) || defined(VMW_KMEMCR_HAS_DTOR)
+#define compat_kmem_cache_create(name, size, align, flags, ctor) \
+		kmem_cache_create(name, size, align, flags, ctor, NULL)
+#else
+#define compat_kmem_cache_create(name, size, align, flags, ctor) \
+		kmem_cache_create(name, size, align, flags, ctor)
+#endif
+
+/*
+ * Up to 2.6.23 kmem_cache constructor has three arguments - pointer to block to
+ * prepare (aka "this"), from which cache it came, and some unused flags.  After
+ * 2.6.23 flags were removed, and order of "this" and cache parameters was swapped...
+ * Since 2.6.27-rc2 everything is different again, and ctor has only one argument.
+ *
+ * HAS_3_ARGS has precedence over HAS_2_ARGS if both are defined.
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 23) && !defined(VMW_KMEMCR_CTOR_HAS_3_ARGS)
+#  define VMW_KMEMCR_CTOR_HAS_3_ARGS
+#endif
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 26) && !defined(VMW_KMEMCR_CTOR_HAS_2_ARGS)
+#  define VMW_KMEMCR_CTOR_HAS_2_ARGS
+#endif
+
+#if defined(VMW_KMEMCR_CTOR_HAS_3_ARGS)
+typedef void compat_kmem_cache_ctor(void *, compat_kmem_cache *, unsigned long);
+#define COMPAT_KMEM_CACHE_CTOR_ARGS(arg) void *arg, \
+                                         compat_kmem_cache *cache, \
+                                         unsigned long flags
+#elif defined(VMW_KMEMCR_CTOR_HAS_2_ARGS)
+typedef void compat_kmem_cache_ctor(compat_kmem_cache *, void *);
+#define COMPAT_KMEM_CACHE_CTOR_ARGS(arg) compat_kmem_cache *cache, \
+                                         void *arg
+#else
+typedef void compat_kmem_cache_ctor(void *);
+#define COMPAT_KMEM_CACHE_CTOR_ARGS(arg) void *arg
+#endif
+
+#endif /* __COMPAT_SLAB_H__ */
--- kernel/linux-2.6.26.3/drivers/misc/vmci/compat_spinlock.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmci/compat_spinlock.h	2008-09-03 10:01:42.000000000 -0500
@@ -0,0 +1,68 @@
+/*********************************************************
+ * Copyright (C) 2005 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_SPINLOCK_H__
+#   define __COMPAT_SPINLOCK_H__
+
+
+/*
+ * The spin_lock() API appeared in 2.1.25 in asm/smp_lock.h
+ * It moved in 2.1.30 to asm/spinlock.h
+ * It moved again in 2.3.18 to linux/spinlock.h
+ *
+ *   --hpreg
+ */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 3, 18)
+#   include <linux/spinlock.h>
+#else
+#   if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 1, 30)
+#      include <asm/spinlock.h>
+#   else
+typedef struct {} spinlock_t;
+#      define spin_lock_init(lock)
+#      define spin_lock(lock)
+#      define spin_unlock(lock)
+#      define spin_lock_irqsave(lock, flags) do {      \
+                    save_flags(flags);                 \
+                    cli();                             \
+                    spin_lock(lock);                   \
+                 } while (0)
+#      define spin_unlock_irqrestore(lock, flags) do { \
+                    spin_unlock(lock);                 \
+                    restore_flags(flags);              \
+                 } while (0)
+#   endif
+#endif
+
+
+/*
+ * Preempt support was added during 2.5.x development cycle, and later
+ * it was backported to 2.4.x.  In 2.4.x backport these definitions
+ * live in linux/spinlock.h, that's why we put them here (in 2.6.x they
+ * are defined in linux/preempt.h which is included by linux/spinlock.h).
+ */
+#ifdef CONFIG_PREEMPT
+#define compat_preempt_disable() preempt_disable()
+#define compat_preempt_enable()  preempt_enable()
+#else
+#define compat_preempt_disable() do { } while (0)
+#define compat_preempt_enable()  do { } while (0)
+#endif
+
+
+#endif /* __COMPAT_SPINLOCK_H__ */
--- kernel/linux-2.6.26.3/drivers/misc/vmci/compat_uaccess.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmci/compat_uaccess.h	2008-09-03 10:01:42.000000000 -0500
@@ -0,0 +1,79 @@
+/*********************************************************
+ * Copyright (C) 2002 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_UACCESS_H__
+#   define __COMPAT_UACCESS_H__
+
+
+/* User space access functions moved in 2.1.7 to asm/uaccess.h --hpreg */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 1, 7)
+#   include <asm/uaccess.h>
+#else
+#   include <asm/segment.h>
+#endif
+
+
+/* get_user() API modified in 2.1.4 to take 2 arguments --hpreg */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 1, 4)
+#   define compat_get_user get_user
+#else
+/*
+ * We assign 0 to the variable in case of failure to prevent "`_var' might be
+ * used uninitialized in this function" compiler warnings. I think it is OK,
+ * because the hardware-based version in newer kernels probably has the same
+ * semantics and does not guarantee that the value of _var will not be
+ * modified, should the access fail --hpreg
+ */
+#   define compat_get_user(_var, _uvAddr) ({                        \
+   int _status;                                                     \
+                                                                    \
+   _status = verify_area(VERIFY_READ, _uvAddr, sizeof(*(_uvAddr))); \
+   if (_status == 0) {                                              \
+      (_var) = get_user(_uvAddr);                                   \
+   } else {                                                         \
+      (_var) = 0;                                                   \
+   }                                                                \
+   _status;                                                         \
+})
+#endif
+
+
+/*
+ * The copy_from_user() API appeared in 2.1.4
+ *
+ * The emulation is not perfect here, but it is conservative: on failure, we
+ * always return the total size, instead of the potentially smaller faulty
+ * size --hpreg
+ *
+ * Since 2.5.55 copy_from_user() is no longer macro.
+ */
+#if !defined(copy_from_user) && LINUX_VERSION_CODE < KERNEL_VERSION(2, 2, 0)
+#   define copy_from_user(_to, _from, _size) ( \
+   verify_area(VERIFY_READ, _from, _size)      \
+       ? (_size)                               \
+       : (memcpy_fromfs(_to, _from, _size), 0) \
+)
+#   define copy_to_user(_to, _from, _size) ( \
+   verify_area(VERIFY_WRITE, _to, _size)     \
+       ? (_size)                             \
+       : (memcpy_tofs(_to, _from, _size), 0) \
+)
+#endif
+
+
+#endif /* __COMPAT_UACCESS_H__ */
--- kernel/linux-2.6.26.3/drivers/misc/vmci/compat_version.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmci/compat_version.h	2008-09-03 10:01:42.000000000 -0500
@@ -0,0 +1,121 @@
+/*********************************************************
+ * Copyright (C) 1998 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_VERSION_H__
+#   define __COMPAT_VERSION_H__
+
+#define INCLUDE_ALLOW_VMMON
+#define INCLUDE_ALLOW_MODULE
+#define INCLUDE_ALLOW_VMCORE
+#define INCLUDE_ALLOW_VMNIXMOD
+#define INCLUDE_ALLOW_DISTRIBUTE
+#include "includeCheck.h"
+
+
+#ifndef __linux__
+#   error "linux-version.h"
+#endif
+
+
+#include <linux/version.h>
+
+/* Appeared in 2.1.90 --hpreg */
+#ifndef KERNEL_VERSION
+#   define KERNEL_VERSION(a, b, c) (((a) << 16) + ((b) << 8) + (c))
+#endif
+
+
+/*
+ * Distinguish relevant classes of Linux kernels.
+ *
+ * The convention is that version X defines all
+ * the KERNEL_Y symbols where Y <= X.
+ *
+ * XXX Do not add more definitions here. This way of doing things does not
+ *     scale, and we are going to phase it out soon --hpreg
+ */
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 1, 0)
+#   define KERNEL_2_1
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 2, 0)
+#   define KERNEL_2_2
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 3, 1)
+#   define KERNEL_2_3_1
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 3, 15)
+/*   new networking */
+#   define KERNEL_2_3_15
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 3, 25)
+/*  new procfs */
+#   define KERNEL_2_3_25
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 3, 29)
+/*  even newer procfs */
+#   define KERNEL_2_3_29
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 3, 43)
+/*  softnet changes */
+#   define KERNEL_2_3_43
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 3, 47)
+/*  more softnet changes */
+#   define KERNEL_2_3_47
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 3, 99)
+/*  name in netdevice struct is array and not pointer */
+#   define KERNEL_2_3_99
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 4, 0)
+/*  New 'owner' member at the beginning of struct file_operations */
+#      define KERNEL_2_4_0
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 4, 8)
+/*  New netif_rx_ni() --hpreg */
+#   define KERNEL_2_4_8
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 4, 22)
+/*  New vmap() */
+#   define KERNEL_2_4_22
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 5, 2)
+/*  New kdev_t, major()/minor() API --hpreg */
+#   define KERNEL_2_5_2
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 5, 5)
+/*  New sk_alloc(), pte_offset_map()/pte_unmap() --hpreg */
+#   define KERNEL_2_5_5
+#endif
+
+
+#endif /* __COMPAT_VERSION_H__ */
--- kernel/linux-2.6.26.3/drivers/misc/vmci/compat_wait.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmci/compat_wait.h	2008-09-03 10:01:42.000000000 -0500
@@ -0,0 +1,225 @@
+/*********************************************************
+ * Copyright (C) 2002 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_WAIT_H__
+#   define __COMPAT_WAIT_H__
+
+
+#include <linux/wait.h>
+#include <linux/poll.h>
+#include <linux/file.h>
+
+#include "compat_file.h"
+
+
+/*
+ * The DECLARE_WAITQUEUE() API appeared in 2.3.1
+ * It was back ported in 2.2.18
+ *
+ *  --hpreg
+ */
+
+#ifndef DECLARE_WAITQUEUE
+
+typedef struct wait_queue *wait_queue_head_t;
+#   define init_waitqueue_head(_headPtr) *(_headPtr) = NULL
+#   define DECLARE_WAITQUEUE(_var, _task) \
+   struct wait_queue _var = {_task, NULL, }
+
+typedef struct wait_queue wait_queue_t;
+#   define init_waitqueue_entry(_wait, _task) ((_wait)->task = (_task))
+
+#endif
+
+/*
+ * The 'struct poll_wqueues' appeared in 2.5.48, when global
+ * /dev/epoll interface was added.  It was backported to the
+ * 2.4.20-wolk4.0s.
+ */
+
+#ifdef VMW_HAVE_EPOLL // {
+#define compat_poll_wqueues struct poll_wqueues
+#else // } {
+#define compat_poll_wqueues poll_table
+#endif // }
+
+#ifdef VMW_HAVE_EPOLL // {
+
+/* If prototype does not match, build will abort here */
+extern void poll_initwait(compat_poll_wqueues *);
+
+#define compat_poll_initwait(wait, table) ( \
+   poll_initwait((table)), \
+   (wait) = &(table)->pt \
+)
+
+#define compat_poll_freewait(wait, table) ( \
+   poll_freewait((table)) \
+)
+
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(2, 4, 0) // {
+
+/* If prototype does not match, build will abort here */
+extern void poll_initwait(compat_poll_wqueues *);
+
+#define compat_poll_initwait(wait, table) ( \
+   (wait) = (table), \
+   poll_initwait(wait) \
+)
+
+#define compat_poll_freewait(wait, table) ( \
+   poll_freewait((table)) \
+)
+
+#else // } {
+
+#define compat_poll_initwait(wait, table) ( \
+   (wait) = (table), /* confuse compiler */ \
+   (wait) = (poll_table *) __get_free_page(GFP_KERNEL), \
+   (wait)->nr = 0, \
+   (wait)->entry = (struct poll_table_entry *)((wait) + 1), \
+   (wait)->next = NULL \
+)
+
+static inline void
+poll_freewait(poll_table *wait)
+{
+   while (wait) {
+      struct poll_table_entry * entry;
+      poll_table *old;
+
+      entry = wait->entry + wait->nr;
+      while (wait->nr > 0) {
+	 wait->nr--;
+	 entry--;
+	 remove_wait_queue(entry->wait_address, &entry->wait);
+	 compat_fput(entry->filp);
+      }
+      old = wait;
+      wait = wait->next;
+      free_page((unsigned long) old);
+   }
+}
+
+#define compat_poll_freewait(wait, table) ( \
+   poll_freewait((wait)) \
+)
+
+#endif // }
+
+/*
+ * The wait_event_interruptible_timeout() interface is not
+ * defined in pre-2.6 kernels.
+ */
+#ifndef wait_event_interruptible_timeout
+#define __wait_event_interruptible_timeout(wq, condition, ret)		\
+do {									\
+   wait_queue_t __wait;						        \
+   init_waitqueue_entry(&__wait, current);				\
+									\
+   add_wait_queue(&wq, &__wait);					\
+   for (;;) {							        \
+      set_current_state(TASK_INTERRUPTIBLE);			        \
+      if (condition)						        \
+	 break;						                \
+      if (!signal_pending(current)) {				        \
+	 ret = schedule_timeout(ret);			                \
+	 if (!ret)					                \
+	    break;					                \
+	 continue;					                \
+      }							                \
+      ret = -ERESTARTSYS;					        \
+      break;							        \
+   }								        \
+   set_current_state(TASK_RUNNING);				        \
+   remove_wait_queue(&wq, &__wait);				        \
+} while (0)
+
+#define wait_event_interruptible_timeout(wq, condition, timeout)	\
+({									\
+   long __ret = timeout;						\
+   if (!(condition))						        \
+      __wait_event_interruptible_timeout(wq, condition, __ret);         \
+   __ret;								\
+})
+#endif
+
+/*
+ * The wait_event_timeout() interface is not
+ * defined in pre-2.6 kernels.
+ */
+#ifndef wait_event_timeout
+#define __wait_event_timeout(wq, condition, ret)        		\
+do {									\
+   wait_queue_t __wait;						        \
+   init_waitqueue_entry(&__wait, current);				\
+									\
+   add_wait_queue(&wq, &__wait);					\
+   for (;;) {							        \
+      set_current_state(TASK_UNINTERRUPTIBLE);        	                \
+      if (condition)						        \
+         break;						                \
+      ret = schedule_timeout(ret);			                \
+      if (!ret)					                        \
+         break;					                        \
+   }								        \
+   set_current_state(TASK_RUNNING);				        \
+   remove_wait_queue(&wq, &__wait);				        \
+} while (0)
+
+#define wait_event_timeout(wq, condition, timeout)	                \
+({									\
+   long __ret = timeout;						\
+   if (!(condition))						        \
+      __wait_event_timeout(wq, condition, __ret);                       \
+   __ret;								\
+})
+#endif
+
+/*
+ * DEFINE_WAIT() and friends were added in 2.5.39 and backported to 2.4.28.
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 28) || \
+   (LINUX_VERSION_CODE >= KERNEL_VERSION(2, 5, 0) && \
+    LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 39))
+# define COMPAT_DEFINE_WAIT(_wait)                              \
+   DECLARE_WAITQUEUE(_wait, current)
+# define compat_init_prepare_to_wait(_sleep, _wait, _state)     \
+   do {                                                         \
+      __set_current_state(_state);                              \
+      add_wait_queue(_sleep, _wait);                            \
+   } while (0)
+# define compat_cont_prepare_to_wait(_sleep, _wait, _state)     \
+   set_current_state(_state)
+# define compat_finish_wait(_sleep, _wait, _state)              \
+   do {                                                         \
+      __set_current_state(_state);                              \
+      remove_wait_queue(_sleep, _wait);                         \
+   } while (0)
+#else
+# define COMPAT_DEFINE_WAIT(_wait)                              \
+   DEFINE_WAIT(_wait)
+# define compat_init_prepare_to_wait(_sleep, _wait, _state)     \
+   prepare_to_wait(_sleep, _wait, _state)
+# define compat_cont_prepare_to_wait(_sleep, _wait, _state)     \
+   prepare_to_wait(_sleep, _wait, _state)
+# define compat_finish_wait(_sleep, _wait, _state)              \
+   finish_wait(_sleep, _wait)
+#endif
+
+#endif /* __COMPAT_WAIT_H__ */
--- kernel/linux-2.6.26.3/drivers/misc/vmci/COPYING	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmci/COPYING	2008-09-03 09:57:34.000000000 -0500
@@ -0,0 +1,339 @@
+		    GNU GENERAL PUBLIC LICENSE
+		       Version 2, June 1991
+
+ Copyright (C) 1989, 1991 Free Software Foundation, Inc.,
+ 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ Everyone is permitted to copy and distribute verbatim copies
+ of this license document, but changing it is not allowed.
+
+			    Preamble
+
+  The licenses for most software are designed to take away your
+freedom to share and change it.  By contrast, the GNU General Public
+License is intended to guarantee your freedom to share and change free
+software--to make sure the software is free for all its users.  This
+General Public License applies to most of the Free Software
+Foundation's software and to any other program whose authors commit to
+using it.  (Some other Free Software Foundation software is covered by
+the GNU Lesser General Public License instead.)  You can apply it to
+your programs, too.
+
+  When we speak of free software, we are referring to freedom, not
+price.  Our General Public Licenses are designed to make sure that you
+have the freedom to distribute copies of free software (and charge for
+this service if you wish), that you receive source code or can get it
+if you want it, that you can change the software or use pieces of it
+in new free programs; and that you know you can do these things.
+
+  To protect your rights, we need to make restrictions that forbid
+anyone to deny you these rights or to ask you to surrender the rights.
+These restrictions translate to certain responsibilities for you if you
+distribute copies of the software, or if you modify it.
+
+  For example, if you distribute copies of such a program, whether
+gratis or for a fee, you must give the recipients all the rights that
+you have.  You must make sure that they, too, receive or can get the
+source code.  And you must show them these terms so they know their
+rights.
+
+  We protect your rights with two steps: (1) copyright the software, and
+(2) offer you this license which gives you legal permission to copy,
+distribute and/or modify the software.
+
+  Also, for each author's protection and ours, we want to make certain
+that everyone understands that there is no warranty for this free
+software.  If the software is modified by someone else and passed on, we
+want its recipients to know that what they have is not the original, so
+that any problems introduced by others will not reflect on the original
+authors' reputations.
+
+  Finally, any free program is threatened constantly by software
+patents.  We wish to avoid the danger that redistributors of a free
+program will individually obtain patent licenses, in effect making the
+program proprietary.  To prevent this, we have made it clear that any
+patent must be licensed for everyone's free use or not licensed at all.
+
+  The precise terms and conditions for copying, distribution and
+modification follow.
+
+		    GNU GENERAL PUBLIC LICENSE
+   TERMS AND CONDITIONS FOR COPYING, DISTRIBUTION AND MODIFICATION
+
+  0. This License applies to any program or other work which contains
+a notice placed by the copyright holder saying it may be distributed
+under the terms of this General Public License.  The "Program", below,
+refers to any such program or work, and a "work based on the Program"
+means either the Program or any derivative work under copyright law:
+that is to say, a work containing the Program or a portion of it,
+either verbatim or with modifications and/or translated into another
+language.  (Hereinafter, translation is included without limitation in
+the term "modification".)  Each licensee is addressed as "you".
+
+Activities other than copying, distribution and modification are not
+covered by this License; they are outside its scope.  The act of
+running the Program is not restricted, and the output from the Program
+is covered only if its contents constitute a work based on the
+Program (independent of having been made by running the Program).
+Whether that is true depends on what the Program does.
+
+  1. You may copy and distribute verbatim copies of the Program's
+source code as you receive it, in any medium, provided that you
+conspicuously and appropriately publish on each copy an appropriate
+copyright notice and disclaimer of warranty; keep intact all the
+notices that refer to this License and to the absence of any warranty;
+and give any other recipients of the Program a copy of this License
+along with the Program.
+
+You may charge a fee for the physical act of transferring a copy, and
+you may at your option offer warranty protection in exchange for a fee.
+
+  2. You may modify your copy or copies of the Program or any portion
+of it, thus forming a work based on the Program, and copy and
+distribute such modifications or work under the terms of Section 1
+above, provided that you also meet all of these conditions:
+
+    a) You must cause the modified files to carry prominent notices
+    stating that you changed the files and the date of any change.
+
+    b) You must cause any work that you distribute or publish, that in
+    whole or in part contains or is derived from the Program or any
+    part thereof, to be licensed as a whole at no charge to all third
+    parties under the terms of this License.
+
+    c) If the modified program normally reads commands interactively
+    when run, you must cause it, when started running for such
+    interactive use in the most ordinary way, to print or display an
+    announcement including an appropriate copyright notice and a
+    notice that there is no warranty (or else, saying that you provide
+    a warranty) and that users may redistribute the program under
+    these conditions, and telling the user how to view a copy of this
+    License.  (Exception: if the Program itself is interactive but
+    does not normally print such an announcement, your work based on
+    the Program is not required to print an announcement.)
+
+These requirements apply to the modified work as a whole.  If
+identifiable sections of that work are not derived from the Program,
+and can be reasonably considered independent and separate works in
+themselves, then this License, and its terms, do not apply to those
+sections when you distribute them as separate works.  But when you
+distribute the same sections as part of a whole which is a work based
+on the Program, the distribution of the whole must be on the terms of
+this License, whose permissions for other licensees extend to the
+entire whole, and thus to each and every part regardless of who wrote it.
+
+Thus, it is not the intent of this section to claim rights or contest
+your rights to work written entirely by you; rather, the intent is to
+exercise the right to control the distribution of derivative or
+collective works based on the Program.
+
+In addition, mere aggregation of another work not based on the Program
+with the Program (or with a work based on the Program) on a volume of
+a storage or distribution medium does not bring the other work under
+the scope of this License.
+
+  3. You may copy and distribute the Program (or a work based on it,
+under Section 2) in object code or executable form under the terms of
+Sections 1 and 2 above provided that you also do one of the following:
+
+    a) Accompany it with the complete corresponding machine-readable
+    source code, which must be distributed under the terms of Sections
+    1 and 2 above on a medium customarily used for software interchange; or,
+
+    b) Accompany it with a written offer, valid for at least three
+    years, to give any third party, for a charge no more than your
+    cost of physically performing source distribution, a complete
+    machine-readable copy of the corresponding source code, to be
+    distributed under the terms of Sections 1 and 2 above on a medium
+    customarily used for software interchange; or,
+
+    c) Accompany it with the information you received as to the offer
+    to distribute corresponding source code.  (This alternative is
+    allowed only for noncommercial distribution and only if you
+    received the program in object code or executable form with such
+    an offer, in accord with Subsection b above.)
+
+The source code for a work means the preferred form of the work for
+making modifications to it.  For an executable work, complete source
+code means all the source code for all modules it contains, plus any
+associated interface definition files, plus the scripts used to
+control compilation and installation of the executable.  However, as a
+special exception, the source code distributed need not include
+anything that is normally distributed (in either source or binary
+form) with the major components (compiler, kernel, and so on) of the
+operating system on which the executable runs, unless that component
+itself accompanies the executable.
+
+If distribution of executable or object code is made by offering
+access to copy from a designated place, then offering equivalent
+access to copy the source code from the same place counts as
+distribution of the source code, even though third parties are not
+compelled to copy the source along with the object code.
+
+  4. You may not copy, modify, sublicense, or distribute the Program
+except as expressly provided under this License.  Any attempt
+otherwise to copy, modify, sublicense or distribute the Program is
+void, and will automatically terminate your rights under this License.
+However, parties who have received copies, or rights, from you under
+this License will not have their licenses terminated so long as such
+parties remain in full compliance.
+
+  5. You are not required to accept this License, since you have not
+signed it.  However, nothing else grants you permission to modify or
+distribute the Program or its derivative works.  These actions are
+prohibited by law if you do not accept this License.  Therefore, by
+modifying or distributing the Program (or any work based on the
+Program), you indicate your acceptance of this License to do so, and
+all its terms and conditions for copying, distributing or modifying
+the Program or works based on it.
+
+  6. Each time you redistribute the Program (or any work based on the
+Program), the recipient automatically receives a license from the
+original licensor to copy, distribute or modify the Program subject to
+these terms and conditions.  You may not impose any further
+restrictions on the recipients' exercise of the rights granted herein.
+You are not responsible for enforcing compliance by third parties to
+this License.
+
+  7. If, as a consequence of a court judgment or allegation of patent
+infringement or for any other reason (not limited to patent issues),
+conditions are imposed on you (whether by court order, agreement or
+otherwise) that contradict the conditions of this License, they do not
+excuse you from the conditions of this License.  If you cannot
+distribute so as to satisfy simultaneously your obligations under this
+License and any other pertinent obligations, then as a consequence you
+may not distribute the Program at all.  For example, if a patent
+license would not permit royalty-free redistribution of the Program by
+all those who receive copies directly or indirectly through you, then
+the only way you could satisfy both it and this License would be to
+refrain entirely from distribution of the Program.
+
+If any portion of this section is held invalid or unenforceable under
+any particular circumstance, the balance of the section is intended to
+apply and the section as a whole is intended to apply in other
+circumstances.
+
+It is not the purpose of this section to induce you to infringe any
+patents or other property right claims or to contest validity of any
+such claims; this section has the sole purpose of protecting the
+integrity of the free software distribution system, which is
+implemented by public license practices.  Many people have made
+generous contributions to the wide range of software distributed
+through that system in reliance on consistent application of that
+system; it is up to the author/donor to decide if he or she is willing
+to distribute software through any other system and a licensee cannot
+impose that choice.
+
+This section is intended to make thoroughly clear what is believed to
+be a consequence of the rest of this License.
+
+  8. If the distribution and/or use of the Program is restricted in
+certain countries either by patents or by copyrighted interfaces, the
+original copyright holder who places the Program under this License
+may add an explicit geographical distribution limitation excluding
+those countries, so that distribution is permitted only in or among
+countries not thus excluded.  In such case, this License incorporates
+the limitation as if written in the body of this License.
+
+  9. The Free Software Foundation may publish revised and/or new versions
+of the General Public License from time to time.  Such new versions will
+be similar in spirit to the present version, but may differ in detail to
+address new problems or concerns.
+
+Each version is given a distinguishing version number.  If the Program
+specifies a version number of this License which applies to it and "any
+later version", you have the option of following the terms and conditions
+either of that version or of any later version published by the Free
+Software Foundation.  If the Program does not specify a version number of
+this License, you may choose any version ever published by the Free Software
+Foundation.
+
+  10. If you wish to incorporate parts of the Program into other free
+programs whose distribution conditions are different, write to the author
+to ask for permission.  For software which is copyrighted by the Free
+Software Foundation, write to the Free Software Foundation; we sometimes
+make exceptions for this.  Our decision will be guided by the two goals
+of preserving the free status of all derivatives of our free software and
+of promoting the sharing and reuse of software generally.
+
+			    NO WARRANTY
+
+  11. BECAUSE THE PROGRAM IS LICENSED FREE OF CHARGE, THERE IS NO WARRANTY
+FOR THE PROGRAM, TO THE EXTENT PERMITTED BY APPLICABLE LAW.  EXCEPT WHEN
+OTHERWISE STATED IN WRITING THE COPYRIGHT HOLDERS AND/OR OTHER PARTIES
+PROVIDE THE PROGRAM "AS IS" WITHOUT WARRANTY OF ANY KIND, EITHER EXPRESSED
+OR IMPLIED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
+MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE.  THE ENTIRE RISK AS
+TO THE QUALITY AND PERFORMANCE OF THE PROGRAM IS WITH YOU.  SHOULD THE
+PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF ALL NECESSARY SERVICING,
+REPAIR OR CORRECTION.
+
+  12. IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING
+WILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MAY MODIFY AND/OR
+REDISTRIBUTE THE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES,
+INCLUDING ANY GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING
+OUT OF THE USE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED
+TO LOSS OF DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY
+YOU OR THIRD PARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER
+PROGRAMS), EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE
+POSSIBILITY OF SUCH DAMAGES.
+
+		     END OF TERMS AND CONDITIONS
+
+	    How to Apply These Terms to Your New Programs
+
+  If you develop a new program, and you want it to be of the greatest
+possible use to the public, the best way to achieve this is to make it
+free software which everyone can redistribute and change under these terms.
+
+  To do so, attach the following notices to the program.  It is safest
+to attach them to the start of each source file to most effectively
+convey the exclusion of warranty; and each file should have at least
+the "copyright" line and a pointer to where the full notice is found.
+
+    <one line to give the program's name and a brief idea of what it does.>
+    Copyright (C) <year>  <name of author>
+
+    This program is free software; you can redistribute it and/or modify
+    it under the terms of the GNU General Public License as published by
+    the Free Software Foundation; either version 2 of the License, or
+    (at your option) any later version.
+
+    This program is distributed in the hope that it will be useful,
+    but WITHOUT ANY WARRANTY; without even the implied warranty of
+    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+    GNU General Public License for more details.
+
+    You should have received a copy of the GNU General Public License along
+    with this program; if not, write to the Free Software Foundation, Inc.,
+    51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA.
+
+Also add information on how to contact you by electronic and paper mail.
+
+If the program is interactive, make it output a short notice like this
+when it starts in an interactive mode:
+
+    Gnomovision version 69, Copyright (C) year name of author
+    Gnomovision comes with ABSOLUTELY NO WARRANTY; for details type `show w'.
+    This is free software, and you are welcome to redistribute it
+    under certain conditions; type `show c' for details.
+
+The hypothetical commands `show w' and `show c' should show the appropriate
+parts of the General Public License.  Of course, the commands you use may
+be called something other than `show w' and `show c'; they could even be
+mouse-clicks or menu items--whatever suits your program.
+
+You should also get your employer (if you work as a programmer) or your
+school, if any, to sign a "copyright disclaimer" for the program, if
+necessary.  Here is a sample; alter the names:
+
+  Yoyodyne, Inc., hereby disclaims all copyright interest in the program
+  `Gnomovision' (which makes passes at compilers) written by James Hacker.
+
+  <signature of Ty Coon>, 1 April 1989
+  Ty Coon, President of Vice
+
+This General Public License does not permit incorporating your program into
+proprietary programs.  If your program is a subroutine library, you may
+consider it more useful to permit linking proprietary applications with the
+library.  If this is what you want to do, use the GNU Lesser General
+Public License instead of this License.
--- kernel/linux-2.6.26.3/drivers/misc/vmci/driver-config.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmci/driver-config.h	2008-09-03 10:01:42.000000000 -0500
@@ -0,0 +1,78 @@
+/*********************************************************
+ * Copyright (C) 1998 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * Sets the proper defines from the Linux header files
+ *
+ * This file must be included before the inclusion of any kernel header file,
+ * with the exception of linux/autoconf.h and linux/version.h --hpreg
+ */
+
+#ifndef __VMX_CONFIG_H__
+#define __VMX_CONFIG_H__
+
+#define INCLUDE_ALLOW_VMCORE
+#define INCLUDE_ALLOW_VMMON
+#define INCLUDE_ALLOW_MODULE
+#define INCLUDE_ALLOW_VMNIXMOD
+#include "includeCheck.h"
+
+#include <linux/autoconf.h>
+#include "compat_version.h"
+
+/*
+ * We rely on Kernel Module support.  Check here.
+ */
+#ifndef CONFIG_MODULES
+#   error "No Module support in this kernel.  Please configure with CONFIG_MODULES"
+#endif
+
+/*
+ * 2.2 kernels still use __SMP__ (derived from CONFIG_SMP
+ * in the main Makefile), so we do it here.
+ */
+
+#ifdef CONFIG_SMP
+#   define __SMP__ 1
+#endif
+
+#if defined(CONFIG_MODVERSIONS) && defined(KERNEL_2_1)
+#   if LINUX_VERSION_CODE < KERNEL_VERSION(2,5,60)
+/*
+ * MODVERSIONS might be already defined when using kernel's Makefiles.
+ */
+#      ifndef MODVERSIONS
+#         define MODVERSIONS
+#      endif
+#      include <linux/modversions.h>
+#   endif
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 24)
+/*
+ * Force the uintptr_t definition to come from linux/types.h instead of vm_basic_types.h.
+ */
+#   include <linux/types.h>
+#   define _STDINT_H 1
+#endif
+
+#ifndef __KERNEL__
+#   define __KERNEL__
+#endif
+
+#endif
--- kernel/linux-2.6.26.3/drivers/misc/vmci/includeCheck.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmci/includeCheck.h	2008-09-03 10:01:42.000000000 -0500
@@ -0,0 +1,132 @@
+/*********************************************************
+ * Copyright (C) 1998 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * includeCheck.h --
+ *
+ *	Restrict include file use.
+ *
+ * In every .h file, define one or more of these
+ *
+ *	INCLUDE_ALLOW_VMX 
+ *	INCLUDE_ALLOW_USERLEVEL 
+ *	INCLUDE_ALLOW_VMMEXT
+ *	INCLUDE_ALLOW_VMCORE
+ *	INCLUDE_ALLOW_MODULE
+ *      INCLUDE_ALLOW_VMNIXMOD 
+ *	INCLUDE_ALLOW_VMKERNEL 
+ *	INCLUDE_ALLOW_DISTRIBUTE
+ *	INCLUDE_ALLOW_VMK_MODULE
+ *      INCLUDE_ALLOW_VMKDRIVERS
+ *      INCLUDE_ALLOW_VMIROM
+ *
+ * Then include this file.
+ *
+ * Any file that has INCLUDE_ALLOW_DISTRIBUTE defined will potentially
+ * be distributed in source form along with GPLed code.  Ensure
+ * that this is acceptable.
+ */
+
+
+/*
+ * Declare a VMCORE-only variable to help classify object
+ * files.  The variable goes in the common block and does
+ * not create multiple definition link-time conflicts.
+ */
+
+#if defined VMCORE && defined VMX86_DEVEL && defined VMX86_DEBUG && \
+    defined linux && !defined MODULE && \
+    !defined COMPILED_WITH_VMCORE
+#define COMPILED_WITH_VMCORE compiled_with_vmcore
+#ifdef ASM
+        .comm   compiled_with_vmcore, 0
+#else
+        asm(".comm compiled_with_vmcore, 0");
+#endif /* ASM */
+#endif
+
+
+#if defined VMCORE && \
+    !(defined VMX86_VMX || defined VMM || \
+      defined MONITOR_APP || defined VMMON)
+#error "Makefile problem: VMCORE without VMX86_VMX or \
+        VMM or MONITOR_APP or MODULE."
+#endif
+
+#if defined VMCORE && !defined INCLUDE_ALLOW_VMCORE
+#error "The surrounding include file is not allowed in vmcore."
+#endif
+#undef INCLUDE_ALLOW_VMCORE
+
+#if defined VMX86_VMX && !defined VMCORE && \
+    !(defined INCLUDE_ALLOW_VMX || defined INCLUDE_ALLOW_USERLEVEL)
+#error "The surrounding include file is not allowed in the VMX."
+#endif
+#undef INCLUDE_ALLOW_VMX
+
+#if defined USERLEVEL && !defined VMX86_VMX && !defined VMCORE && \
+    !defined INCLUDE_ALLOW_USERLEVEL
+#error "The surrounding include file is not allowed at userlevel."
+#endif
+#undef INCLUDE_ALLOW_USERLEVEL
+
+#if defined VMM && !defined VMCORE && \
+    !defined INCLUDE_ALLOW_VMMEXT
+#error "The surrounding include file is not allowed in the monitor."
+#endif
+#undef INCLUDE_ALLOW_VMMEXT
+
+#if defined MODULE && !defined VMKERNEL_MODULE && !defined VMNIXMOD && \
+    !defined VMMON && !defined INCLUDE_ALLOW_MODULE
+#error "The surrounding include file is not allowed in driver modules."
+#endif
+#undef INCLUDE_ALLOW_MODULE
+
+#if defined VMMON && !defined INCLUDE_ALLOW_VMMON
+#error "The surrounding include file is not allowed in vmmon."
+#endif
+#undef INCLUDE_ALLOW_VMMON
+
+#if defined VMKERNEL && !defined INCLUDE_ALLOW_VMKERNEL
+#error "The surrounding include file is not allowed in the vmkernel."
+#endif
+#undef INCLUDE_ALLOW_VMKERNEL
+
+#if defined GPLED_CODE && !defined INCLUDE_ALLOW_DISTRIBUTE
+#error "The surrounding include file is not allowed in GPL code."
+#endif
+#undef INCLUDE_ALLOW_DISTRIBUTE
+
+#if defined VMKERNEL_MODULE && !defined VMKERNEL && \
+    !defined INCLUDE_ALLOW_VMK_MODULE && !defined INCLUDE_ALLOW_VMKDRIVERS
+#error "The surrounding include file is not allowed in vmkernel modules."
+#endif
+#undef INCLUDE_ALLOW_VMK_MODULE
+#undef INCLUDE_ALLOW_VMKDRIVERS
+
+#if defined VMNIXMOD && !defined INCLUDE_ALLOW_VMNIXMOD
+#ifndef VMNIXMOD_VM
+#error "The surrounding include file is not allowed in vmnixmod."
+#endif
+#endif
+#undef INCLUDE_ALLOW_VMNIXMOD
+
+#if defined VMIROM && ! defined INCLUDE_ALLOW_VMIROM
+#error "The surrounding include file is not allowed in vmirom."
+#endif
+#undef INCLUDE_ALLOW_VMIROM
--- kernel/linux-2.6.26.3/drivers/misc/vmci/kernelStubs.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmci/kernelStubs.h	2008-09-03 10:01:42.000000000 -0500
@@ -0,0 +1,146 @@
+/*********************************************************
+ * Copyright (C) 2006 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * kernelStubs.h
+ *
+ * KernelStubs implements some userspace library functions in terms
+ * of kernel functions to allow library userspace code to be used in a
+ * kernel.
+ */
+
+#ifndef __KERNELSTUBS_H__
+#define __KERNELSTUBS_H__
+
+#ifdef linux
+#   ifndef __KERNEL__
+#      error "__KERNEL__ is not defined"
+#   endif
+#   include "driver-config.h" // Must be included before any other header files
+#   include "vm_basic_types.h"
+#   include <linux/kernel.h>
+#   include <linux/string.h>
+#elif defined(_WIN32)
+#   include "vm_basic_types.h"
+#   include <ntddk.h>   /* kernel memory APIs */
+#   include <stdio.h>   /* for _vsnprintf, vsprintf */
+#   include <stdarg.h>  /* for va_start stuff */
+#   include <stdlib.h>  /* for min macro. */
+#   include "vm_assert.h"  /* Our assert macros */
+#elif defined(__FreeBSD__)
+#   include "vm_basic_types.h"
+#   ifndef _KERNEL
+#      error "_KERNEL is not defined"
+#   endif
+#   include <sys/types.h>
+#   include <sys/malloc.h>
+#   include <sys/param.h>
+#   include <sys/kernel.h>
+#   include <machine/stdarg.h>
+#   include <sys/libkern.h>
+#   include "vm_assert.h"
+#elif defined(__APPLE__)
+#   include "vm_basic_types.h"
+#   ifndef KERNEL
+#      error "KERNEL is not defined"
+#   endif
+#   include <stdarg.h>
+#   include <string.h>
+#endif
+
+/*
+ * Function Prototypes
+ */
+
+#if defined(linux) || defined(__APPLE__)     /* if (linux) || (__APPLE__) { */
+
+#  ifdef linux                               /* if (linux) { */
+char *strdup(const char *source);
+#  endif
+
+/* Shared between Linux and Apple kernel stubs. */
+void *malloc(size_t size);
+void free(void *mem);
+void *calloc(size_t num, size_t len);
+void *realloc(void *ptr, size_t newSize);
+
+#elif defined(_WIN32)                           /* } else if (_WIN32) { */
+
+#if (_WIN32_WINNT == 0x0400)
+/* The following declarations are missing on NT4. */
+typedef unsigned int UINT_PTR;
+typedef unsigned int SIZE_T;
+
+/* No free with tag availaible on NT4 kernel! */
+#define KRNL_STUBS_FREE(P,T)     ExFreePool((P))
+
+#else /* _WIN32_WINNT */
+#define KRNL_STUBS_FREE(P,T)     ExFreePoolWithTag((P),(T))
+/* Win 2K and later useful kernel function, documented but not declared! */
+NTKERNELAPI VOID ExFreePoolWithTag(IN PVOID  P, IN ULONG  Tag);
+#endif /* _WIN32_WINNT */
+
+#elif defined(__FreeBSD__)                      /* } else if (FreeBSD) { */
+
+/* Kernel memory on FreeBSD is tagged for statistics and sanity checking. */
+MALLOC_DECLARE(M_VMWARE_TEMP);
+
+/*
+ * On FreeBSD, the general memory allocator for both userland and the kernel is named
+ * malloc, but the kernel malloc() takes more arguments.  The following alias & macros
+ * work around this, to provide the standard malloc() API for userspace code that is
+ * being used in the kernel.
+ */
+
+#   undef malloc
+
+static INLINE void *
+__compat_malloc(unsigned long size, struct malloc_type *type, int flags) {
+   return malloc(size, type, flags);
+}
+
+#   define malloc(size)         __compat_malloc(size, M_VMWARE_TEMP, M_NOWAIT)
+#   define calloc(count, size)  __compat_malloc((count) * (size),       \
+                                                M_VMWARE_TEMP, M_NOWAIT|M_ZERO)
+#   define realloc(buf, size)   realloc(buf, size, M_VMWARE_TEMP, M_NOWAIT)
+#   define free(buf)            free(buf, M_VMWARE_TEMP)
+#   define strchr(s,c)          index(s,c)
+#   define strrchr(s,c)         rindex(s,c)
+
+#endif                                          /* } */
+
+/*
+ * Stub functions we provide.
+ */
+
+void Panic(const char *fmt, ...);
+
+char *Str_Strcpy(char *buf, const char *src, size_t maxSize);
+int Str_Vsnprintf(char *str, size_t size, const char *format,
+                  va_list arguments);
+char *Str_Vasprintf(size_t *length, const char *format,
+                    va_list arguments);
+char *Str_Asprintf(size_t *length, const char *Format, ...);
+
+/*
+ * Functions the driver must implement for the stubs.
+ */
+EXTERN void Debug(const char *fmt, ...);
+
+
+#endif /* __KERNELSTUBS_H__ */
--- kernel/linux-2.6.26.3/drivers/misc/vmci/kernelStubsLinux.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmci/kernelStubsLinux.c	2008-09-03 10:01:42.000000000 -0500
@@ -0,0 +1,426 @@
+/*********************************************************
+ * Copyright (C) 2006 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * kernelStubsLinux.c
+ *
+ * This file contains implementations of common userspace functions in terms
+ * that the Linux kernel can understand.
+ */
+
+/* Must come before any kernel header file */
+#include "driver-config.h"
+#include "kernelStubs.h"
+#include "compat_kernel.h"
+#include "compat_page.h"
+#include "compat_sched.h"
+#include <linux/slab.h>
+
+#include "vm_assert.h"
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Panic --
+ *
+ *    Prints the debug message and stops the system.
+ *
+ * Results:
+ *    None.
+ *
+ * Side effects:
+ *    None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+void
+Panic(const char *fmt, ...) // IN
+{
+   va_list args;
+   char *result;
+
+   va_start(args, fmt);
+   result = Str_Vasprintf(NULL, fmt, args);
+   va_end(args);
+
+   if (result) {
+      printk(KERN_EMERG "%s", result);
+   }
+
+   BUG();
+
+   while (1); // Avoid compiler warning.
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * Str_Strcpy--
+ *
+ *    Wrapper for strcpy that checks for buffer overruns.
+ *
+ * Results:
+ *    Same as strcpy.
+ *
+ * Side effects:
+ *    None.
+ *
+ *----------------------------------------------------------------------
+ */
+
+char *
+Str_Strcpy(char *buf,       // OUT
+           const char *src, // IN
+           size_t maxSize)  // IN
+{
+   unsigned int *stack = (unsigned int *)&buf;
+   size_t len;
+
+   len = strlen(src);
+   if (len >= maxSize) {
+      Panic("%s:%d Buffer too small 0x%x\n", __FILE__,__LINE__,
+            stack[-1]);
+   }
+   return memcpy(buf, src, len + 1);
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * Str_Vsnprintf --
+ *
+ *	Compatability wrapper b/w different libc versions
+ *
+ * Results:
+ *	int - number of bytes written (not including NULL terminate character),
+ *	      -1 on overflow (insufficient space for NULL terminate is considered
+ *	      overflow)
+ *
+ *	NB: on overflow the buffer WILL be null terminated
+ *
+ * Side effects:
+ *	None
+ *
+ *----------------------------------------------------------------------
+ */
+
+int
+Str_Vsnprintf(char *str,          // OUT
+              size_t size,        // IN
+              const char *format, // IN
+              va_list arguments)  // IN
+{
+   int retval;
+   retval = vsnprintf(str, size, format, arguments);
+
+   /*
+    * Linux glibc 2.0.x returns -1 and null terminates (which we shouldn't
+    * be linking against), but glibc 2.1.x follows c99 and returns
+    * characters that would have been written.
+    */
+   if (retval >= size) {
+      return -1;
+   }
+   return retval;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Str_Vasprintf --
+ *
+ *    Allocate and format a string, using the GNU libc way to specify the
+ *    format (i.e. optionally allow the use of positional parameters)
+ *
+ * Results:
+ *    The allocated string on success (if 'length' is not NULL, *length
+ *       is set to the length of the allocated string)
+ *    NULL on failure
+ *
+ * Side effects:
+ *    None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+char *
+Str_Vasprintf(size_t *length,       // OUT
+              const char *format,   // IN
+              va_list arguments)    // IN
+{
+   /*
+    * Simple implementation of Str_Vasprintf when userlevel libraries are not
+    * available (e.g. for use in drivers). We just fallback to vsnprintf,
+    * doubling if we didn't have enough space.
+    */
+   unsigned int bufSize;
+   char *buf;
+   int retval;
+
+   bufSize = strlen(format);
+   buf = NULL;
+
+   do {
+      /*
+       * Initial allocation of strlen(format) * 2. Should this be tunable?
+       * XXX Yes, this could overflow and spin forever when you get near 2GB
+       *     allocations. I don't care. --rrdharan
+       */
+      va_list args2;
+
+      bufSize *= 2;
+      buf = realloc(buf, bufSize);
+
+      if (!buf) {
+         return NULL;
+      }
+
+      va_copy(args2, arguments);
+      retval = Str_Vsnprintf(buf, bufSize, format, args2);
+      va_end(args2);
+   } while (retval == -1);
+
+   if (length) {
+      *length = retval;
+   }
+
+   /*
+    * Try to trim the buffer here to save memory?
+    */
+   return buf;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Str_Asprintf --
+ *
+ *    Same as Str_Vasprintf(), but parameters are passed inline --hpreg
+ *
+ * Results:
+ *    Same as Str_Vasprintf()
+ *
+ * Side effects:
+ *    Same as Str_Vasprintf()
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+char *
+Str_Asprintf(size_t *length,       // OUT
+             const char *format,   // IN
+             ...)                  // IN
+{
+   va_list arguments;
+   char *result;
+
+   va_start(arguments, format);
+   result = Str_Vasprintf(length, format, arguments);
+   va_end(arguments);
+
+   return result;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * strdup --
+ *
+ *    Duplicates a string.
+ *
+ * Results:
+ *    A pointer to memory containing the duplicated string or NULL if no
+ *    memory was available.
+ *
+ * Side effects:
+ *    None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+char *
+strdup(const char *source) // IN
+{
+   char *target = NULL;
+   if (source) {
+
+      /*
+       * We call our special implementation of malloc() because the users of
+       * strdup() will call free(), and that'll decrement the pointer before
+       * freeing it. Thus, we need to make sure that the allocated block
+       * also stores the block length before the block itself (see malloc()
+       * below).
+       */
+      unsigned int len = strlen(source);
+      target = malloc(len + 1);
+      if (target) {
+         memcpy(target, source, len + 1);
+      }
+   }
+
+   return target;
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * malloc --
+ *
+ *      Allocate memory using kmalloc. There is no realloc
+ *      equivalent, so we roll our own by padding each allocation with
+ *      4 (or 8 for 64 bit guests) extra bytes to store the block length.
+ *
+ * Results:
+ *      Pointer to driver heap memory, offset by 4 (or 8)
+ *      bytes from the real block pointer.
+ *
+ * Side effects:
+ *      None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+void *
+malloc(size_t size) // IN
+{
+   size_t *ptr;
+   ptr = kmalloc(size + sizeof size, GFP_KERNEL);
+
+   if (ptr) {
+      *ptr++ = size;
+   }
+   return ptr;
+}
+
+/*
+ *---------------------------------------------------------------------------
+ *
+ * free --
+ *
+ *     Free memory allocated by a previous call to malloc, calloc or realloc.
+ *
+ * Results:
+ *     None.
+ *
+ * Side effects:
+ *     Calls kfree to free the real (base) pointer.
+ *
+ *---------------------------------------------------------------------------
+ */
+
+void
+free(void *mem) // IN
+{
+   if (mem) {
+      size_t *dataPtr = (size_t *)mem;
+      kfree(--dataPtr);
+   }
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * calloc --
+ *
+ *      Malloc and zero.
+ *
+ * Results:
+ *      Pointer to driver heap memory (see malloc, above).
+ *
+ * Side effects:
+ *      None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+void *
+calloc(size_t num, // IN
+       size_t len) // IN
+{
+   size_t size;
+   void *ptr;
+
+   size = num * len;
+   ptr = malloc(size);
+   if (ptr) {
+      memset(ptr, 0, size);
+   }
+   return ptr;
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * realloc --
+ *
+ *      Since the driver heap has no realloc equivalent, we have to roll our
+ *      own. Fortunately, we can retrieve the block size of every block we
+ *      hand out since we stashed it at allocation time (see malloc above).
+ *
+ * Results:
+ *      Pointer to memory block valid for 'newSize' bytes, or NULL if
+ *      allocation failed.
+ *
+ * Side effects:
+ *      Could copy memory around.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+void *
+realloc(void* ptr,      // IN
+        size_t newSize) // IN
+{
+   void *newPtr;
+   size_t *dataPtr;
+   size_t length, lenUsed;
+
+   dataPtr = (size_t *)ptr;
+   length = ptr ? dataPtr[-1] : 0;
+   if (newSize == 0) {
+      if (ptr) {
+         free(ptr);
+         newPtr = NULL;
+      } else {
+         newPtr = malloc(newSize);
+      }
+   } else if (newSize == length) {
+      newPtr = ptr;
+   } else if ((newPtr = malloc(newSize))) {
+      if (length < newSize) {
+         lenUsed = length;
+      } else {
+         lenUsed = newSize;
+      }
+      memcpy(newPtr, ptr, lenUsed);
+      free(ptr);
+   }
+   return newPtr;
+}
+
+
--- kernel/linux-2.6.26.3/drivers/misc/vmci/Makefile	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmci/Makefile	2008-09-03 09:57:34.000000000 -0500
@@ -0,0 +1,31 @@
+#############################################################
+# Copyright 1998 VMware, Inc.  All rights reserved. 
+#############################################################
+####
+#### This program is free software; you can redistribute it and/or modify it
+#### under the terms of the GNU General Public License as published by the
+#### Free Software Foundation version 2 and no later version.
+####
+#### This program is distributed in the hope that it will be useful, but
+#### WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+#### or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+#### for more details.
+####
+#### You should have received a copy of the GNU General Public License along
+#### with this program; if not, write to the Free Software Foundation, Inc.,
+#### 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+
+####
+####  VMware vmci Makefile to be distributed externally
+####
+####
+
+obj-$(CONFIG_VMCI) += vmci.o
+
+vmci-objs := kernelStubsLinux.o vmciDatagram.o vmci_drv.o \
+             vmciEvent.o vmciGuestDs.o vmciGuestKernelIf.o \
+             vmciKernelIf.o vmciProcess.o vmciQueuePair.o \
+             vmciUtil.o
+
+EXTRA_CFLAGS += -DVMW_USING_KBUILD -DVMW_HAVE_EPOLL
+EXTRA_CFLAGS += -DVMX86_TOOLS
--- kernel/linux-2.6.26.3/drivers/misc/vmci/pgtbl.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmci/pgtbl.h	2008-09-03 10:01:42.000000000 -0500
@@ -0,0 +1,385 @@
+/*********************************************************
+ * Copyright (C) 2002 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __PGTBL_H__
+#   define __PGTBL_H__
+
+
+#include "compat_highmem.h"
+#include "compat_pgtable.h"
+#include "compat_spinlock.h"
+#include "compat_page.h"
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 3, 11)
+# define compat_active_mm  mm
+#else
+# define compat_active_mm  active_mm
+#endif
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * PgtblPte2MPN --
+ *
+ *    Returns the page structure associated to a Page Table Entry.
+ *
+ *    This function is not allowed to schedule() because it can be called while
+ *    holding a spinlock --hpreg
+ *
+ * Results:
+ *    INVALID_MPN on failure
+ *    mpn         on success
+ *
+ * Side effects:
+ *    None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE MPN
+PgtblPte2MPN(pte_t *pte)   // IN
+{
+   if (pte_present(*pte) == 0) {
+      return INVALID_MPN;
+   }
+   return pte_pfn(*pte);
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * PgtblPte2Page --
+ *
+ *    Returns the page structure associated to a Page Table Entry.
+ *
+ *    This function is not allowed to schedule() because it can be called while
+ *    holding a spinlock --hpreg
+ *
+ * Results:
+ *    The page structure if the page table entry points to a physical page
+ *    NULL if the page table entry does not point to a physical page
+ *
+ * Side effects:
+ *    None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE struct page *
+PgtblPte2Page(pte_t *pte) // IN
+{
+   if (pte_present(*pte) == 0) {
+      return NULL;
+   }
+
+   return compat_pte_page(*pte);
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * PgtblPGD2PTELocked --
+ *
+ *    Walks through the hardware page tables to try to find the pte
+ *    associated to a virtual address.
+ *
+ * Results:
+ *    pte. Caller must call pte_unmap if valid pte returned.
+ *
+ * Side effects:
+ *    None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE pte_t *
+PgtblPGD2PTELocked(compat_pgd_t *pgd,    // IN: PGD to start with
+                   VA addr)              // IN: Address in the virtual address
+                                         //     space of that process
+{
+   compat_pud_t *pud;
+   pmd_t *pmd;
+   pte_t *pte;
+
+   if (compat_pgd_present(*pgd) == 0) {
+      return NULL;
+   }
+
+   pud = compat_pud_offset(pgd, addr);
+   if (compat_pud_present(*pud) == 0) {
+      return NULL;
+   }
+
+   pmd = pmd_offset_map(pud, addr);
+   if (pmd_present(*pmd) == 0) {
+      pmd_unmap(pmd);
+      return NULL;
+   }
+
+   pte = pte_offset_map(pmd, addr);
+   pmd_unmap(pmd);
+   return pte;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * PgtblVa2PTELocked --
+ *
+ *    Walks through the hardware page tables to try to find the pte
+ *    associated to a virtual address.
+ *
+ * Results:
+ *    pte. Caller must call pte_unmap if valid pte returned.
+ *
+ * Side effects:
+ *    None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE pte_t *
+PgtblVa2PTELocked(struct mm_struct *mm, // IN: Mm structure of a process
+                  VA addr)              // IN: Address in the virtual address
+                                        //     space of that process
+{
+   return PgtblPGD2PTELocked(compat_pgd_offset(mm, addr), addr);
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * PgtblVa2MPNLocked --
+ *
+ *    Retrieve MPN for a given va.
+ *
+ *    Caller must call pte_unmap if valid pte returned. The mm->page_table_lock 
+ *    must be held, so this function is not allowed to schedule() --hpreg
+ *
+ * Results:
+ *    INVALID_MPN on failure
+ *    mpn         on success
+ *
+ * Side effects:
+ *    None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE MPN
+PgtblVa2MPNLocked(struct mm_struct *mm, // IN: Mm structure of a process
+                  VA addr)              // IN: Address in the virtual address
+{
+   pte_t *pte;
+
+   pte = PgtblVa2PTELocked(mm, addr);
+   if (pte != NULL) {
+      MPN mpn = PgtblPte2MPN(pte);
+      pte_unmap(pte);
+      return mpn;
+   }
+   return INVALID_MPN;
+} 
+
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 0)
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * PgtblKVa2MPNLocked --
+ *
+ *    Retrieve MPN for a given kernel va.
+ *
+ *    Caller must call pte_unmap if valid pte returned. The mm->page_table_lock
+ *    must be held, so this function is not allowed to schedule() --hpreg
+ *
+ * Results:
+ *    INVALID_MPN on failure
+ *    mpn         on success
+ *
+ * Side effects:
+ *    None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE MPN
+PgtblKVa2MPNLocked(struct mm_struct *mm, // IN: Mm structure of a caller
+                   VA addr)              // IN: Address in the virtual address
+{
+   pte_t *pte;
+
+   pte = PgtblPGD2PTELocked(compat_pgd_offset_k(mm, addr), addr);
+   if (pte != NULL) {
+      MPN mpn = PgtblPte2MPN(pte);
+      pte_unmap(pte);
+      return mpn;
+   }
+   return INVALID_MPN;
+}
+#endif
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * PgtblVa2PageLocked --
+ *
+ *    Return the "page" struct for a given va.
+ *
+ * Results:
+ *    struct page or NULL.  The mm->page_table_lock must be held, so this 
+ *    function is not allowed to schedule() --hpreg
+ *
+ * Side effects:
+ *    None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE struct page *
+PgtblVa2PageLocked(struct mm_struct *mm, // IN: Mm structure of a process
+                   VA addr)              // IN: Address in the virtual address
+{
+   pte_t *pte;
+
+   pte = PgtblVa2PTELocked(mm, addr);
+   if (pte != NULL) {
+      struct page *page = PgtblPte2Page(pte);
+      pte_unmap(pte);
+      return page;
+   } else {
+      return NULL;
+   }
+} 
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * PgtblVa2MPN --
+ *
+ *    Walks through the hardware page tables of the current process to try to
+ *    find the page structure associated to a virtual address.
+ *
+ * Results:
+ *    Same as PgtblVa2MPNLocked()
+ *
+ * Side effects:
+ *    None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE int
+PgtblVa2MPN(VA addr)  // IN
+{
+   struct mm_struct *mm;
+   MPN mpn;
+
+   /* current->mm is NULL for kernel threads, so use active_mm. */
+   mm = current->compat_active_mm;
+   if (compat_get_page_table_lock(mm)) {
+      spin_lock(compat_get_page_table_lock(mm));
+   }
+   mpn = PgtblVa2MPNLocked(mm, addr);
+   if (compat_get_page_table_lock(mm)) {
+      spin_unlock(compat_get_page_table_lock(mm));
+   }
+   return mpn;
+}
+
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 0)
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * PgtblKVa2MPN --
+ *
+ *    Walks through the hardware page tables of the current process to try to
+ *    find the page structure associated to a virtual address.
+ *
+ * Results:
+ *    Same as PgtblVa2MPNLocked()
+ *
+ * Side effects:
+ *    None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE int
+PgtblKVa2MPN(VA addr)  // IN
+{
+   struct mm_struct *mm;
+   MPN mpn;
+
+   mm = current->compat_active_mm;
+   if (compat_get_page_table_lock(mm)) {
+      spin_lock(compat_get_page_table_lock(mm));
+   }
+   mpn = PgtblKVa2MPNLocked(mm, addr);
+   if (compat_get_page_table_lock(mm)) {
+      spin_unlock(compat_get_page_table_lock(mm));
+   }
+   return mpn;
+}
+#endif
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * PgtblVa2Page --
+ *
+ *    Walks through the hardware page tables of the current process to try to
+ *    find the page structure associated to a virtual address.
+ *
+ * Results:
+ *    Same as PgtblVa2PageLocked()
+ *
+ * Side effects:
+ *    None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE struct page *
+PgtblVa2Page(VA addr) // IN
+{
+   struct mm_struct *mm;
+   struct page *page;
+
+   mm = current->compat_active_mm;
+   if (compat_get_page_table_lock(mm)) {
+      spin_lock(compat_get_page_table_lock(mm));
+   }
+   page = PgtblVa2PageLocked(mm, addr);
+   if (compat_get_page_table_lock(mm)) {
+      spin_unlock(compat_get_page_table_lock(mm));
+   }
+   return page;
+}
+
+
+#endif /* __PGTBL_H__ */
--- kernel/linux-2.6.26.3/drivers/misc/vmci/vm_assert.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmci/vm_assert.h	2008-09-03 10:01:42.000000000 -0500
@@ -0,0 +1,317 @@
+/*********************************************************
+ * Copyright (C) 1998-2004 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * vm_assert.h --
+ *
+ *	The basic assertion facility for all VMware code.
+ *
+ *	For proper use, see
+ *	http://vmweb.vmware.com/~mts/WebSite/guide/programming/asserts.html
+ */
+
+#ifndef _VM_ASSERT_H_
+#define _VM_ASSERT_H_
+
+#define INCLUDE_ALLOW_USERLEVEL
+#define INCLUDE_ALLOW_VMMEXT
+#define INCLUDE_ALLOW_MODULE
+#define INCLUDE_ALLOW_VMMON
+#define INCLUDE_ALLOW_VMNIXMOD
+#define INCLUDE_ALLOW_VMKERNEL
+#define INCLUDE_ALLOW_VMKDRIVERS
+#define INCLUDE_ALLOW_VMK_MODULE
+#define INCLUDE_ALLOW_DISTRIBUTE
+#define INCLUDE_ALLOW_VMCORE
+#define INCLUDE_ALLOW_VMIROM
+#include "includeCheck.h"
+
+// XXX not necessary except some places include vm_assert.h improperly
+#include "vm_basic_types.h"
+#include "vm_basic_defs.h"
+
+
+/*
+ * XXX old file code
+ */
+
+#ifdef FILECODEINT
+#error "Don't define FILECODEINT.  It is obsolete."
+#endif
+#ifdef FILECODE
+#error "Don't define FILECODE.  It is obsolete."
+#endif
+
+
+/*
+ * Panic and log functions
+ */
+
+EXTERN void Log(const char *fmt, ...) PRINTF_DECL(1, 2);
+EXTERN void Warning(const char *fmt, ...) PRINTF_DECL(1, 2);
+EXTERN NORETURN void Panic(const char *fmt, ...) PRINTF_DECL(1, 2);
+
+EXTERN void LogThrottled(uint32 *count, const char *fmt, ...)
+            PRINTF_DECL(2, 3);
+EXTERN void WarningThrottled(uint32 *count, const char *fmt, ...)
+            PRINTF_DECL(2, 3);
+
+/* DB family:  messages which are parsed by logfile database system */
+#define WarningDB Warning
+#define LogDB Log
+#define WarningThrottledDB WarningThrottled
+#define LogThrottledDB LogThrottled
+
+
+/*
+ * Stress testing: redefine ASSERT_IFNOT() to taste
+ */
+
+#ifndef ASSERT_IFNOT
+   #ifdef __cplusplus
+      #define ASSERT_IFNOT(cond, panic) (UNLIKELY(!(cond)) ? (panic) : (void)0)
+   #else
+      #define ASSERT_IFNOT(cond, panic) (UNLIKELY(!(cond)) ? (panic) : 0)
+   #endif
+#endif
+
+
+/*
+ * Assert, panic, and log macros
+ *
+ * Some of these are redefined below undef !VMX86_DEBUG.
+ * ASSERT() is special cased because of interaction with Windows DDK.
+ */
+
+#if defined VMX86_DEBUG || defined ASSERT_ALWAYS_AVAILABLE
+#undef ASSERT
+#define ASSERT(cond) \
+           ASSERT_IFNOT(cond, _ASSERT_PANIC(AssertAssert))
+#endif
+#define ASSERT_BUG(bug, cond) \
+           ASSERT_IFNOT(cond, _ASSERT_PANIC_BUG(bug, AssertAssert))
+#define ASSERT_BUG_DEBUGONLY(bug, cond) ASSERT_BUG(bug, cond)
+
+#define PANIC()        _ASSERT_PANIC(AssertPanic)
+#define PANIC_BUG(bug) _ASSERT_PANIC_BUG(bug, AssertPanic)
+
+#define ASSERT_NOT_IMPLEMENTED(cond) \
+           ASSERT_IFNOT(cond, NOT_IMPLEMENTED())
+#define ASSERT_NOT_IMPLEMENTED_BUG(bug, cond) \
+           ASSERT_IFNOT(cond, NOT_IMPLEMENTED_BUG(bug))
+
+#define NOT_IMPLEMENTED()        _ASSERT_PANIC(AssertNotImplemented)
+#define NOT_IMPLEMENTED_BUG(bug) _ASSERT_PANIC_BUG(bug, AssertNotImplemented)
+
+#define NOT_REACHED()            _ASSERT_PANIC(AssertNotReached)
+#define NOT_REACHED_BUG(bug)     _ASSERT_PANIC_BUG(bug, AssertNotReached)
+
+#define ASSERT_MEM_ALLOC(cond) \
+           ASSERT_IFNOT(cond, _ASSERT_PANIC(AssertMemAlloc))
+
+#ifdef VMX86_DEVEL
+   #define ASSERT_LENGTH(real, expected) \
+              ASSERT_IFNOT((real) == (expected), \
+                 Panic(AssertLengthFmt, __FILE__, __LINE__, real, expected))
+#else
+   #define ASSERT_LENGTH(real, expected) ASSERT((real) == (expected))
+#endif
+
+#ifdef VMX86_DEVEL
+   #define ASSERT_DEVEL(cond) ASSERT(cond)
+#else
+   #define ASSERT_DEVEL(cond) ((void) 0)
+#endif
+
+#define ASSERT_NO_INTERRUPTS()  ASSERT(!INTERRUPTS_ENABLED())
+#define ASSERT_HAS_INTERRUPTS() ASSERT(INTERRUPTS_ENABLED())
+
+#define ASSERT_LOG_UNEXPECTED(bug, cond) \
+           (UNLIKELY(!(cond)) ? LOG_UNEXPECTED(bug) : 0)
+#ifdef VMX86_DEVEL
+   #define LOG_UNEXPECTED(bug) \
+              Warning(AssertUnexpectedFmt, __FILE__, __LINE__, bug)
+#else
+   #define LOG_UNEXPECTED(bug) \
+              Log(AssertUnexpectedFmt, __FILE__, __LINE__, bug)
+#endif
+
+#define ASSERT_NOT_TESTED(cond) (UNLIKELY(!(cond)) ? NOT_TESTED() : 0)
+#ifdef VMX86_DEVEL
+   #define NOT_TESTED() Warning(AssertNotTestedFmt, __FILE__, __LINE__)
+#else
+   #define NOT_TESTED() Log(AssertNotTestedFmt, __FILE__, __LINE__)
+#endif
+
+#define NOT_TESTED_ONCE()                                               \
+   do {                                                                 \
+      static Bool alreadyPrinted = FALSE;                               \
+      if (UNLIKELY(!alreadyPrinted)) {                                  \
+	 alreadyPrinted = TRUE;                                         \
+	 NOT_TESTED();                                                  \
+      }                                                                 \
+   } while (0)
+
+#define NOT_TESTED_1024()                                               \
+   do {                                                                 \
+      static uint16 count = 0;                                          \
+      if (UNLIKELY(count == 0)) { NOT_TESTED(); }                       \
+      count = (count + 1) & 1023;                                       \
+   } while (0)
+
+#define LOG_ONCE(_s)                                                    \
+   do {                                                                 \
+      static Bool logged = FALSE;                                       \
+      if (!logged) {                                                    \
+	 Log _s;                                                        \
+         logged = TRUE;                                                 \
+      }                                                                 \
+   } while (0)
+
+
+/*
+ * Redefine macros that are only in debug versions
+ */
+
+#if !defined VMX86_DEBUG && !defined ASSERT_ALWAYS_AVAILABLE // {
+
+#undef  ASSERT
+#define ASSERT(cond) ((void) 0)
+
+#undef  ASSERT_BUG_DEBUGONLY
+#define ASSERT_BUG_DEBUGONLY(bug, cond) ((void) 0)
+
+#undef  ASSERT_LENGTH
+#define ASSERT_LENGTH(real, expected) ((void) 0)
+
+/*
+ * Expand NOT_REACHED() as appropriate for each situation.
+ *
+ * Mainly, we want the compiler to infer the same control-flow
+ * information as it would from Panic().  Otherwise, different
+ * compilation options will lead to different control-flow-derived
+ * errors, causing some make targets to fail while others succeed.
+ *
+ * VC++ has the __assume() built-in function which we don't trust
+ * (see bug 43485); gcc has no such construct; we just panic in
+ * userlevel code.  The monitor doesn't want to pay the size penalty
+ * (measured at 212 bytes for the release vmm for a minimal infinite
+ * loop; panic would cost even more) so it does without and lives
+ * with the inconsistency.
+ */
+
+#ifdef VMM
+#undef  NOT_REACHED
+#define NOT_REACHED() ((void) 0)
+#else
+// keep debug definition
+#endif
+
+#undef  ASSERT_LOG_UNEXPECTED
+#define ASSERT_LOG_UNEXPECTED(bug, cond) ((void) 0)
+
+#undef LOG_UNEXPECTED
+#define LOG_UNEXPECTED(bug) ((void) 0)
+
+#undef  ASSERT_NOT_TESTED
+#define ASSERT_NOT_TESTED(cond) ((void) 0)
+#undef  NOT_TESTED
+#define NOT_TESTED() ((void) 0)
+#undef  NOT_TESTED_ONCE
+#define NOT_TESTED_ONCE() ((void) 0)
+#undef  NOT_TESTED_1024
+#define NOT_TESTED_1024() ((void) 0)
+
+#endif // !VMX86_DEBUG }
+
+
+/*
+ * Compile-time assertions.
+ *
+ * ASSERT_ON_COMPILE does not use the common
+ * switch (0) { case 0: case (e): ; } trick because some compilers (e.g. MSVC)
+ * generate code for it.
+ *
+ * The implementation uses both enum and typedef because the typedef alone is
+ * insufficient; gcc allows arrays to be declared with non-constant expressions
+ * (even in typedefs, where it makes no sense).
+ */
+
+#define ASSERT_ON_COMPILE(e) \
+   do { \
+      enum { AssertOnCompileMisused = ((e) ? 1 : -1) }; \
+      typedef char AssertOnCompileFailed[AssertOnCompileMisused]; \
+   } while (0)
+
+
+/*
+ * To put an ASSERT_ON_COMPILE() outside a function, wrap it
+ * in MY_ASSERTS().  The first parameter must be unique in
+ * each .c file where it appears.  For example,
+ *
+ * MY_ASSERTS(FS3_INT,
+ *    ASSERT_ON_COMPILE(sizeof(FS3_DiskLock) == 128);
+ *    ASSERT_ON_COMPILE(sizeof(FS3_DiskLockReserved) == DISK_BLOCK_SIZE);
+ *    ASSERT_ON_COMPILE(sizeof(FS3_DiskBlock) == DISK_BLOCK_SIZE);
+ *    ASSERT_ON_COMPILE(sizeof(Hardware_DMIUUID) == 16);
+ * )
+ *
+ * Caution: ASSERT() within MY_ASSERTS() is silently ignored.
+ * The same goes for anything else not evaluated at compile time.
+ */
+
+#define MY_ASSERTS(name, assertions) \
+   static INLINE void name(void) { \
+      assertions \
+   }
+
+
+/*
+ * Internal macros, functions, and strings
+ *
+ * The monitor wants to save space at call sites, so it has specialized
+ * functions for each situation.  User level wants to save on implementation
+ * so it uses generic functions.
+ */
+
+#if !defined VMM || defined MONITOR_APP // {
+
+#define _ASSERT_PANIC(name) \
+           Panic(_##name##Fmt "\n", __FILE__, __LINE__)
+#define _ASSERT_PANIC_BUG(bug, name) \
+           Panic(_##name##Fmt " bugNr=%d\n", __FILE__, __LINE__, bug)
+
+#define AssertLengthFmt     _AssertLengthFmt
+#define AssertUnexpectedFmt _AssertUnexpectedFmt
+#define AssertNotTestedFmt  _AssertNotTestedFmt
+
+#endif // }
+
+// these don't have newline so a bug can be tacked on
+#define _AssertPanicFmt            "PANIC %s:%d"
+#define _AssertAssertFmt           "ASSERT %s:%d"
+#define _AssertNotImplementedFmt   "NOT_IMPLEMENTED %s:%d"
+#define _AssertNotReachedFmt       "NOT_REACHED %s:%d"
+#define _AssertMemAllocFmt         "MEM_ALLOC %s:%d"
+
+// these are complete formats with newline
+#define _AssertLengthFmt           "LENGTH %s:%d r=%#x e=%#x\n"
+#define _AssertUnexpectedFmt       "UNEXPECTED %s:%d bugNr=%d\n"
+#define _AssertNotTestedFmt        "NOT_TESTED %s:%d\n"
+
+#endif /* ifndef _VM_ASSERT_H_ */
--- kernel/linux-2.6.26.3/drivers/misc/vmci/vm_atomic.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmci/vm_atomic.h	2008-09-03 10:01:42.000000000 -0500
@@ -0,0 +1,2049 @@
+/*********************************************************
+ * Copyright (C) 1998 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * vm_atomic.h --
+ *
+ *	Atomic power
+ */
+
+#ifndef _ATOMIC_H_
+#define _ATOMIC_H_
+
+#define INCLUDE_ALLOW_USERLEVEL
+#define INCLUDE_ALLOW_VMMEXT
+#define INCLUDE_ALLOW_MODULE
+#define INCLUDE_ALLOW_VMMON
+#define INCLUDE_ALLOW_VMNIXMOD
+#define INCLUDE_ALLOW_VMKDRIVERS
+#define INCLUDE_ALLOW_VMK_MODULE
+#define INCLUDE_ALLOW_VMKERNEL
+#define INCLUDE_ALLOW_DISTRIBUTE
+#define INCLUDE_ALLOW_VMCORE
+#define INCLUDE_ALLOW_VMIROM
+#include "includeCheck.h"
+
+#include "vm_basic_types.h"
+
+
+/* Basic atomic type: 32 bits */
+typedef struct Atomic_uint32 {
+   volatile uint32 value;
+} Atomic_uint32;
+
+
+/* Basic atomic type: 64 bits */
+typedef struct  Atomic_uint64 {
+   volatile uint64 value;
+} Atomic_uint64 ALIGNED(8);
+
+
+/*
+ * Prototypes for msft atomics.  These are defined & inlined by the
+ * compiler so no function definition is needed.  The prototypes are
+ * needed for c++.  Since amd64 compiler doesn't support inline asm we
+ * have to use these.  Unfortunately, we still have to use some inline asm
+ * for the 32 bit code since the and/or/xor implementations didn't show up
+ * untill xp or 2k3.
+ * 
+ * The declarations for the intrinsic functions were taken from ntddk.h
+ * in the DDK. The declarations must match otherwise the 64-bit c++
+ * compiler will complain about second linkage of the intrinsic functions.
+ * We define the intrinsic using the basic types corresponding to the 
+ * Windows typedefs. This avoids having to include windows header files
+ * to get to the windows types.
+ */
+#if defined(_MSC_VER) && _MSC_VER >= 1310
+#ifdef __cplusplus
+extern "C" {
+#endif
+long  _InterlockedExchange(long volatile*, long);
+long  _InterlockedCompareExchange(long volatile*, long, long);
+long  _InterlockedExchangeAdd(long volatile*, long);
+long  _InterlockedDecrement(long volatile*);
+long  _InterlockedIncrement(long volatile*);
+#pragma intrinsic(_InterlockedExchange, _InterlockedCompareExchange)
+#pragma intrinsic(_InterlockedExchangeAdd, _InterlockedDecrement)
+#pragma intrinsic(_InterlockedIncrement)
+
+#if defined(VM_X86_64)
+long     _InterlockedAnd(long volatile*, long);
+__int64  _InterlockedAnd64(__int64 volatile*, __int64);
+long     _InterlockedOr(long volatile*, long);
+__int64  _InterlockedOr64(__int64 volatile*, __int64);
+long     _InterlockedXor(long volatile*, long);
+__int64  _InterlockedXor64(__int64 volatile*, __int64);
+__int64  _InterlockedExchangeAdd64(__int64 volatile*, __int64);
+__int64  _InterlockedIncrement64(__int64 volatile*);
+__int64  _InterlockedDecrement64(__int64 volatile*);
+__int64  _InterlockedExchange64(__int64 volatile*, __int64);
+__int64  _InterlockedCompareExchange64(__int64 volatile*, __int64, __int64);
+#if !defined(_WIN64)
+#pragma intrinsic(_InterlockedAnd, _InterlockedAnd64)
+#pragma intrinsic(_InterlockedOr, _InterlockedOr64)
+#pragma intrinsic(_InterlockedXor, _InterlockedXor64)
+#pragma intrinsic(_InterlockedExchangeAdd64, _InterlockedIncrement64)
+#pragma intrinsic(_InterlockedDecrement64, _InterlockedExchange64)
+#pragma intrinsic(_InterlockedCompareExchange64)
+#endif /* !_WIN64 */
+#endif /* __x86_64__ */
+
+#ifdef __cplusplus
+}
+#endif
+#endif /* _MSC_VER */
+
+
+/* Convert a volatile int to Atomic_uint32. */
+static INLINE Atomic_uint32 *
+Atomic_VolatileToAtomic(volatile uint32 *var)
+{
+   return (Atomic_uint32 *)var;
+}
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Atomic_Init, Atomic_SetFence, AtomicUseFence --
+ *
+ *      Determine whether an lfence intruction is executed after
+ *	every locked instruction.
+ *
+ *	Certain AMD processes have a bug (see bug 107024) that
+ *	requires an lfence after every locked instruction.
+ *
+ *	The global variable AtomicUseFence controls whether lfence
+ *	is used (see AtomicEpilogue).
+ *
+ *	Atomic_SetFence sets AtomicUseFence to the given value.
+ *
+ *	Atomic_Init computes and sets AtomicUseFence.
+ *	It does not take into account the number of processors.
+ *
+ *	The rationale for all this complexity is that Atomic_Init
+ *	is the easy-to-use interface.  It can be called a number
+ *	of times cheaply, and does not depend on other libraries.
+ *	However, because the number of CPUs is difficult to compute,
+ *	it does without it and always assumes there are more than one.
+ *
+ *	For programs that care or have special requirements,
+ *	Atomic_SetFence can be called directly, in addition to Atomic_Init.
+ *	It overrides the effect of Atomic_Init, and can be called
+ *	before, after, or between calls to Atomic_Init.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+// The freebsd assembler doesn't know the lfence instruction
+#if defined(__GNUC__) &&                                                \
+     __GNUC__ >= 3 &&                                                   \
+    (defined(__VMKERNEL__) || !defined(__FreeBSD__)) &&                 \
+    (!defined(MODULE) || defined(__VMKERNEL_MODULE__)) &&               \
+    !defined(__APPLE__) /* PR136775 */
+#define ATOMIC_USE_FENCE
+#endif
+
+#if defined(VMATOMIC_IMPORT_DLLDATA)
+VMX86_EXTERN_DATA Bool AtomicUseFence;
+#else
+EXTERN Bool AtomicUseFence;
+#endif
+
+EXTERN Bool atomicFenceInitialized;
+
+void AtomicInitFence(void);
+
+static INLINE void
+Atomic_Init(void)
+{
+#ifdef ATOMIC_USE_FENCE
+   if (!atomicFenceInitialized) {
+      AtomicInitFence();
+   }
+#endif
+}
+
+static INLINE void
+Atomic_SetFence(Bool fenceAfterLock) /* IN: TRUE to enable lfence */
+                                     /*     FALSE to disable. */
+{
+   AtomicUseFence = fenceAfterLock;
+#if defined(__VMKERNEL__)
+   extern void Atomic_SetFenceVMKAPI(Bool fenceAfterLock);
+   Atomic_SetFenceVMKAPI(fenceAfterLock);  
+#endif
+   atomicFenceInitialized = TRUE;
+}
+
+
+/* Conditionally execute fence after interlocked instruction. */
+static INLINE void
+AtomicEpilogue(void)
+{
+#ifdef ATOMIC_USE_FENCE
+   if (UNLIKELY(AtomicUseFence)) {
+      asm volatile ("lfence" ::: "memory");
+   }
+#endif
+}
+
+
+/*
+ * All the assembly code is tricky and written conservatively.
+ * For example, to make sure gcc won't introduce copies,
+ * we force the addressing mode like this:
+ *
+ *    "xchgl %0, (%1)"
+ *    : "=r" (val)
+ *    : "r" (&var->value),
+ *      "0" (val)
+ *    : "memory"
+ *
+ * - edward
+ *
+ * Actually - turns out that gcc never generates memory aliases (it
+ * still does generate register aliases though), so we can be a bit
+ * more agressive with the memory constraints. The code above can be
+ * modified like this:
+ *
+ *    "xchgl %0, %1"
+ *    : "=r" (val),
+ *      "=m" (var->value),
+ *    : "0" (val),
+ *      "1" (var->value)
+ *
+ * The advantages are that gcc can use whatever addressing mode it
+ * likes to access the memory value, and that we dont have to use a
+ * way-too-generic "memory" clobber as there is now an explicit
+ * declaration that var->value is modified.
+ *
+ * see also /usr/include/asm/atomic.h to convince yourself this is a
+ * valid optimization.
+ *
+ * - walken
+ */
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Atomic_Read --
+ *
+ *      Read
+ *
+ * Results:
+ *      The value of the atomic variable.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE uint32
+Atomic_Read(Atomic_uint32 const *var) // IN
+{
+   return var->value;
+}
+#define Atomic_Read32 Atomic_Read
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Atomic_Write --
+ *
+ *      Write
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE void
+Atomic_Write(Atomic_uint32 *var, // IN
+             uint32 val)         // IN
+{
+   var->value = val;
+}
+#define Atomic_Write32 Atomic_Write
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Atomic_ReadWrite --
+ *
+ *      Read followed by write
+ *
+ * Results:
+ *      The value of the atomic variable before the write.
+ *
+ * Side effects:
+ *      None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE uint32
+Atomic_ReadWrite(Atomic_uint32 *var, // IN
+                 uint32 val)         // IN
+#ifdef __GNUC__
+{
+   /* Checked against the Intel manual and GCC --walken */
+   __asm__ __volatile__(
+      "xchgl %0, %1"
+#   if VM_ASM_PLUS
+      : "=r" (val),
+	"+m" (var->value)
+      : "0" (val)
+#   else
+      : "=r" (val),
+	"=m" (var->value)
+      : "0" (val),
+	"1" (var->value)
+#   endif
+   );
+   AtomicEpilogue();
+   return val;
+}
+#elif _MSC_VER >= 1310
+{
+   return _InterlockedExchange((long *)&var->value, (long)val);
+}
+#elif _MSC_VER
+#pragma warning(push)
+#pragma warning(disable : 4035)         // disable no-return warning
+{
+   __asm mov eax, val
+   __asm mov ebx, var
+   __asm xchg [ebx]Atomic_uint32.value, eax
+   // eax is the return value, this is documented to work - edward
+}
+#pragma warning(pop)
+#else
+#error No compiler defined for Atomic_ReadWrite
+#endif
+#define Atomic_ReadWrite32 Atomic_ReadWrite
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Atomic_ReadIfEqualWrite --
+ *
+ *      Compare exchange: Read variable, if equal to oldVal, write newVal
+ *
+ * Results:
+ *      The value of the atomic variable before the write.
+ *
+ * Side effects:
+ *      The variable may be modified.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE uint32
+Atomic_ReadIfEqualWrite(Atomic_uint32 *var, // IN
+                        uint32 oldVal,      // IN
+                        uint32 newVal)      // IN
+#ifdef __GNUC__
+{
+   uint32 val;
+
+   /* Checked against the Intel manual and GCC --walken */
+   __asm__ __volatile__(
+      "lock; cmpxchgl %2, %1"
+#   if VM_ASM_PLUS
+      : "=a" (val),
+	"+m" (var->value)
+      : "r" (newVal),
+	"0" (oldVal)
+#   else
+      : "=a" (val),
+	"=m" (var->value)
+      : "r" (newVal),
+	"0" (oldVal) 
+     /* 
+      * "1" (var->value): results in inconsistent constraints on gcc 2.7.2.3
+      * when compiling enterprise-2.2.17-14-RH7.0-update.
+      * The constraint has been commented out for now. We may consider doing
+      * this systematically, but we need to be sure it is the right thing to
+      * do. However, it is also possible that the offending use of this asm
+      * function will be removed in the near future in which case we may 
+      * decide to reintroduce the constraint instead. hpreg & agesen.
+      */
+#   endif
+      : "cc"
+   );
+   AtomicEpilogue();
+   return val;
+}
+#elif _MSC_VER >= 1310
+{
+   return _InterlockedCompareExchange((long *)&var->value,
+				      (long)newVal,
+				      (long)oldVal);
+}
+#elif _MSC_VER
+#pragma warning(push)
+#pragma warning(disable : 4035)         // disable no-return warning
+{
+   __asm mov eax, oldVal
+   __asm mov ebx, var
+   __asm mov ecx, newVal
+   __asm lock cmpxchg [ebx]Atomic_uint32.value, ecx
+   // eax is the return value, this is documented to work - edward
+}
+#pragma warning(pop)
+#else
+#error No compiler defined for Atomic_ReadIfEqualWrite
+#endif
+#define Atomic_ReadIfEqualWrite32 Atomic_ReadIfEqualWrite
+
+
+#if defined(__x86_64__)
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Atomic_ReadIfEqualWrite64 --
+ *
+ *      Compare exchange: Read variable, if equal to oldVal, write newVal
+ *
+ * Results:
+ *      The value of the atomic variable before the write.
+ *
+ * Side effects:
+ *      The variable may be modified.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE uint64
+Atomic_ReadIfEqualWrite64(Atomic_uint64 *var, // IN
+                          uint64 oldVal,      // IN
+                          uint64 newVal)      // IN
+{
+#if defined(__GNUC__)
+   uint64 val;
+
+   /* Checked against the AMD manual and GCC --hpreg */
+   __asm__ __volatile__(
+      "lock; cmpxchgq %2, %1"
+      : "=a" (val),
+	"+m" (var->value)
+      : "r" (newVal),
+	"0" (oldVal)
+      : "cc"
+   );
+   AtomicEpilogue();
+   return val;
+#elif _MSC_VER
+   return _InterlockedCompareExchange64((__int64 *)&var->value,
+					(__int64)newVal,
+					(__int64)oldVal);
+#else
+#error No compiler defined for Atomic_ReadIfEqualWrite64
+#endif
+}
+#endif
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Atomic_And --
+ *
+ *      Atomic read, bitwise AND with a value, write.
+ *
+ * Results:
+ *      None
+ *
+ * Side effects:
+ *      None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE void
+Atomic_And(Atomic_uint32 *var, // IN
+           uint32 val)         // IN
+{
+#ifdef __GNUC__
+   /* Checked against the Intel manual and GCC --walken */
+   __asm__ __volatile__(
+      "lock; andl %1, %0"
+#   if VM_ASM_PLUS
+      : "+m" (var->value)
+      : "ri" (val)
+#   else
+      : "=m" (var->value)
+      : "ri" (val),
+        "0" (var->value)
+#   endif
+      : "cc"
+   );
+   AtomicEpilogue();
+#elif _MSC_VER
+#if defined(__x86_64__)
+   _InterlockedAnd((long *)&var->value, (long)val);
+#else
+   __asm mov eax, val
+   __asm mov ebx, var
+   __asm lock and [ebx]Atomic_uint32.value, eax
+#endif
+#else
+#error No compiler defined for Atomic_And
+#endif
+}
+#define Atomic_And32 Atomic_And
+
+
+#if defined(__x86_64__)
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Atomic_And64 --
+ *
+ *      Atomic read, bitwise AND with a value, write.
+ *
+ * Results:
+ *      None
+ *
+ * Side effects:
+ *      None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE void
+Atomic_And64(Atomic_uint64 *var, // IN
+             uint64 val)         // IN
+{
+#if defined(__GNUC__)
+   /* Checked against the AMD manual and GCC --hpreg */
+   __asm__ __volatile__(
+      "lock; andq %1, %0"
+      : "+m" (var->value)
+      : "ri" (val)
+      : "cc"
+   );
+   AtomicEpilogue();
+#elif _MSC_VER
+   _InterlockedAnd64((__int64 *)&var->value, (__int64)val);
+#else
+#error No compiler defined for Atomic_And64
+#endif
+}
+#endif
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Atomic_Or --
+ *
+ *      Atomic read, bitwise OR with a value, write.
+ *
+ * Results:
+ *      None
+ *
+ * Side effects:
+ *      None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE void
+Atomic_Or(Atomic_uint32 *var, // IN
+          uint32 val)         // IN
+{
+#ifdef __GNUC__
+   /* Checked against the Intel manual and GCC --walken */
+   __asm__ __volatile__(
+      "lock; orl %1, %0"
+#   if VM_ASM_PLUS
+      : "+m" (var->value)
+      : "ri" (val)
+#   else
+      : "=m" (var->value)
+      : "ri" (val),
+        "0" (var->value)
+#   endif
+      : "cc"
+   );
+   AtomicEpilogue();
+#elif _MSC_VER
+#if defined(__x86_64__)
+   _InterlockedOr((long *)&var->value, (long)val);
+#else
+   __asm mov eax, val
+   __asm mov ebx, var
+   __asm lock or [ebx]Atomic_uint32.value, eax
+#endif
+#else
+#error No compiler defined for Atomic_Or
+#endif
+}
+#define Atomic_Or32 Atomic_Or
+
+
+#if defined(__x86_64__)
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Atomic_Or64 --
+ *
+ *      Atomic read, bitwise OR with a value, write.
+ *
+ * Results:
+ *      None
+ *
+ * Side effects:
+ *      None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE void
+Atomic_Or64(Atomic_uint64 *var, // IN
+            uint64 val)         // IN
+{
+#if defined(__GNUC__)
+   /* Checked against the AMD manual and GCC --hpreg */
+   __asm__ __volatile__(
+      "lock; orq %1, %0"
+      : "+m" (var->value)
+      : "ri" (val)
+      : "cc"
+   );
+   AtomicEpilogue();
+#elif _MSC_VER
+   _InterlockedOr64((__int64 *)&var->value, (__int64)val);
+#else
+#error No compiler defined for Atomic_Or64
+#endif
+}
+#endif
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Atomic_Xor --
+ *
+ *      Atomic read, bitwise XOR with a value, write.
+ *
+ * Results:
+ *      None
+ *
+ * Side effects:
+ *      None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE void
+Atomic_Xor(Atomic_uint32 *var, // IN
+           uint32 val)         // IN
+{
+#ifdef __GNUC__
+   /* Checked against the Intel manual and GCC --walken */
+   __asm__ __volatile__(
+      "lock; xorl %1, %0"
+#   if VM_ASM_PLUS
+      : "+m" (var->value)
+      : "ri" (val)
+#   else
+      : "=m" (var->value)
+      : "ri" (val),
+        "0" (var->value)
+#   endif
+      : "cc"
+   );
+   AtomicEpilogue();
+#elif _MSC_VER
+#if defined(__x86_64__)
+   _InterlockedXor((long *)&var->value, (long)val);
+#else
+   __asm mov eax, val
+   __asm mov ebx, var
+   __asm lock xor [ebx]Atomic_uint32.value, eax
+#endif
+#else
+#error No compiler defined for Atomic_Xor
+#endif
+}
+#define Atomic_Xor32 Atomic_Xor
+
+
+#if defined(__x86_64__)
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Atomic_Xor64 --
+ *
+ *      Atomic read, bitwise XOR with a value, write.
+ *
+ * Results:
+ *      None
+ *
+ * Side effects:
+ *      None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE void
+Atomic_Xor64(Atomic_uint64 *var, // IN
+             uint64 val)         // IN
+{
+#if defined(__GNUC__)
+   /* Checked against the AMD manual and GCC --hpreg */
+   __asm__ __volatile__(
+      "lock; xorq %1, %0"
+      : "+m" (var->value)
+      : "ri" (val)
+      : "cc"
+   );
+   AtomicEpilogue();
+#elif _MSC_VER
+   _InterlockedXor64((__int64 *)&var->value, (__int64)val);
+#else
+#error No compiler defined for Atomic_Xor64
+#endif
+}
+#endif
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Atomic_Add --
+ *
+ *      Atomic read, add a value, write.
+ *
+ * Results:
+ *      None
+ *
+ * Side effects:
+ *      None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE void
+Atomic_Add(Atomic_uint32 *var, // IN
+           uint32 val)         // IN
+{
+#ifdef __GNUC__
+   /* Checked against the Intel manual and GCC --walken */
+   __asm__ __volatile__(
+      "lock; addl %1, %0"
+#   if VM_ASM_PLUS
+      : "+m" (var->value)
+      : "ri" (val)
+#   else
+      : "=m" (var->value)
+      : "ri" (val),
+        "0" (var->value)
+#   endif
+      : "cc"
+   );
+   AtomicEpilogue();
+#elif _MSC_VER >= 1310
+   _InterlockedExchangeAdd((long *)&var->value, (long)val);
+#elif _MSC_VER
+   __asm mov eax, val
+   __asm mov ebx, var
+   __asm lock add [ebx]Atomic_uint32.value, eax
+#else
+#error No compiler defined for Atomic_Add
+#endif
+}
+#define Atomic_Add32 Atomic_Add
+
+
+#if defined(__x86_64__)
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Atomic_Add64 --
+ *
+ *      Atomic read, add a value, write.
+ *
+ * Results:
+ *      None
+ *
+ * Side effects:
+ *      None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE void
+Atomic_Add64(Atomic_uint64 *var, // IN
+             uint64 val)         // IN
+{
+#if defined(__GNUC__)
+   /* Checked against the AMD manual and GCC --hpreg */
+   __asm__ __volatile__(
+      "lock; addq %1, %0"
+      : "+m" (var->value)
+      : "ri" (val)
+      : "cc"
+   );
+   AtomicEpilogue();
+#elif _MSC_VER
+   _InterlockedExchangeAdd64((__int64 *)&var->value, (__int64)val);
+#else
+#error No compiler defined for Atomic_Add64
+#endif
+}
+#endif
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Atomic_Sub --
+ *
+ *      Atomic read, subtract a value, write.
+ *
+ * Results:
+ *      None
+ *
+ * Side effects:
+ *      None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE void
+Atomic_Sub(Atomic_uint32 *var, // IN
+           uint32 val)         // IN
+{
+#ifdef __GNUC__
+   /* Checked against the Intel manual and GCC --walken */
+   __asm__ __volatile__(
+      "lock; subl %1, %0"
+#   if VM_ASM_PLUS
+      : "+m" (var->value)
+      : "ri" (val)
+#   else
+      : "=m" (var->value)
+      : "ri" (val),
+        "0" (var->value)
+#   endif
+      : "cc"
+   );
+   AtomicEpilogue();
+#elif _MSC_VER >= 1310
+   _InterlockedExchangeAdd((long *)&var->value, (long)-val);
+#elif _MSC_VER
+   __asm mov eax, val
+   __asm mov ebx, var
+   __asm lock sub [ebx]Atomic_uint32.value, eax
+#else
+#error No compiler defined for Atomic_Sub
+#endif
+}
+#define Atomic_Sub32 Atomic_Sub
+
+
+#if defined(__x86_64__)
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Atomic_Sub64 --
+ *
+ *      Atomic read, subtract a value, write.
+ *
+ * Results:
+ *      None
+ *
+ * Side effects:
+ *      None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE void
+Atomic_Sub64(Atomic_uint64 *var, // IN
+             uint64 val)         // IN
+{
+#ifdef __GNUC__
+   /* Checked against the AMD manual and GCC --hpreg */
+   __asm__ __volatile__(
+      "lock; subq %1, %0"
+      : "+m" (var->value)
+      : "ri" (val)
+      : "cc"
+   );
+   AtomicEpilogue();
+#elif _MSC_VER
+   _InterlockedExchangeAdd64((__int64 *)&var->value, (__int64)-val);
+#else
+#error No compiler defined for Atomic_Sub64
+#endif
+}
+#endif
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Atomic_Inc --
+ *
+ *      Atomic read, increment, write.
+ *
+ * Results:
+ *      None
+ *
+ * Side effects:
+ *      None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE void
+Atomic_Inc(Atomic_uint32 *var) // IN
+{
+#ifdef __GNUC__
+   /* Checked against the Intel manual and GCC --walken */
+   __asm__ __volatile__(
+      "lock; incl %0"
+#   if VM_ASM_PLUS
+      : "+m" (var->value)
+      :
+#   else
+      : "=m" (var->value)
+      : "0" (var->value)
+#   endif
+      : "cc"
+   );
+   AtomicEpilogue();
+#elif _MSC_VER >= 1310
+   _InterlockedIncrement((long *)&var->value);
+#elif _MSC_VER
+   __asm mov ebx, var
+   __asm lock inc [ebx]Atomic_uint32.value
+#else
+#error No compiler defined for Atomic_Inc
+#endif
+}
+#define Atomic_Inc32 Atomic_Inc
+
+
+#if defined(__x86_64__)
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Atomic_Inc64 --
+ *
+ *      Atomic read, increment, write.
+ *
+ * Results:
+ *      None
+ *
+ * Side effects:
+ *      None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE void
+Atomic_Inc64(Atomic_uint64 *var) // IN
+{
+#if defined(__GNUC__)
+   /* Checked against the AMD manual and GCC --hpreg */
+   __asm__ __volatile__(
+      "lock; incq %0"
+      : "+m" (var->value)
+      :
+      : "cc"
+   );
+   AtomicEpilogue();
+#elif _MSC_VER
+   _InterlockedIncrement64((__int64 *)&var->value);
+#else
+#error No compiler defined for Atomic_Inc64
+#endif
+}
+#endif
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Atomic_Dec --
+ *
+ *      Atomic read, decrement, write.
+ *
+ * Results:
+ *      None
+ *
+ * Side effects:
+ *      None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE void
+Atomic_Dec(Atomic_uint32 *var) // IN
+{
+#ifdef __GNUC__
+   /* Checked against the Intel manual and GCC --walken */
+   __asm__ __volatile__(
+      "lock; decl %0"
+#   if VM_ASM_PLUS
+      : "+m" (var->value)
+      :
+#   else
+      : "=m" (var->value)
+      : "0" (var->value)
+#   endif
+      : "cc"
+   );
+   AtomicEpilogue();
+#elif _MSC_VER >= 1310
+   _InterlockedDecrement((long *)&var->value);
+#elif _MSC_VER
+   __asm mov ebx, var
+   __asm lock dec [ebx]Atomic_uint32.value
+#else
+#error No compiler defined for Atomic_Dec
+#endif
+}
+#define Atomic_Dec32 Atomic_Dec
+
+
+#if defined(__x86_64__)
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Atomic_Dec64 --
+ *
+ *      Atomic read, decrement, write.
+ *
+ * Results:
+ *      None
+ *
+ * Side effects:
+ *      None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE void
+Atomic_Dec64(Atomic_uint64 *var) // IN
+{
+#if defined(__GNUC__)
+   /* Checked against the AMD manual and GCC --hpreg */
+   __asm__ __volatile__(
+      "lock; decq %0"
+      : "+m" (var->value)
+      :
+      : "cc"
+   );
+   AtomicEpilogue();
+#elif _MSC_VER
+   _InterlockedDecrement64((__int64 *)&var->value);
+#else
+#error No compiler defined for Atomic_Dec64
+#endif
+}
+#endif
+
+
+/*
+ * Note that the technique below can be used to implement ReadX(), where X is
+ * an arbitrary mathematical function.
+ */
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Atomic_FetchAndOr --
+ *
+ *      Atomic read (returned), bitwise OR with a value, write.
+ *
+ * Results:
+ *      The value of the variable before the operation.
+ *
+ * Side effects:
+ *      None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE uint32
+Atomic_FetchAndOr(Atomic_uint32 *var, // IN
+                  uint32 val)         // IN
+{
+   uint32 res;
+
+   do {
+      res = var->value;
+   } while (res != Atomic_ReadIfEqualWrite(var, res, res | val));
+
+   return res;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Atomic_FetchAndAnd --
+ *
+ *      Atomic read (returned), bitwise And with a value, write.
+ *
+ * Results:
+ *      The value of the variable before the operation.
+ *
+ * Side effects:
+ *      None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE uint32
+Atomic_FetchAndAnd(Atomic_uint32 *var, // IN
+                   uint32 val)         // IN
+{
+   uint32 res;
+
+   do {
+      res = var->value;
+   } while (res != Atomic_ReadIfEqualWrite(var, res, res & val));
+
+   return res;
+}
+#define Atomic_ReadOr32 Atomic_FetchAndOr
+
+
+#if defined(__x86_64__)
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Atomic_ReadOr64 --
+ *
+ *      Atomic read (returned), bitwise OR with a value, write.
+ *
+ * Results:
+ *      The value of the variable before the operation.
+ *
+ * Side effects:
+ *      None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE uint64
+Atomic_ReadOr64(Atomic_uint64 *var, // IN
+                uint64 val)         // IN
+{
+   uint64 res;
+
+   do {
+      res = var->value;
+   } while (res != Atomic_ReadIfEqualWrite64(var, res, res | val));
+
+   return res;
+}
+#endif
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Atomic_FetchAndAddUnfenced --
+ *
+ *      Atomic read (returned), add a value, write.
+ *
+ *      If you have to implement FetchAndAdd() on an architecture other than
+ *      x86 or x86-64, you might want to consider doing something similar to
+ *      Atomic_FetchAndOr().
+ *
+ *      The "Unfenced" version of Atomic_FetchAndInc never executes
+ *      "lfence" after the interlocked operation.
+ *
+ * Results:
+ *      The value of the variable before the operation.
+ *
+ * Side effects:
+ *      None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE uint32
+Atomic_FetchAndAddUnfenced(Atomic_uint32 *var, // IN
+                           uint32 val)         // IN
+#ifdef __GNUC__
+{
+   /* Checked against the Intel manual and GCC --walken */
+   __asm__ __volatile__(
+#   if VM_ASM_PLUS
+      "lock; xaddl %0, %1"
+      : "=r" (val),
+	"+m" (var->value)
+      : "0" (val)
+      : "cc"
+#   else
+      "lock; xaddl %0, (%1)"
+      : "=r" (val)
+      : "r" (&var->value),
+	"0" (val)
+      : "cc", "memory"
+#   endif
+   );
+   return val;
+}
+#elif _MSC_VER >= 1310
+{
+   return _InterlockedExchangeAdd((long *)&var->value, (long)val);
+}
+#elif _MSC_VER
+#pragma warning(push)
+#pragma warning(disable : 4035)         // disable no-return warning
+{
+   __asm mov eax, val
+   __asm mov ebx, var
+   __asm lock xadd [ebx]Atomic_uint32.value, eax
+}
+#pragma warning(pop)
+#else
+#error No compiler defined for Atomic_FetchAndAdd
+#endif
+#define Atomic_ReadAdd32 Atomic_FetchAndAdd
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Atomic_FetchAndAdd --
+ *
+ *      Atomic read (returned), add a value, write.
+ *
+ *      If you have to implement FetchAndAdd() on an architecture other than
+ *      x86 or x86-64, you might want to consider doing something similar to
+ *      Atomic_FetchAndOr().
+ *
+ *      Unlike "Unfenced" version, this one may execute the "lfence" after
+ *      interlocked operation.
+ *
+ * Results:
+ *      The value of the variable before the operation.
+ *
+ * Side effects:
+ *      None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE uint32
+Atomic_FetchAndAdd(Atomic_uint32 *var, // IN
+                   uint32 val)         // IN
+#ifdef __GNUC__
+{
+   val = Atomic_FetchAndAddUnfenced(var, val);
+   AtomicEpilogue();
+   return val;
+}
+#else
+{
+   return Atomic_FetchAndAddUnfenced(var, val);
+}
+#endif
+
+
+#if defined(__x86_64__)
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Atomic_ReadAdd64 --
+ *
+ *      Atomic read (returned), add a value, write.
+ *
+ * Results:
+ *      The value of the variable before the operation.
+ *
+ * Side effects:
+ *      None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE uint64
+Atomic_ReadAdd64(Atomic_uint64 *var, // IN
+                 uint64 val)         // IN
+{
+#if defined(__GNUC__)
+   /* Checked against the AMD manual and GCC --hpreg */
+   __asm__ __volatile__(
+      "lock; xaddq %0, %1"
+      : "=r" (val),
+	"+m" (var->value)
+      : "0" (val)
+      : "cc"
+   );
+   AtomicEpilogue();
+   return val;
+#elif _MSC_VER
+   return _InterlockedExchangeAdd64((__int64 *)&var->value, (__int64)val);
+#else
+#error No compiler defined for Atomic_ReadAdd64
+#endif
+}
+#endif
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Atomic_FetchAndInc --
+ *
+ *      Atomic read (returned), increment, write.
+ *
+ * Results:
+ *      The value of the variable before the operation.
+ *
+ * Side effects:
+ *      None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE uint32
+Atomic_FetchAndInc(Atomic_uint32 *var) // IN
+{
+   return Atomic_FetchAndAdd(var, 1);
+}
+#define Atomic_ReadInc32 Atomic_FetchAndInc
+
+
+#if defined(__x86_64__)
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Atomic_ReadInc64 --
+ *
+ *      Atomic read (returned), increment, write.
+ *
+ * Results:
+ *      The value of the variable before the operation.
+ *
+ * Side effects:
+ *      None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE uint64
+Atomic_ReadInc64(Atomic_uint64 *var) // IN
+{
+   return Atomic_ReadAdd64(var, 1);
+}
+#endif
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Atomic_FetchAndDec --
+ *
+ *      Atomic read (returned), decrement, write.
+ *
+ * Results:
+ *      The value of the variable before the operation.
+ *
+ * Side effects:
+ *      None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE uint32
+Atomic_FetchAndDec(Atomic_uint32 *var) // IN
+{
+   return Atomic_FetchAndAdd(var, (uint32)-1);
+}
+#define Atomic_ReadDec32 Atomic_FetchAndDec
+
+
+#if defined(__x86_64__)
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Atomic_ReadDec64 --
+ *
+ *      Atomic read (returned), decrement, write.
+ *
+ * Results:
+ *      The value of the variable before the operation.
+ *
+ * Side effects:
+ *      None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE uint64
+Atomic_ReadDec64(Atomic_uint64 *var) // IN
+{
+   return Atomic_ReadAdd64(var, CONST64U(-1));
+}
+#endif
+
+
+/*
+ * Usage of this helper struct is strictly reserved to the following
+ * function. --hpreg
+ */
+typedef struct {
+   uint32 lowValue;
+   uint32 highValue;
+} S_uint64;
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Atomic_CMPXCHG64 --
+ *
+ *      Compare exchange: Read variable, if equal to oldVal, write newVal
+ *
+ *      XXX: Ensure that if this function is to be inlined by gcc, it is 
+ *      compiled with -fno-strict-aliasing. Otherwise it will break. 
+ *      Unfortunately we know that gcc 2.95.3 (used to build the FreeBSD 3.2
+ *      Tools) does not honor -fno-strict-aliasing. As a workaround, we avoid 
+ *      inlining the function entirely for versions of gcc under 3.0.
+ *
+ * Results:
+ *      TRUE if equal, FALSE if not equal
+ *
+ * Side effects:
+ *      None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+#if defined(__GNUC__) && __GNUC__ < 3
+static Bool
+#else
+static INLINE Bool
+#endif
+Atomic_CMPXCHG64(Atomic_uint64 *var,   // IN/OUT
+                 uint64 const *oldVal, // IN
+                 uint64 const *newVal) // IN
+#ifdef __GNUC__
+{
+   Bool equal;
+
+   /* Checked against the Intel manual and GCC --walken */
+#ifdef VMM64
+   uint64 dummy;
+   __asm__ __volatile__(
+      "lock; cmpxchgq %3, %0" "\n\t"
+      "sete %1"
+      : "+m" (*var),
+	"=qm" (equal),
+	"=a" (dummy)
+      : "r" (*newVal),
+        "2" (*oldVal)
+      : "cc"
+   );
+#else /* 32-bit version */
+   int dummy1, dummy2;
+#   if defined __PIC__ && !vm_x86_64 // %ebx is reserved by the compiler.
+#      if defined __GNUC__ && __GNUC__ < 3 // Part of #188541 - for RHL 6.2 etc.
+   __asm__ __volatile__(
+      "xchg %%ebx, %6\n\t"
+      "mov (%%ebx), %%ecx\n\t"
+      "mov (%%ebx), %%ebx\n\t"
+      "lock; cmpxchg8b (%3)\n\t"
+      "xchg %%ebx, %6\n\t"
+      "sete %0"
+      : "=a" (equal), "=d" (dummy2), "=D" (dummy1)
+      : "S" (var), "0" (((S_uint64 const *)oldVal)->lowValue),
+        "1" (((S_uint64 const *)oldVal)->highValue), "D" (newVal)
+      : "ecx", "cc", "memory"
+      );
+#      else
+   __asm__ __volatile__(
+      "xchgl %%ebx, %6"      "\n\t"
+      // %3 is a register to make sure it cannot be %ebx-relative.
+      "lock; cmpxchg8b (%3)" "\n\t"
+      "xchgl %%ebx, %6"      "\n\t"
+      // Must come after restoring %ebx: %0 could be %ebx-relative.
+      "sete %0"
+      :	"=qm" (equal),
+	"=a" (dummy1),
+	"=d" (dummy2)
+      : "r" (var),
+        "1" (((S_uint64 const *)oldVal)->lowValue),
+        "2" (((S_uint64 const *)oldVal)->highValue),
+        // Cannot use "m" here: 'newVal' is read-only.
+        "r" (((S_uint64 const *)newVal)->lowValue),
+        "c" (((S_uint64 const *)newVal)->highValue)
+      : "cc", "memory"
+   );
+#      endif
+#   else
+   __asm__ __volatile__(
+      "lock; cmpxchg8b %0" "\n\t"
+      "sete %1"
+#      if VM_ASM_PLUS
+      : "+m" (*var),
+#      else
+      : "=m" (*var),
+#      endif
+	"=qm" (equal),
+	"=a" (dummy1),
+	"=d" (dummy2)
+      : "2" (((S_uint64 const *)oldVal)->lowValue),
+        "3" (((S_uint64 const *)oldVal)->highValue),
+        "b" (((S_uint64 const *)newVal)->lowValue),
+        "c" (((S_uint64 const *)newVal)->highValue)
+      : "cc"
+   );
+#   endif
+#endif
+   AtomicEpilogue();
+   return equal;
+} 
+#elif _MSC_VER
+#if defined(__x86_64__)
+{
+   return *oldVal == _InterlockedCompareExchange64((__int64 *)&var->value,
+                                                   (__int64)*newVal, 
+						   (__int64)*oldVal);
+}
+#else
+#pragma warning(push)
+#pragma warning(disable : 4035)		// disable no-return warning
+{
+   __asm mov esi, var
+   __asm mov edx, oldVal
+   __asm mov ecx, newVal
+   __asm mov eax, [edx]S_uint64.lowValue
+   __asm mov edx, [edx]S_uint64.highValue
+   __asm mov ebx, [ecx]S_uint64.lowValue
+   __asm mov ecx, [ecx]S_uint64.highValue
+   __asm lock cmpxchg8b [esi]
+   __asm sete al
+   __asm movzx eax, al
+   // eax is the return value, this is documented to work - edward
+} 
+#pragma warning(pop)
+#endif
+#else
+#error No compiler defined for Atomic_CMPXCHG64
+#endif
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Atomic_CMPXCHG32 --
+ *
+ *      Compare exchange: Read variable, if equal to oldVal, write newVal
+ *
+ * Results:
+ *      TRUE if equal, FALSE if not equal
+ *
+ * Side effects:
+ *      None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE Bool
+Atomic_CMPXCHG32(Atomic_uint32 *var,   // IN/OUT
+                 uint32 oldVal, // IN
+                 uint32 newVal) // IN
+{
+#ifdef __GNUC__
+   Bool equal;
+
+   uint32 dummy;
+   __asm__ __volatile__(
+      "lock; cmpxchgl %3, %0" "\n\t"
+      "sete %1"
+#   if VM_ASM_PLUS
+      : "+m" (*var),
+	"=qm" (equal),
+	"=a" (dummy)
+      : "r" (newVal),
+        "2" (oldVal)
+#   else
+      : "=m" (*var),
+	"=qm" (equal),
+	"=a" (dummy)
+      : /*"0" (*var), */
+        "r" (newVal),
+        "2" (oldVal)
+#   endif
+      : "cc"
+   );
+   AtomicEpilogue();
+   return equal;
+#else
+   return (Atomic_ReadIfEqualWrite(var, oldVal, newVal) == oldVal);
+#endif
+} 
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Atomic_Read64 --
+ *
+ *      Read and return.
+ *
+ * Results:
+ *      The value of the atomic variable.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE uint64
+Atomic_Read64(Atomic_uint64 const *var) // IN
+#if defined(__x86_64__)
+{
+   return var->value;
+}
+#elif defined(__GNUC__) && defined(__i386__) /* GCC on x86 */
+{
+   uint64 value;
+   /* 
+    * Since cmpxchg8b will replace the contents of EDX:EAX with the
+    * value in memory if there is no match, we need only execute the
+    * instruction once in order to atomically read 64 bits from
+    * memory.  The only constraint is that ECX:EBX must have the same
+    * value as EDX:EAX so that if the comparison succeeds.  We
+    * intentionally don't tell gcc that we are using ebx and ecx as we
+    * don't modify them and do not care what value they store.
+    */
+   __asm__ __volatile__(
+      "mov %%ebx, %%eax"   "\n\t"
+      "mov %%ecx, %%edx"   "\n\t"
+      "lock; cmpxchg8b %1"
+      : "=&A" (value)
+      : "m" (*var)
+      : "cc"
+   );
+   AtomicEpilogue();
+   return value;
+}
+#elif _MSC_VER /* MSC (assume on x86 for now) */
+#   pragma warning(push)
+#   pragma warning(disable : 4035)		// disable no-return warning
+{
+   __asm mov ecx, var
+   __asm mov edx, ecx
+   __asm mov eax, ebx
+   __asm lock cmpxchg8b [ecx]
+   // edx:eax is the return value; this is documented to work. --mann
+}
+#   pragma warning(pop)
+#else
+#   error No compiler defined for Atomic_Read64
+#endif
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * Atomic_FetchAndAdd64 --
+ *
+ *      Atomically adds a 64-bit integer to another
+ *
+ * Results:
+ *      Returns the old value just prior to the addition
+ *
+ * Side effects:
+ *      None
+ *
+ *----------------------------------------------------------------------
+ */
+
+static INLINE uint64
+Atomic_FetchAndAdd64(Atomic_uint64 *var, // IN/OUT
+		     uint64 addend)      // IN
+{
+   uint64 oldVal;
+   uint64 newVal;
+
+   do {
+      oldVal = var->value;
+      newVal = oldVal + addend;
+   } while (!Atomic_CMPXCHG64(var, &oldVal, &newVal));
+
+   return oldVal;
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * Atomic_FetchAndInc64 --
+ *
+ *      Atomically increments a 64-bit integer
+ *
+ * Results:
+ *      Returns the old value just prior to incrementing
+ *
+ * Side effects:
+ *      None
+ *
+ *----------------------------------------------------------------------
+ */
+
+static INLINE uint64
+Atomic_FetchAndInc64(Atomic_uint64 *var) // IN/OUT
+{
+   return Atomic_FetchAndAdd64(var, 1);
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * Atomic_FetchAndDec64 --
+ *
+ *      Atomically decrements a 64-bit integer
+ *
+ * Results:
+ *      Returns the old value just prior to decrementing
+ *
+ * Side effects:
+ *      None
+ *
+ *----------------------------------------------------------------------
+ */
+
+static INLINE uint64
+Atomic_FetchAndDec64(Atomic_uint64 *var) // IN/OUT
+{
+   uint64 oldVal;
+   uint64 newVal;
+
+   do {
+      oldVal = var->value;
+      newVal = oldVal - 1;
+   } while (!Atomic_CMPXCHG64(var, &oldVal, &newVal));
+
+   return oldVal;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Atomic_ReadWrite64 --
+ *
+ *      Read followed by write
+ *
+ * Results:
+ *      The value of the atomic variable before the write.
+ *
+ * Side effects:
+ *      None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE uint64
+Atomic_ReadWrite64(Atomic_uint64 *var, // IN
+                   uint64 val)         // IN
+{
+#if defined(__x86_64__)
+#if defined(__GNUC__)
+   /* Checked against the AMD manual and GCC --hpreg */
+   __asm__ __volatile__(
+      "xchgq %0, %1"
+      : "=r" (val),
+	"+m" (var->value)
+      : "0" (val)
+   );
+   AtomicEpilogue();
+   return val;
+#elif _MSC_VER
+   return _InterlockedExchange64((__int64 *)&var->value, (__int64)val);
+#else
+#error No compiler defined for Atomic_ReadWrite64
+#endif
+#else
+   uint64 oldVal;
+
+   do {
+      oldVal = var->value;
+   } while (!Atomic_CMPXCHG64(var, &oldVal, &val));
+
+   return oldVal;
+#endif
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Atomic_Write64 --
+ *
+ *      Write
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE void
+Atomic_Write64(Atomic_uint64 *var, // IN
+               uint64 val)         // IN
+{
+#if defined(__x86_64__)
+   var->value = val;
+#else
+   (void)Atomic_ReadWrite64(var, val);
+#endif
+}
+
+
+/*
+ * Template code for the Atomic_<name> type and its operators.
+ *
+ * The cast argument is an intermedia type cast to make some
+ * compilers stop complaining about casting uint32 <-> void *,
+ * even though we only do it in the 32-bit case so they are always
+ * the same size.  So for val of type uint32, instead of
+ * (void *)val, we have (void *)(uintptr_t)val.
+ * The specific problem case is the Windows ddk compiler
+ * (as used by the SVGA driver).  -- edward
+ */
+
+#define MAKE_ATOMIC_TYPE(name, size, in, out, cast)                           \
+   typedef Atomic_uint ## size Atomic_ ## name;                               \
+                                                                              \
+                                                                              \
+   static INLINE out                                                          \
+   Atomic_Read ## name(Atomic_ ## name const *var)                            \
+   {                                                                          \
+      return (out)(cast)Atomic_Read ## size(var);                             \
+   }                                                                          \
+                                                                              \
+                                                                              \
+   static INLINE void                                                         \
+   Atomic_Write ## name(Atomic_ ## name *var,                                 \
+                        in val)                                               \
+   {                                                                          \
+      Atomic_Write ## size(var, (uint ## size)(cast)val);                     \
+   }                                                                          \
+                                                                              \
+                                                                              \
+   static INLINE out                                                          \
+   Atomic_ReadWrite ## name(Atomic_ ## name *var,                             \
+                            in val)                                           \
+   {                                                                          \
+      return (out)(cast)Atomic_ReadWrite ## size(var,                         \
+		(uint ## size)(cast)val);                                     \
+   }                                                                          \
+                                                                              \
+                                                                              \
+   static INLINE out                                                          \
+   Atomic_ReadIfEqualWrite ## name(Atomic_ ## name *var,                      \
+                                   in oldVal,                                 \
+                                   in newVal)                                 \
+   {                                                                          \
+      return (out)(cast)Atomic_ReadIfEqualWrite ## size(var,                  \
+                (uint ## size)(cast)oldVal, (uint ## size)(cast)newVal);      \
+   }                                                                          \
+                                                                              \
+                                                                              \
+   static INLINE void                                                         \
+   Atomic_And ## name(Atomic_ ## name *var,                                   \
+                      in val)                                                 \
+   {                                                                          \
+      Atomic_And ## size(var, (uint ## size)(cast)val);                       \
+   }                                                                          \
+                                                                              \
+                                                                              \
+   static INLINE void                                                         \
+   Atomic_Or ## name(Atomic_ ## name *var,                                    \
+                     in val)                                                  \
+   {                                                                          \
+      Atomic_Or ## size(var, (uint ## size)(cast)val);                        \
+   }                                                                          \
+                                                                              \
+                                                                              \
+   static INLINE void                                                         \
+   Atomic_Xor ## name(Atomic_ ## name *var,                                   \
+                      in val)                                                 \
+   {                                                                          \
+      Atomic_Xor ## size(var, (uint ## size)(cast)val);                       \
+   }                                                                          \
+                                                                              \
+                                                                              \
+   static INLINE void                                                         \
+   Atomic_Add ## name(Atomic_ ## name *var,                                   \
+                      in val)                                                 \
+   {                                                                          \
+      Atomic_Add ## size(var, (uint ## size)(cast)val);                       \
+   }                                                                          \
+                                                                              \
+                                                                              \
+   static INLINE void                                                         \
+   Atomic_Sub ## name(Atomic_ ## name *var,                                   \
+                      in val)                                                 \
+   {                                                                          \
+      Atomic_Sub ## size(var, (uint ## size)(cast)val);                       \
+   }                                                                          \
+                                                                              \
+                                                                              \
+   static INLINE void                                                         \
+   Atomic_Inc ## name(Atomic_ ## name *var)                                   \
+   {                                                                          \
+      Atomic_Inc ## size(var);                                                \
+   }                                                                          \
+                                                                              \
+                                                                              \
+   static INLINE void                                                         \
+   Atomic_Dec ## name(Atomic_ ## name *var)                                   \
+   {                                                                          \
+      Atomic_Dec ## size(var);                                                \
+   }                                                                          \
+                                                                              \
+                                                                              \
+   static INLINE out                                                          \
+   Atomic_ReadOr ## name(Atomic_ ## name *var,                                \
+                         in val)                                              \
+   {                                                                          \
+      return (out)(cast)Atomic_ReadOr ## size(var, (uint ## size)(cast)val);  \
+   }                                                                          \
+                                                                              \
+                                                                              \
+   static INLINE out                                                          \
+   Atomic_ReadAdd ## name(Atomic_ ## name *var,                               \
+                          in val)                                             \
+   {                                                                          \
+      return (out)(cast)Atomic_ReadAdd ## size(var, (uint ## size)(cast)val); \
+   }                                                                          \
+                                                                              \
+                                                                              \
+   static INLINE out                                                          \
+   Atomic_ReadInc ## name(Atomic_ ## name *var)                               \
+   {                                                                          \
+      return (out)(cast)Atomic_ReadInc ## size(var);                          \
+   }                                                                          \
+                                                                              \
+                                                                              \
+   static INLINE out                                                          \
+   Atomic_ReadDec ## name(Atomic_ ## name *var)                               \
+   {                                                                          \
+      return (out)(cast)Atomic_ReadDec ## size(var);                          \
+   }
+
+
+/*
+ * Since we use a macro to generate these definitions, it is hard to look for
+ * them. So DO NOT REMOVE THIS COMMENT and keep it up-to-date. --hpreg
+ *
+ * Atomic_Ptr
+ * Atomic_ReadPtr --
+ * Atomic_WritePtr --
+ * Atomic_ReadWritePtr --
+ * Atomic_ReadIfEqualWritePtr --
+ * Atomic_AndPtr --
+ * Atomic_OrPtr --
+ * Atomic_XorPtr --
+ * Atomic_AddPtr --
+ * Atomic_SubPtr --
+ * Atomic_IncPtr --
+ * Atomic_DecPtr --
+ * Atomic_ReadOrPtr --
+ * Atomic_ReadAddPtr --
+ * Atomic_ReadIncPtr --
+ * Atomic_ReadDecPtr --
+ *
+ * Atomic_Int
+ * Atomic_ReadInt --
+ * Atomic_WriteInt --
+ * Atomic_ReadWriteInt --
+ * Atomic_ReadIfEqualWriteInt --
+ * Atomic_AndInt --
+ * Atomic_OrInt --
+ * Atomic_XorInt --
+ * Atomic_AddInt --
+ * Atomic_SubInt --
+ * Atomic_IncInt --
+ * Atomic_DecInt --
+ * Atomic_ReadOrInt --
+ * Atomic_ReadAddInt --
+ * Atomic_ReadIncInt --
+ * Atomic_ReadDecInt --
+ */
+#if defined(__x86_64__)
+MAKE_ATOMIC_TYPE(Ptr, 64, void const *, void *, uintptr_t)
+MAKE_ATOMIC_TYPE(Int, 64, int, int, int)
+#else
+MAKE_ATOMIC_TYPE(Ptr, 32, void const *, void *, uintptr_t)
+MAKE_ATOMIC_TYPE(Int, 32, int, int, int)
+#endif
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Atomic_MFence --
+ *
+ *      Implements mfence in terms of a lock xor. The reason for implementing
+ *      our own mfence is that not all of our supported cpus have an assembly
+ *      mfence (P3, Athlon). We put it here to avoid duplicating code which is
+ *      also why it is prefixed with "Atomic_".
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      Cause loads and stores prior to this to be globally
+ *      visible.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE void
+Atomic_MFence(void)
+{
+   Atomic_uint32 fence;
+   Atomic_Xor(&fence, 0x1);
+}
+
+#endif // ifndef _ATOMIC_H_
--- kernel/linux-2.6.26.3/drivers/misc/vmci/vm_basic_defs.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmci/vm_basic_defs.h	2008-09-03 10:01:42.000000000 -0500
@@ -0,0 +1,606 @@
+/*********************************************************
+ * Copyright (C) 2003 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * vm_basic_defs.h --
+ *
+ *	Standard macros for VMware source code.
+ */
+
+#ifndef _VM_BASIC_DEFS_H_
+#define _VM_BASIC_DEFS_H_
+
+#define INCLUDE_ALLOW_USERLEVEL
+#define INCLUDE_ALLOW_VMMEXT
+#define INCLUDE_ALLOW_MODULE
+#define INCLUDE_ALLOW_VMMON
+#define INCLUDE_ALLOW_VMNIXMOD
+#define INCLUDE_ALLOW_VMKERNEL
+#define INCLUDE_ALLOW_VMKDRIVERS
+#define INCLUDE_ALLOW_VMK_MODULE
+#define INCLUDE_ALLOW_DISTRIBUTE
+#define INCLUDE_ALLOW_VMCORE
+#define INCLUDE_ALLOW_VMIROM
+#include "includeCheck.h"
+#include "vm_basic_types.h" // For INLINE.
+
+/* Checks for FreeBSD, filtering out VMKERNEL. */
+#define __IS_FREEBSD__ (!defined(VMKERNEL) && defined(__FreeBSD__))
+#define __IS_FREEBSD_VER__(ver) (__IS_FREEBSD__ && __FreeBSD_version >= (ver))
+
+#if defined _WIN32 && defined USERLEVEL
+   #include <stddef.h>  /*
+                         * We re-define offsetof macro from stddef, make 
+                         * sure that its already defined before we do it
+                         */
+   #include <windows.h>	// for Sleep() and LOWORD() etc.
+#endif
+
+
+/*
+ * Simple macros
+ */
+
+#if (defined __APPLE__ || defined __FreeBSD__) && \
+    (!defined KERNEL && !defined _KERNEL && !defined VMKERNEL && !defined __KERNEL__)
+#   include <stddef.h>
+#else
+// XXX the __cplusplus one matches that of VC++, to prevent redefinition warning
+// XXX the other one matches that of gcc3.3.3/glibc2.2.4 to prevent redefinition warnings
+#ifndef offsetof
+#ifdef __cplusplus
+#define offsetof(s,m)   (size_t)&(((s *)0)->m)
+#else
+#define offsetof(TYPE, MEMBER) ((size_t) &((TYPE *)0)->MEMBER)
+#endif
+#endif
+#endif // __APPLE__
+
+#ifndef ARRAYSIZE
+#define ARRAYSIZE(a) (sizeof (a) / sizeof *(a))
+#endif
+
+#ifndef MIN
+#define MIN(_a, _b)   (((_a) < (_b)) ? (_a) : (_b))
+#endif
+
+/* The Solaris 9 cross-compiler complains about these not being used */
+#ifndef sun
+static INLINE int 
+Min(int a, int b)
+{
+   return a < b ? a : b;
+}
+#endif
+
+#ifndef MAX
+#define MAX(_a, _b)   (((_a) > (_b)) ? (_a) : (_b))
+#endif
+
+#ifndef sun
+static INLINE int 
+Max(int a, int b)
+{
+   return a > b ? a : b;
+}
+#endif
+
+#define ROUNDUP(x,y)		(((x) + (y) - 1) / (y) * (y))
+#define ROUNDDOWN(x,y)		((x) / (y) * (y))
+#define ROUNDUPBITS(x, bits)	(((uintptr_t) (x) + MASK(bits)) & ~MASK(bits))
+#define ROUNDDOWNBITS(x, bits)	((uintptr_t) (x) & ~MASK(bits))
+#define CEILING(x, y)		(((x) + (y) - 1) / (y))
+#if defined __APPLE__
+#include <machine/param.h>
+#undef MASK
+#endif
+#define MASK(n)			((1 << (n)) - 1)	/* make an n-bit mask */
+#define DWORD_ALIGN(x)          ((((x)+3) >> 2) << 2)
+#define QWORD_ALIGN(x)          ((((x)+4) >> 3) << 3)
+
+#define IMPLIES(a,b) (!(a) || (b))
+
+/*
+ * Not everybody (e.g., the monitor) has NULL
+ */
+
+#ifndef NULL
+#ifdef  __cplusplus
+#define NULL    0
+#else
+#define NULL    ((void *)0)
+#endif
+#endif
+
+
+/* 
+ * Token concatenation
+ *
+ * The C preprocessor doesn't prescan arguments when they are
+ * concatenated or stringified.  So we need extra levels of
+ * indirection to convince the preprocessor to expand its
+ * arguments.
+ */
+
+#define CONC(x, y)              x##y
+#define XCONC(x, y)             CONC(x, y)
+#define XXCONC(x, y)            XCONC(x, y)
+#define MAKESTR(x)              #x
+#define XSTR(x)                 MAKESTR(x)
+
+
+/*
+ * Page operations
+ *
+ * It has been suggested that these definitions belong elsewhere
+ * (like x86types.h).  However, I deem them common enough
+ * (since even regular user-level programs may want to do
+ * page-based memory manipulation) to be here.
+ * -- edward
+ */
+
+#ifndef PAGE_SHIFT // {
+#if defined VM_I386
+   #define PAGE_SHIFT    12
+#elif defined __APPLE__
+   #define PAGE_SHIFT    12
+#else
+   #error
+#endif
+#endif // }
+
+#ifndef PAGE_SIZE
+#define PAGE_SIZE     (1<<PAGE_SHIFT)
+#endif
+
+#ifndef PAGE_MASK
+#define PAGE_MASK     (PAGE_SIZE - 1)
+#endif
+
+#ifndef PAGE_OFFSET
+#define PAGE_OFFSET(_addr)  ((uintptr_t)(_addr)&(PAGE_SIZE-1))
+#endif
+
+#ifndef VM_PAGE_BASE
+#define VM_PAGE_BASE(_addr)  ((_addr)&~(PAGE_SIZE-1))
+#endif
+
+#ifndef VM_PAGES_SPANNED
+#define VM_PAGES_SPANNED(_addr, _size) \
+   ((((_addr) & (PAGE_SIZE - 1)) + (_size) + (PAGE_SIZE - 1)) >> PAGE_SHIFT)
+#endif
+
+#ifndef BYTES_2_PAGES
+#define BYTES_2_PAGES(_nbytes) ((_nbytes) >> PAGE_SHIFT)
+#endif
+
+#ifndef PAGES_2_BYTES
+#define PAGES_2_BYTES(_npages) (((uint64)(_npages)) << PAGE_SHIFT)
+#endif
+
+#ifndef MBYTES_2_PAGES
+#define MBYTES_2_PAGES(_nbytes) ((_nbytes) << (20 - PAGE_SHIFT))
+#endif
+
+#ifndef PAGES_2_MBYTES
+#define PAGES_2_MBYTES(_npages) ((_npages) >> (20 - PAGE_SHIFT))
+#endif
+
+#ifndef VM_PAE_LARGE_PAGE_SHIFT
+#define VM_PAE_LARGE_PAGE_SHIFT 21
+#endif 
+
+#ifndef VM_PAE_LARGE_PAGE_SIZE
+#define VM_PAE_LARGE_PAGE_SIZE (1 << VM_PAE_LARGE_PAGE_SHIFT)
+#endif
+
+#ifndef VM_PAE_LARGE_PAGE_MASK
+#define VM_PAE_LARGE_PAGE_MASK (VM_PAE_LARGE_PAGE_SIZE - 1)
+#endif
+
+#ifndef VM_PAE_LARGE_2_SMALL_PAGES
+#define VM_PAE_LARGE_2_SMALL_PAGES (BYTES_2_PAGES(VM_PAE_LARGE_PAGE_SIZE))
+#endif
+
+/*
+ * Word operations
+ */
+
+#ifndef LOWORD
+#define LOWORD(_dw)   ((_dw) & 0xffff)
+#endif
+#ifndef HIWORD
+#define HIWORD(_dw)   (((_dw) >> 16) & 0xffff)
+#endif
+
+#ifndef LOBYTE
+#define LOBYTE(_w)    ((_w) & 0xff)
+#endif
+#ifndef HIBYTE
+#define HIBYTE(_w)    (((_w) >> 8) & 0xff)
+#endif
+
+#define HIDWORD(_qw)   ((uint32)((_qw) >> 32))
+#define LODWORD(_qw)   ((uint32)(_qw))
+#define QWORD(_hi, _lo)   ((((uint64)(_hi)) << 32) | ((uint32)(_lo)))
+
+
+/*
+ * Deposit a field _src at _pos bits from the right,
+ * with a length of _len, into the integer _target.
+ */
+
+#define DEPOSIT_BITS(_src,_pos,_len,_target) { \
+	unsigned mask = ((1 << _len) - 1); \
+	unsigned shiftedmask = ((1 << _len) - 1) << _pos; \
+	_target = (_target & ~shiftedmask) | ((_src & mask) << _pos); \
+}
+
+
+/*
+ * Get return address.
+ */
+
+#ifdef _MSC_VER
+#ifdef __cplusplus
+extern "C"
+#endif 
+void *_ReturnAddress(void);
+#pragma intrinsic(_ReturnAddress)
+#define GetReturnAddress() _ReturnAddress()
+#elif __GNUC__
+#define GetReturnAddress() __builtin_return_address(0)
+#endif
+
+
+#ifdef __GNUC__
+#ifndef sun
+
+/*
+ * Get the frame pointer. We use this assembly hack instead of
+ * __builtin_frame_address() due to a bug introduced in gcc 4.1.1
+ */
+static INLINE_SINGLE_CALLER uintptr_t
+GetFrameAddr(void)
+{
+   uintptr_t bp;
+#if (__GNUC__ < 4 || (__GNUC__ == 4 && __GNUC_MINOR__ == 0))
+   bp = (uintptr_t)__builtin_frame_address(0);
+#elif (__GNUC__ == 4 && __GNUC_MINOR__ == 1 && __GNUC_PATCHLEVEL__ <= 3)
+#  if defined(VMM64) || defined(VM_X86_64)
+     __asm__ __volatile__("movq %%rbp, %0\n" : "=g" (bp));
+#  else
+     __asm__ __volatile__("movl %%ebp, %0\n" : "=g" (bp));
+#  endif
+#else
+   __asm__ __volatile__(
+#ifdef __linux__
+      ".print \"This newer version of GCC may or may not have the "
+               "__builtin_frame_address bug.  Need to update this. "
+               "See bug 147638.\"\n"
+      ".abort"
+#else /* MacOS */
+      ".abort \"This newer version of GCC may or may not have the "
+               "__builtin_frame_address bug.  Need to update this. "
+               "See bug 147638.\"\n"
+#endif
+      : "=g" (bp)
+   );
+#endif
+   return bp;
+}
+
+
+/*
+ * Returns the frame pointer of the calling function.
+ * Equivalent to __builtin_frame_address(1).
+ */
+static INLINE_SINGLE_CALLER uintptr_t
+GetCallerFrameAddr(void)
+{
+   return *(uintptr_t*)GetFrameAddr();
+}
+
+#endif // sun
+#endif // __GNUC__
+
+/*
+ * Data prefetch was added in gcc 3.1.1
+ * http://www.gnu.org/software/gcc/gcc-3.1/changes.html
+ */
+#ifdef __GNUC__
+#  if ((__GNUC__ > 3) || (__GNUC__ == 3 && __GNUC_MINOR__ > 1) || \
+       (__GNUC__ == 3 && __GNUC_MINOR__ == 1 && __GNUC_PATCHLEVEL__ >= 1))
+#     define PREFETCH_R(var) __builtin_prefetch((var), 0 /* read */, \
+                                                3 /* high temporal locality */)
+#     define PREFETCH_W(var) __builtin_prefetch((var), 1 /* write */, \
+                                                3 /* high temporal locality */)
+#  else
+#     define PREFETCH_R(var) ((void)(var))
+#     define PREFETCH_W(var) ((void)(var))
+#  endif
+#endif /* __GNUC__ */
+
+
+#ifdef USERLEVEL // {
+
+/*
+ * Note this might be a problem on NT b/c while sched_yield guarantees it
+ * moves you to the end of your priority list, Sleep(0) offers no such
+ * guarantee.  Bummer.  --Jeremy.
+ */
+
+#if defined(N_PLAT_NLM)
+/* We do not have YIELD() as we do not need it yet... */
+#elif defined(_WIN32)
+#      define YIELD()		Sleep(0)
+#else
+#      include <sched.h>        // For sched_yield.  Don't ask.  --Jeremy.
+#      define YIELD()		sched_yield()
+#endif 
+
+
+/*
+ * Standardize some Posix names on Windows.
+ */
+
+#ifdef _WIN32 // {
+
+#define  snprintf  _snprintf
+#define	vsnprintf _vsnprintf
+
+static INLINE void
+sleep(unsigned int sec)
+{
+   Sleep(sec * 1000);
+}
+
+static INLINE void
+usleep(unsigned long usec)
+{
+   Sleep(CEILING(usec, 1000));
+}
+
+typedef int pid_t;
+#define       F_OK          0
+#define       X_OK          1
+#define       W_OK          2
+#define       R_OK          4
+
+#endif // }
+
+/*
+ * Macro for username comparison.
+ */
+
+#ifdef _WIN32 // {
+#define USERCMP(x,y)  Str_Strcasecmp(x,y)
+#else
+#define USERCMP(x,y)  strcmp(x,y)
+#endif // }
+
+
+#endif // }
+
+#ifndef va_copy
+
+#ifdef _WIN32
+
+/*
+ * Windows needs va_copy. This works for both 32 and 64-bit Windows
+ * based on inspection of how varags.h from the Visual C CRTL is
+ * implemented. (Future versions of the RTL may break this).
+ */
+
+#define va_copy(dest, src) ((dest) = (src))
+
+#elif defined(__APPLE__) && defined(KERNEL)
+
+/*
+ * MacOS kernel-mode needs va_copy. Based on inspection of stdarg.h
+ * from the MacOSX10.4u.sdk kernel framework, this should work.
+ * (Future versions of the SDK may break this).
+ */
+
+#define va_copy(dest, src) ((dest) = (src))
+
+#elif defined(__GNUC__) && (__GNUC__ < 3)
+
+/*
+ * Old versions of gcc recognize __va_copy, but not va_copy.
+ */
+
+#define va_copy(dest, src) __va_copy(dest, src)
+
+#endif // _WIN32
+
+#endif // va_copy
+
+/*
+ * This one is outside USERLEVEL because it's used by
+ * files compiled into the Windows hgfs driver or the display
+ * driver.
+ */
+
+#ifdef _WIN32
+#define PATH_MAX 256
+#ifndef strcasecmp
+#define strcasecmp(_s1,_s2)   _stricmp((_s1),(_s2))
+#endif
+#ifndef strncasecmp
+#define strncasecmp(_s1,_s2,_n)   _strnicmp((_s1),(_s2),(_n))
+#endif
+#endif
+
+/* 
+ * Convenience macro for COMMUNITY_SOURCE
+ */
+#undef EXCLUDE_COMMUNITY_SOURCE
+#ifdef COMMUNITY_SOURCE
+   #define EXCLUDE_COMMUNITY_SOURCE(x) 
+#else
+   #define EXCLUDE_COMMUNITY_SOURCE(x) x
+#endif
+
+#undef COMMUNITY_SOURCE_INTEL_SECRET
+#if !defined(COMMUNITY_SOURCE) || defined(INTEL_SOURCE)
+/*
+ * It's ok to include INTEL_SECRET source code for non-commsrc,
+ * or for drops directed at Intel.
+ */
+   #define COMMUNITY_SOURCE_INTEL_SECRET
+#endif
+
+/*
+ * Convenience macros and definitions. Can often be used instead of #ifdef.
+ */
+
+#undef DEBUG_ONLY
+#undef SL_DEBUG_ONLY
+#undef VMX86_SL_DEBUG
+#ifdef VMX86_DEBUG
+#define vmx86_debug      1
+#define DEBUG_ONLY(x)    x
+/*
+ * Be very, very, very careful with SL_DEBUG. Pls ask ganesh or min before 
+ * using it.
+ */
+#define VMX86_SL_DEBUG
+#define vmx86_sl_debug   1
+#define SL_DEBUG_ONLY(x) x
+#else
+#define vmx86_debug      0
+#define DEBUG_ONLY(x)
+#define vmx86_sl_debug   0
+#define SL_DEBUG_ONLY(x)
+#endif
+
+#ifdef VMX86_STATS
+#define vmx86_stats   1
+#define STATS_ONLY(x) x
+#else
+#define vmx86_stats   0
+#define STATS_ONLY(x)
+#endif
+
+#ifdef VMX86_DEVEL
+#define vmx86_devel   1
+#define DEVEL_ONLY(x) x
+#else
+#define vmx86_devel   0
+#define DEVEL_ONLY(x)
+#endif
+
+#ifdef VMX86_LOG
+#define vmx86_log     1
+#define LOG_ONLY(x)   x
+#else
+#define vmx86_log     0
+#define LOG_ONLY(x)
+#endif
+
+#ifdef VMX86_VMM_SERIAL_LOGGING
+#define vmx86_vmm_serial_log     1
+#define VMM_SERIAL_LOG_ONLY(x)   x
+#else
+#define vmx86_vmm_serial_log     0
+#define VMM_SERIAL_LOG_ONLY(x)
+#endif
+
+#ifdef VMX86_SERVER
+#define vmx86_server 1
+#define SERVER_ONLY(x) x
+#define HOSTED_ONLY(x)
+#else
+#define vmx86_server 0
+#define SERVER_ONLY(x)
+#define HOSTED_ONLY(x) x
+#endif
+
+#ifdef VMX86_WGS
+#define vmx86_wgs 1
+#define WGS_ONLY(x) x
+#else
+#define vmx86_wgs 0
+#define WGS_ONLY(x) 
+#endif
+
+#ifdef VMKERNEL
+#define vmkernel 1
+#define VMKERNEL_ONLY(x) x
+#else
+#define vmkernel 0
+#define VMKERNEL_ONLY(x)
+#endif
+
+#ifdef _WIN32
+#define WIN32_ONLY(x) x
+#define POSIX_ONLY(x)
+#else
+#define WIN32_ONLY(x)
+#define POSIX_ONLY(x) x
+#endif
+
+#ifdef VMM
+#define VMM_ONLY(x) x
+#define USER_ONLY(x)
+#else
+#define VMM_ONLY(x)
+#define USER_ONLY(x) x
+#endif
+
+/* VMVISOR ifdef only allowed in the vmkernel */
+#ifdef VMKERNEL
+#ifdef VMVISOR
+#define vmvisor 1
+#define VMVISOR_ONLY(x) x
+#else
+#define vmvisor 0
+#define VMVISOR_ONLY(x)
+#endif
+#endif
+
+#ifdef _WIN32
+#define VMW_INVALID_HANDLE INVALID_HANDLE_VALUE
+#else
+#define VMW_INVALID_HANDLE (-1)
+#endif
+
+#ifdef _WIN32
+#define fsync(fd) _commit(fd)
+#define fileno(f) _fileno(f)
+#else
+#endif
+
+/*
+ * Debug output macros for Windows drivers (the Eng variant is for
+ * display/printer drivers only.
+ */
+#ifdef _WIN32
+#ifndef USES_OLD_WINDDK
+#if defined(VMX86_DEBUG) || defined(ASSERT_ALWAYS_AVAILABLE)
+#define WinDrvPrint(arg, ...) DbgPrint(arg, __VA_ARGS__)
+#define WinDrvEngPrint(arg, ...) EngDbgPrint(arg, __VA_ARGS__)
+#else
+#define WinDrvPrint(arg, ...)
+#define WinDrvEngPrint(arg, ...)
+#endif
+#endif
+#endif // _WIN32
+
+#endif // ifndef _VM_BASIC_DEFS_H_
--- kernel/linux-2.6.26.3/drivers/misc/vmci/vm_basic_types.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmci/vm_basic_types.h	2008-09-03 10:01:42.000000000 -0500
@@ -0,0 +1,866 @@
+/*********************************************************
+ * Copyright (C) 1998-2008 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ *
+ * vm_basic_types.h --
+ *
+ *    basic data types.
+ */
+
+
+#ifndef _VM_BASIC_TYPES_H_
+#define _VM_BASIC_TYPES_H_
+
+#define INCLUDE_ALLOW_USERLEVEL
+#define INCLUDE_ALLOW_VMMEXT
+#define INCLUDE_ALLOW_MODULE
+#define INCLUDE_ALLOW_VMMON
+#define INCLUDE_ALLOW_VMNIXMOD
+#define INCLUDE_ALLOW_VMKERNEL
+#define INCLUDE_ALLOW_VMKDRIVERS
+#define INCLUDE_ALLOW_VMK_MODULE
+#define INCLUDE_ALLOW_DISTRIBUTE
+#define INCLUDE_ALLOW_VMCORE
+#define INCLUDE_ALLOW_VMIROM
+#include "includeCheck.h"
+
+/* STRICT ANSI means the Xserver build and X defines Bool differently. */
+#if !defined(__STRICT_ANSI__) || defined(__FreeBSD__)
+typedef char           Bool;
+#endif
+
+#ifndef FALSE
+#define FALSE          0
+#endif
+
+#ifndef TRUE
+#define TRUE           1
+#endif
+
+#define IsBool(x)      (((x) & ~1) == 0)
+#define IsBool2(x, y)  ((((x) | (y)) & ~1) == 0)
+
+/*
+ * Macros __i386__ and __ia64 are intrinsically defined by GCC
+ */
+#ifdef __i386__
+#define VM_I386
+#endif
+
+#ifdef _WIN64
+#define __x86_64__
+#endif
+
+#ifdef __x86_64__
+#define VM_X86_64
+#define VM_I386
+#define vm_x86_64 (1)
+#else
+#define vm_x86_64 (0)
+#endif
+
+
+
+#ifdef _WIN32
+/* safe assumption for a while */
+#define VM_I386
+#endif
+
+#ifdef _MSC_VER
+typedef unsigned __int64 uint64;
+typedef signed __int64 int64;
+
+#pragma warning (3 :4505) // unreferenced local function
+#pragma warning (disable :4018) // signed/unsigned mismatch
+#pragma warning (disable :4761) // integral size mismatch in argument; conversion supplied
+#pragma warning (disable :4305) // truncation from 'const int' to 'short'
+#pragma warning (disable :4244) // conversion from 'unsigned short' to 'unsigned char'
+#pragma warning (disable :4267) // truncation of 'size_t'
+#pragma warning (disable :4146) // unary minus operator applied to unsigned type, result still unsigned
+#pragma warning (disable :4142) // benign redefinition of type
+
+#elif __GNUC__
+/* The Xserver source compiles with -ansi -pendantic */
+#ifndef __STRICT_ANSI__
+#if defined(VM_X86_64)
+typedef unsigned long uint64;
+typedef long int64;
+#else
+typedef unsigned long long uint64;
+typedef long long int64;
+#endif
+#elif __FreeBSD__
+typedef unsigned long long uint64;
+typedef long long int64;
+#endif
+#else
+#error - Need compiler define for int64/uint64
+#endif
+
+typedef unsigned int       uint32;
+typedef unsigned short     uint16;
+typedef unsigned char      uint8;
+
+typedef int       int32;
+typedef short     int16;
+typedef char      int8;
+
+/*
+ * FreeBSD (for the tools build) unconditionally defines these in
+ * sys/inttypes.h so don't redefine them if this file has already
+ * been included. [greg]
+ *
+ * This applies to Solaris as well.
+ */
+
+/*
+ * Before trying to do the includes based on OS defines, see if we can use
+ * feature-based defines to get as much functionality as possible
+ */
+
+#ifdef HAVE_INTTYPES_H
+#include <inttypes.h>
+#endif
+#ifdef HAVE_SYS_TYPES_H
+#include <sys/types.h>
+#endif
+#ifdef HAVE_SYS_INTTYPES_H
+#include <sys/inttypes.h>
+#endif
+#ifdef HAVE_STDINT_H
+#include <stdint.h>
+#endif
+#ifdef HAVE_STDLIB_H
+#include <stdlib.h>
+#endif
+
+#ifdef __FreeBSD__
+#include <sys/param.h> /* For __FreeBSD_version */         
+#endif
+
+#if !defined(USING_AUTOCONF)
+#   if defined(__FreeBSD__) || defined(sun)
+#      ifdef KLD_MODULE
+#         include <sys/types.h>
+#      else
+#         if !defined(VMKERNEL) && (__FreeBSD_version >= 500043)
+#            include <inttypes.h>
+#            include <sys/types.h>
+#         else
+#            include <sys/inttypes.h>
+#         endif
+#      endif
+#   elif defined __APPLE__
+#      if KERNEL
+#         include <sys/unistd.h>
+#         include <sys/types.h> /* mostly for size_t */
+#         include <stdint.h>
+#      else
+#         include <unistd.h>
+#         include <inttypes.h>
+#         include <stdlib.h>
+#         include <stdint.h>
+#      endif
+#   else
+#      if !defined(__intptr_t_defined) && !defined(intptr_t)
+#         define __intptr_t_defined
+#         define intptr_t  intptr_t
+#         ifdef VM_I386
+#            ifdef VM_X86_64
+typedef int64     intptr_t;
+#            else
+typedef int32     intptr_t;
+#            endif
+#         endif
+#      endif
+
+#      ifndef _STDINT_H
+#         ifdef VM_I386
+#            ifdef VM_X86_64
+typedef uint64    uintptr_t;
+#            else
+typedef uint32    uintptr_t;
+#            endif
+#         endif
+#      endif
+#   endif
+#endif
+
+
+/*
+ * Time
+ * XXX These should be cleaned up.  -- edward
+ */
+
+typedef int64 VmTimeType;          /* Time in microseconds */
+typedef int64 VmTimeRealClock;     /* Real clock kept in microseconds */
+typedef int64 VmTimeVirtualClock;  /* Virtual Clock kept in CPU cycles */
+
+/*
+ * Printf format specifiers for size_t and 64-bit number.
+ * Use them like this:
+ *    printf("%"FMT64"d\n", big);
+ *
+ * FMTH is for handles/fds.
+ */
+
+#ifdef _MSC_VER
+   #define FMT64      "I64"
+   #ifdef VM_X86_64
+      #define FMTSZ      "I64"
+      #define FMTPD      "I64"
+      #define FMTH       "I64"
+   #else
+      #define FMTSZ      "I"
+      #define FMTPD      "I"
+      #define FMTH       "I"
+   #endif
+#elif __GNUC__
+   #define FMTH ""
+   #if defined(N_PLAT_NLM) || defined(sun) || \
+       (defined(__FreeBSD__) && (__FreeBSD__ + 0) && ((__FreeBSD__ + 0) < 5))
+      /*
+       * Why (__FreeBSD__ + 0)?  See bug 141008.
+       * Yes, we really need to test both (__FreeBSD__ + 0) and
+       * ((__FreeBSD__ + 0) < 5).  No, we can't remove "+ 0" from
+       * ((__FreeBSD__ + 0) < 5).
+       */
+      #ifdef VM_X86_64
+         #define FMTSZ  "l"
+         #define FMTPD  "l"
+      #else
+         #define FMTSZ  ""
+         #define FMTPD  ""
+      #endif
+   #elif defined(__linux__) \
+      || (defined(_POSIX_C_SOURCE) && _POSIX_C_SOURCE >= 200112L) \
+      || (defined(_POSIX_VERSION) && _POSIX_VERSION >= 200112L) \
+      || (defined(_POSIX2_VERSION) && _POSIX2_VERSION >= 200112L)
+      /* BSD/Darwin, Linux */
+      #define FMTSZ     "z"
+
+      #ifdef VM_X86_64
+         #define FMTPD  "l"
+      #else
+         #define FMTPD  ""
+      #endif
+   #else
+      /* Systems with a pre-C99 libc */
+      #define FMTSZ     "Z"
+      #ifdef VM_X86_64
+         #define FMTPD  "l"
+      #else
+         #define FMTPD  ""
+      #endif
+   #endif
+   #ifdef VM_X86_64
+      #define FMT64     "l"
+   #elif defined(sun) || defined(__APPLE__) || defined(__FreeBSD__)
+      #define FMT64     "ll"
+   #else
+      #define FMT64     "L"
+   #endif
+#else
+   #error - Need compiler define for FMT64 and FMTSZ
+#endif
+
+/*
+ * Suffix for 64-bit constants.  Use it like this:
+ *    CONST64(0x7fffffffffffffff) for signed or
+ *    CONST64U(0x7fffffffffffffff) for unsigned.
+ *
+ * 2004.08.30(thutt):
+ *   The vmcore/asm64/gen* programs are compiled as 32-bit
+ *   applications, but must handle 64 bit constants.  If the
+ *   64-bit-constant defining macros are already defined, the
+ *   definition will not be overwritten.
+ */
+
+#if !defined(CONST64) || !defined(CONST64U)
+#ifdef _MSC_VER
+#define CONST64(c) c##I64
+#define CONST64U(c) c##uI64
+#elif __GNUC__
+#ifdef VM_X86_64
+#define CONST64(c) c##L
+#define CONST64U(c) c##uL
+#else
+#define CONST64(c) c##LL
+#define CONST64U(c) c##uLL
+#endif
+#else
+#error - Need compiler define for CONST64
+#endif
+#endif
+
+/*
+ * Use CONST3264/CONST3264U if you want a constant to be
+ * treated as a 32-bit number on 32-bit compiles and
+ * a 64-bit number on 64-bit compiles. Useful in the case
+ * of shifts, like (CONST3264U(1) << x), where x could be
+ * more than 31 on a 64-bit compile.
+ */
+
+#ifdef VM_X86_64
+    #define CONST3264(a) CONST64(a)
+    #define CONST3264U(a) CONST64U(a)
+#else
+    #define CONST3264(a) (a)
+    #define CONST3264U(a) (a)
+#endif
+
+#define MIN_INT32  ((int32)0x80000000)
+#define MAX_INT32  ((int32)0x7fffffff)
+
+#define MIN_UINT32 ((uint32)0)
+#define MAX_UINT32 ((uint32)0xffffffff)
+
+#define MIN_INT64  (CONST64(0x8000000000000000))
+#define MAX_INT64  (CONST64(0x7fffffffffffffff))
+
+#define MIN_UINT64 (CONST64U(0))
+#define MAX_UINT64 (CONST64U(0xffffffffffffffff))
+
+typedef uint8 *TCA;  /* Pointer into TC (usually). */
+
+/*
+ * Type big enough to hold an integer between 0..100
+ */
+typedef uint8 Percent;
+#define AsPercent(v)	((Percent)(v))
+#define CHOOSE_PERCENT  AsPercent(101)
+
+
+typedef uintptr_t VA;
+typedef uintptr_t VPN;
+
+typedef uint64    PA;
+typedef uint32    PPN;
+
+typedef uint64    PhysMemOff;
+typedef uint64    PhysMemSize;
+
+/* The Xserver source compiles with -ansi -pendantic */
+#ifndef __STRICT_ANSI__
+typedef uint64    BA;
+#endif
+typedef uint32    BPN;
+typedef uint32    PageNum;
+typedef unsigned  MemHandle;
+typedef int32     World_ID;
+
+#define INVALID_WORLD_ID ((World_ID)0)
+
+typedef World_ID User_CartelID;
+#define INVALID_CARTEL_ID INVALID_WORLD_ID
+
+typedef User_CartelID User_SessionID;
+#define INVALID_SESSION_ID INVALID_CARTEL_ID
+
+typedef User_CartelID User_CartelGroupID;
+#define INVALID_CARTELGROUP_ID INVALID_CARTEL_ID
+
+typedef uint32 Worldlet_ID;
+#define INVALID_WORLDLET_ID ((Worldlet_ID)0)
+
+/* world page number */
+typedef uint32    WPN;
+
+/* The Xserver source compiles with -ansi -pendantic */
+#ifndef __STRICT_ANSI__
+typedef uint64     MA;
+typedef uint32     MPN;
+#endif
+
+/*
+ * This type should be used for variables that contain sector
+ * position/quantity.
+ */
+typedef uint64 SectorType;
+
+/*
+ * Linear address
+ */
+
+typedef uintptr_t LA;
+typedef uintptr_t LPN;
+#define LA_2_LPN(_la)     ((_la) >> PAGE_SHIFT)
+#define LPN_2_LA(_lpn)    ((_lpn) << PAGE_SHIFT)
+
+#define LAST_LPN   ((((LA)  1) << (8 * sizeof(LA)   - PAGE_SHIFT)) - 1)
+#define LAST_LPN32 ((((LA32)1) << (8 * sizeof(LA32) - PAGE_SHIFT)) - 1)
+#define LAST_LPN64 ((((LA64)1) << (8 * sizeof(LA64) - PAGE_SHIFT)) - 1)
+
+/* Valid bits in a LPN. */
+#define LPN_MASK   LAST_LPN
+#define LPN_MASK32 LAST_LPN32
+#define LPN_MASK64 LAST_LPN64
+
+/*
+ * On 64 bit platform, address and page number types default
+ * to 64 bit. When we need to represent a 32 bit address, we use
+ * types defined below.
+ *
+ * On 32 bit platform, the following types are the same as the
+ * default types.
+ */
+typedef uint32 VA32;
+typedef uint32 VPN32;
+typedef uint32 LA32;
+typedef uint32 LPN32;
+typedef uint32 PA32;
+typedef uint32 PPN32;
+typedef uint32 MA32;
+typedef uint32 MPN32;
+
+/*
+ * On 64 bit platform, the following types are the same as the
+ * default types.
+ */
+typedef uint64 VA64;
+typedef uint64 VPN64;
+typedef uint64 LA64;
+typedef uint64 LPN64;
+typedef uint64 PA64;
+typedef uint64 PPN64;
+typedef uint64 MA64;
+typedef uint64 MPN64;
+
+/*
+ * VA typedefs for user world apps.
+ */
+typedef VA32 UserVA32;
+typedef VA64 UserVA64;
+typedef UserVA32 UserVAConst; /* Userspace ptr to data that we may only read. */
+typedef UserVA64 UserVA64Const; /* Used by 64-bit syscalls until conversion is finished. */
+#ifdef VMKERNEL
+typedef UserVA32 UserVA;
+#else
+typedef void * UserVA;
+#endif
+
+
+/*
+ * Maximal possible PPN value (errors too) that PhysMem can handle.
+ * Must be at least as large as MAX_PPN which is the maximum PPN
+ * for any region other than buserror.
+ */
+#define PHYSMEM_MAX_PPN ((PPN)0xffffffff)
+#define MAX_PPN         ((PPN)0x1fffffff)   /* Maximal observable PPN value. */
+#define INVALID_PPN     ((PPN)0xffffffff)
+
+#define INVALID_BPN  ((BPN) 0x1fffffff)
+
+#define INVALID_MPN  ((MPN)-1)
+#define MEMREF_MPN   ((MPN)-2)
+#define RESERVED_MPN ((MPN) 0)
+/* Support 39 bits of address space, minus one page. */
+#define MAX_MPN      ((MPN) 0x07ffffff)
+
+#define INVALID_LPN ((LPN)-1)
+#define INVALID_VPN ((VPN)-1)
+#define INVALID_LPN64 ((LPN64)-1)
+#define INVALID_PAGENUM ((PageNum)-1)
+#define INVALID_WPN ((WPN) -1)
+
+
+/*
+ * Format modifier for printing VA, LA, and VPN.
+ * Use them like this: Log("%#"FMTLA"x\n", laddr)
+ */
+
+#if defined(VMM64) || defined(FROBOS64) || vm_x86_64 || defined __APPLE__
+#   define FMTLA "l"
+#   define FMTVA "l"
+#   define FMTVPN "l"
+#else
+#   define FMTLA ""
+#   define FMTVA ""
+#   define FMTVPN ""
+#endif
+
+#ifndef EXTERN
+#define EXTERN        extern
+#endif
+#define CONST         const
+
+
+#ifndef INLINE
+#   ifdef _MSC_VER
+#      define INLINE        __inline
+#   else
+#      define INLINE        inline
+#   endif
+#endif
+
+
+/*
+ * Annotation for data that may be exported into a DLL and used by other
+ * apps that load that DLL and import the data.
+ */
+#if defined(_WIN32) && defined(VMX86_IMPORT_DLLDATA)
+#  define VMX86_EXTERN_DATA       extern __declspec(dllimport)
+#else // !_WIN32
+#  define VMX86_EXTERN_DATA       extern
+#endif
+
+#if defined(_WIN32) && !defined(VMX86_NO_THREADS)
+#define THREADSPECIFIC __declspec(thread)
+#else
+#define THREADSPECIFIC
+#endif
+
+/*
+ * Due to the wonderful "registry redirection" feature introduced in
+ * 64-bit Windows, if you access any key under HKLM\Software in 64-bit
+ * code, you need to open/create/delete that key with
+ * VMKEY_WOW64_32KEY if you want a consistent view with 32-bit code.
+ */
+
+#ifdef _WIN32
+#ifdef _WIN64
+#define VMW_KEY_WOW64_32KEY KEY_WOW64_32KEY
+#else
+#define VMW_KEY_WOW64_32KEY 0x0
+#endif
+#endif
+
+
+/*
+ * Consider the following reasons functions are inlined:
+ *
+ *  1) inlined for performance reasons
+ *  2) inlined because it's a single-use function
+ *
+ * Functions which meet only condition 2 should be marked with this
+ * inline macro; It is not critical to be inlined (but there is a
+ * code-space & runtime savings by doing so), so when other callers
+ * are added the inline-ness should be removed.
+ */
+
+#if __GNUC__ > 3 || (__GNUC__ == 3 && __GNUC_MINOR__ >= 3)
+/*
+ * Starting at version 3.3, gcc does not always inline functions marked
+ * 'inline' (it depends on their size). To force gcc to do so, one must use the
+ * extra __always_inline__ attribute.
+ */
+#   define INLINE_SINGLE_CALLER INLINE __attribute__((__always_inline__))
+#   if    defined(VMM) \
+       && (__GNUC__ > 4 || (__GNUC__ == 4 && __GNUC_MINOR__ > 1))
+#      warning Verify INLINE_SINGLE_CALLER '__always_inline__' attribute (did \
+             monitor size change?)
+#   endif
+#else
+#   define INLINE_SINGLE_CALLER INLINE
+#endif
+
+/*
+ * Used when a hard guaranteed of no inlining is needed. Very few
+ * instances need this since the absence of INLINE is a good hint
+ * that gcc will not do inlining.
+ */
+
+#if defined(__GNUC__) && defined(VMM)
+#define ABSOLUTELY_NOINLINE __attribute__((__noinline__))
+#endif
+
+/*
+ * Attributes placed on function declarations to tell the compiler
+ * that the function never returns.
+ */
+
+#ifdef _MSC_VER
+#define NORETURN __declspec(noreturn)
+#elif __GNUC__ > 2 || (__GNUC__ == 2 && __GNUC_MINOR__ >= 9)
+#define NORETURN __attribute__((__noreturn__))
+#else
+#define NORETURN
+#endif
+
+/*
+ * GCC 3.2 inline asm needs the + constraint for input/ouput memory operands.
+ * Older GCCs don't know about it --hpreg
+ */
+
+#if __GNUC__ > 3 || (__GNUC__ == 3 && __GNUC_MINOR__ >= 2)
+#   define VM_ASM_PLUS 1
+#else
+#   define VM_ASM_PLUS 0
+#endif
+
+/*
+ * Branch prediction hints:
+ *     LIKELY(exp)   - Expression exp is likely TRUE.
+ *     UNLIKELY(exp) - Expression exp is likely FALSE.
+ *   Usage example:
+ *        if (LIKELY(excCode == EXC_NONE)) {
+ *               or
+ *        if (UNLIKELY(REAL_MODE(vc))) {
+ *
+ * We know how to predict branches on gcc3 and later (hopefully),
+ * all others we don't so we do nothing.
+ */
+
+#if (__GNUC__ >= 3)
+/*
+ * gcc3 uses __builtin_expect() to inform the compiler of an expected value.
+ * We use this to inform the static branch predictor. The '!!' in LIKELY
+ * will convert any !=0 to a 1.
+ */
+#define LIKELY(_exp)     __builtin_expect(!!(_exp), 1)
+#define UNLIKELY(_exp)   __builtin_expect((_exp), 0)
+#else
+#define LIKELY(_exp)      (_exp)
+#define UNLIKELY(_exp)    (_exp)
+#endif
+
+/*
+ * GCC's argument checking for printf-like functions
+ * This is conditional until we have replaced all `"%x", void *'
+ * with `"0x%08x", (uint32) void *'. Note that %p prints different things
+ * on different platforms.  Argument checking is enabled for the
+ * vmkernel, which has already been cleansed.
+ *
+ * fmtPos is the position of the format string argument, beginning at 1
+ * varPos is the position of the variable argument, beginning at 1
+ */
+
+#if defined(__GNUC__)
+# define PRINTF_DECL(fmtPos, varPos) __attribute__((__format__(__printf__, fmtPos, varPos)))
+#else
+# define PRINTF_DECL(fmtPos, varPos)
+#endif
+
+#if defined(__GNUC__)
+# define SCANF_DECL(fmtPos, varPos) __attribute__((__format__(__scanf__, fmtPos, varPos)))
+#else
+# define SCANF_DECL(fmtPos, varPos)
+#endif
+
+/*
+ * UNUSED_PARAM should surround the parameter name and type declaration,
+ * e.g. "int MyFunction(int var1, UNUSED_PARAM(int var2))"
+ *
+ */
+
+#ifndef UNUSED_PARAM
+# if defined(__GNUC__)
+#  define UNUSED_PARAM(_parm) _parm  __attribute__((__unused__))
+# else
+#  define UNUSED_PARAM(_parm) _parm
+# endif
+#endif
+
+/*
+ * REGPARM defaults to REGPARM3, i.e., a requent that gcc
+ * puts the first three arguments in registers.  (It is fine
+ * if the function has fewer than three args.)  Gcc only.
+ * Syntactically, put REGPARM where you'd put INLINE or NORETURN.
+ */
+
+#if defined(__GNUC__)
+# define REGPARM0 __attribute__((regparm(0)))
+# define REGPARM1 __attribute__((regparm(1)))
+# define REGPARM2 __attribute__((regparm(2)))
+# define REGPARM3 __attribute__((regparm(3)))
+# define REGPARM REGPARM3
+#else
+# define REGPARM0
+# define REGPARM1
+# define REGPARM2
+# define REGPARM3
+# define REGPARM
+#endif
+
+/*
+ * ALIGNED specifies minimum alignment in "n" bytes.
+ */
+
+#ifdef __GNUC__
+#define ALIGNED(n) __attribute__((__aligned__(n)))
+#else
+#define ALIGNED(n)
+#endif
+
+/*
+ * __func__ is a stringified function name that is part of the C99 standard. The block
+ * below defines __func__ on older systems where the compiler does not support that
+ * macro.
+ */
+#if defined(__GNUC__) \
+   && ((__GNUC__ == 2 && __GNUC_MINOR < 96) \
+       || (__GNUC__ < 2))
+#   define __func__ __FUNCTION__
+#endif
+
+/*
+ * Once upon a time, this was used to silence compiler warnings that
+ * get generated when the compiler thinks that a function returns
+ * when it is marked noreturn.  Don't do it.  Use NOT_REACHED().
+ */
+
+#define INFINITE_LOOP()           do { } while (1)
+
+/*
+ * On FreeBSD (for the tools build), size_t is typedef'd if _BSD_SIZE_T_
+ * is defined. Use the same logic here so we don't define it twice. [greg]
+ */
+#ifdef __FreeBSD__
+#   ifdef _BSD_SIZE_T_
+#      undef _BSD_SIZE_T_
+#      ifdef VM_I386
+#         ifdef VM_X86_64
+             typedef uint64 size_t;
+#         else
+             typedef uint32 size_t;
+#         endif
+#      endif /* VM_I386 */
+#   endif
+
+#   ifdef _BSD_SSIZE_T_
+#      undef _BSD_SSIZE_T_
+#      define _SSIZE_T
+#      define __ssize_t_defined
+#      define _SSIZE_T_DECLARED
+#      ifdef VM_I386
+#         ifdef VM_X86_64
+             typedef int64 ssize_t;
+#         else
+             typedef int32 ssize_t;
+#         endif
+#      endif /* VM_I386 */
+#   endif
+
+#else
+#   ifndef _SIZE_T
+#      define _SIZE_T
+#      ifdef VM_I386
+#         ifdef VM_X86_64
+             typedef uint64 size_t;
+#         else
+             typedef uint32 size_t;
+#         endif
+#      endif /* VM_I386 */
+#   endif
+
+#   if !defined(FROBOS) && !defined(_SSIZE_T) && !defined(ssize_t) && \
+       !defined(__ssize_t_defined) && !defined(_SSIZE_T_DECLARED)
+#      define _SSIZE_T
+#      define __ssize_t_defined
+#      define _SSIZE_T_DECLARED
+#      ifdef VM_I386
+#         ifdef VM_X86_64
+             typedef int64 ssize_t;
+#         else
+             typedef int32 ssize_t;
+#         endif
+#      endif /* VM_I386 */
+#   endif
+
+#endif
+
+/*
+ * Format modifier for printing pid_t.  On sun the pid_t is a ulong, but on
+ * Linux it's an int.
+ * Use this like this: printf("The pid is %"FMTPID".\n", pid);
+ */
+#ifdef sun
+#   ifdef VM_X86_64
+#      define FMTPID "d"
+#   else
+#      define FMTPID "lu"
+#   endif
+#else
+# define FMTPID "d"
+#endif
+
+/*
+ * Format modifier for printing uid_t.  On sun the uid_t is a ulong, but on
+ * Linux it's an int.
+ * Use this like this: printf("The uid is %"FMTUID".\n", uid);
+ */
+#ifdef sun
+#   ifdef VM_X86_64
+#      define FMTUID "u"
+#   else
+#      define FMTUID "lu"
+#   endif
+#else
+# define FMTUID "u"
+#endif
+
+/*
+ * Format modifier for printing mode_t.  On sun the mode_t is a ulong, but on
+ * Linux it's an int.
+ * Use this like this: printf("The mode is %"FMTMODE".\n", mode);
+ */
+#ifdef sun
+#   ifdef VM_X86_64
+#      define FMTMODE "o"
+#   else
+#      define FMTMODE "lo"
+#   endif
+#else
+# define FMTMODE "o"
+#endif
+
+/*
+ * Format modifier for printing time_t. Most platforms define a time_t to be
+ * a long int, but on FreeBSD (as of 5.0, it seems), the time_t is a signed
+ * size quantity. Refer to the definition of FMTSZ to see why we need silly
+ * preprocessor arithmetic.
+ * Use this like this: printf("The mode is %"FMTTIME".\n", time);
+ */
+#if defined(__FreeBSD__) && (__FreeBSD__ + 0) && ((__FreeBSD__ + 0) >= 5)
+#   define FMTTIME FMTSZ"d"
+#else
+#   define FMTTIME "ld"
+#endif
+
+/*
+ * Define MXSemaHandle here so both vmmon and vmx see this definition.
+ */
+
+#ifdef _WIN32
+typedef uintptr_t MXSemaHandle;
+#else
+typedef int MXSemaHandle;
+#endif
+
+/*
+ * Define type for poll device handles.
+ */
+
+#ifdef _WIN32
+typedef uintptr_t PollDevHandle;
+#else
+typedef int PollDevHandle;
+#endif
+
+/*
+ * Define the utf16_t type.
+ */
+
+#if defined(_WIN32) && defined(_NATIVE_WCHAR_T_DEFINED)
+typedef wchar_t utf16_t;
+#else
+typedef uint16 utf16_t;
+#endif
+
+#endif  /* _VM_BASIC_TYPES_H_ */
--- kernel/linux-2.6.26.3/drivers/misc/vmci/vmci_call_defs.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmci/vmci_call_defs.h	2008-09-03 10:01:42.000000000 -0500
@@ -0,0 +1,266 @@
+/*********************************************************
+ * Copyright (C) 2006-2007 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef _VMCI_CALL_DEFS_H_
+#define _VMCI_CALL_DEFS_H_
+
+#define INCLUDE_ALLOW_USERLEVEL
+#define INCLUDE_ALLOW_VMMEXT
+#define INCLUDE_ALLOW_MODULE
+#define INCLUDE_ALLOW_VMMON
+#define INCLUDE_ALLOW_VMCORE
+#define INCLUDE_ALLOW_VMKMOD
+#define INCLUDE_ALLOW_VMKERNEL
+#define INCLUDE_ALLOW_DISTRIBUTE
+#include "includeCheck.h"
+
+#include "vm_basic_types.h"
+#include "vmci_defs.h"
+
+/*
+ * All structs here are an integral size of their largest member, ie. a struct 
+ * with at least one 8-byte member will have a size that is an integral of 8.
+ * A struct which has a largest member of size 4 will have a size that is an
+ * integral of 4. This is because Windows CL enforces this rule. 32 bit gcc 
+ * doesn't e.g. 32 bit gcc can misalign an 8 byte member if it is preceeded by
+ * a 4 byte member. 
+ */
+
+/*
+ * Base struct for vmci datagrams.
+ */
+
+typedef struct VMCIDatagram {
+   VMCIHandle dst;
+   VMCIHandle src;
+   uint64     payloadSize;
+} VMCIDatagram;
+
+typedef int
+(*VMCIDatagramRecvCB)(void *clientData,   // IN: client data for handler
+                      VMCIDatagram *msg); // IN: 
+
+/* Flag for creating a wellknown handle instead of a per context handle. */
+#define VMCI_FLAG_WELLKNOWN_DG_HND 0x1
+
+/* 
+ * Maximum supported size of a VMCI datagram for routable datagrams.
+ * Datagrams going to the hypervisor are allowed to be larger.
+ */
+#define VMCI_MAX_DG_SIZE (17 * 4096)
+#define VMCI_MAX_DG_PAYLOAD_SIZE (VMCI_MAX_DG_SIZE - sizeof(VMCIDatagram))
+#define VMCI_DG_PAYLOAD(_dg) (void *)((char *)(_dg) + sizeof(VMCIDatagram))
+#define VMCI_DG_HEADERSIZE sizeof(VMCIDatagram)
+#define VMCI_DG_SIZE(_dg) (VMCI_DG_HEADERSIZE + (size_t)(_dg)->payloadSize)
+#define VMCI_DG_SIZE_ALIGNED(_dg) ((VMCI_DG_SIZE(_dg) + 7) & (size_t)CONST64U(0xfffffffffffffff8))
+#define VMCI_MAX_DATAGRAM_QUEUE_SIZE  (VMCI_MAX_DG_SIZE * 2)
+
+/* 
+ * Struct for sending VMCI_DATAGRAM_REQUEST_MAP and VMCI_DATAGRAM_REMOVE_MAP
+ * datagrams. Struct size is 32 bytes. All fields in struct are aligned to
+ * their natural alignment.
+ */
+typedef struct VMCIDatagramWellKnownMapMsg {
+   VMCIDatagram hdr;
+   VMCIId       wellKnownID;
+   uint32       _pad;
+} VMCIDatagramWellKnownMapMsg;
+
+
+/*
+ * Struct used for querying, via VMCI_RESOURCES_QUERY, the availability of 
+ * hypervisor resources. 
+ * Struct size is 16 bytes. All fields in struct are aligned to their natural
+ * alignment.
+ */
+typedef struct VMCIResourcesQueuryHdr {
+   VMCIDatagram hdr;
+   uint32       numResources;
+   uint32       _padding;
+} VMCIResourcesQueryHdr;
+
+
+/*
+ * Convenience struct for negotiating vectors. Must match layout of
+ * VMCIResourceQueryHdr minus the VMCIDatagram header.
+ */
+typedef struct VMCIResourcesQueryMsg {
+   uint32        numResources;
+   uint32        _padding;
+   VMCI_Resource resources[1];
+} VMCIResourcesQueryMsg;
+
+
+/* 
+ * The maximum number of resources that can be queried using
+ * VMCI_RESOURCE_QUERY is 31, as the result is encoded in the lower 31
+ * bits of a positive return value. Negative values are reserved for
+ * errors.
+ */
+#define VMCI_RESOURCE_QUERY_MAX_NUM 31
+
+/* Maximum size for the VMCI_RESOURCE_QUERY request. */
+#define VMCI_RESOURCE_QUERY_MAX_SIZE sizeof(VMCIResourcesQueryHdr) \
+      + VMCI_RESOURCE_QUERY_MAX_NUM * sizeof(VMCI_Resource)
+
+/* 
+ * Struct used for making VMCI_SHAREDMEM_CREATE message. Struct size is 24 bytes.
+ * All fields in struct are aligned to their natural alignment.
+ */
+typedef struct VMCISharedMemCreateMsg {
+   VMCIDatagram hdr;
+   VMCIHandle   handle;
+   uint32       memSize;
+   uint32       _padding;
+   /* PPNs placed after struct. */
+} VMCISharedMemCreateMsg;
+
+
+/* 
+ * Struct used for sending VMCI_SHAREDMEM_ATTACH messages. Same as struct used 
+ * for create messages.
+ */
+typedef VMCISharedMemCreateMsg VMCISharedMemAttachMsg;
+
+
+/* 
+ * Struct used for sending VMCI_SHAREDMEM_DETACH messsages. Struct size is 16
+ * bytes. All fields in struct are aligned to their natural alignment.
+ */
+typedef struct VMCISharedMemDetachMsg {
+   VMCIDatagram hdr;
+   VMCIHandle handle;
+} VMCISharedMemDetachMsg;
+
+
+/* 
+ * Struct used for sending VMCI_SHAREDMEM_QUERY messages. Same as struct used 
+ * for detach messages.
+ */
+typedef VMCISharedMemDetachMsg VMCISharedMemQueryMsg;
+
+
+/* 
+ * This struct is used to contain data for events.  Size of this struct is a
+ * multiple of 8 bytes, and all fields are aligned to their natural alignment.
+ */
+typedef struct VMCI_EventData {
+   VMCI_Event event; /* 4 bytes. */
+   uint32     _pad;
+   /*
+    * Event payload is put here.
+    */
+} VMCI_EventData;
+
+
+/*
+ * We use the following inline function to access the payload data associated
+ * with an event data.
+ */
+
+static INLINE void *
+VMCIEventDataPayload(VMCI_EventData *evData) // IN:
+{
+   return (void *)((char *)evData + sizeof *evData);
+}
+
+/*
+ * Define the different VMCI_EVENT payload data types here.  All structs must
+ * be a multiple of 8 bytes, and fields must be aligned to their natural
+ * alignment.
+ */
+typedef struct VMCIEventPayload_Context {
+   VMCIId contextID; /* 4 bytes. */
+   uint32 _pad;
+} VMCIEventPayload_Context;
+
+typedef struct VMCIEventPayload_QP {
+   VMCIHandle handle; /* QueuePair handle. */
+   VMCIId     peerId; /* Context id of attaching/detaching VM. */
+   uint32     _pad;
+} VMCIEventPayload_QP;
+
+/*
+ * We define the following struct to get the size of the maximum event data
+ * the hypervisor may send to the guest.  If adding a new event payload type
+ * above, add it to the following struct too (inside the union).
+ */
+typedef struct VMCIEventData_Max {
+   VMCI_EventData eventData;
+   union {
+      VMCIEventPayload_Context contextPayload;
+      VMCIEventPayload_QP      qpPayload;
+   } evDataPayload;
+} VMCIEventData_Max;
+
+
+/* 
+ * Struct used for VMCI_EVENT_SUBSCRIBE/UNSUBSCRIBE and VMCI_EVENT_HANDLER 
+ * messages.  Struct size is 32 bytes.  All fields in struct are aligned to
+ * their natural alignment.
+ */
+typedef struct VMCIEventMsg {
+   VMCIDatagram   hdr;
+   VMCI_EventData eventData; /* Has event type and payload. */
+   /*
+    * Payload gets put here.
+    */
+} VMCIEventMsg;
+
+
+/*
+ * We use the following inline function to access the payload data associated
+ * with an event message.
+ */
+
+static INLINE void *
+VMCIEventMsgPayload(VMCIEventMsg *eMsg) // IN:
+{
+   return VMCIEventDataPayload(&eMsg->eventData);
+}
+
+
+/* Flags for VMCI QueuePair API. */
+#define VMCI_QPFLAG_ATTACH_ONLY 0x1 /* Fail alloc if QP not created by peer. */
+#define VMCI_QPFLAG_LOCAL       0x2 /* Only allow attaches from local context. */
+/* Update the following (bitwise OR flags) while adding new flags. */
+#define VMCI_QP_ALL_FLAGS       (VMCI_QPFLAG_ATTACH_ONLY | VMCI_QPFLAG_LOCAL)
+
+/*
+ * Structs used for QueuePair alloc and detach messages.  We align fields of
+ * these structs to 64bit boundaries.
+ */
+
+typedef struct VMCIQueuePairAllocMsg {
+   VMCIDatagram   hdr;
+   VMCIHandle     handle;
+   VMCIId         peer; /* 32bit field. */
+   uint32         flags;
+   uint64         produceSize;
+   uint64         consumeSize;
+   uint64         numPPNs;
+   /* List of PPNs placed here. */
+} VMCIQueuePairAllocMsg;
+
+
+typedef struct VMCIQueuePairDetachMsg {
+   VMCIDatagram  hdr;
+   VMCIHandle    handle;
+} VMCIQueuePairDetachMsg;
+
+#endif
--- kernel/linux-2.6.26.3/drivers/misc/vmci/vmciDatagram.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmci/vmciDatagram.c	2008-09-03 10:01:42.000000000 -0500
@@ -0,0 +1,914 @@
+/*********************************************************
+ * Copyright (C) 2006 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/* 
+ * vmciDatagram.c --
+ *
+ *      Simple Datagram API for the Linux guest driver.
+ */
+
+#ifdef __linux__
+#  include "driver-config.h"
+
+#  define EXPORT_SYMTAB
+
+#  include <linux/module.h>
+#  include "compat_kernel.h"
+#  include "compat_pci.h"
+#elif defined(_WIN32)
+#  include <ntddk.h>
+#elif defined(SOLARIS)
+#  include <sys/ddi.h>
+#  include <sys/sunddi.h>
+#else
+#  error "Platform not support by VMCI datagram API."
+#endif // linux
+
+#include "vm_basic_types.h"
+#include "vm_assert.h"
+#include "vmci_defs.h"
+#include "vmci_kernel_if.h"
+#include "vmci_infrastructure.h"
+#include "vmciInt.h"
+#include "vmciUtil.h"
+#include "vmciDatagram.h"
+
+typedef struct DatagramHashEntry {
+   struct DatagramHashEntry  *next;
+   int                       refCount;
+
+   VMCIHandle                handle;
+   uint32                    flags;
+   VMCIDatagramRecvCB        recvCB;
+   void                      *clientData;
+   VMCIEvent                 destroyEvent;
+} DatagramHashEntry;
+
+#define HASH_TABLE_SIZE 64
+
+/* 
+ * Hash table containing all the datagram handles for this VM. It is 
+ * synchronized using a single lock but we should consider making it more
+ * fine grained, e.g. a per bucket lock or per set of buckets' lock.
+ */
+
+typedef struct DatagramHashTable {
+   VMCILock lock;
+   DatagramHashEntry *entries[HASH_TABLE_SIZE];
+} DatagramHashTable; 
+
+
+static int DatagramReleaseCB(void *clientData);
+static int DatagramHashAddEntry(DatagramHashEntry *entry, VMCIId contextID);
+static int DatagramHashRemoveEntry(VMCIHandle handle);
+static DatagramHashEntry *DatagramHashGetEntry(VMCIHandle handle);
+static void DatagramHashReleaseEntry(DatagramHashEntry *entry);
+static Bool DatagramHandleUniqueLocked(VMCIHandle handle);
+static int DatagramProcessNotify(void *clientData, VMCIDatagram *msg);
+
+DatagramHashTable hashTable;
+
+/*
+ *------------------------------------------------------------------------------
+ *
+ *  DatagramReleaseCB --
+ *
+ *     Callback to release the datagram entry reference. It is called by the 
+ *     VMCI_WaitOnEvent function before it blocks.
+ * 
+ *  Result:
+ *     None.
+ *     
+ *------------------------------------------------------------------------------
+ */
+
+static int
+DatagramReleaseCB(void *clientData)
+{
+   DatagramHashEntry *entry = (DatagramHashEntry *)clientData;
+   ASSERT(entry);
+   DatagramHashReleaseEntry(entry);
+
+   return 0;
+}
+
+
+/*
+ *-------------------------------------------------------------------------
+ *
+ *  DatagramHashAddEntry --
+ *     Given a datagram handle entry, adds it to the hashtable of datagram
+ *     entries.  Allocates a resource id iff the handle of the given entry
+ *     is an invalid one.  0 through VMCI_RESERVED_RESOURCE_ID_MAX are
+ *     reserved resource ids.
+ *
+ *  Result:
+ *     VMCI_SUCCESS if added, error if not.
+ *     
+ *-------------------------------------------------------------------------
+ */
+
+static int
+DatagramHashAddEntry(DatagramHashEntry *entry, // IN:
+                     VMCIId contextID)         // IN:
+{
+   int idx;
+   VMCILockFlags flags;
+   static VMCIId datagramRID = VMCI_RESERVED_RESOURCE_ID_MAX + 1;
+
+   ASSERT(entry && contextID != VMCI_INVALID_ID);
+
+   VMCI_GrabLock_BH(&hashTable.lock, &flags);
+   if (!VMCI_HANDLE_INVALID(entry->handle) &&
+       !DatagramHandleUniqueLocked(entry->handle)) {
+      VMCI_ReleaseLock_BH(&hashTable.lock, flags);
+      return VMCI_ERROR_DUPLICATE_ENTRY;
+   } else if (VMCI_HANDLE_INVALID(entry->handle)) {
+      VMCIId oldRID = datagramRID;
+      VMCIHandle handle;
+      Bool foundRID = FALSE;
+
+      /*
+       * Generate a unique datagram rid.  Keep on trying until we wrap around
+       * in the RID space.
+       */
+      ASSERT(oldRID > VMCI_RESERVED_RESOURCE_ID_MAX);
+      do {
+         handle = VMCI_MAKE_HANDLE(contextID, datagramRID);
+         foundRID = DatagramHandleUniqueLocked(handle);
+         datagramRID++;
+         if (UNLIKELY(!datagramRID)) {
+            /*
+             * Skip the reserved rids.
+             */
+            datagramRID = VMCI_RESERVED_RESOURCE_ID_MAX + 1;
+         }
+      } while (!foundRID && datagramRID != oldRID);
+
+      if (LIKELY(foundRID)) {
+         entry->handle = handle;
+      } else {
+         /*
+          * We wrapped around --- no rids were free.
+          */
+         ASSERT(datagramRID == oldRID);
+         VMCI_ReleaseLock_BH(&hashTable.lock, flags);
+         return VMCI_ERROR_NO_HANDLE;
+      }
+   }
+   
+   ASSERT(!VMCI_HANDLE_INVALID(entry->handle));
+   idx = VMCI_Hash(entry->handle, HASH_TABLE_SIZE);
+
+   /* New entry is added to top/front of hash bucket. */
+   entry->refCount++;
+   entry->next = hashTable.entries[idx];
+   hashTable.entries[idx] = entry;
+   VMCI_ReleaseLock_BH(&hashTable.lock, flags);
+
+   return VMCI_SUCCESS;
+}
+
+
+/*
+ *-------------------------------------------------------------------------
+ *
+ *  DatagramHashRemoveEntry --
+ *
+ *  Result:
+ *     VMCI_SUCCESS if removed, VMCI_ERROR_NO_HANDLE if not found.
+ *     
+ *-------------------------------------------------------------------------
+ */
+
+static int
+DatagramHashRemoveEntry(VMCIHandle handle)
+{ 
+   int result = VMCI_ERROR_NOT_FOUND;
+   VMCILockFlags flags;
+   DatagramHashEntry *prev, *cur;
+   int idx = VMCI_Hash(handle, HASH_TABLE_SIZE);
+
+   prev = NULL;
+   VMCI_GrabLock_BH(&hashTable.lock, &flags);
+   cur = hashTable.entries[idx];
+   while (TRUE) {
+      if (cur == NULL) {
+	 break;
+      }
+      if (VMCI_HANDLE_EQUAL(cur->handle, handle)) {
+	 /* Remove entry and break. */
+	 if (prev) {
+	    prev->next = cur->next;
+	 } else {
+	    hashTable.entries[idx] = cur->next;
+	 }
+
+	 cur->refCount--;
+	 
+	 /* 
+	  * We know that DestroyHnd still has a reference so refCount must be 
+	  * at least 1.
+	  */	  
+	 ASSERT(cur->refCount > 0);
+	 result = VMCI_SUCCESS;
+	 break;
+      }
+      prev = cur;
+      cur = cur->next;
+   }
+   VMCI_ReleaseLock_BH(&hashTable.lock, flags);
+
+   return result;
+}
+
+
+/*
+ *-------------------------------------------------------------------------
+ *
+ *  DatagramHashGetEntry --
+ *
+ *  Result:
+ *     None.
+ *     
+ *-------------------------------------------------------------------------
+ */
+
+static DatagramHashEntry *
+DatagramHashGetEntry(VMCIHandle handle)
+{
+   VMCILockFlags flags;
+   DatagramHashEntry *cur;
+   int idx = VMCI_Hash(handle, HASH_TABLE_SIZE);
+   
+   VMCI_GrabLock_BH(&hashTable.lock, &flags);
+   for (cur = hashTable.entries[idx]; cur != NULL; cur = cur->next) {
+      if (VMCI_HANDLE_EQUAL(cur->handle, handle)) {
+	 cur->refCount++;
+	 break;
+      }
+   }
+   VMCI_ReleaseLock_BH(&hashTable.lock, flags);
+   
+   return cur;
+}
+
+
+/*
+ *-------------------------------------------------------------------------
+ *
+ *  DatagramHashReleaseEntry --
+ *
+ *  Result:
+ *     None.
+ *     
+ *-------------------------------------------------------------------------
+ */
+
+static void
+DatagramHashReleaseEntry(DatagramHashEntry *entry)
+{
+   VMCILockFlags flags;
+
+   VMCI_GrabLock_BH(&hashTable.lock, &flags);
+   entry->refCount--;
+
+   /* Check if this is last reference and signal the destroy event if so. */
+   if (entry->refCount == 0) { 
+      VMCI_SignalEvent(&entry->destroyEvent);
+   }
+   VMCI_ReleaseLock_BH(&hashTable.lock, flags);
+}
+
+
+/*
+ *------------------------------------------------------------------------------
+ *
+ *  DatagramHandleUniqueLocked --
+ *
+ *     Checks whether the given handle is already in the hash
+ *     table. Assumes that the caller to have the hash table lock.
+ *
+ *  Result:
+ *     None.
+ *     
+ *------------------------------------------------------------------------------
+ */
+
+static Bool
+DatagramHandleUniqueLocked(VMCIHandle handle)
+{
+   Bool unique = TRUE;
+   DatagramHashEntry *entry;
+   int idx = VMCI_Hash(handle, HASH_TABLE_SIZE);
+
+   entry = hashTable.entries[idx];
+   while (entry) {
+      if (VMCI_HANDLE_EQUAL(entry->handle, handle)) {
+	 unique = FALSE;
+	 break;
+      }
+      entry = entry->next;
+   }
+
+   return unique;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VMCIDatagram_CreateHnd --
+ *
+ *      Creates a datagram endpoint and returns a handle to it.
+ *
+ * Results:
+ *      Returns handle if success, negative errno value otherwise.
+ *
+ * Side effects:
+ *      Datagram endpoint is created both in guest and on host.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+#ifdef __linux__
+EXPORT_SYMBOL(VMCIDatagram_CreateHnd);
+#endif
+
+int
+VMCIDatagram_CreateHnd(VMCIId resourceID,          // IN:
+                       uint32 flags,               // IN:
+                       VMCIDatagramRecvCB recvCB,  // IN:
+                       void *clientData,           // IN:
+                       VMCIHandle *outHandle)      // OUT:
+   
+{
+   int result;
+   DatagramHashEntry *entry;
+   VMCIHandle handle;
+   VMCIId contextID = VMCI_GetContextID();
+
+   if (!recvCB || !outHandle) {
+      return VMCI_ERROR_INVALID_ARGS;
+   }
+
+   /* Validate contextID. */
+   if (contextID == VMCI_INVALID_ID) {
+      return VMCI_ERROR_NO_RESOURCES;
+   }
+
+   if ((flags & VMCI_FLAG_WELLKNOWN_DG_HND) != 0) {
+      VMCIDatagramWellKnownMapMsg wkMsg;  
+      if (resourceID == VMCI_INVALID_ID) {
+	 return VMCI_ERROR_INVALID_ARGS;
+      }
+      wkMsg.hdr.dst.context = VMCI_HYPERVISOR_CONTEXT_ID;
+      wkMsg.hdr.dst.resource = VMCI_DATAGRAM_REQUEST_MAP;
+      wkMsg.hdr.src = VMCI_ANON_SRC_HANDLE;
+      wkMsg.hdr.payloadSize = sizeof wkMsg - VMCI_DG_HEADERSIZE;
+      wkMsg.wellKnownID = resourceID;
+      result = VMCI_SendDatagram((VMCIDatagram *)&wkMsg);
+      if (result < VMCI_SUCCESS) {
+	 VMCI_LOG(("Failed to reserve wellknown id %d, error %d.\n",
+		   resourceID, result));
+	 return result;
+      }
+
+      handle = VMCI_MAKE_HANDLE(VMCI_WELL_KNOWN_CONTEXT_ID, resourceID);
+   } else {
+      if (resourceID == VMCI_INVALID_ID) {
+         handle = VMCI_INVALID_HANDLE;
+      } else {
+         handle = VMCI_MAKE_HANDLE(contextID, resourceID);
+      }
+   }
+
+   /* Update local datastructure. */
+   entry = VMCI_AllocKernelMem(sizeof *entry, VMCI_MEMORY_NONPAGED);
+   if (entry == NULL) {
+      return VMCI_ERROR_NO_MEM;
+   }
+   
+   entry->handle = handle;
+   entry->flags = flags;
+   entry->recvCB = recvCB;
+   entry->clientData = clientData;
+   entry->refCount = 0;
+   VMCI_CreateEvent(&entry->destroyEvent);
+
+   result = DatagramHashAddEntry(entry, contextID);
+   if (result != VMCI_SUCCESS) {
+      VMCI_LOG(("Failed to add new entry, err 0x%x.\n", result));
+      VMCI_DestroyEvent(&entry->destroyEvent);
+      VMCI_FreeKernelMem(entry, sizeof *entry);
+      return result;
+   }
+
+   ASSERT(!VMCI_HANDLE_INVALID(entry->handle));
+   *outHandle = entry->handle;
+   return VMCI_SUCCESS;
+}
+
+		      
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VMCIDatagram_DestroyHnd --
+ *
+ *      Destroys a handle.
+ *
+ * Results:
+ *      VMCI_SUCCESS or error code.
+ *
+ * Side effects:
+ *      Host and guest state is cleaned up.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+#ifdef __linux__
+EXPORT_SYMBOL(VMCIDatagram_DestroyHnd);
+#endif
+
+int
+VMCIDatagram_DestroyHnd(VMCIHandle handle)       // IN
+{
+   DatagramHashEntry *entry = DatagramHashGetEntry(handle);
+   if (entry == NULL) {
+      return VMCI_ERROR_NOT_FOUND;
+   }
+   
+   DatagramHashRemoveEntry(entry->handle);
+
+   /*
+    * We wait for destroyEvent to be signalled. The resource is released
+    * as part of the wait.
+    */
+   VMCI_WaitOnEvent(&entry->destroyEvent, DatagramReleaseCB, entry);
+
+   
+   if ((entry->flags & VMCI_FLAG_WELLKNOWN_DG_HND) != 0) {
+      int result;
+      VMCIDatagramWellKnownMapMsg wkMsg;
+
+      wkMsg.hdr.dst.context = VMCI_HYPERVISOR_CONTEXT_ID;
+      wkMsg.hdr.dst.resource = VMCI_DATAGRAM_REMOVE_MAP;
+      wkMsg.hdr.src = VMCI_ANON_SRC_HANDLE;
+      wkMsg.hdr.payloadSize = sizeof wkMsg - VMCI_DG_HEADERSIZE;
+      wkMsg.wellKnownID = entry->handle.resource;
+      result = VMCI_SendDatagram((VMCIDatagram *)&wkMsg);
+      if (result < VMCI_SUCCESS) {
+	 VMCI_LOG(("Failed to remove well-known mapping for resource %d.\n",
+		   entry->handle.resource));
+      }
+   }
+   
+   /* We know we are now holding the last reference so we can free the entry. */
+   VMCI_DestroyEvent(&entry->destroyEvent);
+   VMCI_FreeKernelMem(entry, sizeof *entry);
+
+   return VMCI_SUCCESS;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VMCIDatagram_Send --
+ *
+ *      Sends the payload to the destination datagram handle.
+ *
+ * Results:
+ *      Returns number of bytes sent if success, or error code if failure.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+#ifdef __linux__
+EXPORT_SYMBOL(VMCIDatagram_Send);
+#endif
+
+int
+VMCIDatagram_Send(VMCIDatagram *msg) // IN		
+{
+   uint32 retval;
+   DatagramHashEntry *entry;
+
+   if (msg == NULL) {
+      VMCI_LOG(("Invalid datagram.\n"));
+      return VMCI_ERROR_INVALID_ARGS;
+   }
+
+   if (VMCI_DG_SIZE(msg) > VMCI_MAX_DG_SIZE) {
+      VMCI_LOG(("Payload size %"FMT64"u too big to send.\n", msg->payloadSize));
+      return VMCI_ERROR_INVALID_ARGS;
+   }
+
+   /* Check srcHandle exists otherwise fail. */
+   entry = DatagramHashGetEntry(msg->src);
+   if (entry == NULL) {
+      VMCI_LOG(("Couldn't find handle 0x%x:0x%x.\n", 
+		msg->src.context, msg->src.resource));
+      return VMCI_ERROR_INVALID_ARGS;
+   }
+   
+   retval = VMCI_SendDatagram(msg);
+   DatagramHashReleaseEntry(entry);
+
+   return retval;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VMCIDatagram_Dispatch --
+ *
+ *      Forwards the datagram corresponding entry's callback.
+ *
+ * Results:
+ *      VMCI_SUCCESS on success, error code if not.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+int
+VMCIDatagram_Dispatch(VMCIId contextID,  // IN: unused
+		      VMCIDatagram *msg) // IN
+{
+   DatagramHashEntry *entry;
+   
+   ASSERT(msg);
+
+   entry = DatagramHashGetEntry(msg->dst);
+   if (entry == NULL) {
+      VMCI_LOG(("destination handle 0x%x:0x%x doesn't exists.\n",
+		msg->dst.context, msg->dst.resource));
+      return VMCI_ERROR_NO_HANDLE;
+   }
+   
+   if (entry->recvCB) {
+      entry->recvCB(entry->clientData, msg);
+   } else {
+      VMCI_LOG(("no handle callback for handle 0x%x:0x%x payload of "
+		"size %"FMT64"d.\n", 
+		msg->dst.context, msg->dst.resource, msg->payloadSize));
+   }
+   DatagramHashReleaseEntry(entry);
+
+   return VMCI_SUCCESS;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VMCIDatagram_Init --
+ *
+ *      Register guest call handlers.
+ *
+ * Results:
+ *      None
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+void 
+VMCIDatagram_Init(void)
+{
+   int i;
+   
+   VMCI_InitLock(&hashTable.lock,
+                 "VMCIDatagramHashtable",
+                 VMCI_LOCK_RANK_MIDDLE_BH);
+   for (i = 0; i < HASH_TABLE_SIZE; i++) {
+      hashTable.entries[i] = NULL;
+   }
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VMCIDatagram_CheckHostCapabilities --
+ *
+ *      Verify that the host supports the resources we need. 
+ *      None are required for datagrams since they are implicitly supported.
+ *
+ * Results:
+ *      TRUE.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+Bool
+VMCIDatagram_CheckHostCapabilities(void)
+{
+   return TRUE;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * DatagramProcessNotify --
+ *
+ *      Callback to send a notificaton to a vmci process. Creates datagram
+ *      copy and signals the process.
+ *
+ * Results:
+ *      VMCI_SUCCESS on success, appropriate error code otherwise.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static int
+DatagramProcessNotify(void *clientData,   // IN:
+                      VMCIDatagram *msg)  // IN:
+{
+   VMCIDatagramProcess *dgmProc = (VMCIDatagramProcess *) clientData;
+   size_t dgmSize;
+   VMCIDatagram *dgm;
+   DatagramQueueEntry *dqEntry;
+   VMCILockFlags flags;
+   
+   ASSERT(dgmProc != NULL && msg != NULL);
+   dgmSize = VMCI_DG_SIZE(msg);
+   ASSERT(dgmSize <= VMCI_MAX_DG_SIZE);
+
+   dgm = VMCI_AllocKernelMem(dgmSize,
+			     VMCI_MEMORY_NONPAGED | VMCI_MEMORY_ATOMIC);
+   if (!dgm) {
+      VMCI_LOG(("VMCI: Failed to allocate datagram of size %d bytes.\n",
+		(uint32)dgmSize));
+      return VMCI_ERROR_NO_MEM;
+   }
+   memcpy(dgm, msg, dgmSize);
+
+   /* Allocate datagram queue entry and add it to the target fd's queue. */
+   dqEntry = VMCI_AllocKernelMem(sizeof *dqEntry, 
+				 VMCI_MEMORY_NONPAGED | VMCI_MEMORY_ATOMIC);
+   if (dqEntry == NULL) {
+      VMCI_FreeKernelMem(dgm, dgmSize);
+      VMCI_LOG(("VMCI: Failed to allocate memory for process datagram.\n"));
+      return VMCI_ERROR_NO_MEM;
+   }
+   dqEntry->dg = dgm;
+
+   VMCI_GrabLock_BH(&dgmProc->datagramQueueLock, &flags);
+   if (dgmProc->datagramQueueSize + dgmSize >= VMCI_MAX_DATAGRAM_QUEUE_SIZE) {
+      VMCI_ReleaseLock_BH(&dgmProc->datagramQueueLock, flags);
+      VMCI_FreeKernelMem(dgm, dgmSize);
+      VMCI_FreeKernelMem(dqEntry, sizeof *dqEntry);
+      VMCI_LOG(("VMCI: Datagram process receive queue is full.\n"));
+      return VMCI_ERROR_NO_RESOURCES;
+   }
+
+   LIST_QUEUE(&dqEntry->listItem, &dgmProc->datagramQueue);
+   dgmProc->pendingDatagrams++;
+   dgmProc->datagramQueueSize += dgmSize;
+#ifdef SOLARIS
+   /* 
+    * Release the lock here for Solaris. Otherwise, a deadlock 
+    * may occur since pollwakeup(9F) (invoked from VMCIHost_SignalCall)
+    * and poll_common (invoked from poll(2)) try to grab a common lock.
+    * The man pages of pollwakeup(9F) and chpoll(9E) talk about this.
+    */
+   VMCI_ReleaseLock_BH(&dgmProc->datagramQueueLock, flags);
+#endif
+   VMCIHost_SignalCall(&dgmProc->host);
+#ifndef SOLARIS
+   /* For platforms other than Solaris, release the lock here. */
+   VMCI_ReleaseLock_BH(&dgmProc->datagramQueueLock, flags);
+#endif
+
+   DEBUG_ONLY(VMCI_LOG(("VMCI: Sent datagram with resource id %d and size %u.\n",
+                        msg->dst.resource, (uint32)dgmSize));)
+   /* dqEntry and dgm are freed when user reads call.. */
+
+   return VMCI_SUCCESS;
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * VMCIDatagramProcess_Create --
+ *
+ *      Creates a new VMCIDatagramProcess object.
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      None.
+ *
+ *----------------------------------------------------------------------
+ */
+
+int
+VMCIDatagramProcess_Create(VMCIDatagramProcess **outDgmProc,    // IN:
+                           VMCIDatagramCreateInfo *createInfo)  // IN:
+{
+   VMCIDatagramProcess *dgmProc;
+
+   ASSERT(createInfo);
+   ASSERT(outDgmProc);
+   dgmProc = VMCI_AllocKernelMem(sizeof *dgmProc, VMCI_MEMORY_NONPAGED);
+   if (dgmProc == NULL) {
+      return VMCI_ERROR_NO_MEM;
+   }
+
+   VMCI_InitLock(&dgmProc->datagramQueueLock, "VMCIDgmProc",
+		 VMCI_LOCK_RANK_MIDDLE_BH);
+   VMCIHost_InitContext(&dgmProc->host, createInfo->eventHnd);
+   dgmProc->pendingDatagrams = 0;
+   dgmProc->datagramQueueSize = 0;
+   dgmProc->datagramQueue = NULL;
+
+   /*
+    * We pass the result and corresponding handle to user level via the 
+    * createInfo.
+    */
+   createInfo->result = VMCIDatagram_CreateHnd(createInfo->resourceID,
+					       createInfo->flags,
+					       DatagramProcessNotify,
+					       (void *)dgmProc,
+					       &dgmProc->handle);
+   if (createInfo->result < VMCI_SUCCESS) {
+      VMCI_FreeKernelMem(dgmProc, sizeof *dgmProc);
+      return createInfo->result;
+   }
+   createInfo->handle = dgmProc->handle;
+
+   *outDgmProc = dgmProc;
+   return VMCI_SUCCESS;
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * VMCIDatagramProcess_Destroy --
+ *
+ *      Destroys a VMCIDatagramProcess object.
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      None.
+ *
+ *----------------------------------------------------------------------
+ */
+
+void
+VMCIDatagramProcess_Destroy(VMCIDatagramProcess *dgmProc) // IN:
+{
+   ListItem *curr, *next;
+   DatagramQueueEntry *dqEntry;
+   VMCILockFlags flags;
+
+   if (!dgmProc) {
+      return;
+   }
+
+   if (!VMCI_HANDLE_EQUAL(dgmProc->handle, VMCI_INVALID_HANDLE)) {
+
+      /* 
+       * We block in destroy so we know that there can be no more 
+       * callbacks to DatagramProcessNotifyCB when we return from
+       * this call.
+       */
+      VMCIDatagram_DestroyHnd(dgmProc->handle);
+      dgmProc->handle = VMCI_INVALID_HANDLE;
+   }
+
+   /* Flush dgmProc's call queue. */
+   VMCI_GrabLock_BH(&dgmProc->datagramQueueLock, &flags);
+   LIST_SCAN_SAFE(curr, next, dgmProc->datagramQueue) {
+      dqEntry = LIST_CONTAINER(curr, DatagramQueueEntry, listItem);
+      LIST_DEL(curr, &dgmProc->datagramQueue);
+      ASSERT(dqEntry && dqEntry->dg);
+      VMCI_FreeKernelMem(dqEntry->dg, VMCI_DG_SIZE(dqEntry->dg));
+      VMCI_FreeKernelMem(dqEntry, sizeof *dqEntry);
+   }
+   VMCI_ReleaseLock_BH(&dgmProc->datagramQueueLock, flags);
+   VMCIHost_ReleaseContext(&dgmProc->host);
+   VMCI_CleanupLock(&dgmProc->datagramQueueLock);
+   VMCI_FreeKernelMem(dgmProc, sizeof *dgmProc);
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * VMCIDatagramProcess_ReadCall --
+ *
+ *      Dequeues the next guest call and returns it to user level.
+ *
+ * Results:
+ *      0 on success, appropriate error code otherwise.
+ *
+ * Side effects:
+ *      None.
+ *
+ *----------------------------------------------------------------------
+ */
+
+int
+VMCIDatagramProcess_ReadCall(VMCIDatagramProcess *dgmProc, // IN:
+                             size_t maxSize,               // IN: max size of dg
+                             VMCIDatagram **dg)            // OUT: 
+{
+   DatagramQueueEntry *dqEntry;
+   ListItem *listItem;
+   VMCILockFlags flags;
+
+   ASSERT(dgmProc);
+   ASSERT(dg);
+
+   /* Dequeue the next dgmProc datagram queue entry. */
+   VMCI_GrabLock_BH(&dgmProc->datagramQueueLock, &flags);
+
+   /*
+    * Currently, we do not support blocking read of datagrams on Mac and
+    * Solaris. XXX: This will go away soon.
+    */
+
+#if defined(SOLARIS) || defined(__APPLE__)
+   if (dgmProc->pendingDatagrams == 0) {
+      VMCIHost_ClearCall(&dgmProc->host);
+      VMCI_ReleaseLock_BH(&dgmProc->datagramQueueLock, flags);
+      VMCI_LOG(("VMCI: No datagrams pending.\n"));
+      return VMCI_ERROR_NO_MORE_DATAGRAMS;
+   }
+#else
+   while (dgmProc->pendingDatagrams == 0) {
+      VMCIHost_ClearCall(&dgmProc->host);
+      if (!VMCIHost_WaitForCallLocked(&dgmProc->host, &dgmProc->datagramQueueLock,
+                                      &flags, TRUE)) {
+         VMCI_ReleaseLock_BH(&dgmProc->datagramQueueLock, flags);
+         VMCI_LOG(("VMCI: Blocking read of datagram interrupted.\n"));
+         return VMCI_ERROR_NO_MORE_DATAGRAMS;
+      }
+   }
+#endif
+
+   listItem = LIST_FIRST(dgmProc->datagramQueue);
+   ASSERT (listItem != NULL);
+
+   dqEntry = LIST_CONTAINER(listItem, DatagramQueueEntry, listItem);
+   ASSERT(dqEntry->dg);
+
+   /* Check the size of the userland buffer. */
+   if (maxSize < VMCI_DG_SIZE(dqEntry->dg)) {
+      VMCI_ReleaseLock_BH(&dgmProc->datagramQueueLock, flags);
+      VMCI_LOG(("VMCI: Caller's buffer is too small.\n"));
+      return VMCI_ERROR_NO_MEM;
+   }
+   
+   LIST_DEL(listItem, &dgmProc->datagramQueue);
+   dgmProc->pendingDatagrams--;
+   dgmProc->datagramQueueSize -= VMCI_DG_SIZE(dqEntry->dg);
+   if (dgmProc->pendingDatagrams == 0) {
+      VMCIHost_ClearCall(&dgmProc->host);
+   }
+   VMCI_ReleaseLock_BH(&dgmProc->datagramQueueLock, flags);
+
+   *dg = dqEntry->dg;
+   VMCI_FreeKernelMem(dqEntry, sizeof *dqEntry);
+
+   return VMCI_SUCCESS;
+}
+
--- kernel/linux-2.6.26.3/drivers/misc/vmci/vmciDatagram.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmci/vmciDatagram.h	2008-09-03 10:01:42.000000000 -0500
@@ -0,0 +1,62 @@
+/*********************************************************
+ * Copyright (C) 2006 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/* 
+ * vmciDatagram.h --
+ *
+ *      Simple Datagram API for the Linux guest driver.
+ */
+
+#ifndef __VMCI_DATAGRAM_H__
+#define __VMCI_DATAGRAM_H__
+
+#define INCLUDE_ALLOW_MODULE
+#include "includeCheck.h"
+
+#include "vmci_defs.h"
+#include "vmci_kernel_if.h"
+#include "vmci_infrastructure.h"
+#include "circList.h"
+#include "vmciGuestKernelAPI.h"
+#include "vmci_iocontrols.h"
+
+typedef struct DatagramQueueEntry {
+   ListItem listItem; /* For queuing. */
+   VMCIDatagram *dg;  /* Pending datagram. */
+} DatagramQueueEntry;
+
+typedef struct VMCIDatagramProcess {
+   VMCILock   datagramQueueLock;
+   VMCIHandle handle;
+   VMCIHost   host;
+   uint32     pendingDatagrams;
+   size_t     datagramQueueSize;
+   ListItem   *datagramQueue;
+} VMCIDatagramProcess;
+
+void VMCIDatagram_Init(void);
+Bool VMCIDatagram_CheckHostCapabilities(void);
+int VMCIDatagram_Dispatch(VMCIId contextID, VMCIDatagram *msg);
+
+int VMCIDatagramProcess_Create(VMCIDatagramProcess **outDgmProc,
+                               VMCIDatagramCreateInfo *createInfo);
+void VMCIDatagramProcess_Destroy(VMCIDatagramProcess *dgmProc);
+int VMCIDatagramProcess_ReadCall(VMCIDatagramProcess *dgmProc,
+				 size_t maxSize, VMCIDatagram **dg);
+		
+#endif //__VMCI_DATAGRAM_H__
--- kernel/linux-2.6.26.3/drivers/misc/vmci/vmci_defs.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmci/vmci_defs.h	2008-09-03 10:01:42.000000000 -0500
@@ -0,0 +1,290 @@
+/*********************************************************
+ * Copyright (C) 2005-2008 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef _VMCI_DEF_H_
+#define _VMCI_DEF_H_
+
+#define INCLUDE_ALLOW_USERLEVEL
+#define INCLUDE_ALLOW_VMMEXT
+#define INCLUDE_ALLOW_MODULE
+#define INCLUDE_ALLOW_VMMON
+#define INCLUDE_ALLOW_VMCORE
+#define INCLUDE_ALLOW_VMK_MODULE
+#define INCLUDE_ALLOW_VMKERNEL
+#define INCLUDE_ALLOW_DISTRIBUTE
+#include "includeCheck.h"
+
+#include "vm_basic_types.h"
+
+/* Register offsets. */
+#define VMCI_STATUS_ADDR      0x00
+#define VMCI_CONTROL_ADDR     0x04
+#define VMCI_ICR_ADDR	      0x08
+#define VMCI_IMR_ADDR         0x0c
+#define VMCI_DATA_OUT_ADDR    0x10
+#define VMCI_DATA_IN_ADDR     0x14
+#define VMCI_CAPS_ADDR        0x18
+#define VMCI_RESULT_LOW_ADDR  0x1c
+#define VMCI_RESULT_HIGH_ADDR 0x20
+
+/* Max number of devices. */
+#define VMCI_MAX_DEVICES 1
+
+/* Status register bits. */
+#define VMCI_STATUS_INT_ON     0x1
+
+/* Control register bits. */
+#define VMCI_CONTROL_RESET        0x1
+#define VMCI_CONTROL_INT_ENABLE   0x2
+#define VMCI_CONTROL_INT_DISABLE  0x4
+
+/* Capabilities register bits. */
+#define VMCI_CAPS_HYPERCALL    0x1 
+#define VMCI_CAPS_GUESTCALL    0x2
+#define VMCI_CAPS_DATAGRAM     0x4
+
+/* Interrupt Cause register bits. */
+#define VMCI_ICR_DATAGRAM     0x1
+
+/* Interrupt Mask register bits. */
+#define VMCI_IMR_DATAGRAM     0x1
+
+/* 
+ * We have a fixed set of resource IDs available in the VMX. 
+ * This allows us to have a very simple implementation since we statically 
+ * know how many will create datagram handles. If a new caller arrives and
+ * we have run out of slots we can manually increment the maximum size of
+ * available resource IDs.
+ */
+
+typedef uint32 VMCI_Resource;
+
+/* VMCI reserved hypervisor datagram resource IDs. */
+#define VMCI_RESOURCES_QUERY      0
+#define VMCI_GET_CONTEXT_ID       1
+#define VMCI_SHAREDMEM_CREATE     2
+#define VMCI_SHAREDMEM_ATTACH     3
+#define VMCI_SHAREDMEM_DETACH     4
+#define VMCI_SHAREDMEM_QUERY      5
+#define VMCI_DATAGRAM_REQUEST_MAP 6
+#define VMCI_DATAGRAM_REMOVE_MAP  7
+#define VMCI_EVENT_SUBSCRIBE      8
+#define VMCI_EVENT_UNSUBSCRIBE    9
+#define VMCI_QUEUEPAIR_ALLOC      10
+#define VMCI_QUEUEPAIR_DETACH     11
+#define VMCI_RESOURCE_MAX         12
+
+/* VMCI Ids. */
+typedef uint32 VMCIId;
+
+typedef struct VMCIHandle {
+   VMCIId context;
+   VMCIId resource;
+} VMCIHandle;
+
+static INLINE
+VMCIHandle VMCI_MAKE_HANDLE(VMCIId cid, 
+			    VMCIId rid)
+{
+   VMCIHandle h = {cid, rid};
+   return h;
+}
+
+#define VMCI_HANDLE_TO_CONTEXT_ID(_handle) ((_handle).context)
+#define VMCI_HANDLE_TO_RESOURCE_ID(_handle) ((_handle).resource)
+#define VMCI_HANDLE_EQUAL(_h1, _h2) ((_h1).context == (_h2).context && \
+				     (_h1).resource == (_h2).resource)
+
+#define VMCI_INVALID_ID 0xFFFFFFFF
+static const VMCIHandle VMCI_INVALID_HANDLE = {VMCI_INVALID_ID, 
+					       VMCI_INVALID_ID};
+
+#define VMCI_HANDLE_INVALID(_handle)   \
+   VMCI_HANDLE_EQUAL((_handle), VMCI_INVALID_HANDLE)
+
+/*
+ * The below defines can be used to send anonymous requests.
+ * This also indicates that no response is expected.
+ */
+#define VMCI_ANON_SRC_CONTEXT_ID   VMCI_INVALID_ID
+#define VMCI_ANON_SRC_RESOURCE_ID  VMCI_INVALID_ID
+#define VMCI_ANON_SRC_HANDLE       VMCI_MAKE_HANDLE(VMCI_ANON_SRC_CONTEXT_ID, \
+						    VMCI_ANON_SRC_RESOURCE_ID)
+
+/* The lowest 16 context ids are reserved for internal use. */
+#define VMCI_RESERVED_CID_LIMIT 16
+
+/*
+ * Hypervisor context id, used for calling into hypervisor
+ * supplied services from the VM. 
+ */
+#define VMCI_HYPERVISOR_CONTEXT_ID 0
+
+/* 
+ * Well-known context id, a logical context that contains 
+ * a set of well-known services.
+ */
+#define VMCI_WELL_KNOWN_CONTEXT_ID 1
+
+/* Todo: Change host context id to dynamic/random id. */
+#define VMCI_HOST_CONTEXT_ID  2
+
+/* 
+ * The VMCI_CONTEXT_RESOURCE_ID is used together with VMCI_MAKE_HANDLE to make 
+ * handles that refer to a specific context.
+ */
+#define VMCI_CONTEXT_RESOURCE_ID 0
+
+
+/* VMCI error codes. */
+#define VMCI_SUCCESS_QUEUEPAIR_ATTACH     5
+#define VMCI_SUCCESS_QUEUEPAIR_CREATE     4
+#define VMCI_SUCCESS_LAST_DETACH          3
+#define VMCI_SUCCESS_ACCESS_GRANTED       2
+#define VMCI_SUCCESS_ENTRY_DEAD           1
+#define VMCI_SUCCESS                      0
+#define VMCI_ERROR_INVALID_RESOURCE      (-1)
+#define VMCI_ERROR_INVALID_ARGS          (-2)
+#define VMCI_ERROR_NO_MEM                (-3)
+#define VMCI_ERROR_DATAGRAM_FAILED       (-4)
+#define VMCI_ERROR_MORE_DATA             (-5)
+#define VMCI_ERROR_NO_MORE_DATAGRAMS     (-6)
+#define VMCI_ERROR_NO_ACCESS             (-7)
+#define VMCI_ERROR_NO_HANDLE             (-8)
+#define VMCI_ERROR_DUPLICATE_ENTRY       (-9)
+#define VMCI_ERROR_DST_UNREACHABLE       (-10)
+#define VMCI_ERROR_PAYLOAD_TOO_LARGE     (-11)
+#define VMCI_ERROR_INVALID_PRIV          (-12)
+#define VMCI_ERROR_GENERIC               (-13)
+#define VMCI_ERROR_PAGE_ALREADY_SHARED   (-14)
+#define VMCI_ERROR_CANNOT_SHARE_PAGE     (-15)
+#define VMCI_ERROR_CANNOT_UNSHARE_PAGE   (-16)
+#define VMCI_ERROR_NO_PROCESS            (-17)
+#define VMCI_ERROR_NO_DATAGRAM           (-18)
+#define VMCI_ERROR_NO_RESOURCES          (-19)
+#define VMCI_ERROR_UNAVAILABLE           (-20)
+#define VMCI_ERROR_NOT_FOUND             (-21)
+#define VMCI_ERROR_ALREADY_EXISTS        (-22)
+#define VMCI_ERROR_NOT_PAGE_ALIGNED      (-23)
+#define VMCI_ERROR_INVALID_SIZE          (-24)
+#define VMCI_ERROR_REGION_ALREADY_SHARED (-25)
+#define VMCI_ERROR_TIMEOUT               (-26)
+#define VMCI_ERROR_DATAGRAM_INCOMPLETE   (-27)
+#define VMCI_ERROR_INCORRECT_IRQL        (-28)
+#define VMCI_ERROR_EVENT_UNKNOWN         (-29)
+#define VMCI_ERROR_OBSOLETE              (-30)
+#define VMCI_ERROR_QUEUEPAIR_MISMATCH    (-31)
+#define VMCI_ERROR_QUEUEPAIR_NOTSET      (-32)
+#define VMCI_ERROR_QUEUEPAIR_NOTOWNER    (-33)
+#define VMCI_ERROR_QUEUEPAIR_NOTATTACHED (-34)
+#define VMCI_ERROR_QUEUEPAIR_NOSPACE     (-35)
+#define VMCI_ERROR_QUEUEPAIR_NODATA      (-36)
+#define VMCI_ERROR_BUSMEM_INVALIDATION   (-37)
+ 
+/* Internal error codes. */
+#define VMCI_SHAREDMEM_ERROR_BAD_CONTEXT (-1000)
+
+#define VMCI_PATH_MAX 256
+
+/* VMCI reserved events. */
+typedef uint32 VMCI_Event;
+
+#define VMCI_EVENT_CTX_ID_UPDATE  0
+#define VMCI_EVENT_CTX_REMOVED    1
+#define VMCI_EVENT_QP_RESUMED     2
+#define VMCI_EVENT_QP_PEER_ATTACH 3
+#define VMCI_EVENT_QP_PEER_DETACH 4
+#define VMCI_EVENT_MAX            5
+
+/* Reserved guest datagram resource ids. */
+#define VMCI_EVENT_HANDLER 0
+
+/* VMCI privileges. */
+typedef enum VMCIResourcePrivilegeType {
+   VMCI_PRIV_CH_PRIV,
+   VMCI_PRIV_DESTROY_RESOURCE,
+   VMCI_PRIV_ASSIGN_CLIENT,
+   VMCI_PRIV_DG_CREATE,
+   VMCI_PRIV_DG_SEND,
+   VMCI_PRIV_SM_CREATE,
+   VMCI_PRIV_SM_ATTACH,
+   VMCI_NUM_PRIVILEGES,
+} VMCIResourcePrivilegeType;
+
+/* 
+ * VMCI coarse-grained privileges (per context or host
+ * process/endpoint. An entity with the restricted flag is only
+ * allowed to interact with the hypervisor and trusted entities.
+ */
+typedef uint32 VMCIPrivilegeFlags;
+
+#define VMCI_PRIVILEGE_FLAG_RESTRICTED     0x01
+#define VMCI_PRIVILEGE_FLAG_TRUSTED        0x02
+#define VMCI_PRIVILEGE_ALL_FLAGS           (VMCI_PRIVILEGE_FLAG_RESTRICTED | \
+				            VMCI_PRIVILEGE_FLAG_TRUSTED)
+#define VMCI_NO_PRIVILEGE_FLAGS            0x00
+#define VMCI_DEFAULT_PROC_PRIVILEGE_FLAGS  VMCI_NO_PRIVILEGE_FLAGS
+#define VMCI_LEAST_PRIVILEGE_FLAGS         VMCI_PRIVILEGE_FLAG_RESTRICTED
+#define VMCI_MAX_PRIVILEGE_FLAGS           VMCI_PRIVILEGE_FLAG_TRUSTED
+
+/* VMCI Discovery Service. */
+
+/* Well-known handle to the discovery service. */
+#define VMCI_DS_RESOURCE_ID 1 /* Reserved resource ID for discovery service. */
+#define VMCI_DS_HANDLE VMCI_MAKE_HANDLE(VMCI_WELL_KNOWN_CONTEXT_ID, \
+					VMCI_DS_RESOURCE_ID)
+#define VMCI_DS_CONTEXT VMCI_MAKE_HANDLE(VMCI_WELL_KNOWN_CONTEXT_ID, \
+					 VMCI_CONTEXT_RESOURCE_ID)
+
+/* Maximum length of a DS message. */
+#define VMCI_DS_MAX_MSG_SIZE        300
+
+/* Command actions. */
+#define VMCI_DS_ACTION_LOOKUP         0
+#define VMCI_DS_ACTION_REGISTER       1
+#define VMCI_DS_ACTION_UNREGISTER     2
+
+/* Defines wire-protocol format for a request send to the DS from a context. */
+typedef struct VMCIDsRequestHeader {
+   int32       action;
+   int32       msgid;
+   VMCIHandle  handle;
+   int32       nameLen;
+   int8        name[1];   
+} VMCIDsRequestHeader;
+
+
+/* Defines the wire-protocol format for a request send from the DS to a context. */
+typedef struct VMCIDsReplyHeader {
+   int32       msgid;
+   int32       code;
+   VMCIHandle  handle;
+   int32       msgLen;
+   int8        msg[1];
+} VMCIDsReplyHeader;
+
+#define VMCI_PUBLIC_GROUP_NAME "vmci public group"
+/* 0 through VMCI_RESERVED_RESOURCE_ID_MAX are reserved. */
+#define VMCI_RESERVED_RESOURCE_ID_MAX 1023
+
+#define VMCI_DOMAIN_NAME_MAXLEN  32
+
+#define VMCI_LGPFX "VMCI: "
+
+#endif
+
--- kernel/linux-2.6.26.3/drivers/misc/vmci/vmci_drv.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmci/vmci_drv.c	2008-09-03 10:01:42.000000000 -0500
@@ -0,0 +1,915 @@
+/*********************************************************
+ * Copyright (C) 2005 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/* 
+ * vmci.c --
+ *
+ *      Linux guest driver for the VMCI device.
+ */
+   
+#include "driver-config.h"
+
+#define EXPORT_SYMTAB
+   
+   
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 9)
+#include <linux/moduleparam.h>
+#endif
+   
+#include "compat_kernel.h"
+#include "compat_module.h"
+#include "compat_pci.h"
+#include "compat_wait.h"
+#include "compat_init.h"
+#include "compat_ioport.h"
+#include "compat_interrupt.h"
+#include "compat_page.h"
+#include "vm_basic_types.h"
+#include "vm_device_version.h"
+#include "kernelStubs.h"
+#include "vmci_iocontrols.h"
+#include "vmci_defs.h"
+#include "vmciInt.h"
+#include "vmci_infrastructure.h"
+#include "vmciDatagram.h"
+#include "vmciProcess.h"
+#include "vmciUtil.h"
+#include "vmciEvent.h"
+#include "vmciQueuePairInt.h"
+#include "vmci_version.h"
+
+#define LGPFX "VMCI: "
+#define VMCI_DEVICE_MINOR_NUM 0
+
+typedef struct vmci_device {
+   struct semaphore lock;
+
+   unsigned int ioaddr;
+   unsigned int ioaddr_size;
+   unsigned int irq;
+
+   Bool         enabled;
+   spinlock_t   dev_spinlock;
+} vmci_device;
+
+static int vmci_probe_device(struct pci_dev *pdev,
+                             const struct pci_device_id *id);
+static void vmci_remove_device(struct pci_dev* pdev);
+static int vmci_open(struct inode *inode, struct file *file);
+static int vmci_close(struct inode *inode, struct file *file);
+static int vmci_ioctl(struct inode *inode, struct file *file, 
+                      unsigned int cmd, unsigned long arg);
+static unsigned int vmci_poll(struct file *file, poll_table *wait);
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 19)
+static compat_irqreturn_t vmci_interrupt(int irq, void *dev_id, 
+                                         struct pt_regs * regs);
+#else
+static compat_irqreturn_t vmci_interrupt(int irq, void *dev_id);
+#endif
+static void dispatch_datagrams(unsigned long data);
+
+static const struct pci_device_id vmci_ids[] = {
+   { PCI_DEVICE(PCI_VENDOR_ID_VMWARE, PCI_DEVICE_ID_VMWARE_VMCI), },
+   { 0 },
+};
+
+static struct file_operations vmci_ops = {
+   .owner   = THIS_MODULE,
+   .open    = vmci_open,
+   .release = vmci_close,
+   .ioctl   = vmci_ioctl,
+   .poll    = vmci_poll,
+};
+
+static struct pci_driver vmci_driver = {
+   .name     = "vmci",
+   .id_table = vmci_ids,
+   .probe = vmci_probe_device,
+   .remove = vmci_remove_device,
+};
+
+static vmci_device vmci_dev;
+
+/* We dynamically request the device major number at init time. */
+static int device_major_nr = 0;
+
+DECLARE_TASKLET(vmci_tasklet, dispatch_datagrams, 
+                (unsigned long)&vmci_dev);
+
+/* 
+ * Allocate a buffer for incoming datagrams globally to avoid repeated 
+ * allocation in the interrupt handler's atomic context. 
+ */ 
+
+static uint8 *data_buffer = NULL;  
+static uint32 data_buffer_size = VMCI_MAX_DG_SIZE;
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * vmci_init --
+ *
+ *      Initialization, called by Linux when the module is loaded.
+ *
+ * Results:
+ *      Returns 0 for success, negative errno value otherwise.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static int
+vmci_init(void)
+{
+   int err = -ENOMEM;
+
+   /* Register device node ops. */
+   err = register_chrdev(0, "vmci", &vmci_ops);
+   if (err < 0) {
+      printk(KERN_ERR "Unable to register vmci device\n"); 
+      return err;
+   }
+   device_major_nr = err;
+
+   printk("VMCI: Major device number is: %d\n", device_major_nr);
+
+   /* Initialize device data. */
+   init_MUTEX(&vmci_dev.lock);
+   spin_lock_init(&vmci_dev.dev_spinlock);
+   vmci_dev.enabled = FALSE;
+
+   data_buffer = vmalloc(data_buffer_size);
+   if (data_buffer == NULL) {
+      goto error;
+   }
+  
+   /* This should be last to make sure we are done initializing. */
+   err = pci_register_driver(&vmci_driver);
+   if (err < 0) {
+      goto error;
+   }
+
+   return 0;
+
+error:
+   unregister_chrdev(device_major_nr, "vmci");
+   vfree(data_buffer);
+   return err;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * vmci_exit --
+ *
+ *      Cleanup, called by Linux when the module is unloaded.
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static void
+vmci_exit(void)
+{
+   pci_unregister_driver(&vmci_driver);
+   
+   unregister_chrdev(device_major_nr, "vmci");
+
+   vfree(data_buffer);
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * vmci_probe_device --
+ *
+ *      Most of the initialization at module load time is done here.
+ *
+ * Results:
+ *      Returns 0 for success, an error otherwise.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static int
+vmci_probe_device(struct pci_dev *pdev,           // IN: vmci PCI device
+                  const struct pci_device_id *id) // IN: matching device ID
+{
+   unsigned int ioaddr;
+   unsigned int ioaddr_size;
+   unsigned int capabilities;
+   int result;
+
+   printk(KERN_INFO "Probing for vmci/PCI.\n");
+
+   result = compat_pci_enable_device(pdev);
+   if (result) {
+      printk(KERN_ERR "Cannot VMCI device %s: error %d\n",
+             compat_pci_name(pdev), result);
+      return result;
+   }
+   compat_pci_set_master(pdev); /* To enable QueuePair functionality. */
+   ioaddr = compat_pci_resource_start(pdev, 0);
+   ioaddr_size = compat_pci_resource_len(pdev, 0);
+
+   /*
+    * Request I/O region with adjusted base address and size. The adjusted
+    * values are needed and used if we release the region in case of failure.
+    */
+
+   if (!compat_request_region(ioaddr, ioaddr_size, "vmci")) {
+      printk(KERN_INFO "vmci: Another driver already loaded "
+                       "for device in slot %s.\n", compat_pci_name(pdev));
+      goto pci_disable;
+   }
+
+   printk(KERN_INFO "Found vmci/PCI at %#x, irq %u.\n", ioaddr, pdev->irq);
+
+   /*
+    * Verify that the VMCI Device supports the capabilities that
+    * we need. If the device is missing capabilities that we would
+    * like to use, check for fallback capabilities and use those
+    * instead (so we can run a new VM on old hosts). Fail the load if
+    * a required capability is missing and there is no fallback.
+    *
+    * Right now, we need datagrams. There are no fallbacks.
+    */
+   capabilities = inl(ioaddr + VMCI_CAPS_ADDR);
+
+   if ((capabilities & VMCI_CAPS_DATAGRAM) == 0) {
+      printk(KERN_ERR "VMCI device does not support datagrams.\n");
+      goto release;
+   }
+
+   /* Let the host know which capabilities we intend to use. */
+   outl(VMCI_CAPS_DATAGRAM, ioaddr + VMCI_CAPS_ADDR);
+
+   /* Device struct initialization. */
+   down(&vmci_dev.lock);
+   if (vmci_dev.enabled) {
+      printk(KERN_ERR "VMCI device already enabled.\n");
+      goto unlock;
+   }
+
+   vmci_dev.ioaddr = ioaddr;
+   vmci_dev.ioaddr_size = ioaddr_size;
+   vmci_dev.irq = pdev->irq;
+
+   /* Check host capabilities. */
+   if (!VMCI_CheckHostCapabilities()) {
+      goto unlock;
+   }
+
+   /* Enable device. */
+   vmci_dev.enabled = TRUE;
+   pci_set_drvdata(pdev, &vmci_dev);
+
+   /* 
+    * We do global initialization here because we need datagrams for
+    * event init. If we ever support more than one VMCI device we will
+    * have to create seperate LateInit/EarlyExit functions that can be
+    * used to do initialization/cleanup that depends on the device
+    * being accessible.  We need to initialize VMCI components before
+    * requesting an irq - the VMCI interrupt handler uses these
+    * components, and it may be invoked once request_irq() has
+    * registered the handler (as the irq line may be shared).
+    */
+   VMCIProcess_Init();
+   VMCIDatagram_Init();
+   VMCIEvent_Init();
+   VMCIUtil_Init();
+   VMCIQueuePair_Init();
+
+   if (request_irq(vmci_dev.irq, vmci_interrupt, COMPAT_IRQF_SHARED, 
+                   "vmci", &vmci_dev)) {
+      printk(KERN_ERR "vmci: irq %u in use\n", vmci_dev.irq);
+      goto components_exit;
+   }
+
+   printk(KERN_INFO "Registered vmci device.\n");
+
+   up(&vmci_dev.lock);
+
+   /* Enable specific interrupt bits. */
+   outl(VMCI_IMR_DATAGRAM, vmci_dev.ioaddr + VMCI_IMR_ADDR);
+
+   /* Enable interrupts. */
+   outl(VMCI_CONTROL_INT_ENABLE, vmci_dev.ioaddr + VMCI_CONTROL_ADDR);
+
+   return 0;
+
+ components_exit:
+   VMCIQueuePair_Exit();
+   VMCIUtil_Exit();
+   VMCIEvent_Exit();
+   VMCIProcess_Exit();
+ unlock:
+   up(&vmci_dev.lock);
+ release:
+   release_region(ioaddr, ioaddr_size);
+ pci_disable:
+   compat_pci_disable_device(pdev);
+   return -EBUSY;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * vmci_remove_device --
+ *
+ *      Cleanup, called for each device on unload.
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static void
+vmci_remove_device(struct pci_dev* pdev)
+{
+   struct vmci_device *dev = pci_get_drvdata(pdev);
+
+   printk(KERN_INFO "Removing vmci device\n");
+
+   VMCIQueuePair_Exit();
+
+   // XXX Todo add exit/cleanup functions for util, sm, dg, and resource apis.
+   VMCIUtil_Exit();
+   VMCIEvent_Exit();
+   //VMCIDatagram_Exit();
+   VMCIProcess_Exit();
+   
+   down(&dev->lock);
+   printk(KERN_INFO "Resetting vmci device\n");
+   outl(VMCI_CONTROL_RESET, vmci_dev.ioaddr + VMCI_CONTROL_ADDR);
+   free_irq(dev->irq, dev);
+   release_region(dev->ioaddr, dev->ioaddr_size);
+   dev->enabled = FALSE;
+
+   printk(KERN_INFO "Unregistered vmci device.\n");
+   up(&dev->lock);
+   
+   compat_pci_disable_device(pdev);
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * vmci_open --
+ *
+ *      Open device.
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static int
+vmci_open(struct inode *inode,  // IN
+          struct file *file)    // IN
+{
+   VMCIGuestDeviceHandle *devHndl;
+   int errcode;
+
+   printk(KERN_INFO "Opening vmci device\n");
+
+   if (MINOR(inode->i_rdev) != VMCI_DEVICE_MINOR_NUM) {
+      return -ENODEV;
+   }
+
+   down(&vmci_dev.lock);
+   if (!vmci_dev.enabled) {
+      printk(KERN_INFO "Received open on uninitialized vmci device.\n");
+      errcode = -ENODEV;
+      goto unlock;
+   }
+
+   /* Do open ... */
+   devHndl = VMCI_AllocKernelMem(sizeof *devHndl, VMCI_MEMORY_NORMAL);
+   if (!devHndl) {
+      printk(KERN_INFO "Failed to create device obj when opening device.\n");
+      errcode = -ENOMEM;
+      goto unlock;
+   }
+   devHndl->obj = NULL;
+   devHndl->objType = VMCIOBJ_NOT_SET;
+   file->private_data = devHndl;
+
+   up(&vmci_dev.lock);
+
+   return 0;
+
+ unlock:
+   up(&vmci_dev.lock);
+   return errcode;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * vmci_close --
+ *
+ *      Close device.
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static int
+vmci_close(struct inode *inode,  // IN
+           struct file *file)    // IN
+{
+   VMCIGuestDeviceHandle *devHndl =
+      (VMCIGuestDeviceHandle *) file->private_data;
+
+   if (devHndl) {
+      if (devHndl->objType == VMCIOBJ_PROCESS) {
+         VMCIProcess_Destroy((VMCIProcess *) devHndl->obj);
+      } else if (devHndl->objType == VMCIOBJ_DATAGRAM_PROCESS) {
+         VMCIDatagramProcess_Destroy((VMCIDatagramProcess *) devHndl->obj);
+      }
+      VMCI_FreeKernelMem(devHndl, sizeof *devHndl);
+      file->private_data = NULL;
+   }
+   return 0;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * vmci_ioctl --
+ *
+ *      IOCTL interface to device.
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static int
+vmci_ioctl(struct inode *inode,  // IN
+           struct file *file,    // IN
+           unsigned int cmd,     // IN
+           unsigned long arg)    // IN
+{
+#ifndef VMX86_DEVEL
+   return -ENOTTY;
+#else
+   int retval;
+   VMCIGuestDeviceHandle *devHndl =
+      (VMCIGuestDeviceHandle *) file->private_data;
+
+   if (devHndl == NULL) {
+      return -EINVAL;
+   }
+
+   switch (cmd) {
+   case IOCTL_VMCI_CREATE_PROCESS: {
+      if (devHndl->objType != VMCIOBJ_NOT_SET) {
+         printk("VMCI: Received IOCTLCMD_VMCI_CREATE_PROCESS on "
+                "initialized handle.\n");
+         retval = -EINVAL;
+         break;
+      }
+      ASSERT(!devHndl->obj);
+      retval = VMCIProcess_Create((VMCIProcess **) &devHndl->obj, -1);
+      if (retval != 0) {
+         printk("VMCI: Failed to create process.\n");
+         break;
+      }
+      devHndl->objType = VMCIOBJ_PROCESS;
+      break;
+   }
+
+   case IOCTL_VMCI_CREATE_DATAGRAM_PROCESS: {
+      VMCIDatagramCreateInfo createInfo;
+      VMCIDatagramProcess *dgmProc;
+
+      if (devHndl->objType != VMCIOBJ_NOT_SET) {
+         printk("VMCI: Received IOCTLCMD_VMCI_CREATE_DATAGRAM_PROCESS on "
+                "initialized handle.\n");
+         retval = -EINVAL;
+         break;
+      }
+      ASSERT(!devHndl->obj);
+
+      retval = copy_from_user(&createInfo, (void *)arg, sizeof createInfo);
+      if (retval != 0) {
+	 printk("VMCI: Error getting datagram create info, %d.\n", retval);
+	 retval = -EFAULT;
+	 break;
+      }
+      
+      if (VMCIDatagramProcess_Create(&dgmProc, &createInfo) < VMCI_SUCCESS) {
+	 retval = -EINVAL;
+	 break;
+      }
+
+      retval = copy_to_user((void *)arg, &createInfo, sizeof createInfo);
+      if (retval != 0) {
+         VMCIDatagramProcess_Destroy(dgmProc);
+         printk("VMCI: Failed to create datagram process.\n");
+	 retval = -EFAULT;
+         break;
+      }
+      devHndl->obj = dgmProc;
+      devHndl->objType = VMCIOBJ_DATAGRAM_PROCESS;
+      break;
+   }
+
+   case IOCTL_VMCI_DATAGRAM_SEND: {
+      VMCIDatagramSendRecvInfo sendInfo;
+      VMCIDatagram *dg = NULL;
+
+      if (devHndl->objType != VMCIOBJ_DATAGRAM_PROCESS) {
+         printk("VMCI: Ioctl %d only valid for process datagram handle.\n",
+		cmd);
+         retval = -EINVAL;
+         break;
+      }
+
+      retval = copy_from_user(&sendInfo, (void *) arg, sizeof sendInfo);
+      if (retval) {
+         printk("VMCI: copy_from_user failed.\n");
+         retval = -EFAULT;
+         break;
+      }
+
+      if (sendInfo.len > VMCI_MAX_DG_SIZE) {
+         printk("VMCI: datagram size too big.\n");
+	 retval = -EINVAL;
+	 break;
+      }
+
+      dg = VMCI_AllocKernelMem(sendInfo.len, VMCI_MEMORY_NORMAL);
+      if (dg == NULL) {
+         printk("VMCI: Cannot allocate memory to dispatch datagram.\n");
+         retval = -ENOMEM;
+         break;
+      }
+
+      retval = copy_from_user(dg, (char *)(VA)sendInfo.addr, sendInfo.len);
+      if (retval != 0) {
+         printk("VMCI: Error getting datagram: %d\n", retval);
+         VMCI_FreeKernelMem(dg, sendInfo.len);
+         retval = -EFAULT;
+         break;
+      }
+
+      DEBUG_ONLY(printk("VMCI: Datagram dst handle 0x%x:0x%x, src handle "
+			"0x%x:0x%x, payload size %"FMT64"u.\n", 
+			dg->dst.context, dg->dst.resource, 
+			dg->src.context, dg->src.resource, dg->payloadSize));
+
+      sendInfo.result = VMCIDatagram_Send(dg);
+      VMCI_FreeKernelMem(dg, sendInfo.len);
+
+      retval = copy_to_user((void *)arg, &sendInfo, sizeof sendInfo);
+      break;
+   }
+
+   case IOCTL_VMCI_DATAGRAM_RECEIVE: {
+      VMCIDatagramSendRecvInfo recvInfo;
+      VMCIDatagram *dg = NULL;
+
+      if (devHndl->objType != VMCIOBJ_DATAGRAM_PROCESS) {
+         printk("VMCI: Ioctl %d only valid for process datagram handle.\n",
+		cmd);
+         retval = -EINVAL;
+         break;
+      }
+
+      retval = copy_from_user(&recvInfo, (void *) arg, sizeof recvInfo);
+      if (retval) {
+         printk("VMCI: copy_from_user failed.\n");
+         retval = -EFAULT;
+         break;
+      }
+
+      ASSERT(devHndl->obj);
+      recvInfo.result = 
+	 VMCIDatagramProcess_ReadCall((VMCIDatagramProcess *)devHndl->obj, 
+				      recvInfo.len, &dg);
+      if (recvInfo.result < VMCI_SUCCESS) {
+	 retval = -EINVAL;
+	 break;
+      }
+      ASSERT(dg);
+      retval = copy_to_user((void *) ((uintptr_t) recvInfo.addr), dg,
+			    VMCI_DG_SIZE(dg));
+      VMCI_FreeKernelMem(dg, VMCI_DG_SIZE(dg));
+      if (retval != 0) {
+	 break;
+      }
+      retval = copy_to_user((void *)arg, &recvInfo, sizeof recvInfo);
+      break;
+   }
+
+   case IOCTL_VMCI_GET_CONTEXT_ID: {
+      VMCIId cid = VMCI_GetContextID();
+
+      retval = copy_to_user((void *)arg, &cid, sizeof cid);
+      break;
+   }
+
+   default:
+      printk(KERN_DEBUG "vmci_ioctl(): unknown ioctl 0x%x.\n", cmd);
+      retval = -EINVAL;
+      break;
+   }
+
+   return retval;
+#endif
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * vmci_poll --
+ *
+ *      vmci poll function
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static unsigned int
+vmci_poll(struct file *file, // IN
+          poll_table *wait)  // IN
+{
+   VMCILockFlags flags;
+   unsigned int mask = 0;
+   VMCIGuestDeviceHandle *devHndl =
+      (VMCIGuestDeviceHandle *) file->private_data;
+
+   /* 
+    * Check for call to this VMCI process. 
+    */
+   
+   if (!devHndl) {
+      return mask;
+   }
+   if (devHndl->objType == VMCIOBJ_DATAGRAM_PROCESS) {
+      VMCIDatagramProcess *dgmProc = (VMCIDatagramProcess *) devHndl->obj;
+      ASSERT(dgmProc);
+      
+      if (wait != NULL) {
+         poll_wait(file, &dgmProc->host.waitQueue, wait);
+      }
+
+      VMCI_GrabLock_BH(&dgmProc->datagramQueueLock, &flags);
+      if (dgmProc->pendingDatagrams > 0) {
+         mask = POLLIN;
+      }
+      VMCI_ReleaseLock_BH(&dgmProc->datagramQueueLock, flags);
+   }
+
+   return mask;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * vmci_interrupt --
+ *
+ *      Interrupt handler.
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 19)
+static compat_irqreturn_t
+vmci_interrupt(int irq,               // IN
+               void *clientdata,      // IN
+               struct pt_regs *regs)  // IN
+#else
+static compat_irqreturn_t
+vmci_interrupt(int irq,               // IN
+               void *clientdata)      // IN
+#endif
+{
+   vmci_device *dev = clientdata;
+   unsigned int icr = 0;
+
+   if (dev == NULL) {
+      printk (KERN_DEBUG "vmci_interrupt(): irq %d for unknown device.\n",
+              irq);
+      return COMPAT_IRQ_NONE;
+   }
+
+   /* Acknowledge interrupt and determine what needs doing. */
+   icr = inl(dev->ioaddr + VMCI_ICR_ADDR);
+   if (icr == 0) {
+      return COMPAT_IRQ_NONE;
+   }
+
+   if (icr & VMCI_ICR_DATAGRAM) {
+      tasklet_schedule(&vmci_tasklet);
+      icr &= ~VMCI_ICR_DATAGRAM;
+   }
+   if (icr != 0) {
+      printk(KERN_INFO LGPFX"Ignoring unknown interrupt cause (%d).\n", icr);
+   }
+
+   return COMPAT_IRQ_HANDLED;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VMCI_DeviceEnabled --
+ *
+ *      Checks whether the VMCI device is enabled.
+ *
+ * Results:
+ *      TRUE if device is enabled, FALSE otherwise.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+Bool
+VMCI_DeviceEnabled(void)
+{
+   Bool retval;
+
+   down(&vmci_dev.lock);
+   retval = vmci_dev.enabled;
+   up(&vmci_dev.lock);
+   
+   return retval;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VMCI_SendDatagram --
+ *
+ *      VM to hypervisor call mechanism. We use the standard VMware naming
+ *      convention since shared code is calling this function as well.
+ *
+ * Results:
+ *      The result of the hypercall.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+int
+VMCI_SendDatagram(VMCIDatagram *dg)
+{
+   unsigned long flags;
+   int result;
+
+   /* Check args. */
+   if (dg == NULL) {
+      return VMCI_ERROR_INVALID_ARGS;
+   }
+
+   /*
+    * Need to acquire spinlock on the device because
+    * the datagram data may be spread over multiple pages and the monitor may
+    * interleave device user rpc calls from multiple VCPUs. Acquiring the
+    * spinlock precludes that possibility. Disabling interrupts to avoid
+    * incoming datagrams during a "rep out" and possibly landing up in this
+    * function.
+    */
+   spin_lock_irqsave(&vmci_dev.dev_spinlock, flags);
+
+   /* 
+    * Send the datagram and retrieve the return value from the result register.
+    */
+   __asm__ __volatile__(
+      "cld\n\t"
+      "rep outsb\n\t"
+      : /* No output. */
+      : "d"(vmci_dev.ioaddr + VMCI_DATA_OUT_ADDR),
+	"c"(VMCI_DG_SIZE(dg)), "S"(dg)
+      );
+
+   /*
+    * XXX Should read result high port as well when updating handlers to
+    * return 64bit.
+    */
+   result = inl(vmci_dev.ioaddr + VMCI_RESULT_LOW_ADDR);
+   spin_unlock_irqrestore(&vmci_dev.dev_spinlock, flags);
+
+   return result;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * dispatch_datagrams --
+ *
+ *      Reads and dispatches incoming datagrams.
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      Reads data from the device.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+void
+dispatch_datagrams(unsigned long data)
+{
+   vmci_device *dev = (vmci_device *)data;
+
+   if (dev == NULL) {
+      printk(KERN_DEBUG "vmci: dispatch_datagrams(): no vmci device"
+	     "present.\n");
+      return;
+   }
+      
+   if (data_buffer == NULL) {
+      printk(KERN_DEBUG "vmci: dispatch_datagrams(): no buffer present.\n");
+      return;
+   }
+
+
+   VMCI_ReadDatagramsFromPort((VMCIIoHandle) 0, dev->ioaddr + VMCI_DATA_IN_ADDR,
+			      data_buffer, data_buffer_size);
+}
+
+
+module_init(vmci_init);
+module_exit(vmci_exit);
+MODULE_DEVICE_TABLE(pci, vmci_ids);
+
+/* Module information. */
+MODULE_AUTHOR("VMware, Inc.");
+MODULE_DESCRIPTION("VMware Virtual Machine Communication Interface");
+MODULE_VERSION(VMCI_DRIVER_VERSION_STRING);
+MODULE_LICENSE("GPL v2");
--- kernel/linux-2.6.26.3/drivers/misc/vmci/vmciEvent.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmci/vmciEvent.c	2008-09-03 10:01:42.000000000 -0500
@@ -0,0 +1,468 @@
+/*********************************************************
+ * Copyright (C) 2007 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * vmciEvent.c --
+ *
+ *     VMCI Event code for host and guests.
+ */
+
+#if defined(__linux__) && !defined(VMKERNEL)
+#  include "driver-config.h"
+
+#  define EXPORT_SYMTAB
+
+#  include <linux/module.h>
+#  include "compat_kernel.h"
+#endif // __linux__
+#include "vmci_defs.h"
+#include "vmci_kernel_if.h"
+#include "vmci_infrastructure.h"
+#include "vmciEvent.h"
+#ifdef VMX86_TOOLS 
+#  include "vmciInt.h"
+#  include "vmciGuestKernelAPI.h"
+#  include "vmciUtil.h"
+#else
+#  include "vmciDriver.h"
+#endif
+#include "circList.h"
+#ifdef VMKERNEL
+#  include "vm_libc.h"
+#endif
+
+#define EVENT_MAGIC 0xEABE0000
+
+
+typedef struct VMCISubscription {
+   VMCIId         id;
+   VMCI_Event     event;
+   VMCI_EventCB   callback;
+   void           *callbackData;
+   ListItem       subscriberListItem;
+} VMCISubscription;
+
+typedef struct VMCISubscriptionItem {
+   ListItem          listItem;
+   VMCISubscription  sub;
+} VMCISubscriptionItem;
+
+
+static VMCISubscription *VMCIEventFind(VMCIId subID);
+static int VMCIEventRegisterSubscription(VMCISubscription *sub, VMCI_Event event,
+                                         VMCI_EventCB callback, 
+                                         void *callbackData);
+static VMCISubscription *VMCIEventUnregisterSubscription(VMCIId subID);
+
+/*
+ * In the guest, VMCI events are dispatched from interrupt context, so
+ * the locks need to be bottom half safe. In the host kernel, this
+ * isn't so, and regular locks are used instead.
+ */
+
+#ifdef VMX86_TOOLS 
+#define VMCIEventInitLock(_lock, _name) VMCI_InitLock(_lock, _name, VMCI_LOCK_RANK_MIDDLE_BH)
+#define VMCIEventGrabLock(_lock, _flags) VMCI_GrabLock_BH(_lock, _flags)
+#define VMCIEventReleaseLock(_lock, _flags) VMCI_ReleaseLock_BH(_lock, _flags)
+#else
+#define VMCIEventInitLock(_lock, _name) VMCI_InitLock(_lock, _name, VMCI_LOCK_RANK_HIGH)
+#define VMCIEventGrabLock(_lock, _flags) VMCI_GrabLock(_lock, _flags)
+#define VMCIEventReleaseLock(_lock, _flags) VMCI_ReleaseLock(_lock, _flags)
+#endif
+
+
+static ListItem *subscriberArray[VMCI_EVENT_MAX] = {NULL};
+static VMCILock subscriberLock;
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * VMCIEvent_Init --
+ *
+ *      General init code.
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      None.
+ *
+ *----------------------------------------------------------------------
+ */
+
+void
+VMCIEvent_Init(void)
+{
+   VMCIEventInitLock(&subscriberLock, "VMCIEventSubscriberLock");
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * VMCIEvent_Exit --
+ *
+ *      General exit code.
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      None.
+ *
+ *----------------------------------------------------------------------
+ */
+
+void
+VMCIEvent_Exit(void)
+{
+   VMCILockFlags flags;
+   ListItem *iter, *iter2;
+   VMCI_Event e;
+
+   /* We free all memory at exit. */
+   VMCIEventGrabLock(&subscriberLock, &flags);
+   for (e = 0; e < VMCI_EVENT_MAX; e++) {
+      LIST_SCAN_SAFE(iter, iter2, subscriberArray[e]) {
+         VMCISubscription *cur = 
+            LIST_CONTAINER(iter, VMCISubscription, subscriberListItem);
+         VMCI_FreeKernelMem(cur, sizeof *cur);
+      }
+      subscriberArray[e] = NULL;
+   }
+   VMCIEventReleaseLock(&subscriberLock, flags);
+   VMCI_CleanupLock(&subscriberLock);
+}
+
+#ifdef VMX86_TOOLS
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VMCIEvent_CheckHostCapabilities --
+ *
+ *      Verify that the host supports the hypercalls we need. If it does not,
+ *      try to find fallback hypercalls and use those instead.
+ *
+ * Results:
+ *      TRUE if required hypercalls (or fallback hypercalls) are
+ *      supported by the host, FALSE otherwise.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+Bool
+VMCIEvent_CheckHostCapabilities(void)
+{
+   /* VMCIEvent does not require any hypercalls. */
+   return TRUE;
+}
+#endif
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VMCIEventFind --
+ *
+ *      Find entry. Assumes lock is held.
+ *
+ * Results:
+ *      Entry if found, NULL if not.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static VMCISubscription *
+VMCIEventFind(VMCIId subID)  // IN
+{
+   ListItem *iter;
+   VMCI_Event e;
+
+   for (e = 0; e < VMCI_EVENT_MAX; e++) {
+      LIST_SCAN(iter, subscriberArray[e]) {
+         VMCISubscription *cur = 
+            LIST_CONTAINER(iter, VMCISubscription, subscriberListItem);
+	 if (cur->id == subID) {
+	    return cur;
+	 }
+      }
+   }
+   return NULL;
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * VMCIEvent_Dispatch -- 
+ *
+ *      Dispatcher for the VMCI_EVENT_RECEIVE datagrams. Calls all 
+ *      subscribers for given event.
+ *
+ * Results:
+ *      VMCI_SUCCESS on success, error code otherwise.
+ *
+ * Side effects:
+ *      None.
+ *
+ *----------------------------------------------------------------------
+ */
+
+int
+VMCIEvent_Dispatch(VMCIDatagram *msg)  // IN
+{
+   ListItem *iter;
+   VMCILockFlags flags;
+   VMCIEventMsg *eventMsg = (VMCIEventMsg *)msg;
+
+   ASSERT(msg && 
+          msg->src.context == VMCI_HYPERVISOR_CONTEXT_ID &&
+          msg->dst.resource == VMCI_EVENT_HANDLER);
+
+   if (msg->payloadSize < sizeof(VMCI_Event) ||
+       msg->payloadSize > sizeof(VMCIEventData_Max)) {
+      return VMCI_ERROR_INVALID_ARGS;
+   }
+
+   if (eventMsg->eventData.event >= VMCI_EVENT_MAX) {
+      return VMCI_ERROR_EVENT_UNKNOWN;
+   }
+
+   VMCIEventGrabLock(&subscriberLock, &flags);
+   LIST_SCAN(iter, subscriberArray[eventMsg->eventData.event]) {
+      uint8 eventPayload[sizeof(VMCIEventData_Max)];
+      VMCI_EventData *ed;
+      VMCISubscription *cur = LIST_CONTAINER(iter, VMCISubscription,
+                                             subscriberListItem);
+      ASSERT(cur && cur->event == eventMsg->eventData.event);
+
+      /* We set event data before each callback to ensure isolation. */
+      memset(eventPayload, 0, sizeof eventPayload);
+      memcpy(eventPayload, VMCI_DG_PAYLOAD(eventMsg),
+             (size_t)eventMsg->hdr.payloadSize); 
+      ed = (VMCI_EventData *)eventPayload;
+      cur->callback(cur->id, ed, cur->callbackData);
+   }
+   VMCIEventReleaseLock(&subscriberLock, flags);
+
+   return VMCI_SUCCESS;
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * VMCIEventRegisterSubscription --
+ *
+ *      Initialize and add subscription to subscriber list.
+ *
+ * Results:
+ *      VMCI_SUCCESS on success, error code otherwise.
+ *
+ * Side effects:
+ *      None.
+ *
+ *----------------------------------------------------------------------
+ */
+
+static int
+VMCIEventRegisterSubscription(VMCISubscription *sub,   // IN
+                              VMCI_Event event,        // IN
+                              VMCI_EventCB callback,   // IN
+                              void *callbackData)      // IN
+{
+#  define VMCI_EVENT_MAX_ATTEMPTS 10
+   static VMCIId subscriptionID = 0;
+   VMCILockFlags flags;
+   uint32 attempts = 0;
+   int result;
+   Bool success;
+
+   ASSERT(sub);
+   
+   if (event >= VMCI_EVENT_MAX || callback == NULL) {
+      VMCI_LOG(("VMCIEvent: Failed to subscribe to event %d cb %p data %p.\n",
+                event, callback, callbackData));
+      return VMCI_ERROR_INVALID_ARGS;
+   }
+   
+   sub->event = event;
+   sub->callback = callback;
+   sub->callbackData = callbackData;
+   
+   VMCIEventGrabLock(&subscriberLock, &flags);
+   ASSERT(subscriberArray);
+   for (success = FALSE, attempts = 0;
+	success == FALSE && attempts < VMCI_EVENT_MAX_ATTEMPTS;
+	attempts++) {
+
+      /* 
+       * We try to get an id a couple of time before claiming we are out of
+       * resources.
+       */
+      sub->id = ++subscriptionID;
+
+      /* Test for duplicate id. */
+      if (VMCIEventFind(sub->id) == NULL) {
+	 /* We succeeded if we didn't find a duplicate. */
+	 success = TRUE;
+      }
+   }
+
+   if (success) {
+      LIST_QUEUE(&sub->subscriberListItem, &subscriberArray[event]);
+      result = VMCI_SUCCESS;
+   } else {
+      result = VMCI_ERROR_NO_RESOURCES;
+   }
+   VMCIEventReleaseLock(&subscriberLock, flags);
+
+   return result;
+#  undef VMCI_EVENT_MAX_ATTEMPTS
+}
+
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * VMCIEventUnregisterSubscription --
+ *
+ *      Remove subscription from subscriber list.
+ *
+ * Results:
+ *      VMCISubscription when found, NULL otherwise.
+ *
+ * Side effects:
+ *      None.
+ *
+ *----------------------------------------------------------------------
+ */
+
+static VMCISubscription *
+VMCIEventUnregisterSubscription(VMCIId subID)    // IN
+{
+   VMCILockFlags flags;
+   VMCISubscription *s;
+   
+   VMCIEventGrabLock(&subscriberLock, &flags);
+   s = VMCIEventFind(subID);
+   if (s != NULL) {
+      LIST_DEL(&s->subscriberListItem, &subscriberArray[s->event]);
+   }
+   VMCIEventReleaseLock(&subscriberLock, flags);
+   
+   return s;
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * VMCIEvent_Subscribe --
+ *
+ *      Subscribe to given event.
+ *
+ * Results:
+ *      VMCI_SUCCESS on success, error code otherwise.
+ *
+ * Side effects:
+ *      None.
+ *
+ *----------------------------------------------------------------------
+ */
+
+#if defined(__linux__) && !defined(VMKERNEL)
+EXPORT_SYMBOL(VMCIEvent_Subscribe);
+#endif
+
+int
+VMCIEvent_Subscribe(VMCI_Event event,        // IN
+                    VMCI_EventCB callback,   // IN
+                    void *callbackData,      // IN
+                    VMCIId *subscriptionID)  // OUT
+{
+   int retval;
+   VMCISubscription *s = NULL;  
+   
+   if (subscriptionID == NULL) {
+      VMCI_LOG(("VMCIEvent: Invalid arguments.\n"));
+      return VMCI_ERROR_INVALID_ARGS;
+   }
+
+   s = VMCI_AllocKernelMem(sizeof *s, VMCI_MEMORY_NONPAGED);
+   if (s == NULL) {
+      return VMCI_ERROR_NO_MEM;
+   }
+   
+   retval = VMCIEventRegisterSubscription(s, event, callback, callbackData);
+   if (retval < VMCI_SUCCESS) {
+      VMCI_FreeKernelMem(s, sizeof *s);
+      return retval;
+   }
+
+   *subscriptionID = s->id;
+   return retval;
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * VMCIEvent_Unsubscribe --
+ *
+ *      Unsubscribe to given event. Removes it from list and frees it. 
+ *      Will return callbackData if requested by caller.
+ *
+ * Results:
+ *      VMCI_SUCCESS on success, error code otherwise.
+ *
+ * Side effects:
+ *      None.
+ *
+ *----------------------------------------------------------------------
+ */
+
+#if defined(__linux__) && !defined(VMKERNEL)
+EXPORT_SYMBOL(VMCIEvent_Unsubscribe);
+#endif
+
+int
+VMCIEvent_Unsubscribe(VMCIId subID)   // IN
+{
+   VMCISubscription *s;
+
+   /* 
+    * Return subscription. At this point we know noone else is accessing
+    * the subscription so we can free it. 
+    */
+   s = VMCIEventUnregisterSubscription(subID);
+   if (s == NULL) {
+      return VMCI_ERROR_NOT_FOUND;
+
+   }
+   VMCI_FreeKernelMem(s, sizeof *s);
+
+   return VMCI_SUCCESS;
+}
--- kernel/linux-2.6.26.3/drivers/misc/vmci/vmciEvent.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmci/vmciEvent.h	2008-09-03 10:01:42.000000000 -0500
@@ -0,0 +1,56 @@
+/*********************************************************
+ * Copyright (C) 2007 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/* 
+ * vmciEvent.h --
+ *
+ *      Event code for the vmci guest driver
+ */
+
+#ifndef __VMCI_EVENT_H__
+#define __VMCI_EVENT_H__
+
+#define INCLUDE_ALLOW_MODULE
+#define INCLUDE_ALLOW_VMMON
+#define INCLUDE_ALLOW_VMCORE
+#define INCLUDE_ALLOW_VMKERNEL
+#include "includeCheck.h"
+
+#include "vmci_defs.h"
+#include "vmci_call_defs.h"
+
+void VMCIEvent_Init(void);
+void VMCIEvent_Exit(void);
+int  VMCIEvent_Dispatch(VMCIDatagram *msg);
+#ifdef VMX86_TOOLS
+Bool VMCIEvent_CheckHostCapabilities(void);
+#else
+
+/* 
+ * Public VMCI Event API for host kernel.
+ */
+
+typedef void (*VMCI_EventCB)(VMCIId subID, VMCI_EventData *ed,
+			     void *clientData);
+
+int VMCIEvent_Subscribe(VMCI_Event event, VMCI_EventCB callback, 
+                        void *callbackData, VMCIId *subID);
+int VMCIEvent_Unsubscribe(VMCIId subID);
+#endif
+
+#endif //__VMCI_EVENT_H__
--- kernel/linux-2.6.26.3/drivers/misc/vmci/vmciGuestDs.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmci/vmciGuestDs.c	2008-09-03 10:01:42.000000000 -0500
@@ -0,0 +1,259 @@
+/*********************************************************
+ * Copyright (C) 2007 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * vmciGuestDs.c
+ *
+ * Implements the client-access API to the VMCI discovery service in
+ * the guest kernel.
+ *
+ */
+
+#ifdef __linux__
+#  include "driver-config.h"
+
+#  define EXPORT_SYMTAB
+
+#  include <linux/module.h>
+#  include "compat_kernel.h"
+#  include "compat_pci.h"
+#elif defined(_WIN32)
+#  include <ntddk.h>
+#elif defined(SOLARIS)
+#  include <sys/ddi.h>
+#  include <sys/sunddi.h>
+#else
+#  error "Platform not support by VMCI datagram API."
+#endif // linux
+
+#include "vm_basic_types.h"
+#include "vm_atomic.h"
+#include "vm_assert.h"
+#include "vmci_defs.h"
+#include "vmci_kernel_if.h"
+#include "vmci_infrastructure.h"
+#include "vmciInt.h"
+#include "vmciUtil.h"
+#include "vmciDatagram.h"
+
+static Atomic_uint32 MsgIdCounter = { 0 };
+
+typedef struct VMCIDsRecvData {
+   VMCIHost context;
+   VMCILock lock;
+   int status;
+   uint8 buffer[VMCI_DS_MAX_MSG_SIZE];
+} VMCIDsRecvData;
+
+static int VMCIDsDoCall(int action, const char *name, VMCIHandle handle,
+                        VMCIHandle *handleOut);
+static int VMCIDsRecvCB(void *clientData, struct VMCIDatagram *msg);
+
+/*
+ *-------------------------------------------------------------------------
+ *
+ *  VMCIDs_Lookup --
+ *
+ *       Look up a handle in the VMCI discovery service based on 
+ *       the given name.
+ *
+ *  Results:
+ *       Error code. 0 if success.
+ *     
+ *  Side effects:
+ *       None.
+ *
+ *-------------------------------------------------------------------------
+ */
+
+#ifdef __linux__
+EXPORT_SYMBOL(VMCIDs_Lookup);
+#endif
+
+int 
+VMCIDs_Lookup(const char *name,	  // IN
+              VMCIHandle *out)    // 
+{
+   return VMCIDsDoCall(VMCI_DS_ACTION_LOOKUP, name, VMCI_INVALID_HANDLE, out);
+}
+
+
+/*
+ *-------------------------------------------------------------------------
+ *
+ *  VMCIDsDoCall --
+ *
+ *       Serialize a call into the CDS wire-format, send it across
+ *       the VMCI device, wait for a response, and return
+ *       the results.
+ *
+ *  Results:
+ *       Error code. 0 if success.
+ *     
+ *  Side effects:
+ *       None.
+ *
+ *-------------------------------------------------------------------------
+ */
+
+
+static int
+VMCIDsDoCall(int action,            // IN
+             const char *name,      // IN
+             VMCIHandle handle,	    // IN: For the "register" action
+             VMCIHandle *handleOut) // OUT: For the "lookup" action
+{
+   int8 *sendBuffer = NULL;
+   const size_t sendBufferSize = VMCI_DS_MAX_MSG_SIZE + sizeof(VMCIDatagram);
+   int nameLen, requestSize, res;
+   uint32 savedMsgIdCounter;
+   VMCIDsReplyHeader *reply;
+   VMCIHandle dsHandle = VMCI_INVALID_HANDLE;
+   VMCIDsRecvData *recvData = NULL;
+   VMCIDatagram *dgram;
+   VMCIDsRequestHeader *request;
+   VMCILockFlags flags;
+   
+   nameLen = strlen(name);
+   if (nameLen + sizeof *request > sendBufferSize) {
+      res = VMCI_ERROR_INVALID_ARGS;
+      goto out;
+   }
+
+   sendBuffer = VMCI_AllocKernelMem(sendBufferSize, VMCI_MEMORY_NONPAGED);
+   if (sendBuffer == NULL) {
+      res = VMCI_ERROR_NO_MEM;
+      goto out;
+   }
+
+   recvData = VMCI_AllocKernelMem(sizeof *recvData, VMCI_MEMORY_NONPAGED);
+   if (recvData == NULL) {
+      res = VMCI_ERROR_NO_MEM;
+      goto out;
+   }
+
+   VMCIHost_InitContext(&recvData->context, (uintptr_t) recvData);
+   VMCI_InitLock(&recvData->lock, "VMCIDsRecvHandler", VMCI_LOCK_RANK_MIDDLE_BH);
+
+   savedMsgIdCounter = Atomic_FetchAndInc(&MsgIdCounter);
+
+   dgram = (VMCIDatagram *) sendBuffer;
+   request = (VMCIDsRequestHeader *) (sendBuffer + sizeof *dgram);
+
+   /* Serialize request. */
+   request->action = action;
+   request->msgid = savedMsgIdCounter;  
+   request->handle = handle;
+   request->nameLen = nameLen;
+   memcpy(request->name, name, nameLen + 1);
+   
+   requestSize = sizeof *request + nameLen;
+
+   if (VMCIDatagram_CreateHnd(VMCI_INVALID_ID, 0, VMCIDsRecvCB, 
+                              recvData, &dsHandle) != VMCI_SUCCESS) {
+      res = VMCI_ERROR_NO_HANDLE;
+      goto out;
+   }
+   
+   dgram->dst = VMCI_DS_HANDLE;
+   dgram->src = dsHandle;
+   dgram->payloadSize = requestSize;
+   
+   /* Send the datagram to CDS. */
+   res = VMCIDatagram_Send(dgram);
+   if (res <=  0) {
+      goto out;
+   }
+
+   /* Block here waiting for the reply */
+   VMCI_GrabLock_BH(&recvData->lock, &flags);
+   VMCIHost_WaitForCallLocked(&recvData->context, &recvData->lock, &flags, TRUE);
+   VMCI_ReleaseLock_BH(&recvData->lock, flags);
+   
+   if (recvData->status != VMCI_SUCCESS) {
+      res = recvData->status;
+      goto out;
+   }
+
+   reply = (VMCIDsReplyHeader *) recvData->buffer;
+   /* Check that the msgid matches what we expect. */
+   if (reply->msgid != savedMsgIdCounter) {
+      res = VMCI_ERROR_GENERIC;
+      goto out;
+   }
+   
+   if (handleOut != NULL) {
+      *handleOut = reply->handle;
+   }
+   
+   res = reply->code;
+
+out:
+   if (!VMCI_HANDLE_EQUAL(dsHandle, VMCI_INVALID_HANDLE)) {
+      VMCIDatagram_DestroyHnd(dsHandle);
+   }
+   if (recvData) {
+      VMCI_CleanupLock(&recvData->lock);
+      VMCIHost_ReleaseContext(&recvData->context);
+      VMCI_FreeKernelMem(recvData, sizeof *recvData);
+   }
+   if (sendBuffer) {
+      VMCI_FreeKernelMem(sendBuffer, sendBufferSize);
+   }
+   return res;
+}
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VMCIDsRecvCB --
+ *
+ *      Receive callback for the Discovery Service query datagram
+ *      handle.
+ *
+ * Results:
+ *      If the received payload is not larger than the MAX, it is
+ *      copied into clientData.
+ *
+ * Side effects:
+ *      Signals the thread waiting for the reply.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+
+static int 
+VMCIDsRecvCB(void *clientData,          // IN: client data for handler
+             struct VMCIDatagram *msg)  // IN
+{
+   VMCIDsRecvData *recvData = clientData;
+   VMCILockFlags flags;
+
+   ASSERT(msg->payloadSize <= VMCI_DS_MAX_MSG_SIZE);
+   if (msg->payloadSize <= VMCI_DS_MAX_MSG_SIZE) {
+      memcpy(recvData->buffer, VMCI_DG_PAYLOAD(msg), (size_t)msg->payloadSize);
+      recvData->status = VMCI_SUCCESS;
+   } else {
+      recvData->status = VMCI_ERROR_PAYLOAD_TOO_LARGE;
+   }
+
+   VMCI_GrabLock_BH(&recvData->lock, &flags);
+   VMCIHost_SignalCall(&recvData->context);
+   VMCI_ReleaseLock_BH(&recvData->lock, flags);
+   return 0;
+}
--- kernel/linux-2.6.26.3/drivers/misc/vmci/vmciGuestKernelAPI.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmci/vmciGuestKernelAPI.h	2008-09-03 10:01:42.000000000 -0500
@@ -0,0 +1,81 @@
+/*********************************************************
+ * Copyright (C) 2007 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/* 
+ * vmciGuestKernelAPI.h --
+ *
+ *    Kernel API exported from the VMCI guest driver.
+ */
+
+#ifndef __VMCI_GUESTKERNELAPI_H__
+#define __VMCI_GUESTKERNELAPI_H__
+
+/* VMCI guest kernel API version number. */
+#define VMCI_GUEST_KERNEL_API_VERSION  1
+
+/* Macros to operate on the driver version number. */
+#define VMCI_MAJOR_VERSION(v)       (((v) >> 16) & 0xffff)
+#define VMCI_MINOT_VERSION(v)       ((v) & 0xffff)
+
+#define INCLUDE_ALLOW_MODULE
+#include "includeCheck.h"
+
+#include "vmci_defs.h"
+#include "vmci_call_defs.h"
+
+#if defined(__linux__) || defined(_WIN32)
+   /* XXX TODO for other guests. */
+#  include "vmci_queue_pair.h"
+#endif
+
+/* VMCI Device Usage API. */
+Bool VMCI_DeviceGet(void);
+void VMCI_DeviceRelease(void);
+
+/* VMCI Datagram API. */
+int VMCIDatagram_CreateHnd(VMCIId resourceID, uint32 flags,
+			   VMCIDatagramRecvCB recvCB, void *clientData,
+			   VMCIHandle *outHandle);
+int VMCIDatagram_DestroyHnd(VMCIHandle handle);
+int VMCIDatagram_Send(VMCIDatagram *msg);
+
+/* VMCI Utility API. */
+VMCIId VMCI_GetContextID(void);
+uint32 VMCI_Version(void);
+
+/* VMCI Event API. */
+
+typedef void (*VMCI_EventCB)(VMCIId subID, VMCI_EventData *ed,
+			     void *clientData);
+
+int VMCIEvent_Subscribe(VMCI_Event event, VMCI_EventCB callback, 
+                        void *callbackData, VMCIId *subID);
+int VMCIEvent_Unsubscribe(VMCIId subID);
+
+/* VMCI Discovery Service API. */
+int VMCIDs_Lookup(const char *name, VMCIHandle *out);
+
+#if defined(__linux__) || defined(_WIN32)
+/* VMCI QueuePair API.  XXX TODO for other guests. */
+int VMCIQueuePair_Alloc(VMCIHandle *handle, VMCIQueue **produceQ,
+                        uint64 produceSize, VMCIQueue **consumeQ,
+                        uint64 consumeSize, VMCIId peer, uint32 flags);
+int VMCIQueuePair_Detach(VMCIHandle handle);
+#endif
+
+#endif /* !__VMCI_GUESTKERNELAPI_H__ */
--- kernel/linux-2.6.26.3/drivers/misc/vmci/vmciGuestKernelIf.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmci/vmciGuestKernelIf.c	2008-09-03 10:01:42.000000000 -0500
@@ -0,0 +1,66 @@
+/*********************************************************
+ * Copyright (C) 2007 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * vmciGuestKernelIf.c -- 
+ * 
+ *      This file implements guest only OS helper functions for VMCI.
+ *      This is the linux specific implementation.
+ */ 
+
+/* Must come before any kernel header file */
+#include "driver-config.h"
+
+#if !defined(linux) || defined(VMKERNEL)
+#error "Wrong platform."
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 9)
+#include <linux/moduleparam.h>
+#endif
+
+#include "compat_version.h"
+#include "compat_pci.h"
+#include "vm_basic_types.h"
+#include "vmciGuestKernelIf.h"
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VMCI_ReadPortBytes --
+ *
+ *      Copy memory from an I/O port to kernel memory.
+ *
+ * Results:
+ *      No results.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+void
+VMCI_ReadPortBytes(VMCIIoHandle handle,  // IN: Unused
+		   VMCIIoPort port,      // IN
+		   uint8 *buffer,        // OUT
+		   size_t bufferLength)  // IN
+{
+   insb(port, buffer, bufferLength);
+}
--- kernel/linux-2.6.26.3/drivers/misc/vmci/vmciGuestKernelIf.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmci/vmciGuestKernelIf.h	2008-09-03 10:01:42.000000000 -0500
@@ -0,0 +1,63 @@
+/*********************************************************
+ * Copyright (C) 2007 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * vmciGuestKernelIf.h -- 
+ * 
+ *      This file defines OS encapsulation helper functions that are
+ *      needed only in VMCI guest kernel code. It must work for
+ *      windows, solaris and linux kernel, ie. using defines
+ *      where necessary.
+ */ 
+ 
+#ifndef _VMCI_GUEST_KERNEL_IF_H_
+#define _VMCI_GUEST_KERNEL_IF_H_
+
+#if !defined(linux) && !defined(_WIN32) && !defined(SOLARIS)
+#error "Platform not supported."
+#endif
+
+#if defined(_WIN32)
+#include <ntddk.h>
+#endif 
+
+#ifdef SOLARIS
+#  include <sys/ddi.h>
+#  include <sys/sunddi.h> 
+#  include <sys/types.h>
+#endif
+
+#include "vm_basic_types.h"
+#include "vmci_defs.h"
+
+#if defined(linux)
+  typedef unsigned short int VMCIIoPort;
+  typedef int VMCIIoHandle;
+#elif defined(_WIN32)
+  typedef PUCHAR VMCIIoPort;
+  typedef int VMCIIoHandle;
+#elif defined(SOLARIS)
+  typedef uint8_t * VMCIIoPort;
+  typedef ddi_acc_handle_t VMCIIoHandle;
+#endif // VMKERNEL
+
+void VMCI_ReadPortBytes(VMCIIoHandle handle, VMCIIoPort port, uint8 *buffer,
+			size_t bufferLength);
+
+#endif // _VMCI_GUEST_KERNEL_IF_H_
+
--- kernel/linux-2.6.26.3/drivers/misc/vmci/vmci_handle_array.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmci/vmci_handle_array.h	2008-09-03 10:01:42.000000000 -0500
@@ -0,0 +1,344 @@
+/*********************************************************
+ * Copyright (C) 2006 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * vmci_handle_array.h --
+ *
+ *	Simple dynamic array.
+ */
+
+#ifndef _VMCI_HANDLE_ARRAY_H_
+#define _VMCI_HANDLE_ARRAY_H_
+
+#define INCLUDE_ALLOW_VMMON
+#define INCLUDE_ALLOW_MODULE
+#define INCLUDE_ALLOW_VMCORE
+#define INCLUDE_ALLOW_VMKERNEL
+#include "includeCheck.h"
+
+#include "vmci_kernel_if.h"
+#include "vmware.h"
+
+#include "vmci_defs.h"
+#include "vm_assert.h"
+#ifdef VMKERNEL 
+#include "vm_libc.h"
+#endif // VMKERNEL
+
+#ifdef SOLARIS
+#include <sys/ddi.h>
+#include <sys/kmem.h>
+#include <sys/types.h>
+#include <sys/systm.h>
+#endif
+ 
+#define VMCI_HANDLE_ARRAY_DEFAULT_SIZE 4
+
+typedef struct VMCIHandleArray {
+   uint32          capacity;
+   uint32          size;
+   VMCIHandle      entries[1];
+} VMCIHandleArray;
+
+
+/*
+ *-----------------------------------------------------------------------------------
+ *
+ * VMCIHandleArray_Create --
+ *
+ * Results:
+ *      Array if successful, NULL if not.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------------
+ */
+
+static INLINE VMCIHandleArray *
+VMCIHandleArray_Create(uint32 capacity) 
+{
+   VMCIHandleArray *array;
+   
+   if (capacity == 0) {
+      capacity = VMCI_HANDLE_ARRAY_DEFAULT_SIZE;
+   }
+
+   array = (VMCIHandleArray *)VMCI_AllocKernelMem(sizeof array->capacity +
+                                                  sizeof array->size +
+                                                  capacity * sizeof(VMCIHandle),
+                                                  VMCI_MEMORY_NONPAGED);
+   if (array == NULL) {
+      return NULL;
+   }
+   array->capacity = capacity;
+   array->size = 0;
+   
+   return array;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------------
+ *
+ * VMCIHandleArray_Destroy --
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------------
+ */
+
+static INLINE void
+VMCIHandleArray_Destroy(VMCIHandleArray *array) 
+{
+   VMCI_FreeKernelMem(array,
+                      sizeof array->capacity + sizeof array->size +
+                      array->capacity * sizeof(VMCIHandle));
+}
+
+
+/*
+ *-----------------------------------------------------------------------------------
+ *
+ * VMCIHandleArray_AppendEntry --
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      Array may be reallocated.
+ *
+ *-----------------------------------------------------------------------------------
+ */
+
+static INLINE void
+VMCIHandleArray_AppendEntry(VMCIHandleArray **arrayPtr,
+                            VMCIHandle handle)
+{
+   VMCIHandleArray *array;
+
+   ASSERT(arrayPtr && *arrayPtr);
+   array = *arrayPtr;
+
+   if (UNLIKELY(array->size >= array->capacity)) {
+      /* reallocate. */
+      uint32 arraySize = sizeof array->capacity + sizeof array->size +
+         array->capacity * sizeof(VMCIHandle);
+      VMCIHandleArray *newArray = 
+	      VMCI_AllocKernelMem(arraySize + array->capacity * sizeof(VMCIHandle),
+                             VMCI_MEMORY_NONPAGED);
+      if (newArray == NULL) {
+         return;
+      }
+      memcpy(newArray, array, arraySize);
+      newArray->capacity *= 2;
+      VMCI_FreeKernelMem(array, arraySize);
+      *arrayPtr = newArray;
+      array = newArray;
+   }
+   array->entries[array->size] = handle;
+   array->size++;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------------
+ *
+ * VMCIHandleArray_RemoveEntry --
+ *
+ * Results:
+ *      Handle that was removed, VMCI_INVALID_HANDLE if entry not found.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------------
+ */
+
+static INLINE VMCIHandle
+VMCIHandleArray_RemoveEntry(VMCIHandleArray *array,
+                            VMCIHandle entryHandle)
+{
+   int i;
+   VMCIHandle handle = VMCI_INVALID_HANDLE;
+
+   ASSERT(array);
+   for (i = 0; i < array->size; i++) {
+      if (VMCI_HANDLE_EQUAL(array->entries[i], entryHandle)) {
+	 handle = array->entries[i];
+	 array->entries[i] = array->entries[array->size-1];
+	 array->entries[array->size-1] = VMCI_INVALID_HANDLE;
+	 array->size--;
+	 break;
+      }
+   }
+
+   return handle;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------------
+ *
+ * VMCIHandleArray_RemoveTail --
+ *
+ * Results:
+ *      Handle that was removed, VMCI_INVALID_HANDLE if array was empty.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------------
+ */
+
+static INLINE VMCIHandle
+VMCIHandleArray_RemoveTail(VMCIHandleArray *array)
+{
+   VMCIHandle handle;
+   
+   if (array->size == 0) {
+      return VMCI_INVALID_HANDLE;
+   }
+   handle = array->entries[array->size-1];
+   array->entries[array->size-1] = VMCI_INVALID_HANDLE;
+   array->size--;
+   
+   return handle;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------------
+ *
+ * VMCIHandleArray_GetEntry --
+ *
+ * Results:
+ *      Handle at given index, VMCI_INVALID_HANDLE if invalid index.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------------
+ */
+
+static INLINE VMCIHandle
+VMCIHandleArray_GetEntry(const VMCIHandleArray *array,
+                         uint32 index)
+{
+   ASSERT(array);
+   if (UNLIKELY(index >= array->size)) {
+      return VMCI_INVALID_HANDLE;
+   }
+ 
+  return array->entries[index];
+}
+
+
+/*
+ *-----------------------------------------------------------------------------------
+ *
+ * VMCIHandleArray_GetSize --
+ *
+ * Results:
+ *      Number of entries in array.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------------
+ */
+
+static INLINE uint32
+VMCIHandleArray_GetSize(const VMCIHandleArray *array)
+{
+   ASSERT(array);
+   return array->size;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------------
+ *
+ * VMCIHandleArray_HasEntry --
+ *
+ * Results:
+ *      TRUE is entry exists in array, FALSE if not.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------------
+ */
+
+static INLINE Bool
+VMCIHandleArray_HasEntry(const VMCIHandleArray *array,
+                         VMCIHandle entryHandle)
+{
+   int i;
+
+   ASSERT(array);
+   for (i = 0; i < array->size; i++) {
+      if (VMCI_HANDLE_EQUAL(array->entries[i], entryHandle)) {
+	 return TRUE;
+      }
+   }
+
+   return FALSE;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------------
+ *
+ * VMCIHandleArray_GetCopy --
+ *
+ * Results:
+ *      Returns pointer to copy of array on success or NULL, if memory allocation
+ *      fails.
+ *
+ * Side effects:
+ *      Allocates nonpaged memory.
+ *
+ *-----------------------------------------------------------------------------------
+ */
+
+static INLINE VMCIHandleArray *
+VMCIHandleArray_GetCopy(const VMCIHandleArray *array)
+{
+   VMCIHandleArray *arrayCopy;
+
+   ASSERT(array);
+   
+   arrayCopy = (VMCIHandleArray *)VMCI_AllocKernelMem(sizeof array->capacity + 
+                                                      sizeof array->size +
+                                                      array->size * sizeof(VMCIHandle),
+                                                      VMCI_MEMORY_NONPAGED);
+   if (arrayCopy != NULL) {
+      memcpy(&arrayCopy->size, &array->size,
+             sizeof array->size + array->size * sizeof(VMCIHandle));
+      arrayCopy->capacity = array->size;
+   }
+
+   return arrayCopy;
+}
+
+#endif // _VMCI_HANDLE_ARRAY_H_
--- kernel/linux-2.6.26.3/drivers/misc/vmci/vmci_infrastructure.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmci/vmci_infrastructure.h	2008-09-03 10:01:42.000000000 -0500
@@ -0,0 +1,95 @@
+/*********************************************************
+ * Copyright (C) 2006 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * vmci_infrastructure.h -- 
+ * 
+ *      This file implements the VMCI infrastructure.
+ */ 
+ 
+#ifndef _VMCI_INFRASTRUCTURE_H_
+#define _VMCI_INFRASTRUCTURE_H_
+
+#define INCLUDE_ALLOW_USERLEVEL
+#define INCLUDE_ALLOW_VMMEXT
+#define INCLUDE_ALLOW_MODULE
+#define INCLUDE_ALLOW_VMMON
+#define INCLUDE_ALLOW_VMCORE
+#define INCLUDE_ALLOW_VMKERNEL
+#define INCLUDE_ALLOW_DISTRIBUTE
+#include "includeCheck.h"
+
+#include "vmware.h"
+#include "vmci_defs.h"
+
+typedef enum {
+   VMCIOBJ_VMX_VM = 10,
+   VMCIOBJ_CONTEXT,
+   VMCIOBJ_PROCESS,
+   VMCIOBJ_DATAGRAM_PROCESS,
+   VMCIOBJ_NOT_SET,
+} VMCIObjType;
+
+/* Guestcalls currently support a maximum of 8 uint64 arguments. */
+#define VMCI_GUESTCALL_MAX_ARGS_SIZE 64
+
+/* Used to determine what checkpoint state to get and set. */
+#define VMCI_NOTIFICATION_CPT_STATE 0x1
+#define VMCI_WELLKNOWN_CPT_STATE 0x2
+#define VMCI_QP_CPT_STATE 0x3
+#define VMCI_QP_INFO_CPT_STATE 0x4
+
+/* Used to control the VMCI device in the vmkernel */
+#define VMCI_DEV_RESET            0x01
+#define VMCI_DEV_QP_RESET         0x02
+#define VMCI_DEV_QUIESCE          0x03
+#define VMCI_DEV_UNQUIESCE        0x04
+#define VMCI_DEV_QP_BREAK_SHARING 0x05
+
+/*
+ *-------------------------------------------------------------------------
+ *
+ *  VMCI_Hash --
+ *
+ *     Hash function used by the Simple Datagram API. Based on the djb2 
+ *     hash function by Dan Bernstein.
+ * 
+ *  Result:
+ *     Returns guest call size.
+ *     
+ *  Side effects:
+ *     None.
+ *
+ *-------------------------------------------------------------------------
+ */
+
+static INLINE int
+VMCI_Hash(VMCIHandle handle, // IN
+          unsigned size)     // IN
+{
+   int i;
+   int hash = 5381;
+   uint64 handleValue = (uint64)handle.resource << 32 | handle.context;
+
+   for (i = 0; i < sizeof handle; i++) {
+      hash = ((hash << 5) + hash) + (uint8)(handleValue >> (i*8));
+   }
+   return hash & (size -1);
+}
+
+#endif // _VMCI_INFRASTRUCTURE_H_
--- kernel/linux-2.6.26.3/drivers/misc/vmci/vmciInt.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmci/vmciInt.h	2008-09-03 10:01:42.000000000 -0500
@@ -0,0 +1,39 @@
+/*********************************************************
+ * Copyright (C) 2006 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __VMCI_INT_H__
+#define __VMCI_INT_H__
+
+#define INCLUDE_ALLOW_MODULE
+#include "includeCheck.h"
+
+#include "vm_basic_types.h"
+#include "vmci_call_defs.h"
+#include "vmciProcess.h"
+
+#define DOLOG(...) printk(KERN_INFO __VA_ARGS__)
+#define VMCI_LOG(_args) DOLOG _args
+
+/* 
+ * Called by common code, hence the different naming convention. 
+ * XXX Should be in vmci.h.
+ */
+int VMCI_SendDatagram(VMCIDatagram *dg);
+Bool VMCI_DeviceEnabled(void);
+
+#endif /* __VMCIINT_H__ */
--- kernel/linux-2.6.26.3/drivers/misc/vmci/vmci_iocontrols.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmci/vmci_iocontrols.h	2008-09-03 10:01:42.000000000 -0500
@@ -0,0 +1,395 @@
+/*********************************************************
+ * Copyright (C) 2007 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+
+/*
+ * vmci_iocontrols.h
+ *
+ *        The VMCI driver io controls.
+ */
+
+#ifndef _VMCI_IOCONTROLS_H_
+#define _VMCI_IOCONTROLS_H_
+
+#define INCLUDE_ALLOW_USERLEVEL
+#define INCLUDE_ALLOW_VMMON
+#define INCLUDE_ALLOW_VMCORE
+#define INCLUDE_ALLOW_MODULE
+#define INCLUDE_ALLOW_VMKERNEL
+#include "includeCheck.h"
+
+#include "vmci_defs.h"
+
+/*
+ * Driver version.
+ *
+ * Increment major version when you make an incompatible change.
+ * Compatibility goes both ways (old driver with new executable
+ * as well as new driver with old executable).
+ */
+
+#define VMCI_VERSION_SHIFT_WIDTH   16 /* Never change this. */
+#define VMCI_MAJOR_VERSION_VALUE    8 /* Bump major version number here. */
+#define VMCI_MINOR_VERSION_VALUE    0 /* Bump minor version number here. */
+
+/* Don't modify the next three macros. */
+#define VMCI_VERSION           (VMCI_MAJOR_VERSION_VALUE << \
+                                VMCI_VERSION_SHIFT_WIDTH |  \
+                                VMCI_MINOR_VERSION_VALUE)
+#define VMCI_VERSION_MAJOR(v)  ((uint32) (v) >> VMCI_VERSION_SHIFT_WIDTH)
+#define VMCI_VERSION_MINOR(v)  ((uint16) (v))
+
+#if defined(__linux__) || defined(__APPLE__) || defined(SOLARIS) || defined(VMKERNEL)
+/*
+ * Linux defines _IO* macros, but the core kernel code ignore the encoded
+ * ioctl value. It is up to individual drivers to decode the value (for
+ * example to look at the size of a structure to determine which version
+ * of a specific command should be used) or not (which is what we
+ * currently do, so right now the ioctl value for a given command is the
+ * command itself).
+ *
+ * Hence, we just define the IOCTL_VMCI_foo values directly, with no
+ * intermediate IOCTLCMD_ representation.
+ */
+#  define IOCTLCMD(_cmd) IOCTL_VMCI_ ## _cmd
+#else // if defined(__linux__)
+/*
+ * On platforms other than Linux, IOCTLCMD_foo values are just numbers, and
+ * we build the IOCTL_VMCI_foo values around these using platform-specific
+ * format for encoding arguments and sizes.
+ */
+#  define IOCTLCMD(_cmd) IOCTLCMD_VMCI_ ## _cmd
+#endif
+
+
+enum IOCTLCmd_VMCI {
+   /*
+    * We need to bracket the range of values used for ioctls, because x86_64
+    * Linux forces us to explicitly register ioctl handlers by value for
+    * handling 32 bit ioctl syscalls.  Hence FIRST and LAST.  Pick something
+    * for FIRST that doesn't collide with vmmon (2001+).
+    */
+#if defined(__linux__)
+   IOCTLCMD(FIRST) = 1951,
+#else
+   /* Start at 0. */
+   IOCTLCMD(FIRST),
+#endif
+   IOCTLCMD(VERSION) = IOCTLCMD(FIRST),
+
+   /* BEGIN VMCI */
+   IOCTLCMD(INIT_CONTEXT),
+   IOCTLCMD(CREATE_PROCESS),
+   IOCTLCMD(CREATE_DATAGRAM_PROCESS),
+   IOCTLCMD(SHAREDMEM_CREATE),
+   IOCTLCMD(SHAREDMEM_ATTACH),
+   IOCTLCMD(SHAREDMEM_QUERY),
+   IOCTLCMD(SHAREDMEM_DETACH),
+   IOCTLCMD(VERSION2),
+   IOCTLCMD(QUEUEPAIR_ALLOC),
+   IOCTLCMD(QUEUEPAIR_SETPAGEFILE),
+   IOCTLCMD(QUEUEPAIR_DETACH),
+   IOCTLCMD(DATAGRAM_SEND),
+   IOCTLCMD(DATAGRAM_RECEIVE),
+   IOCTLCMD(DATAGRAM_REQUEST_MAP),
+   IOCTLCMD(DATAGRAM_REMOVE_MAP),
+   IOCTLCMD(CTX_ADD_NOTIFICATION),
+   IOCTLCMD(CTX_REMOVE_NOTIFICATION),
+   IOCTLCMD(CTX_GET_CPT_STATE),
+   IOCTLCMD(CTX_SET_CPT_STATE),
+   IOCTLCMD(GET_CONTEXT_ID),
+   /* END VMCI */
+
+   /*
+    * BEGIN VMCI SOCKETS
+    *
+    * We mark the end of the vmci commands and the start of the vmci sockets
+    * commands since they are used in separate modules on Linux.
+    * */
+   IOCTLCMD(LAST),
+   IOCTLCMD(SOCKETS_FIRST) = IOCTLCMD(LAST),
+   IOCTLCMD(SOCKETS_ACCEPT) = IOCTLCMD(SOCKETS_FIRST),
+   IOCTLCMD(SOCKETS_BIND),
+   IOCTLCMD(SOCKETS_CLOSE),
+   IOCTLCMD(SOCKETS_CONNECT),
+   /*
+    * The next two values are public (vmci_sockets.h) and cannot be changed.
+    * That means the number of values above these cannot be changed either
+    * unless the base index (specified below) is updated accordingly.
+    */
+   IOCTLCMD(SOCKETS_GET_AF_VALUE),
+   IOCTLCMD(SOCKETS_GET_LOCAL_CID),
+   IOCTLCMD(SOCKETS_GET_SOCK_NAME),
+   IOCTLCMD(SOCKETS_GET_SOCK_OPT),
+   IOCTLCMD(SOCKETS_GET_VM_BY_NAME),
+   IOCTLCMD(SOCKETS_LISTEN),
+   IOCTLCMD(SOCKETS_RECV),
+   IOCTLCMD(SOCKETS_RECV_FROM),
+   IOCTLCMD(SOCKETS_SELECT),
+   IOCTLCMD(SOCKETS_SEND),
+   IOCTLCMD(SOCKETS_SEND_TO),
+   IOCTLCMD(SOCKETS_SET_SOCK_OPT),
+   IOCTLCMD(SOCKETS_SHUTDOWN),
+   IOCTLCMD(SOCKETS_SOCKET),
+   /* END VMCI SOCKETS */
+
+   // Must be last.
+   IOCTLCMD(SOCKETS_LAST)
+};
+
+
+#if defined _WIN32
+/*
+ * Windows VMCI ioctl definitions.
+ */
+
+/* These values cannot be changed since some of the ioctl values are public. */
+#define FILE_DEVICE_VMCI         0x8103
+#define VMCI_IOCTL_BASE_INDEX    0x801
+#define VMCIIOCTL_BUFFERED(name) \
+      CTL_CODE(FILE_DEVICE_VMCI, \
+	       VMCI_IOCTL_BASE_INDEX + IOCTLCMD_VMCI_ ## name, \
+	       METHOD_BUFFERED, \
+	       FILE_ANY_ACCESS)
+#define VMCIIOCTL_NEITHER(name) \
+      CTL_CODE(FILE_DEVICE_VMCI, \
+	       VMCI_IOCTL_BASE_INDEX + IOCTLCMD_VMCI_ ## name, \
+	       METHOD_NEITHER, \
+	       FILE_ANY_ACCESS)
+
+#define IOCTL_VMCI_VERSION		VMCIIOCTL_BUFFERED(VERSION)
+
+/* BEGIN VMCI */
+#define IOCTL_VMCI_INIT_CONTEXT         VMCIIOCTL_BUFFERED(INIT_CONTEXT)
+#define IOCTL_VMCI_CREATE_PROCESS       VMCIIOCTL_BUFFERED(CREATE_PROCESS)
+#define IOCTL_VMCI_CREATE_DATAGRAM_PROCESS \
+               VMCIIOCTL_BUFFERED(CREATE_DATAGRAM_PROCESS)
+#define IOCTL_VMCI_HYPERCALL            VMCIIOCTL_BUFFERED(HYPERCALL)
+#define IOCTL_VMCI_SHAREDMEM_CREATE  \
+               VMCIIOCTL_BUFFERED(SHAREDMEM_CREATE)
+#define IOCTL_VMCI_SHAREDMEM_ATTACH  \
+               VMCIIOCTL_BUFFERED(SHAREDMEM_ATTACH)
+#define IOCTL_VMCI_SHAREDMEM_QUERY   \
+               VMCIIOCTL_BUFFERED(SHAREDMEM_QUERY)
+#define IOCTL_VMCI_SHAREDMEM_DETACH  \
+               VMCIIOCTL_BUFFERED(SHAREDMEM_DETACH)
+#define IOCTL_VMCI_VERSION2		VMCIIOCTL_BUFFERED(VERSION2)
+#define IOCTL_VMCI_QUEUEPAIR_ALLOC  \
+               VMCIIOCTL_BUFFERED(QUEUEPAIR_ALLOC)
+#define IOCTL_VMCI_QUEUEPAIR_SETPAGEFILE  \
+               VMCIIOCTL_BUFFERED(QUEUEPAIR_SETPAGEFILE)
+#define IOCTL_VMCI_QUEUEPAIR_DETACH  \
+               VMCIIOCTL_BUFFERED(QUEUEPAIR_DETACH)
+#define IOCTL_VMCI_DATAGRAM_SEND	VMCIIOCTL_BUFFERED(DATAGRAM_SEND)
+#define IOCTL_VMCI_DATAGRAM_RECEIVE	VMCIIOCTL_NEITHER(DATAGRAM_RECEIVE)
+#define IOCTL_VMCI_DATAGRAM_REQUEST_MAP	VMCIIOCTL_BUFFERED(DATAGRAM_REQUEST_MAP)
+#define IOCTL_VMCI_DATAGRAM_REMOVE_MAP	VMCIIOCTL_BUFFERED(DATAGRAM_REMOVE_MAP)
+#define IOCTL_VMCI_CTX_ADD_NOTIFICATION	VMCIIOCTL_BUFFERED(CTX_ADD_NOTIFICATION)
+#define IOCTL_VMCI_CTX_REMOVE_NOTIFICATION \
+               VMCIIOCTL_BUFFERED(CTX_REMOVE_NOTIFICATION)
+#define IOCTL_VMCI_CTX_GET_CPT_STATE \
+               VMCIIOCTL_BUFFERED(CTX_GET_CPT_STATE)
+#define IOCTL_VMCI_CTX_SET_CPT_STATE \
+               VMCIIOCTL_BUFFERED(CTX_SET_CPT_STATE)
+#define IOCTL_VMCI_GET_CONTEXT_ID    \
+               VMCIIOCTL_BUFFERED(GET_CONTEXT_ID)
+/* END VMCI */
+
+/* BEGIN VMCI SOCKETS */
+#define IOCTL_VMCI_SOCKETS_ACCEPT \
+               VMCIIOCTL_BUFFERED(SOCKETS_ACCEPT)
+#define IOCTL_VMCI_SOCKETS_BIND \
+               VMCIIOCTL_BUFFERED(SOCKETS_BIND)
+#define IOCTL_VMCI_SOCKETS_CLOSE \
+               VMCIIOCTL_BUFFERED(SOCKETS_CLOSE)
+#define IOCTL_VMCI_SOCKETS_CONNECT \
+               VMCIIOCTL_BUFFERED(SOCKETS_CONNECT)
+#define IOCTL_VMCI_SOCKETS_GET_AF_VALUE \
+               VMCIIOCTL_BUFFERED(SOCKETS_GET_AF_VALUE)
+#define IOCTL_VMCI_SOCKETS_GET_LOCAL_CID \
+               VMCIIOCTL_BUFFERED(SOCKETS_GET_LOCAL_CID)
+#define IOCTL_VMCI_SOCKETS_GET_SOCK_NAME \
+               VMCIIOCTL_BUFFERED(SOCKETS_GET_SOCK_NAME)
+#define IOCTL_VMCI_SOCKETS_GET_SOCK_OPT \
+               VMCIIOCTL_BUFFERED(SOCKETS_GET_SOCK_OPT)
+#define IOCTL_VMCI_SOCKETS_GET_VM_BY_NAME \
+               VMCIIOCTL_BUFFERED(SOCKETS_GET_VM_BY_NAME)
+#define IOCTL_VMCI_SOCKETS_LISTEN \
+               VMCIIOCTL_BUFFERED(SOCKETS_LISTEN)
+#define IOCTL_VMCI_SOCKETS_RECV \
+               VMCIIOCTL_BUFFERED(SOCKETS_RECV)
+#define IOCTL_VMCI_SOCKETS_RECV_FROM \
+               VMCIIOCTL_BUFFERED(SOCKETS_RECV_FROM)
+#define IOCTL_VMCI_SOCKETS_SELECT \
+               VMCIIOCTL_BUFFERED(SOCKETS_SELECT)
+#define IOCTL_VMCI_SOCKETS_SEND \
+               VMCIIOCTL_BUFFERED(SOCKETS_SEND)
+#define IOCTL_VMCI_SOCKETS_SEND_TO \
+               VMCIIOCTL_BUFFERED(SOCKETS_SEND_TO)
+#define IOCTL_VMCI_SOCKETS_SET_SOCK_OPT \
+               VMCIIOCTL_BUFFERED(SOCKETS_SET_SOCK_OPT)
+#define IOCTL_VMCI_SOCKETS_SHUTDOWN \
+               VMCIIOCTL_BUFFERED(SOCKETS_SHUTDOWN)
+#define IOCTL_VMCI_SOCKETS_SOCKET \
+               VMCIIOCTL_BUFFERED(SOCKETS_SOCKET)
+/* END VMCI SOCKETS */
+
+#endif // _WIN32
+
+
+/*
+ * VMCI driver initialization. This block can also be used to
+ * pass initial group membership etc.
+ */
+typedef struct VMCIInitBlock {
+   VMCIId             cid;
+   VMCIPrivilegeFlags flags;
+#ifdef _WIN32
+   uint64             event; /* Handle for signalling vmci calls on windows. */
+#endif // _WIN32
+} VMCIInitBlock;
+
+typedef struct VMCISharedMemInfo {
+   VMCIHandle handle;
+   uint32     size;
+   uint32     result;     
+   VA64       va; /* Currently only used in the guest. */ 
+   char       pageFileName[VMCI_PATH_MAX];
+} VMCISharedMemInfo;
+
+typedef struct VMCIQueuePairAllocInfo {
+   VMCIHandle handle;
+   VMCIId     peer;
+   uint32     flags;
+   uint64     produceSize;
+   uint64     consumeSize;
+   VA64       producePageFile; /* User VA. */
+   VA64       consumePageFile; /* User VA. */
+   uint64     producePageFileSize; /* Size of the file name array. */
+   uint64     consumePageFileSize; /* Size of the file name array. */ 
+   int32      result;
+   uint32     _pad;
+} VMCIQueuePairAllocInfo;
+
+typedef struct VMCIQueuePairPageFileInfo {
+   VMCIHandle handle;
+   VA64       producePageFile; /* User VA. */
+   VA64       consumePageFile; /* User VA. */
+   uint64     producePageFileSize; /* Size of the file name array. */
+   uint64     consumePageFileSize; /* Size of the file name array. */ 
+   int32      result;
+   uint32     _pad;
+} VMCIQueuePairPageFileInfo;
+
+typedef struct VMCIQueuePairDetachInfo {
+   VMCIHandle handle;
+   int32      result;
+   uint32     _pad;
+} VMCIQueuePairDetachInfo;
+
+typedef struct VMCIDatagramSendRecvInfo {
+   VA64   addr;
+   uint32 len;
+   int32  result;
+} VMCIDatagramSendRecvInfo;
+
+/* Used to create datagram endpoints in guest or host userlevel. */
+typedef struct VMCIDatagramCreateInfo {
+   VMCIId      resourceID;
+   uint32      flags; 
+   int         eventHnd;
+   int         result;     // result of handle create operation
+   VMCIHandle  handle;     // handle if successfull
+} VMCIDatagramCreateInfo;
+
+/* Used to add/remove well-known datagram mappings. */
+typedef struct VMCIDatagramMapInfo {
+   VMCIId      wellKnownID;
+   int         result;
+} VMCIDatagramMapInfo;
+
+
+/* Used to add/remove remote context notifications. */
+typedef struct VMCINotifyAddRemoveInfo {
+   VMCIId      remoteCID;
+   int         result;
+} VMCINotifyAddRemoveInfo;
+
+
+/* Used to set/get current context's checkpoint state. */
+typedef struct VMCICptBufInfo {
+   VA64        cptBuf;
+   uint32      cptType;
+   uint32      bufSize;
+   int32       result;
+   uint32      _pad;
+} VMCICptBufInfo;
+
+
+#ifdef __APPLE__
+/*
+ * Mac OS ioctl definitions.
+ *
+ * Mac OS defines _IO* macros, and the core kernel code uses the size encoded
+ * in the ioctl value to copy the memory back and forth (depending on the
+ * direction encoded in the ioctl value) between the user and kernel address
+ * spaces.
+ * See iocontrolsMacOS.h for details on how this is done. We use sockets only
+ * for vmci.
+ */
+
+#include <sys/ioccom.h>
+
+enum VMCrossTalkSockOpt {
+   VMCI_SO_VERSION = 0,
+   VMCI_SO_CONTEXT                  = IOCTL_VMCI_INIT_CONTEXT,
+   VMCI_SO_PROCESS                  = IOCTL_VMCI_CREATE_PROCESS,
+   VMCI_SO_DATAGRAM_PROCESS         = IOCTL_VMCI_CREATE_DATAGRAM_PROCESS,
+   VMCI_SO_SHAREDMEM_CREATE         = IOCTL_VMCI_SHAREDMEM_CREATE,
+   VMCI_SO_SHAREDMEM_ATTACH         = IOCTL_VMCI_SHAREDMEM_ATTACH,
+   VMCI_SO_SHAREDMEM_QUERY          = IOCTL_VMCI_SHAREDMEM_QUERY,
+   VMCI_SO_SHAREDMEM_DETACH         = IOCTL_VMCI_SHAREDMEM_DETACH,
+   VMCI_SO_VERSION2                 = IOCTL_VMCI_VERSION2,
+   VMCI_SO_QUEUEPAIR_ALLOC          = IOCTL_VMCI_QUEUEPAIR_ALLOC,
+   VMCI_SO_QUEUEPAIR_SETPAGEFILE    = IOCTL_VMCI_QUEUEPAIR_SETPAGEFILE,
+   VMCI_SO_QUEUEPAIR_DETACH         = IOCTL_VMCI_QUEUEPAIR_DETACH,
+   VMCI_SO_DATAGRAM_SEND            = IOCTL_VMCI_DATAGRAM_SEND,
+   VMCI_SO_DATAGRAM_RECEIVE         = IOCTL_VMCI_DATAGRAM_RECEIVE, 
+   VMCI_SO_DATAGRAM_REQUEST_MAP     = IOCTL_VMCI_DATAGRAM_REQUEST_MAP,
+   VMCI_SO_DATAGRAM_REMOVE_MAP      = IOCTL_VMCI_DATAGRAM_REMOVE_MAP, 
+   VMCI_SO_CTX_ADD_NOTIFICATION     = IOCTL_VMCI_CTX_ADD_NOTIFICATION, 
+   VMCI_SO_CTX_REMOVE_NOTIFICATION  = IOCTL_VMCI_CTX_REMOVE_NOTIFICATION, 
+   VMCI_SO_CTX_GET_CPT_STATE        = IOCTL_VMCI_CTX_GET_CPT_STATE, 
+   VMCI_SO_CTX_SET_CPT_STATE        = IOCTL_VMCI_CTX_SET_CPT_STATE, 
+   VMCI_SO_GET_CONTEXT_ID           = IOCTL_VMCI_GET_CONTEXT_ID,
+   VMCI_SO_USERFD,
+};
+
+#  define VMCI_MACOS_HOST_DEVICE_BASE    "com.vmware.kext.vmci"
+#  ifdef VMX86_DEVEL
+#     define VMCI_MACOS_HOST_DEVICE VMCI_MACOS_HOST_DEVICE_BASE ".devel"
+#  else
+#     define VMCI_MACOS_HOST_DEVICE VMCI_MACOS_HOST_DEVICE_BASE
+#  endif
+
+#endif
+
+/* Clean up helper macros */
+#undef IOCTLCMD
+
+#endif // ifndef _VMCI_IOCONTROLS_H_
--- kernel/linux-2.6.26.3/drivers/misc/vmci/vmciKernelIf.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmci/vmciKernelIf.c	2008-09-03 10:01:42.000000000 -0500
@@ -0,0 +1,1354 @@
+/*********************************************************
+ * Copyright (C) 2007 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * vmciKernelIf.c -- 
+ * 
+ *      This file implements defines and helper functions for VMCI
+ *      host _and_ guest kernel code. This is the linux specific
+ *      implementation.
+ */ 
+
+/* Must come before any kernel header file */
+#include "driver-config.h"
+
+#if !defined(linux) || defined(VMKERNEL)
+#error "Wrong platform."
+#endif
+
+#define EXPORT_SYMTAB
+#define __NO_VERSION__
+#include "compat_module.h"
+
+#include "compat_version.h"
+#include "compat_wait.h"
+#include "compat_interrupt.h"
+#include "compat_spinlock.h"
+#include "compat_slab.h"
+#include "compat_semaphore.h"
+#include "compat_page.h"
+#include "compat_mm.h"
+#include "compat_highmem.h"
+#include "vm_basic_types.h"
+#include "pgtbl.h"
+#include <linux/vmalloc.h>
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 0)
+#  include <linux/mm.h>         /* For vmalloc_to_page() */
+#endif
+#include <linux/socket.h>       /* For memcpy_{to,from}iovec(). */
+#include "vm_assert.h"
+#include "vmci_kernel_if.h"
+#include "vmci_queue_pair.h"
+
+/*
+ * In Linux 2.6.25 kernels and onwards, the symbol init_mm is no
+ * longer exported. This affects the function PgtblKVa2MPN, as it
+ * calls pgd_offset_k which in turn is a macro referencing init_mm.
+ * 
+ * We can avoid using PgtblKVa2MPN on more recent kernels by instead
+ * using the function vmalloc_to_page followed by
+ * page_to_pfn. vmalloc_to_page was introduced in the 2.5 kernels and
+ * backported to some 2.4.x kernels. We use vmalloc_to_page on all
+ * 2.6.x kernels, where it is present for sure, and use PgtblKVa2MPN
+ * on older kernels where it works just fine.
+ */
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 0)
+#  define VMCIKVaToMPN(__VA) page_to_pfn(vmalloc_to_page((void *)(__VA)))
+#else
+#  define VMCIKVaToMPN(__VA) PgtblKVa2MPN(__VA)
+#endif
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VMCI_InitLock
+ *
+ *      Initializes the lock. Must be called before use.
+ *
+ * Results:
+ *      None
+ *
+ * Side effects:
+ *      Thread can block.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+void
+VMCI_InitLock(VMCILock *lock,    // IN:
+              char *name,        // IN: Unused on Linux
+              VMCILockRank rank) // IN: Unused on Linux
+{
+   spin_lock_init(lock);
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VMCI_CleanupLock
+ *
+ *      Cleanup the lock. Must be called before deallocating lock.
+ *
+ * Results:
+ *      None
+ *
+ * Side effects:
+ *      Deletes kernel lock state
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+void
+VMCI_CleanupLock(VMCILock *lock)
+{
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VMCI_GrabLock
+ *
+ *      Grabs the given lock. XXX Fill in specific lock requirements. XXX Move
+ *      locking code into hostif if VMCI stays in vmmon.
+ *
+ * Results:
+ *      None
+ *
+ * Side effects:
+ *      Thread can block.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+void
+VMCI_GrabLock(VMCILock *lock,       // IN
+              VMCILockFlags *flags) // OUT: used to restore irql on windows
+{
+   spin_lock(lock);
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VMCI_ReleaseLock
+ *
+ *      Releases the given lock. XXX Move locking code into hostif if VMCI
+ *      stays in vmmon.
+ *
+ * Results:
+ *      None
+ *
+ * Side effects:
+ *      A thread blocked on this lock may wake up.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+void
+VMCI_ReleaseLock(VMCILock *lock,      // IN
+                 VMCILockFlags flags) // IN
+{
+   spin_unlock(lock);
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VMCI_GrabLock_BH
+ *
+ *      Grabs the given lock and for linux kernels disables bottom half execution.
+ * .    This should be used with locks accessed both from bottom half/tasklet
+ *      contexts, ie. guestcall handlers, and from process contexts to avoid
+ *      deadlocks where the process has the lock and gets descheduled due to a
+ *      bh/tasklet coming in.
+ *
+ * Results:
+ *      None
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+void
+VMCI_GrabLock_BH(VMCILock *lock,        // IN
+                 VMCILockFlags *flags)  // OUT: used to restore
+{
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 3, 4)
+   spin_lock_bh(lock);
+#else
+
+   /* 
+    * Before 2.3.4 linux kernels spin_unlock_bh didn't exist so we are using 
+    * spin_lock_irqsave/restore instead. I wanted to define spin_[un]lock_bh
+    * functions in compat_spinlock.h as local_bh_disable;spin_lock(lock) and
+    * so on, but local_bh_disable/enable does not exist on 2.2.26.
+    */
+   spin_lock_irqsave(lock, *flags);
+#endif // LINUX_VERSION_CODE
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VMCI_ReleaseLock_BH
+ *
+ *      Releases the given lock and for linux kernels reenables bottom half 
+ *      execution.
+ * .    This should be used with locks accessed both from bottom half/tasklet
+ *      contexts, ie. guestcall handlers, and from process contexts to avoid
+ *      deadlocks where the process has the lock and get descheduled due to a
+ *      bh/tasklet coming in.
+ *
+ * Results:
+ *      None
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+void
+VMCI_ReleaseLock_BH(VMCILock *lock,        // IN
+                    VMCILockFlags flags)   // IN
+{
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 3, 4)
+   spin_unlock_bh(lock);
+#else
+
+   /* 
+    * Before 2.3.4 linux kernels spin_unlock_bh didn't exist so we are using 
+    * spin_lock_irqsave/restore instead. I wanted to define spin_[un]lock_bh
+    * functions in compat_spinlock.h as local_bh_disable;spin_lock(lock) and
+     * so on, but local_bh_disable/enable does not exist on 2.2.26.
+     */
+
+   spin_unlock_irqrestore(lock, flags);
+#endif // LINUX_VERSION_CODE
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * VMCIHost_InitContext --
+ *
+ *      Host-specific initialization of VMCI context state.
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      None.
+ *
+ *----------------------------------------------------------------------
+ */
+
+void
+VMCIHost_InitContext(VMCIHost *hostContext, // IN
+                     uintptr_t eventHnd)    // IN
+{
+   init_waitqueue_head(&hostContext->waitQueue);
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * VMCIHost_ReleaseContext --
+ *
+ *      Host-specific release of state allocated by
+ *      VMCIHost_InitContext.
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      None.
+ *
+ *----------------------------------------------------------------------
+ */
+
+void
+VMCIHost_ReleaseContext(VMCIHost *hostContext) // IN
+{
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * VMCIHost_SignalCall --
+ *
+ *      Signal to userlevel that a VMCI call is waiting.
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      None.
+ *
+ *----------------------------------------------------------------------
+ */
+
+void
+VMCIHost_SignalCall(VMCIHost *hostContext)     // IN
+{
+   wake_up(&hostContext->waitQueue);
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * VMCIHost_WaitForCallLocked --
+ *
+ *      Wait until a VMCI call is pending or the waiting thread is
+ *      interrupted. It is assumed that a lock is held prior to
+ *      calling this function. The lock will be released during the
+ *      wait. The correctnes of this funtion depends on that the same
+ *      lock is held when the call is signalled.
+ *
+ * Results:
+ *      TRUE on success
+ *      FALSE if the wait was interrupted.
+ *
+ * Side effects:
+ *      The call may block.
+ *
+ *----------------------------------------------------------------------
+ */
+
+Bool
+VMCIHost_WaitForCallLocked(VMCIHost *hostContext, // IN
+                           VMCILock *lock,        // IN
+                           VMCILockFlags *flags,  // IN
+                           Bool useBH)            // IN
+
+{
+   DECLARE_WAITQUEUE(wait, current);
+
+   /* 
+    * The thread must be added to the wait queue and have its state
+    * changed while holding the lock - otherwise a signal may change
+    * the state in between and have it overwritten causing a loss of
+    * the event.
+    */      
+
+   add_wait_queue(&hostContext->waitQueue, &wait);
+   current->state = TASK_INTERRUPTIBLE;
+
+   if (useBH) {
+      VMCI_ReleaseLock_BH(lock, *flags);
+   } else {
+      VMCI_ReleaseLock(lock, *flags);
+   }
+
+   schedule();
+
+   if (useBH) {
+      VMCI_GrabLock_BH(lock, flags);
+   } else {
+      VMCI_GrabLock(lock, flags);
+   }
+
+   current->state = TASK_RUNNING;
+
+   remove_wait_queue(&hostContext->waitQueue, &wait);
+
+   if (signal_pending(current)) {
+      return FALSE;
+   }
+
+   return TRUE;
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * VMCIHost_ClearCall --
+ *
+ *      Clear the pending call signal.
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      None.
+ *
+ *----------------------------------------------------------------------
+ */
+
+void
+VMCIHost_ClearCall(VMCIHost *hostContext)     // IN
+{
+}
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * VMCI_AllocKernelMem
+ *
+ *      Allocate some kernel memory for the VMCI driver. 
+ *
+ * Results:
+ *      The address allocated or NULL on error. 
+ *      
+ *
+ * Side effects:
+ *      memory is malloced
+ *----------------------------------------------------------------------
+ */
+
+void *
+VMCI_AllocKernelMem(size_t size, int flags)
+{
+   void *ptr;
+
+   if ((flags & VMCI_MEMORY_ATOMIC) != 0) {
+      ptr = kmalloc(size, GFP_ATOMIC);
+   } else {
+      ptr = kmalloc(size, GFP_KERNEL);
+   }
+
+   return ptr;
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * VMCI_FreeKernelMem
+ *
+ *      Free kernel memory allocated for the VMCI driver. 
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      memory is freed.
+ *----------------------------------------------------------------------
+ */
+
+void
+VMCI_FreeKernelMem(void *ptr,   // IN:
+                   size_t size) // IN: Unused on Linux
+{
+   kfree(ptr);
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * VMCI_AllocBuffer
+ *
+ *      Allocate some kernel memory for the VMCI driver. The memory is
+ *      not guaranteed to have a mapping in the virtual address
+ *      space. Use VMCI_MapBuffer to get a VA mapping for the memory.
+ *      
+ * Results:
+ *      A reference to the allocated memory or VMCI_BUFFER_INVALID
+ *      on error.
+ *      
+ *
+ * Side effects:
+ *      memory is allocated.
+ *----------------------------------------------------------------------
+ */
+
+VMCIBuffer
+VMCI_AllocBuffer(size_t size, int flags)
+{
+   return VMCI_AllocKernelMem(size, flags);
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * VMCI_MapBuffer
+ *
+ *      Ensures that the kernel memory allocated with VMCI_AllocBuffer
+ *      has a mapping in the virtual address space.
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      virtual address mapping of kernel memory is established.
+ *----------------------------------------------------------------------
+ */
+
+void *
+VMCI_MapBuffer(VMCIBuffer buf)
+{
+   return buf;
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * VMCI_ReleaseBuffer
+ *
+ *      Releases the VA mapping of kernel memory allocated with
+ *      VMCI_AllocBuffer.
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      virtual address mapping of kernel memory is released.
+ *----------------------------------------------------------------------
+ */
+
+void
+VMCI_ReleaseBuffer(void *ptr) // IN: The VA of the mapped memory
+{
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * VMCI_FreeBuffer
+ *
+ *      Free temporary kernel memory allocated for the VMCI driver. 
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      memory is freed.
+ *----------------------------------------------------------------------
+ */
+
+void
+VMCI_FreeBuffer(VMCIBuffer buf, // IN:
+                size_t size)    // IN: Unused on Linux
+{
+   VMCI_FreeKernelMem(buf, size);
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VMCI_CopyToUser --
+ *
+ *      Copy memory to the user application from a kernel buffer. This
+ *      function may block, so don't call it while holding any kind of
+ *      lock.
+ *
+ * Results:
+ *      0 on success.
+ *      Nonzero on failure.
+ *
+ * Side effects:
+ *      None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+int
+VMCI_CopyToUser(void *dst,        // OUT
+                const void *src,  // IN
+                unsigned int len) // IN
+{
+   return copy_to_user(dst, src, len) ? -EFAULT : 0;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VMCI_CopyFromUser --
+ *
+ *      Copy memory from the user application to a kernel buffer. This
+ *      function may block, so don't call it while holding any kind of
+ *      lock.
+ *
+ * Results:
+ *      0 on success.
+ *      Nonzero on failure.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+int
+VMCI_CopyFromUser(void *dst,        // OUT
+                  const void *src,  // IN
+                  size_t len)       // IN
+{
+   return copy_from_user(dst, src, len);
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VMCI_CreateEvent --
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+void
+VMCI_CreateEvent(VMCIEvent *event)  // IN:
+{
+   init_waitqueue_head(event);
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VMCI_DestroyEvent --
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+void
+VMCI_DestroyEvent(VMCIEvent *event)  // IN:
+{
+   /* Nothing to do. */
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VMCI_SignalEvent --
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+void
+VMCI_SignalEvent(VMCIEvent *event)  // IN:
+{
+   wake_up(event);
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VMCI_WaitOnEvent --
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+void
+VMCI_WaitOnEvent(VMCIEvent *event,              // IN:
+		 VMCIEventReleaseCB releaseCB,  // IN:
+		 void *clientData)              // IN:
+{
+   DECLARE_WAITQUEUE(wait, current);
+
+   if (event == NULL || releaseCB == NULL) {
+      return;
+   }
+
+   add_wait_queue(event, &wait);
+   current->state = TASK_INTERRUPTIBLE;
+
+   /* 
+    * Release the lock or other primitive that makes it possible for us to 
+    * put the current thread on the wait queue without missing the signal. 
+    * Ie. on Linux we need to put ourselves on the wait queue and set our
+    * stateto TASK_INTERRUPTIBLE without another thread signalling us.
+    * The releaseCB is used to synchronize this.
+    */
+   releaseCB(clientData);
+   
+   schedule();
+   current->state = TASK_RUNNING;
+   remove_wait_queue(event, &wait);
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VMCIMutex_Init --
+ *
+ *      Initializes the mutex. Must be called before use.
+ *
+ * Results:
+ *      Success.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+int
+VMCIMutex_Init(VMCIMutex *mutex) // IN:
+{
+   sema_init(mutex, 1);
+   return VMCI_SUCCESS;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VMCIMutex_Destroy --
+ *
+ *      Destroys the mutex.  Does nothing on Linux.
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+void
+VMCIMutex_Destroy(VMCIMutex *mutex) // IN: Unused
+{
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VMCIMutex_Acquire --
+ *
+ *      Acquires the mutex.
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      Thread may block.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+void
+VMCIMutex_Acquire(VMCIMutex *mutex) // IN:
+{
+   down(mutex);
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VMCIMutex_Release --
+ *
+ *      Releases the mutex.
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      May wake up the thread blocking on this mutex.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+void
+VMCIMutex_Release(VMCIMutex *mutex) // IN:
+{
+   up(mutex);
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VMCI_AllocQueueKVA --
+ *
+ *      Allocates kernel memory for the queue header (1 page) plus the
+ *      translation structure for offset -> page mappings.  Allocates physical
+ *      pages for the queue (buffer area), and initializes the translation
+ *      structure.
+ *
+ * Results:
+ *      The VA on success, NULL otherwise.
+ *
+ * Side effects:
+ *      Memory is allocated.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+VA
+VMCI_AllocQueueKVA(uint64 size) // IN: size of queue (not including header)
+{
+   const uint64 numPages = CEILING(size, PAGE_SIZE);
+   VMCIQueue *queue;
+
+   queue = vmalloc(sizeof *queue + numPages * sizeof queue->page[0]);
+   if (queue) {
+      uint64 i;
+
+      /*
+       * Allocate physical pages, they will be mapped/unmapped on demand.
+       */
+      for (i = 0; i < numPages; i++) {
+         queue->page[i] = alloc_pages(GFP_KERNEL, 0); /* One page. */
+         if (!queue->page[i]) {
+            /*
+             * Free all pages allocated.
+             */
+            while (i) {
+               __free_page(queue->page[--i]);
+            }
+            vfree(queue);
+            queue = NULL;
+            break;
+         }
+      }
+   }
+   return (VA)queue;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VMCI_FreeQueueKVA --
+ *
+ *      Frees kernel memory for a given queue (header plus translation
+ *      structure).  Frees all physical pages that held the buffers for this
+ *      queue.
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      Memory is freed.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+void
+VMCI_FreeQueueKVA(VA va,       // IN:
+                  uint64 size) // IN: size of queue (not including header)
+{
+   VMCIQueue *queue = (VMCIQueue *)va;
+
+   if (queue) {
+      uint64 i;
+
+      for (i = 0; i < CEILING(size, PAGE_SIZE); i++) {
+         __free_page(queue->page[i]);
+      }
+      vfree(queue);
+   }
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VMCI_AllocPPNSet --
+ *
+ *      Allocates two list of PPNs --- one for the pages in the produce queue,
+ *      and the other for the pages in the consume queue. Intializes the list
+ *      of PPNs with the page frame numbers of the KVA for the two queues (and
+ *      the queue headers).
+ *
+ * Results:
+ *      Success or failure.
+ *
+ * Side effects:
+ *      Memory may be allocated.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+int
+VMCI_AllocPPNSet(VA produceVA,           // IN:
+                 uint64 numProducePages, // IN: for queue plus header
+                 VA consumeVA,           // IN:
+                 uint64 numConsumePages, // IN: for queue plus header
+                 PPNSet *ppnSet)         // OUT:
+{
+   VMCIPpnList producePPNs;
+   VMCIPpnList consumePPNs;
+   uint64 i;
+   VMCIQueue *produceQ = (VMCIQueue *)produceVA;
+   VMCIQueue *consumeQ = (VMCIQueue *)consumeVA;
+
+   if (!produceVA || !numProducePages || !consumeVA || !numConsumePages ||
+       !ppnSet) {
+      return VMCI_ERROR_INVALID_ARGS;
+   }
+
+   if (ppnSet->initialized) {
+      return VMCI_ERROR_ALREADY_EXISTS;
+   }
+
+   producePPNs =
+      VMCI_AllocKernelMem(numProducePages * sizeof *producePPNs,
+                          VMCI_MEMORY_NORMAL);
+   if (!producePPNs) {
+      return VMCI_ERROR_NO_MEM;
+   }
+
+   consumePPNs =
+      VMCI_AllocKernelMem(numConsumePages * sizeof *consumePPNs,
+                          VMCI_MEMORY_NORMAL);
+   if (!consumePPNs) {
+      VMCI_FreeKernelMem(producePPNs, numProducePages * sizeof *producePPNs);
+      return VMCI_ERROR_NO_MEM;
+   }
+
+   producePPNs[0] = VMCIKVaToMPN(produceVA);
+   for (i = 1; i < numProducePages; i++) {
+      unsigned long pfn;
+
+      producePPNs[i] = pfn = page_to_pfn(produceQ->page[i - 1]);
+
+      /*
+       * Fail allocation if PFN isn't supported by hypervisor.
+       */
+
+      if (sizeof pfn > sizeof *producePPNs &&
+          pfn != producePPNs[i]) {
+         goto ppnError;
+      }
+   }
+   consumePPNs[0] = VMCIKVaToMPN(consumeVA);
+   for (i = 1; i < numConsumePages; i++) {
+      unsigned long pfn;
+
+      consumePPNs[i] = pfn = page_to_pfn(consumeQ->page[i - 1]);
+
+      /*
+       * Fail allocation if PFN isn't supported by hypervisor.
+       */
+
+      if (sizeof pfn > sizeof *consumePPNs &&
+          pfn != consumePPNs[i]) {
+         goto ppnError;
+      }
+   }
+
+   ppnSet->numProducePages = numProducePages;
+   ppnSet->numConsumePages = numConsumePages;
+   ppnSet->producePPNs = producePPNs;
+   ppnSet->consumePPNs = consumePPNs;
+   ppnSet->initialized = TRUE;
+   return VMCI_SUCCESS;
+
+ppnError:
+   VMCI_FreeKernelMem(producePPNs, numProducePages * sizeof *producePPNs);
+   VMCI_FreeKernelMem(consumePPNs, numConsumePages * sizeof *consumePPNs);
+   return VMCI_ERROR_INVALID_ARGS;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VMCI_FreePPNSet --
+ *
+ *      Frees the two list of PPNs for a queue pair.
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+void
+VMCI_FreePPNSet(PPNSet *ppnSet) // IN:
+{
+   ASSERT(ppnSet);
+   if (ppnSet->initialized) {
+      /* Do not call these functions on NULL inputs. */
+      ASSERT(ppnSet->producePPNs && ppnSet->consumePPNs);
+      VMCI_FreeKernelMem(ppnSet->producePPNs,
+                         ppnSet->numProducePages * sizeof *ppnSet->producePPNs);
+      VMCI_FreeKernelMem(ppnSet->consumePPNs,
+                         ppnSet->numConsumePages * sizeof *ppnSet->consumePPNs);
+   }
+   memset(ppnSet, 0, sizeof *ppnSet);
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VMCI_PopulatePPNList --
+ *
+ *      Populates the list of PPNs in the hypercall structure with the PPNS
+ *      of the produce queue and the consume queue.
+ *
+ * Results:
+ *      VMCI_SUCCESS.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+int
+VMCI_PopulatePPNList(uint8 *callBuf,       // OUT:
+                     const PPNSet *ppnSet) // IN:
+{
+   ASSERT(callBuf && ppnSet && ppnSet->initialized);
+   memcpy(callBuf, ppnSet->producePPNs,
+          ppnSet->numProducePages * sizeof *ppnSet->producePPNs);
+   memcpy(callBuf + ppnSet->numProducePages * sizeof *ppnSet->producePPNs,
+          ppnSet->consumePPNs,
+          ppnSet->numConsumePages * sizeof *ppnSet->consumePPNs);
+
+   return VMCI_SUCCESS;
+}
+
+
+#ifdef __KERNEL__
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * __VMCIMemcpyToQueue --
+ *
+ *      Copies from a given buffer or iovector to a VMCI Queue.  Uses
+ *      kmap()/kunmap() to dynamically map/unmap required portions of the queue
+ *      by traversing the offset -> page translation structure for the queue.
+ *      Assumes that offset + size does not wrap around in the queue.
+ *
+ * Results:
+ *      Zero on success, negative error code on failure.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+int
+__VMCIMemcpyToQueue(VMCIQueue *queue,   // OUT:
+                    uint64 queueOffset, // IN:
+                    const void *src,    // IN:
+                    size_t size,        // IN:
+                    Bool isIovec)       // IN: if src is a struct iovec *
+{
+   size_t bytesCopied = 0;
+
+   while (bytesCopied < size) {
+      uint64 pageIndex = (queueOffset + bytesCopied) / PAGE_SIZE;
+      size_t pageOffset = (queueOffset + bytesCopied) & (PAGE_SIZE - 1);
+      void *va = kmap(queue->page[pageIndex]);
+      size_t toCopy;
+
+      ASSERT(va);
+      if (size - bytesCopied > PAGE_SIZE - pageOffset) {
+         /* Enough payload to fill up from this page. */
+         toCopy = PAGE_SIZE - pageOffset;
+      } else {
+         toCopy = size - bytesCopied;
+      }
+
+      if (isIovec) {
+         struct iovec *iov = (struct iovec *)src;
+         int err;
+
+         /* The iovec will track bytesCopied internally. */
+         err = memcpy_fromiovec((uint8 *)va + pageOffset, iov, toCopy);
+         if (err != 0) {
+            kunmap(queue->page[pageIndex]);
+            return err;
+         }
+      } else {
+         memcpy((uint8 *)va + pageOffset, (uint8 *)src + bytesCopied, toCopy);
+      }
+
+      bytesCopied += toCopy;
+      kunmap(queue->page[pageIndex]);
+   }
+
+   return 0;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * __VMCIMemcpyFromQueue --
+ *
+ *      Copies to a given buffer or iovector from a VMCI Queue.  Uses
+ *      kmap()/kunmap() to dynamically map/unmap required portions of the queue
+ *      by traversing the offset -> page translation structure for the queue.
+ *      Assumes that offset + size does not wrap around in the queue.
+ *
+ * Results:
+ *      Zero on success, negative error code on failure.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+int
+__VMCIMemcpyFromQueue(void *dest,             // OUT:
+                      const VMCIQueue *queue, // IN:
+                      uint64 queueOffset,     // IN:
+                      size_t size,            // IN:
+                      Bool isIovec)           // IN: if dest is a struct iovec *
+{
+   size_t bytesCopied = 0;
+
+   while (bytesCopied < size) {
+      uint64 pageIndex = (queueOffset + bytesCopied) / PAGE_SIZE;
+      size_t pageOffset = (queueOffset + bytesCopied) & (PAGE_SIZE - 1);
+      void *va = kmap(queue->page[pageIndex]);
+      size_t toCopy;
+
+      ASSERT(va);
+      if (size - bytesCopied > PAGE_SIZE - pageOffset) {
+         /* Enough payload to fill up this page. */
+         toCopy = PAGE_SIZE - pageOffset;
+      } else {
+         toCopy = size - bytesCopied;
+      }
+
+      if (isIovec) {
+         struct iovec *iov = (struct iovec *)dest;
+         int err;
+
+         /* The iovec will track bytesCopied internally. */
+         err = memcpy_toiovec(iov, (uint8 *)va + pageOffset, toCopy);
+         if (err != 0) {
+            kunmap(queue->page[pageIndex]);
+            return err;
+         }
+      } else {
+         memcpy((uint8 *)dest + bytesCopied, (uint8 *)va + pageOffset, toCopy);
+      }
+
+      bytesCopied += toCopy;
+      kunmap(queue->page[pageIndex]);
+   }
+
+   return 0;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VMCIMemcpyToQueue --
+ *
+ *      Copies from a given buffer to a VMCI Queue.
+ *
+ * Results:
+ *      Zero on success, negative error code on failure.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+EXPORT_SYMBOL(VMCIMemcpyToQueue);
+
+int
+VMCIMemcpyToQueue(VMCIQueue *queue,   // OUT:
+                  uint64 queueOffset, // IN:
+                  const void *src,    // IN:
+                  size_t srcOffset,   // IN:
+                  size_t size)        // IN:
+{
+   return __VMCIMemcpyToQueue(queue, queueOffset,
+                              (uint8 *)src + srcOffset, size, FALSE);
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VMCIMemcpyFromQueue --
+ *
+ *      Copies to a given buffer from a VMCI Queue.
+ *
+ * Results:
+ *      Zero on success, negative error code on failure.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+EXPORT_SYMBOL(VMCIMemcpyFromQueue);
+
+int
+VMCIMemcpyFromQueue(void *dest,             // OUT:
+                    size_t destOffset,      // IN:
+                    const VMCIQueue *queue, // IN:
+                    uint64 queueOffset,     // IN:
+                    size_t size)            // IN:
+{
+   return __VMCIMemcpyFromQueue((uint8 *)dest + destOffset,
+                                queue, queueOffset, size, FALSE);
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VMCIMemcpyToQueueV --
+ *
+ *      Copies from a given iovec from a VMCI Queue.
+ *
+ * Results:
+ *      Zero on success, negative error code on failure.
+ *
+ * Side effects:
+ *      None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+EXPORT_SYMBOL(VMCIMemcpyToQueueV);
+
+int
+VMCIMemcpyToQueueV(VMCIQueue *queue,      // OUT:
+                   uint64 queueOffset,    // IN:
+                   const void *src,       // IN: iovec
+                   size_t srcOffset,      // IN: ignored
+                   size_t size)           // IN:
+{
+
+   /*
+    * We ignore srcOffset because src is really a struct iovec * and will
+    * maintain offset internally.
+    */
+   return __VMCIMemcpyToQueue(queue, queueOffset, src, size, TRUE);
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VMCIMemcpyFromQueueV --
+ *
+ *      Copies to a given iovec from a VMCI Queue.
+ *
+ * Results:
+ *      Zero on success, negative error code on failure.
+ *
+ * Side effects:
+ *      None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+EXPORT_SYMBOL(VMCIMemcpyFromQueueV);
+
+int
+VMCIMemcpyFromQueueV(void *dest,              // OUT: iovec
+                     size_t destOffset,       // IN: ignored
+                     const VMCIQueue *queue,  // IN:
+                     uint64 queueOffset,      // IN:
+                     size_t size)             // IN:
+{
+   /*
+    * We ignore destOffset because dest is really a struct iovec * and will
+    * maintain offset internally.
+    */
+   return __VMCIMemcpyFromQueue(dest, queue, queueOffset, size, TRUE);
+}
+
+#endif
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VMCIWellKnownID_AllowMap --
+ *
+ *      Checks whether the calling context is allowed to register for the given
+ *      well known service ID.  Currently returns FALSE if the service ID is
+ *      within the reserved range and VMCI_PRIVILEGE_FLAG_TRUSTED is not
+ *      provided as the input privilege flags.  Otherwise returns TRUE.
+ *      XXX TODO access control based on host configuration information; this
+ *      will be platform specific implementation.
+ *
+ * Results:
+ *      Boolean value indicating access granted or denied.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+Bool
+VMCIWellKnownID_AllowMap(VMCIId wellKnownID,           // IN:
+                         VMCIPrivilegeFlags privFlags) // IN:
+{
+   if (wellKnownID < VMCI_RESERVED_RESOURCE_ID_MAX &&
+       !(privFlags & VMCI_PRIVILEGE_FLAG_TRUSTED)) {
+      return FALSE;
+   }
+   return TRUE;
+}
--- kernel/linux-2.6.26.3/drivers/misc/vmci/vmci_kernel_if.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmci/vmci_kernel_if.h	2008-09-03 10:01:42.000000000 -0500
@@ -0,0 +1,266 @@
+/*********************************************************
+ * Copyright (C) 2006 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * vmci_kernel_if.h -- 
+ * 
+ *      This file defines helper functions for VMCI host _and_ guest
+ *      kernel code. It must work for windows, macosx, vmkernel and
+ *      linux kernel, ie. using defines where necessary.
+ */ 
+ 
+#ifndef _VMCI_KERNEL_IF_H_
+#define _VMCI_KERNEL_IF_H_
+
+#if !defined(linux) && !defined(_WIN32) && !defined(__APPLE__) && \
+    !defined(VMKERNEL) && !defined(SOLARIS)
+#error "Platform not supported."
+#endif
+
+#if defined(_WIN32)
+#include <ntddk.h>
+#endif 
+
+#if defined(linux) && !defined(VMKERNEL)
+#  include "compat_version.h"
+#  include "compat_wait.h"
+#  include "compat_spinlock.h"
+#  include "compat_semaphore.h"
+#endif // linux
+
+#ifdef __APPLE__
+#  include <IOKit/IOLib.h>
+#include <mach/task.h>
+#include <mach/semaphore.h>
+#endif
+
+#ifdef VMKERNEL
+#include "splock.h"
+#include "semaphore_ext.h"
+#endif
+
+#ifdef SOLARIS
+#  include <sys/mutex.h>
+#  include <sys/poll.h>
+#  include <sys/semaphore.h>
+#endif
+
+#include "vm_basic_types.h"
+#include "vmci_defs.h"
+
+/* Flags for specifying memory type. */
+#define VMCI_MEMORY_NORMAL   0x0
+#define VMCI_MEMORY_ATOMIC   0x1
+#define VMCI_MEMORY_NONPAGED 0x2
+
+/* Platform specific type definitions. */
+
+#if defined(VMKERNEL)
+  typedef SP_SpinLock VMCILock;
+  typedef SP_IRQL VMCILockFlags;
+  typedef Semaphore VMCIEvent;
+  typedef Semaphore VMCIMutex;
+#elif defined(linux)
+  typedef spinlock_t VMCILock;
+  typedef unsigned long VMCILockFlags;
+  typedef wait_queue_head_t VMCIEvent;
+  typedef struct semaphore VMCIMutex;
+  typedef PPN *VMCIPpnList; /* List of PPNs in produce/consume queue. */
+#elif defined(__APPLE__)
+  typedef IOLock *VMCILock;
+  typedef unsigned long VMCILockFlags;
+  typedef semaphore_t VMCIEvent;
+  typedef IOLock *VMCIMutex;
+#elif defined(_WIN32)
+  typedef KSPIN_LOCK VMCILock;
+  typedef KIRQL VMCILockFlags;
+  typedef KEVENT VMCIEvent;
+  typedef FAST_MUTEX VMCIMutex;
+  typedef PMDL VMCIPpnList; /* MDL to map the produce/consume queue. */
+#elif defined(SOLARIS)
+  typedef kmutex_t VMCILock;
+  typedef unsigned long VMCILockFlags;
+  typedef ksema_t VMCIEvent;
+#endif // VMKERNEL
+
+/* Callback needed for correctly waiting on events. */
+typedef int (*VMCIEventReleaseCB)(void *clientData);
+
+/*
+ * The VMCI locks use a ranking scheme similar to the one used by
+ * vmkernel. While holding a lock L1 with rank R1, only locks with
+ * rank higher than R1 may be grabbed. The available ranks for VMCI 
+ * locks are (in descending order):
+ * - VMCI_LOCK_RANK_HIGH_BH : to be used for locks grabbed while executing
+ *   in a bottom half and not held while grabbing other locks.
+ * - VMCI_LOCK_RANK_MIDDLE_BH : to be for locks grabbed while executing in a
+ *   bottom half and held while grabbing locks of rank VMCI_LOCK_RANK_HIGH_BH.
+ * - VMCI_LOCK_RANK_LOW_BH : to be for locks grabbed while executing in a
+ *   bottom half and held while grabbing locks of rank
+ *   VMCI_LOCK_RANK_MIDDLE_BH.
+ * - VMCI_LOCK_RANK_HIGHEST : to be used for locks that are not held while
+ *   grabbing other locks except system locks with higher ranks and bottom
+ *   half locks.
+ * - VMCI_LOCK_RANK_HIGHER : to be used for locks that are held while
+ *   grabbing locks of rank VMCI_LOCK_RANK_HIGHEST or higher.
+ * - VMCI_LOCK_RANK_HIGH : to be used for locks that are held while
+ *   grabbing locks of rank VMCI_LOCK_RANK_HIGHER or higher. This is
+ *   the highest lock rank used by core VMCI services
+ * - VMCI_LOCK_RANK_MIDDLE : to be used for locks that are held while
+ *   grabbing locks of rank VMCI_LOCK_RANK_HIGH or higher.
+ * - VMCI_LOCK_RANK_LOW : to be used for locks that are held while
+ *   grabbing locks of rank VMCI_LOCK_RANK_MIDDLE or higher.
+ * - VMCI_LOCK_RANK_LOWEST : to be used for locks that are held while
+ *   grabbing locks of rank VMCI_LOCK_RANK_LOW or higher.
+ */
+#ifdef VMKERNEL
+  typedef SP_Rank VMCILockRank;
+
+  #define VMCI_LOCK_RANK_HIGH_BH        SP_RANK_IRQ_LEAF
+  #define VMCI_LOCK_RANK_MIDDLE_BH      (SP_RANK_IRQ_LEAF-1)
+  #define VMCI_LOCK_RANK_LOW_BH         SP_RANK_IRQ_LOWEST
+  #define VMCI_LOCK_RANK_HIGHEST        SP_RANK_SHM_MGR-1
+#else
+  typedef unsigned long VMCILockRank;
+
+  #define VMCI_LOCK_RANK_HIGH_BH        0x4000
+  #define VMCI_LOCK_RANK_MIDDLE_BH      0x2000
+  #define VMCI_LOCK_RANK_LOW_BH         0x1000
+  #define VMCI_LOCK_RANK_HIGHEST        0x0fff
+#endif // VMKERNEL
+#define VMCI_LOCK_RANK_HIGHER      (VMCI_LOCK_RANK_HIGHEST-1)
+#define VMCI_LOCK_RANK_HIGH        (VMCI_LOCK_RANK_HIGHER-1)
+#define VMCI_LOCK_RANK_MIDDLE_HIGH (VMCI_LOCK_RANK_HIGH-1)
+#define VMCI_LOCK_RANK_MIDDLE      (VMCI_LOCK_RANK_MIDDLE_HIGH-1)
+#define VMCI_LOCK_RANK_MIDDLE_LOW  (VMCI_LOCK_RANK_MIDDLE-1)
+#define VMCI_LOCK_RANK_LOW         (VMCI_LOCK_RANK_MIDDLE_LOW-1)
+#define VMCI_LOCK_RANK_LOWEST      (VMCI_LOCK_RANK_LOW-1)
+
+
+/*
+ * In vmkernel, we try to reduce the amount of memory mapped into the
+ * virtual address space by only mapping the memory of buffered
+ * datagrams when copying from and to the guest. In other OSes,
+ * regular kernel memory is used. VMCIBuffer is used to reference
+ * possibly unmapped memory.
+ */
+
+#ifdef VMKERNEL
+typedef MPN VMCIBuffer;
+#define VMCI_BUFFER_INVALID INVALID_MPN
+#else
+typedef void * VMCIBuffer;
+#define VMCI_BUFFER_INVALID NULL
+#endif
+
+/*
+ * Host specific struct used for signalling.
+ */
+
+typedef struct VMCIHost {
+#if defined(VMKERNEL)
+   World_ID vmmWorldID;
+#elif defined(linux)
+   wait_queue_head_t  waitQueue;
+#elif defined(__APPLE__)
+   struct Socket *socket; /* vmci Socket object on Mac OS. */
+#elif defined(_WIN32)
+   KEVENT *callEvent; /* Ptr to userlevel event used when signalling 
+                       * new pending guestcalls in kernel.
+                       */
+#elif defined(SOLARIS)
+   struct pollhead pollhead; /* Per datagram handle pollhead structure to
+                              * be treated as a black-box. None of its 
+                              * fields should be referenced.
+                              */
+#endif
+} VMCIHost;
+
+
+void VMCI_InitLock(VMCILock *lock, char *name, VMCILockRank rank);
+void VMCI_CleanupLock(VMCILock *lock);
+void VMCI_GrabLock(VMCILock *lock, VMCILockFlags *flags);
+void VMCI_ReleaseLock(VMCILock *lock, VMCILockFlags flags);
+void VMCI_GrabLock_BH(VMCILock *lock, VMCILockFlags *flags);
+void VMCI_ReleaseLock_BH(VMCILock *lock, VMCILockFlags flags);
+
+void VMCIHost_InitContext(VMCIHost *hostContext, uintptr_t eventHnd);
+void VMCIHost_ReleaseContext(VMCIHost *hostContext);
+void VMCIHost_SignalCall(VMCIHost *hostContext);
+void VMCIHost_ClearCall(VMCIHost *hostContext);
+Bool VMCIHost_WaitForCallLocked(VMCIHost *hostContext,
+                                VMCILock *lock,
+                                VMCILockFlags *flags,
+                                Bool useBH);
+
+void *VMCI_AllocKernelMem(size_t size, int flags);
+void VMCI_FreeKernelMem(void *ptr, size_t size);
+VMCIBuffer VMCI_AllocBuffer(size_t size, int flags);
+void *VMCI_MapBuffer(VMCIBuffer buf);
+void VMCI_ReleaseBuffer(void *ptr);
+void VMCI_FreeBuffer(VMCIBuffer buf, size_t size);
+#ifdef SOLARIS
+int VMCI_CopyToUser(void *dst, const void *src, unsigned int len, int mode);
+#else
+int VMCI_CopyToUser(void *dst, const void *src, unsigned int len);
+/*
+ * Don't need the following for guests, hence no Solaris code for this
+ * function.
+ */
+Bool VMCIWellKnownID_AllowMap(VMCIId wellKnownID,
+                              VMCIPrivilegeFlags privFlags);
+#endif
+
+void VMCI_CreateEvent(VMCIEvent *event);
+void VMCI_DestroyEvent(VMCIEvent *event);
+void VMCI_SignalEvent(VMCIEvent *event);
+void VMCI_WaitOnEvent(VMCIEvent *event, VMCIEventReleaseCB releaseCB, 
+		      void *clientData);
+
+/* XXX TODO for VMKERNEL (host) and Solaris (guest). */
+#if !defined(VMKERNEL) && (defined(__linux__) || defined(_WIN32) || \
+                           defined(__APPLE__))
+int VMCI_CopyFromUser(void *dst, const void *src, size_t len);
+#endif
+
+#if !defined(SOLARIS)
+int VMCIMutex_Init(VMCIMutex *mutex);
+void VMCIMutex_Destroy(VMCIMutex *mutex);
+void VMCIMutex_Acquire(VMCIMutex *mutex);
+void VMCIMutex_Release(VMCIMutex *mutex);
+#endif
+
+/* XXX TODO for Solaris (guest). */
+#if !defined(VMKERNEL) && (defined(__linux__) || defined(_WIN32))
+VA VMCI_AllocQueueKVA(uint64 size);
+void VMCI_FreeQueueKVA(VA va, uint64 size);
+typedef struct PPNSet {
+  uint64      numProducePages;
+  uint64      numConsumePages;
+  VMCIPpnList producePPNs;
+  VMCIPpnList consumePPNs;
+  Bool        initialized;
+} PPNSet;
+int VMCI_AllocPPNSet(VA produceVA, uint64 numProducePages, VA consumeVA,
+                     uint64 numConsumePages, PPNSet *ppnSet);
+void VMCI_FreePPNSet(PPNSet *ppnSet);
+int VMCI_PopulatePPNList(uint8 *callBuf, const PPNSet *ppnSet);
+#endif
+
+#endif // _VMCI_KERNEL_IF_H_
+
--- kernel/linux-2.6.26.3/drivers/misc/vmci/vmciProcess.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmci/vmciProcess.c	2008-09-03 10:01:42.000000000 -0500
@@ -0,0 +1,227 @@
+/*********************************************************
+ * Copyright (C) 2006 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * vmciProcess.c --
+ *
+ *     VMCI Process code for guest driver.
+ */
+
+#ifdef __linux__
+#  include "driver-config.h"
+
+#  define EXPORT_SYMTAB
+
+#  include <linux/module.h>
+#  include "compat_kernel.h"
+#  include "compat_pci.h"
+#endif // __linux__
+
+#include "vmciInt.h"
+#include "vmci_defs.h"
+#include "vmci_kernel_if.h"
+#include "vmciProcess.h"
+#include "vmciDatagram.h"
+#include "vmci_infrastructure.h"
+#include "circList.h"
+#include "vmciUtil.h"
+#include "vmciGuestKernelAPI.h"
+
+static ListItem *processList = NULL;
+static VMCILock processLock;
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * VMCIProcess_Init --
+ *
+ *      General init code.
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      None.
+ *
+ *----------------------------------------------------------------------
+ */
+
+void
+VMCIProcess_Init(void)
+{
+   VMCI_InitLock(&processLock, "VMCIProcessListLock", VMCI_LOCK_RANK_HIGH);
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * VMCIProcess_Exit --
+ *
+ *      General init code.
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      None.
+ *
+ *----------------------------------------------------------------------
+ */
+
+void
+VMCIProcess_Exit(void)
+{
+   VMCI_CleanupLock(&processLock);
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VMCIProcess_CheckHostCapabilities --
+ *
+ *      Verify that the host supports the hypercalls we need. If it does not,
+ *      try to find fallback hypercalls and use those instead.
+ *
+ * Results:
+ *      TRUE if required hypercalls (or fallback hypercalls) are
+ *      supported by the host, FALSE otherwise.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+Bool
+VMCIProcess_CheckHostCapabilities(void)
+{
+   /* VMCIProcess does not require any hypercalls. */
+   return TRUE;
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * VMCIProcess_Create --
+ *
+ *      Creates a new VMCI process.
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      None.
+ *
+ *----------------------------------------------------------------------
+ */
+
+int
+VMCIProcess_Create(VMCIProcess **outProcess,     // IN
+                   int eventHnd)                 // IN
+{
+   VMCIProcess *process;
+   VMCILockFlags flags;
+
+   process = VMCI_AllocKernelMem(sizeof *process, VMCI_MEMORY_NONPAGED);
+   if (process == NULL) {
+      return VMCI_ERROR_NO_MEM;
+   }
+
+   process->pid = (VMCIId)(uintptr_t)process >> 1;
+
+   VMCI_GrabLock(&processLock, &flags);
+   LIST_QUEUE(&process->listItem, &processList);
+   VMCI_ReleaseLock(&processLock, flags);
+
+   *outProcess = process;
+   return 0;
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * VMCIProcess_Destroy --
+ *
+ *      Destroys a VMCI process.
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      None.
+ *
+ *----------------------------------------------------------------------
+ */
+
+void
+VMCIProcess_Destroy(VMCIProcess *process)
+{
+   VMCILockFlags flags;
+
+   /* Dequeue process. */
+   VMCI_GrabLock(&processLock, &flags);
+   LIST_DEL(&process->listItem, &processList);
+   VMCI_ReleaseLock(&processLock, flags);
+
+   VMCI_FreeKernelMem(process, sizeof *process);
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * VMCIProcess_Get --
+ *
+ *      Get the process corresponding to the pid.
+ *
+ * Results:
+ *      VMCI process on success, NULL otherwise.
+ *
+ * Side effects:
+ *      None.
+ *
+ *----------------------------------------------------------------------
+ */
+
+VMCIProcess *
+VMCIProcess_Get(VMCIId processID)  // IN
+{
+   VMCIProcess *process = NULL;  
+   ListItem *next;
+   VMCILockFlags flags;
+
+   VMCI_GrabLock(&processLock, &flags);
+   if (processList == NULL) {
+      goto out;
+   }
+
+   LIST_SCAN(next, processList) {
+      process = LIST_CONTAINER(next, VMCIProcess, listItem);
+      if (process->pid == processID) {
+         break;
+      }
+   }
+
+out:
+   VMCI_ReleaseLock(&processLock, flags);
+   return (process && process->pid == processID) ? process : NULL;
+}
--- kernel/linux-2.6.26.3/drivers/misc/vmci/vmciProcess.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmci/vmciProcess.h	2008-09-03 10:01:42.000000000 -0500
@@ -0,0 +1,49 @@
+/*********************************************************
+ * Copyright (C) 2006 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/* 
+ * vmciProcess.h --
+ *
+ *      Process code for the Linux guest driver
+ */
+
+#ifndef __VMCI_PROCESS_H__
+#define __VMCI_PROCESS_H__
+
+#define INCLUDE_ALLOW_MODULE
+#include "includeCheck.h"
+
+#include "vm_basic_types.h"
+
+#include "vmci_defs.h"
+#include "vmci_handle_array.h"
+#include "circList.h"
+
+typedef struct VMCIProcess {
+   ListItem        listItem;          /* For global process list. */
+   VMCIId          pid;               /* Process id. */
+} VMCIProcess;
+
+void VMCIProcess_Init(void);
+void VMCIProcess_Exit(void);
+Bool VMCIProcess_CheckHostCapabilities(void);
+int VMCIProcess_Create(VMCIProcess **outProcess, int eventHnd);
+void VMCIProcess_Destroy(VMCIProcess *process);
+VMCIProcess *VMCIProcess_Get(VMCIId processID);
+		
+#endif //__VMCI_PROCESS_H__
--- kernel/linux-2.6.26.3/drivers/misc/vmci/vmciQueuePair.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmci/vmciQueuePair.c	2008-09-03 10:01:42.000000000 -0500
@@ -0,0 +1,934 @@
+/*********************************************************
+ * Copyright (C) 2007 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * vmciQueuePair.c --
+ *
+ *     Implements the VMCI QueuePair API.
+ */
+
+#ifdef __linux__
+#  include "driver-config.h"
+#  define EXPORT_SYMTAB
+#  include <asm/page.h>
+#  include <linux/module.h>
+#elif defined(_WIN32)
+#  include <wdm.h>
+#endif /* __linux__ */
+
+#include "vm_assert.h"
+#include "vmci_kernel_if.h"
+#include "vmci_queue_pair.h"
+#include "vmciQueuePairInt.h"
+#include "vmciUtil.h"
+#include "vmciInt.h"
+#include "vmciEvent.h"
+#include "circList.h"
+
+#define LGPFX "VMCIQueuePair: "
+
+typedef struct QueuePairEntry {
+   VMCIHandle handle;
+   VMCIId     peer;
+   uint32     flags;
+   uint64     produceSize;
+   uint64     consumeSize;
+   uint64     numPPNs;
+   PPNSet     ppnSet;
+   VA         produceQVA;
+   VA         consumeQVA;
+   uint32     refCount;
+   ListItem   listItem;
+} QueuePairEntry;
+
+typedef struct QueuePairList {
+   ListItem  *head;
+   VMCIMutex mutex;
+} QueuePairList;
+
+static QueuePairList queuePairList;
+
+static QueuePairEntry *QueuePairList_FindEntry(VMCIHandle handle);
+static void QueuePairList_AddEntry(QueuePairEntry *entry);
+static void QueuePairList_RemoveEntry(QueuePairEntry *entry);
+static QueuePairEntry *QueuePairList_GetHead(void);
+static QueuePairEntry *QueuePairEntryCreate(VMCIHandle handle,
+                                            VMCIId peer, uint32 flags,
+                                            uint64 produceSize,
+                                            uint64 consumeSize,
+                                            VA produceQVA, VA consumeQVA);
+static void QueuePairEntryDestroy(QueuePairEntry *entry);
+static int VMCIQueuePairAlloc_HyperCall(const QueuePairEntry *entry);
+static int VMCIQueuePairAllocHelper(VMCIHandle *handle, VMCIQueue **produceQ,
+                                    uint64 produceSize, VMCIQueue **consumeQ,
+                                    uint64 consumeSize,
+                                    VMCIId peer, uint32 flags);
+static int VMCIQueuePairDetachHelper(VMCIHandle handle);
+static int QueuePairNotifyPeerLocal(Bool attach, VMCIHandle handle);
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * QueuePairLock_Init --
+ *
+ *      Creates the lock protecting the QueuePair list.
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE void
+QueuePairLock_Init(void)
+{
+   VMCIMutex_Init(&queuePairList.mutex);
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * QueuePairLock_Destroy --
+ *
+ *      Destroys the lock protecting the QueuePair list.
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE void
+QueuePairLock_Destroy(void)
+{
+   VMCIMutex_Destroy(&queuePairList.mutex); /* No-op on Linux and Windows. */
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * QueuePairList_Lock --
+ *
+ *      Acquires the lock protecting the QueuePair list.
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE void
+QueuePairList_Lock(void)
+{
+   VMCIMutex_Acquire(&queuePairList.mutex);
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * QueuePairList_Unlock --
+ *
+ *      Releases the lock protecting the QueuePair list.
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE void
+QueuePairList_Unlock(void)
+{
+   VMCIMutex_Release(&queuePairList.mutex);
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VMCIQueuePair_Init --
+ *
+ *      Initalizes QueuePair data structure state.
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+void
+VMCIQueuePair_Init(void)
+{
+   queuePairList.head = NULL;
+   QueuePairLock_Init();
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VMCIQueuePair_Exit --
+ *
+ *      Destroys all QueuePairs. Makes hypercalls to detach from QueuePairs.
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+void
+VMCIQueuePair_Exit(void)
+{
+   QueuePairEntry *entry;
+
+   QueuePairList_Lock();
+
+   while ((entry = QueuePairList_GetHead())) {
+      /*
+       * Don't make a hypercall for local QueuePairs.
+       */
+      if (!(entry->flags & VMCI_QPFLAG_LOCAL)) {
+         VMCIQueuePairDetachMsg detachMsg;
+
+         detachMsg.hdr.dst = VMCI_MAKE_HANDLE(VMCI_HYPERVISOR_CONTEXT_ID,
+                                              VMCI_QUEUEPAIR_DETACH);
+         detachMsg.hdr.src = VMCI_ANON_SRC_HANDLE;
+         detachMsg.hdr.payloadSize = sizeof entry->handle;
+         detachMsg.handle = entry->handle;
+         
+         (void)VMCI_SendDatagram((VMCIDatagram *)&detachMsg);
+      }
+      /*
+       * We cannot fail the exit, so let's reset refCount.
+       */
+      entry->refCount = 0;
+      QueuePairList_RemoveEntry(entry);
+      QueuePairEntryDestroy(entry);
+   }
+
+   QueuePairList_Unlock();
+   QueuePairLock_Destroy();
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * QueuePairList_FindEntry --
+ *
+ *    Searches the list of QueuePairs to find if an entry already exists.
+ *    Assumes that the lock on the list is held.
+ *
+ * Results:
+ *    Pointer to the entry if it exists, NULL otherwise.
+ *
+ * Side effects:
+ *    None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static QueuePairEntry *
+QueuePairList_FindEntry(VMCIHandle handle) // IN:
+{
+   ListItem *next;
+
+   if (VMCI_HANDLE_INVALID(handle)) {
+      return NULL;
+   }
+
+   LIST_SCAN(next, queuePairList.head) {
+      QueuePairEntry *entry = LIST_CONTAINER(next, QueuePairEntry, listItem);
+
+      if (VMCI_HANDLE_EQUAL(entry->handle, handle)) {
+         return entry;
+      }
+   }
+
+   return NULL;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * QueuePairList_AddEntry --
+ *
+ *    Appends a QueuePair entry to the list. Assumes that the lock on the
+ *    list is held.
+ *
+ * Results:
+ *    None.
+ *
+ * Side effects:
+ *    None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static void
+QueuePairList_AddEntry(QueuePairEntry *entry) // IN:
+{
+   if (entry) {
+      LIST_QUEUE(&entry->listItem, &queuePairList.head);
+   }
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * QueuePairList_RemoveEntry --
+ *
+ *    Removes a QueuePair entry from the list. Assumes that the lock on the
+ *    list is held.
+ *
+ * Results:
+ *    None.
+ *
+ * Side effects:
+ *    None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static void
+QueuePairList_RemoveEntry(QueuePairEntry *entry) // IN:
+{
+   if (entry) {
+      LIST_DEL(&entry->listItem, &queuePairList.head);
+   }
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * QueuePairList_GetHead --
+ *
+ *      Returns the entry from the head of the list. Assumes that the list is
+ *      locked.
+ *
+ * Results:
+ *      Pointer to entry.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static QueuePairEntry *
+QueuePairList_GetHead(void)
+{
+   ListItem *first = LIST_FIRST(queuePairList.head);
+
+   if (first) {
+      QueuePairEntry *entry = LIST_CONTAINER(first, QueuePairEntry, listItem);
+      return entry;
+   }
+
+   return NULL;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VMCIQueuePair_Alloc --
+ *
+ *      Allocates a VMCI QueuePair. Only checks validity of input arguments.
+ *      Real work is done in the OS-specific helper routine.
+ *
+ * Results:
+ *      Success or failure.
+ *
+ * Side effects:
+ *      Memory is allocated.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+#ifdef __linux__
+EXPORT_SYMBOL(VMCIQueuePair_Alloc);
+#endif
+
+int
+VMCIQueuePair_Alloc(VMCIHandle *handle,     // IN/OUT:
+                    VMCIQueue  **produceQ,  // OUT:
+                    uint64     produceSize, // IN:
+                    VMCIQueue  **consumeQ,  // OUT:
+                    uint64     consumeSize, // IN:
+                    VMCIId     peer,        // IN:
+                    uint32     flags)       // IN:
+{
+   ASSERT_ON_COMPILE(sizeof(VMCIQueueHeader) <= PAGE_SIZE);
+#  define VMCIQP_OFFSET_OF(Struct, field) ((uintptr_t)&(((Struct *)0)->field))
+#ifdef __linux__
+   ASSERT_ON_COMPILE(VMCIQP_OFFSET_OF(VMCIQueue, page) == PAGE_SIZE);
+#else
+   ASSERT_ON_COMPILE(VMCIQP_OFFSET_OF(VMCIQueue, buffer) == PAGE_SIZE);
+#endif
+#  undef VMCIQP_OFFSET_OF
+
+   if (!handle || !produceQ || !consumeQ || (!produceSize && !consumeSize) ||
+       (flags & ~VMCI_QP_ALL_FLAGS)) {
+      return VMCI_ERROR_INVALID_ARGS;
+   }
+
+   return VMCIQueuePairAllocHelper(handle, produceQ, produceSize, consumeQ,
+                                   consumeSize, peer, flags);
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VMCIQueuePair_Detach --
+ *
+ *      Detaches from a VMCI QueuePair. Only checks validity of input argument.
+ *      Real work is done in the OS-specific helper routine.
+ *
+ * Results:
+ *      Success or failure.
+ *
+ * Side effects:
+ *      Memory is freed.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+#ifdef __linux__
+EXPORT_SYMBOL(VMCIQueuePair_Detach);
+#endif
+
+int
+VMCIQueuePair_Detach(VMCIHandle handle) // IN:
+{
+   if (VMCI_HANDLE_INVALID(handle)) {
+      return VMCI_ERROR_INVALID_ARGS;
+   }
+   return VMCIQueuePairDetachHelper(handle);
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * QueuePairEntryCreate --
+ *
+ *      Allocates and initializes a QueuePairEntry structure.  Allocates a
+ *      QueuePair rid (and handle) iff the given entry has an invalid handle.
+ *      0 through VMCI_RESERVED_RESOURCE_ID_MAX are reserved handles.  Assumes
+ *      that the QP list lock is held by the caller.
+ *
+ * Results:
+ *      Pointer to structure intialized.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+QueuePairEntry *
+QueuePairEntryCreate(VMCIHandle handle,  // IN:
+                     VMCIId peer,        // IN:
+                     uint32 flags,       // IN:
+                     uint64 produceSize, // IN:
+                     uint64 consumeSize, // IN:
+                     VA produceQVA,      // IN:
+                     VA consumeQVA)      // IN:
+{
+   static VMCIId queuePairRID = VMCI_RESERVED_RESOURCE_ID_MAX + 1;
+   QueuePairEntry *entry;
+   const uint64 numPPNs = CEILING(produceSize, PAGE_SIZE) +
+                          CEILING(consumeSize, PAGE_SIZE) +
+                          2; /* One page each for the queue headers. */
+
+   ASSERT((produceSize || consumeSize) && produceQVA && consumeQVA);
+   
+   if (VMCI_HANDLE_INVALID(handle)) {
+      VMCIId contextID = VMCI_GetContextID();
+      VMCIId oldRID = queuePairRID;
+
+      /*
+       * Generate a unique QueuePair rid.  Keep on trying until we wrap around
+       * in the RID space.
+       */
+      ASSERT(oldRID > VMCI_RESERVED_RESOURCE_ID_MAX);
+      do {
+         handle = VMCI_MAKE_HANDLE(contextID, queuePairRID);
+         entry = QueuePairList_FindEntry(handle);
+         queuePairRID++;
+         if (UNLIKELY(!queuePairRID)) {
+            /*
+             * Skip the reserved rids.
+             */
+            queuePairRID = VMCI_RESERVED_RESOURCE_ID_MAX + 1;
+         }
+      } while (entry && queuePairRID != oldRID);
+
+      if (UNLIKELY(entry != NULL)) {
+         ASSERT(queuePairRID == oldRID);
+         /*
+          * We wrapped around --- no rids were free.
+          */
+         return NULL;
+      }
+   }
+
+   ASSERT(!VMCI_HANDLE_INVALID(handle) &&
+          QueuePairList_FindEntry(handle) == NULL);
+   entry = VMCI_AllocKernelMem(sizeof *entry, VMCI_MEMORY_NORMAL);
+   if (entry) {
+      entry->handle = handle;
+      entry->peer = peer;
+      entry->flags = flags;
+      entry->produceSize = produceSize;
+      entry->consumeSize = consumeSize;
+      entry->numPPNs = numPPNs;
+      memset(&entry->ppnSet, 0, sizeof entry->ppnSet);
+      entry->produceQVA = produceQVA;
+      entry->consumeQVA = consumeQVA;
+      entry->refCount = 0;
+      INIT_LIST_ITEM(&entry->listItem);
+   }
+   return entry;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * QueuePairEntryDestroy --
+ *
+ *      Frees a QueuePairEntry structure.
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+void
+QueuePairEntryDestroy(QueuePairEntry *entry) // IN:
+{
+   ASSERT(entry);
+   ASSERT(entry->refCount == 0);
+
+   VMCI_FreePPNSet(&entry->ppnSet);
+   VMCI_FreeQueueKVA(entry->produceQVA, entry->produceSize);
+   VMCI_FreeQueueKVA(entry->consumeQVA, entry->consumeSize);
+   VMCI_FreeKernelMem(entry, sizeof *entry);
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VMCIQueuePairAlloc_HyperCall --
+ *
+ *      Helper to make a QueuePairAlloc hypercall.
+ *
+ * Results:
+ *      Result of the hypercall.
+ *
+ * Side effects:
+ *      Memory is allocated & freed.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+int
+VMCIQueuePairAlloc_HyperCall(const QueuePairEntry *entry) // IN:
+{
+   VMCIQueuePairAllocMsg *allocMsg;
+   size_t msgSize;
+   int result;
+
+   if (!entry || entry->numPPNs <= 2) {
+      return VMCI_ERROR_INVALID_ARGS;
+   }
+
+   ASSERT(!(entry->flags & VMCI_QPFLAG_LOCAL));
+
+   msgSize = sizeof *allocMsg + (size_t)entry->numPPNs * sizeof(PPN);
+   allocMsg = VMCI_AllocKernelMem(msgSize, VMCI_MEMORY_NONPAGED);
+   if (!allocMsg) {
+      return VMCI_ERROR_NO_MEM;
+   }
+
+   allocMsg->hdr.dst = VMCI_MAKE_HANDLE(VMCI_HYPERVISOR_CONTEXT_ID,
+					VMCI_QUEUEPAIR_ALLOC);
+   allocMsg->hdr.src = VMCI_ANON_SRC_HANDLE;
+   allocMsg->hdr.payloadSize = msgSize - VMCI_DG_HEADERSIZE;
+   allocMsg->handle = entry->handle;
+   allocMsg->peer = entry->peer;
+   allocMsg->flags = entry->flags;
+   allocMsg->produceSize = entry->produceSize;
+   allocMsg->consumeSize = entry->consumeSize;
+   allocMsg->numPPNs = entry->numPPNs;
+   result = VMCI_PopulatePPNList((uint8 *)allocMsg + sizeof *allocMsg, &entry->ppnSet);
+   if (result == VMCI_SUCCESS) {
+      result = VMCI_SendDatagram((VMCIDatagram *)allocMsg);
+   }
+   VMCI_FreeKernelMem(allocMsg, msgSize);
+
+   return result;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VMCIQueuePairAllocHelper --
+ *
+ *      Helper for VMCI QueuePairAlloc. Allocates physical pages for the
+ *      QueuePair. Makes OS dependent calls through generic wrappers.
+ *
+ * Results:
+ *      Success or failure.
+ *
+ * Side effects:
+ *      Memory is allocated.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static int
+VMCIQueuePairAllocHelper(VMCIHandle *handle,   // IN/OUT:
+                         VMCIQueue **produceQ, // OUT:
+                         uint64 produceSize,   // IN:
+                         VMCIQueue **consumeQ, // OUT:
+                         uint64 consumeSize,   // IN:
+                         VMCIId peer,          // IN:
+                         uint32 flags)         // IN:
+{
+   const uint64 numProducePages = CEILING(produceSize, PAGE_SIZE) + 1;
+   const uint64 numConsumePages = CEILING(consumeSize, PAGE_SIZE) + 1;
+   VA produceVA = 0;
+   VA consumeVA = 0;
+   int result;
+   QueuePairEntry *queuePairEntry = NULL;
+
+   /*
+    * XXX Check for possible overflow of 'size' arguments when passed to
+    * compat_get_order (after some arithmetic ops).
+    */
+
+   ASSERT(handle && produceQ && consumeQ && (produceSize || consumeSize));
+
+   QueuePairList_Lock();
+
+   if ((queuePairEntry = QueuePairList_FindEntry(*handle))) {
+      if (queuePairEntry->flags & VMCI_QPFLAG_LOCAL) {
+         /* Local attach case. */
+         if (queuePairEntry->refCount > 1) {
+            VMCI_LOG((LGPFX "Error attempting to attach more than once.\n"));
+            result = VMCI_ERROR_UNAVAILABLE;
+            goto errorKeepEntry;
+         }
+
+         if (queuePairEntry->produceSize != consumeSize ||
+             queuePairEntry->consumeSize != produceSize ||
+             queuePairEntry->flags != (flags & ~VMCI_QPFLAG_ATTACH_ONLY)) {
+            VMCI_LOG((LGPFX "Error mismatched queue pair in local attach.\n"));
+            result = VMCI_ERROR_QUEUEPAIR_MISMATCH;
+            goto errorKeepEntry;
+         }
+
+         /*
+          * Do a local attach.  We swap the consume and produce queues for the
+          * attacher and deliver an attach event.
+          */
+         result = QueuePairNotifyPeerLocal(TRUE, *handle);
+         if (result < VMCI_SUCCESS) {
+            goto errorKeepEntry;
+         }
+         produceVA = queuePairEntry->consumeQVA;
+         consumeVA = queuePairEntry->produceQVA;
+         goto out;
+      }
+      result = VMCI_ERROR_ALREADY_EXISTS;
+      goto errorKeepEntry;
+   }
+
+   produceVA = VMCI_AllocQueueKVA(produceSize);
+   if (!produceVA) {
+      VMCI_LOG((LGPFX "Error allocating pages for produce queue.\n"));
+      result = VMCI_ERROR_NO_MEM;
+      goto error;
+   }
+
+   consumeVA = VMCI_AllocQueueKVA(consumeSize);
+   if (!consumeVA) {
+      VMCI_LOG((LGPFX "Error allocating pages for consume queue.\n"));
+      result = VMCI_ERROR_NO_MEM;
+      goto error;
+   }
+
+   queuePairEntry = QueuePairEntryCreate(*handle, peer, flags,
+                                         produceSize, consumeSize,
+                                         produceVA, consumeVA);
+   if (!queuePairEntry) {
+      VMCI_LOG((LGPFX "Error allocating memory in %s.\n", __FUNCTION__));
+      result = VMCI_ERROR_NO_MEM;
+      goto error;
+   }
+
+   result = VMCI_AllocPPNSet(produceVA, numProducePages, consumeVA,
+                             numConsumePages, &queuePairEntry->ppnSet);
+   if (result < VMCI_SUCCESS) {
+      VMCI_LOG((LGPFX "VMCI_AllocPPNSet failed.\n"));
+      goto error;
+   }
+
+   /*
+    * It's only necessary to notify the host if this queue pair will be
+    * attached to from another context.
+    */
+   if (queuePairEntry->flags & VMCI_QPFLAG_LOCAL) {
+      /* Local create case. */
+      VMCIId contextId = VMCI_GetContextID();
+
+      /*
+       * Enforce similar checks on local queue pairs as we do for regular ones.
+       * The handle's context must match the creator or attacher context id
+       * (here they are both the current context id) and the attach-only flag
+       * cannot exist during create.  We also ensure specified peer is this
+       * context or an invalid one.
+       */
+      if (queuePairEntry->handle.context != contextId ||
+          (queuePairEntry->peer != VMCI_INVALID_ID &&
+           queuePairEntry->peer != contextId)) {
+         result = VMCI_ERROR_NO_ACCESS;
+         goto error;
+      }
+
+      if (queuePairEntry->flags & VMCI_QPFLAG_ATTACH_ONLY) {
+         result = VMCI_ERROR_NOT_FOUND;
+         goto error;
+      }
+   } else {
+      result = VMCIQueuePairAlloc_HyperCall(queuePairEntry);
+      if (result < VMCI_SUCCESS) {
+         VMCI_LOG((LGPFX "VMCIQueuePairAlloc_HyperCall result = %d.\n",
+                   result));
+         goto error;
+      }
+   }
+
+   QueuePairList_AddEntry(queuePairEntry);
+
+out:
+   queuePairEntry->refCount++;
+   *handle = queuePairEntry->handle;
+   *produceQ = (VMCIQueue *)produceVA;
+   *consumeQ = (VMCIQueue *)consumeVA;
+
+   /*
+    * We should initialize the queue pair header pages on a local queue pair
+    * create.  For non-local queue pairs, the hypervisor initializes the header
+    * pages in the create step.
+    */
+   if ((queuePairEntry->flags & VMCI_QPFLAG_LOCAL) &&
+       queuePairEntry->refCount == 1) {
+      VMCIQueue_Init(*handle, *produceQ);
+      VMCIQueue_Init(*handle, *consumeQ);
+   }
+
+   QueuePairList_Unlock();
+
+   return VMCI_SUCCESS;
+
+error:
+   QueuePairList_Unlock();
+   if (queuePairEntry) {
+      /* The KVAs will be freed inside the destroy routine. */
+      QueuePairEntryDestroy(queuePairEntry);
+   } else {
+      if (produceVA) {
+         VMCI_FreeQueueKVA(produceVA, produceSize);
+      }
+      if (consumeVA) {
+         VMCI_FreeQueueKVA(consumeVA, consumeSize);
+      }
+   }
+   return result;
+
+errorKeepEntry:
+   /* This path should only be used when an existing entry was found. */
+   ASSERT(queuePairEntry->refCount > 0);
+   QueuePairList_Unlock();
+   return result;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VMCIQueuePairDetachHelper --
+ *
+ *      Helper for VMCI QueuePair detach interface on Linux. Frees the physical
+ *      pages for the QueuePair.
+ *
+ * Results:
+ *      Success or failure.
+ *
+ * Side effects:
+ *      Memory may be freed.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static int
+VMCIQueuePairDetachHelper(VMCIHandle handle)   // IN:
+{
+   int result;
+   QueuePairEntry *entry;
+   uint32 refCount;
+
+   ASSERT(!VMCI_HANDLE_INVALID(handle));
+
+   QueuePairList_Lock();
+
+   entry = QueuePairList_FindEntry(handle);
+   if (!entry) {
+      result = VMCI_ERROR_NOT_FOUND;
+      goto out;
+   }
+
+   ASSERT(entry->refCount >= 1);
+
+   if (entry->flags & VMCI_QPFLAG_LOCAL) {
+      result = VMCI_SUCCESS;
+
+      if (entry->refCount > 1) {
+         result = QueuePairNotifyPeerLocal(FALSE, handle);
+         if (result < VMCI_SUCCESS) {
+            goto out;
+         }
+      }
+   } else {
+      VMCIQueuePairDetachMsg detachMsg;
+
+      detachMsg.hdr.dst = VMCI_MAKE_HANDLE(VMCI_HYPERVISOR_CONTEXT_ID,
+                                           VMCI_QUEUEPAIR_DETACH);
+      detachMsg.hdr.src = VMCI_ANON_SRC_HANDLE;
+      detachMsg.hdr.payloadSize = sizeof handle;
+      detachMsg.handle = handle;
+
+      result = VMCI_SendDatagram((VMCIDatagram *)&detachMsg);
+   }
+
+out:
+   if (result >= VMCI_SUCCESS) {
+      entry->refCount--;
+
+      if (entry->refCount == 0) {
+         QueuePairList_RemoveEntry(entry);
+      }
+   }
+
+   /* If we didn't remove the entry, this could change once we unlock. */
+   refCount = entry ? entry->refCount :
+                      0xffffffff; /* 
+                                   * Value does not matter, silence the
+                                   * compiler.
+                                   */
+                                       
+
+   QueuePairList_Unlock();
+
+   if (result >= VMCI_SUCCESS && refCount == 0) {
+      QueuePairEntryDestroy(entry);
+   }
+   return result;
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * QueuePairNotifyPeerLocal --
+ *
+ *      Dispatches a queue pair event message directly into the local event
+ *      queue.
+ *
+ * Results:
+ *      VMCI_SUCCESS on success, error code otherwise
+ *
+ * Side effects:
+ *      None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+static int
+QueuePairNotifyPeerLocal(Bool attach,           // IN: attach or detach?
+                         VMCIHandle handle)     // IN: queue pair handle
+{
+   VMCIEventMsg *eMsg;
+   VMCIEventPayload_QP *ePayload;
+   /* buf is only 48 bytes. */
+   char buf[sizeof *eMsg + sizeof *ePayload];
+   VMCIId contextId;
+
+   contextId = VMCI_GetContextID();
+
+   eMsg = (VMCIEventMsg *)buf;
+   ePayload = VMCIEventMsgPayload(eMsg);
+
+   eMsg->hdr.dst = VMCI_MAKE_HANDLE(contextId, VMCI_EVENT_HANDLER);
+   eMsg->hdr.src = VMCI_MAKE_HANDLE(VMCI_HYPERVISOR_CONTEXT_ID,
+                                    VMCI_CONTEXT_RESOURCE_ID);
+   eMsg->hdr.payloadSize = sizeof *eMsg + sizeof *ePayload - sizeof eMsg->hdr;
+   eMsg->eventData.event = attach ? VMCI_EVENT_QP_PEER_ATTACH :
+                                    VMCI_EVENT_QP_PEER_DETACH;
+   ePayload->peerId = contextId;
+   ePayload->handle = handle;
+
+   return VMCIEvent_Dispatch((VMCIDatagram *)eMsg);
+}
--- kernel/linux-2.6.26.3/drivers/misc/vmci/vmci_queue_pair.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmci/vmci_queue_pair.h	2008-09-03 10:01:42.000000000 -0500
@@ -0,0 +1,668 @@
+/*********************************************************
+ * Copyright (C) 2007 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef _VMCI_QUEUE_PAIR_H_
+#define _VMCI_QUEUE_PAIR_H_
+
+/*
+ *
+ * vmci_queue_pair.h --
+ *
+ *    Defines queue layout in memory, and helper functions to enqueue and
+ *    dequeue items. XXX needs checksumming?
+ */
+
+#define INCLUDE_ALLOW_MODULE
+#define INCLUDE_ALLOW_VMX
+#include "includeCheck.h"
+
+#include "vm_basic_defs.h"
+#include "vm_basic_types.h"
+#include "vm_atomic.h"
+#include "vmci_defs.h"
+#include "vm_assert.h"
+#if defined(__linux__) && defined(__KERNEL__)
+#  include "vmci_kernel_if.h"
+#endif
+
+
+#if defined(__linux__) && defined(__KERNEL__)
+struct page;
+#endif
+
+
+/*
+ * For a queue of buffer 'size' bytes, the tail and head pointers will be in
+ * the range [0, size-1].
+ */
+
+typedef struct VMCIQueueHeader {
+   /* All fields are 64bit and aligned. */
+   VMCIHandle    handle; /* Identifier. */
+   Atomic_uint64 producerTail; /* Offset in this queue. */
+   Atomic_uint64 consumerHead; /* Offset in peer queue. */
+} VMCIQueueHeader;
+
+typedef struct VMCIQueue {
+   VMCIQueueHeader queueHeader;
+   uint8 _padding[PAGE_SIZE - sizeof(VMCIQueueHeader)];
+#if defined(__linux__) && defined(__KERNEL__)
+   struct page *page[0]; /* List of pages containing queue data. */
+#else
+   uint8 buffer[0]; /* Buffer containing data. */
+#endif
+} VMCIQueue;
+
+
+typedef int VMCIMemcpyToQueueFunc(VMCIQueue *queue, uint64 queueOffset,
+                                  const void *src, size_t srcOffset,
+                                  size_t size);
+typedef int VMCIMemcpyFromQueueFunc(void *dest, size_t destOffset,
+                                    const VMCIQueue *queue, uint64 queueOffset,
+                                    size_t size);
+
+#if defined(__linux__) && defined(__KERNEL__)
+int VMCIMemcpyToQueue(VMCIQueue *queue, uint64 queueOffset, const void *src,
+                      size_t srcOffset, size_t size);
+int VMCIMemcpyFromQueue(void *dest, size_t destOffset, const VMCIQueue *queue,
+                        uint64 queueOffset, size_t size);
+int VMCIMemcpyToQueueV(VMCIQueue *queue, uint64 queueOffset, const void *src,
+                       size_t srcOffset, size_t size);
+int VMCIMemcpyFromQueueV(void *dest, size_t destOffset, const VMCIQueue *queue,
+                         uint64 queueOffset, size_t size);
+#elif defined(_WIN32) && defined(WINNT_DDK)
+int VMCIMemcpyToQueue(VMCIQueue *queue, uint64 queueOffset, const void *src,
+                      size_t srcOffset, size_t size);
+int VMCIMemcpyFromQueue(void *dest, size_t destOffset, const VMCIQueue *queue,
+                        uint64 queueOffset, size_t size);
+#else
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VMCIMemcpyToQueue --
+ *
+ *      Wrapper for memcpy --- copies from a given buffer to a VMCI Queue.
+ *      Assumes that offset + size does not wrap around in the queue.
+ *
+ * Results:
+ *      Zero on success, negative error code on failure.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE int
+VMCIMemcpyToQueue(VMCIQueue *queue,   // OUT:
+                  uint64 queueOffset, // IN:
+                  const void *src,    // IN:
+                  size_t srcOffset,   // IN:
+                  size_t size)        // IN:
+{
+   memcpy(queue->buffer + queueOffset, (uint8 *)src + srcOffset, size);
+   return 0;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VMCIMemcpyFromQueue --
+ *
+ *      Wrapper for memcpy --- copies to a given buffer from a VMCI Queue.
+ *      Assumes that offset + size does not wrap around in the queue.
+ *
+ * Results:
+ *      Zero on success, negative error code on failure.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE int
+VMCIMemcpyFromQueue(void *dest,             // OUT:
+                    size_t destOffset,      // IN:
+                    const VMCIQueue *queue, // IN:
+                    uint64 queueOffset,     // IN:
+                    size_t size)            // IN:
+{
+   memcpy((uint8 *)dest + destOffset, queue->buffer + queueOffset, size);
+   return 0;
+}
+#endif /* __linux__ && __KERNEL__ */
+
+
+/*
+ * If one client of a QueuePair is a 32bit entity, we restrict the QueuePair
+ * size to be less than 4GB, and use 32bit atomic operations on the head and
+ * tail pointers. 64bit atomic read on a 32bit entity involves cmpxchg8b which
+ * is an atomic read-modify-write. This will cause traces to fire when a 32bit
+ * consumer tries to read the producer's tail pointer, for example, because the
+ * consumer has read-only access to the producer's tail pointer.
+ *
+ * We provide the following macros to invoke 32bit or 64bit atomic operations
+ * based on the architecture the code is being compiled on.
+ */
+
+/* Architecture independent maximum queue size. */
+#define QP_MAX_QUEUE_SIZE_ARCH_ANY  CONST64U(0xffffffff)
+
+#ifdef __x86_64__
+#  define QP_MAX_QUEUE_SIZE_ARCH  CONST64U(0xffffffffffffffff)
+#  define QPAtomic_ReadOffset(x)  Atomic_Read64(x)
+#  define QPAtomic_WriteOffset(x, y) Atomic_Write64(x, y)
+#else
+#  define QP_MAX_QUEUE_SIZE_ARCH  CONST64U(0xffffffff)
+#  define QPAtomic_ReadOffset(x)  Atomic_Read32((Atomic_uint32 *)(x))
+#  define QPAtomic_WriteOffset(x, y) \
+            Atomic_Write32((Atomic_uint32 *)(x), (uint32)(y))
+#endif
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VMCIQueue_CheckAlignment --
+ *
+ *      Checks if the given queue is aligned to page boundary.
+ *
+ * Results:
+ *      TRUE or FALSE.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE Bool
+VMCIQueue_CheckAlignment(const VMCIQueue *queue) // IN:
+{
+   return ((uintptr_t)queue & (PAGE_SIZE - 1)) == 0;
+}
+
+
+static INLINE void
+VMCIQueue_GetPointers(const VMCIQueue *produceQ,
+                      const VMCIQueue *consumeQ,
+                      uint64 *producerTail,
+                      uint64 *consumerHead)
+{
+   *producerTail = QPAtomic_ReadOffset(&produceQ->queueHeader.producerTail);
+   *consumerHead = QPAtomic_ReadOffset(&consumeQ->queueHeader.consumerHead);
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VMCIQueue_ResetPointers --
+ *
+ *      Reset the tail pointer (of "this" queue) and the head pointer (of
+ *      "peer" queue).
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE void
+VMCIQueue_ResetPointers(VMCIQueue *queue) // IN:
+{
+   QPAtomic_WriteOffset(&queue->queueHeader.producerTail, CONST64U(0));
+   QPAtomic_WriteOffset(&queue->queueHeader.consumerHead, CONST64U(0));
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VMCIQueue_Init --
+ *
+ *      Initializes a queue's state (head & tail pointers).
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE void
+VMCIQueue_Init(const VMCIHandle handle, // IN:
+               VMCIQueue *queue)        // IN:
+{
+   ASSERT_NOT_IMPLEMENTED(VMCIQueue_CheckAlignment(queue));
+   queue->queueHeader.handle = handle;
+   VMCIQueue_ResetPointers(queue);
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VMCIQueueFreeSpaceInt --
+ *
+ *      Finds available free space in a produce queue to enqueue more
+ *      data or reports an error if queue pair corruption is detected.
+ *
+ * Results:
+ *      Free space size in bytes.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE int
+VMCIQueueFreeSpaceInt(const VMCIQueue *produceQueue, // IN:
+                      const VMCIQueue *consumeQueue, // IN:
+                      const uint64 produceQSize,     // IN:
+                      uint64 *freeSpace)             // OUT:
+{
+   const uint64 tail =
+      QPAtomic_ReadOffset(&produceQueue->queueHeader.producerTail);
+   const uint64 head =
+      QPAtomic_ReadOffset(&consumeQueue->queueHeader.consumerHead);
+
+   ASSERT(freeSpace);
+
+   if (tail >= produceQSize || head >= produceQSize) {
+      return VMCI_ERROR_INVALID_SIZE;
+   }
+
+   /*
+    * Deduct 1 to avoid tail becoming equal to head which causes ambiguity. If
+    * head and tail are equal it means that the queue is empty.
+    */
+   if (tail >= head) {
+      *freeSpace = produceQSize - (tail - head) - 1;
+   } else {
+      *freeSpace = head - tail - 1;
+   }
+
+   return VMCI_SUCCESS;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VMCIQueue_FreeSpace --
+ *
+ *      Finds available free space in a produce queue to enqueue more data.
+ *
+ * Results:
+ *      On success, free space size in bytes (up to MAX_INT64).
+ *      On failure, appropriate error code.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE int64
+VMCIQueue_FreeSpace(const VMCIQueue *produceQueue, // IN:
+                    const VMCIQueue *consumeQueue, // IN:
+                    const uint64 produceQSize)     // IN:
+{
+   uint64 freeSpace;
+   int retval;
+
+   retval = VMCIQueueFreeSpaceInt(produceQueue, consumeQueue, produceQSize,
+                                  &freeSpace);
+
+   if (retval != VMCI_SUCCESS) {
+      return retval;
+   }
+
+   return MIN(freeSpace, MAX_INT64);
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VMCIQueue_BufReady --
+ *
+ *      Finds available data to dequeue from a consume queue.
+ *
+ * Results:
+ *      On success, available data size in bytes (up to MAX_INT64).
+ *      On failure, appropriate error code.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE int64
+VMCIQueue_BufReady(const VMCIQueue *consumeQueue, // IN:
+                   const VMCIQueue *produceQueue, // IN:
+                   const uint64 consumeQSize)     // IN:
+{
+   int retval;
+   uint64 freeSpace;
+
+   retval = VMCIQueueFreeSpaceInt(consumeQueue, produceQueue,
+                                  consumeQSize, &freeSpace);
+   if (retval != VMCI_SUCCESS) {
+      return retval;
+   } else {
+      uint64 available = consumeQSize - freeSpace - 1;
+      return MIN(available, MAX_INT64);
+   }
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * AddPointer --
+ *
+ *      Helper to add a given offset to a head or tail pointer. Wraps the value
+ *      of the pointer around the max size of the queue.
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE void
+AddPointer(Atomic_uint64 *var, // IN:
+           size_t add,         // IN:
+           uint64 max)         // IN:
+{
+   uint64 newVal = QPAtomic_ReadOffset(var);
+
+   if (newVal >= max - add) {
+      newVal -= max;
+   }
+   newVal += add;
+
+   QPAtomic_WriteOffset(var, newVal);
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * __VMCIQueue_Enqueue --
+ *
+ *      Enqueues a given buffer to the produce queue using the provided
+ *      function. As many bytes as possible (space available in the queue)
+ *      are enqueued.
+ *
+ * Results:
+ *      VMCI_ERROR_QUEUEPAIR_NOSPACE if no space was available to enqueue data.
+ *      VMCI_ERROR_INVALID_SIZE, if any queue pointer is outside the queue 
+ *      (as defined by the queue size).
+ *      Otherwise, the number of bytes written to the queue is returned.
+ *
+ * Side effects:
+ *      Updates the tail pointer of the produce queue.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE ssize_t
+__VMCIQueue_Enqueue(VMCIQueue *produceQueue,               // IN:
+                    const VMCIQueue *consumeQueue,         // IN:
+                    const uint64 produceQSize,             // IN:
+                    const void *buf,                       // IN:
+                    size_t bufSize,                        // IN:
+                    VMCIMemcpyToQueueFunc memcpyToQueue)   // IN:
+{
+   const int64 freeSpace = VMCIQueue_FreeSpace(produceQueue, consumeQueue,
+                                               produceQSize);
+   const uint64 tail =
+      QPAtomic_ReadOffset(&produceQueue->queueHeader.producerTail);
+   size_t written;
+
+   if (!freeSpace) {
+      return VMCI_ERROR_QUEUEPAIR_NOSPACE;
+   }
+   if (freeSpace < 0) {
+      return (ssize_t)freeSpace;
+   }
+
+   written = (size_t)(freeSpace > bufSize ? bufSize : freeSpace);
+   if (LIKELY(tail + written < produceQSize)) {
+      memcpyToQueue(produceQueue, tail, buf, 0, written);
+   } else {
+      /* Tail pointer wraps around. */
+      const size_t tmp = (size_t)(produceQSize - tail);
+
+      memcpyToQueue(produceQueue, tail, buf, 0, tmp);
+      memcpyToQueue(produceQueue, 0, buf, tmp, written - tmp);
+   }
+   AddPointer(&produceQueue->queueHeader.producerTail, written, produceQSize);
+   return written;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VMCIQueue_Enqueue --
+ *
+ *      Enqueues a given buffer to the produce queue. As many bytes as possible
+ *      (space available in the queue) are enqueued. If bufSize is larger than
+ *      the maximum value of ssize_t the result is unspecified.
+ *
+ * Results:
+ *      VMCI_ERROR_QUEUEPAIR_NOSPACE if no space was available to enqueue data.
+ *      VMCI_ERROR_INVALID_SIZE, if any queue pointer is outside the queue 
+ *      (as defined by the queue size).
+ *      Otherwise, the number of bytes written to the queue is returned.
+ *
+ * Side effects:
+ *      Updates the tail pointer of the produce queue.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE ssize_t
+VMCIQueue_Enqueue(VMCIQueue *produceQueue,       // IN:
+                  const VMCIQueue *consumeQueue, // IN:
+                  const uint64 produceQSize,     // IN:
+                  const void *buf,               // IN:
+                  size_t bufSize)                // IN:
+{
+   return __VMCIQueue_Enqueue(produceQueue, consumeQueue, produceQSize,
+                              buf, bufSize, VMCIMemcpyToQueue);
+}
+
+
+#if defined(__linux__) && defined(__KERNEL__)
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VMCIQueue_EnqueueV --
+ *
+ *      Enqueues a given iovec to the produce queue. As many bytes as possible
+ *      (space available in the queue) are enqueued. If bufSize is larger than
+ *      the maximum value of ssize_t the result is unspecified.
+ *
+ * Results:
+ *      VMCI_ERROR_QUEUEPAIR_NOSPACE if no space was available to enqueue data.
+ *      VMCI_ERROR_INVALID_SIZE, if any queue pointer is outside the queue 
+ *      (as defined by the queue size).
+ *      Otherwise, the number of bytes written to the queue is returned.
+ *
+ * Side effects:
+ *      Updates the tail pointer of the produce queue.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE ssize_t
+VMCIQueue_EnqueueV(VMCIQueue *produceQueue,       // IN:
+                   const VMCIQueue *consumeQueue, // IN:
+                   const uint64 produceQSize,     // IN:
+                   struct iovec *iov,             // IN:
+                   size_t iovSize)                // IN:
+{
+   return __VMCIQueue_Enqueue(produceQueue, consumeQueue, produceQSize,
+                              (void *)iov, iovSize, VMCIMemcpyToQueueV);
+}
+#endif
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * __VMCIQueue_Dequeue --
+ *
+ *      Dequeues data (if available) from the given consume queue. Writes data
+ *      to the user provided buffer using the provided function.
+ *
+ * Results:
+ *      VMCI_ERROR_QUEUEPAIR_NODATA if no data was available to dequeue.
+ *      VMCI_ERROR_INVALID_SIZE, if any queue pointer is outside the queue 
+ *      (as defined by the queue size).
+ *      Otherwise the number of bytes dequeued is returned.
+ *
+ * Side effects:
+ *      Updates the head pointer of the consume queue.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE ssize_t
+__VMCIQueue_Dequeue(VMCIQueue *produceQueue,                    // IN:
+                    const VMCIQueue *consumeQueue,              // IN:
+                    const uint64 consumeQSize,                  // IN:
+                    void *buf,                                  // IN:
+                    size_t bufSize,                             // IN:
+                    VMCIMemcpyFromQueueFunc memcpyFromQueue)    // IN:
+{
+   const int64 bufReady = VMCIQueue_BufReady(consumeQueue, produceQueue,
+                                             consumeQSize);
+   const uint64 head =
+      QPAtomic_ReadOffset(&produceQueue->queueHeader.consumerHead);
+   size_t written;
+
+   if (!bufReady) {
+      return VMCI_ERROR_QUEUEPAIR_NODATA;
+   }
+   if (bufReady < 0) {
+      return (ssize_t)bufReady;
+   }
+
+   written = (size_t)(bufReady > bufSize ? bufSize : bufReady);
+   if (LIKELY(head + written < consumeQSize)) {
+      memcpyFromQueue(buf, 0, consumeQueue, head, written);
+   } else {
+      /* Head pointer wraps around. */
+      const size_t tmp = (size_t)(consumeQSize - head);
+
+      memcpyFromQueue(buf, 0, consumeQueue, head, tmp);
+      memcpyFromQueue(buf, tmp, consumeQueue, 0, written - tmp);
+   }
+   AddPointer(&produceQueue->queueHeader.consumerHead, written, consumeQSize);
+   return written;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VMCIQueue_Dequeue --
+ *
+ *      Dequeues data (if available) from the given consume queue. Writes data
+ *      to the user provided buffer. If bufSize is larger than the maximum
+ *      value of ssize_t the result is unspecified.
+ *
+ * Results:
+ *      VMCI_ERROR_QUEUEPAIR_NODATA if no data was available to dequeue.
+ *      VMCI_ERROR_INVALID_SIZE, if any queue pointer is outside the queue 
+ *      (as defined by the queue size).
+ *      Otherwise the number of bytes dequeued is returned.
+ *
+ * Side effects:
+ *      Updates the head pointer of the consume queue.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE ssize_t
+VMCIQueue_Dequeue(VMCIQueue *produceQueue,       // IN:
+                  const VMCIQueue *consumeQueue, // IN:
+                  const uint64 consumeQSize,     // IN:
+                  void *buf,                     // IN:
+                  size_t bufSize)                // IN:
+{
+   return __VMCIQueue_Dequeue(produceQueue, consumeQueue, consumeQSize,
+                              buf, bufSize, VMCIMemcpyFromQueue);
+}
+
+
+#if defined(__linux__) && defined(__KERNEL__)
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VMCIQueue_DequeueV --
+ *
+ *      Dequeues data (if available) from the given consume queue. Writes data
+ *      to the user provided iovec. If bufSize is larger than the maximum
+ *      value of ssize_t the result is unspecified.
+ *
+ * Results:
+ *      VMCI_ERROR_QUEUEPAIR_NODATA if no data was available to dequeue.
+ *      VMCI_ERROR_INVALID_SIZE, if any queue pointer is outside the queue 
+ *      (as defined by the queue size).
+ *      Otherwise the number of bytes dequeued is returned.
+ *
+ * Side effects:
+ *      Updates the head pointer of the consume queue.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE ssize_t
+VMCIQueue_DequeueV(VMCIQueue *produceQueue,       // IN:
+                   const VMCIQueue *consumeQueue, // IN:
+                   const uint64 consumeQSize,     // IN:
+                   struct iovec *iov,             // IN:
+                   size_t iovSize)                // IN:
+{
+   return __VMCIQueue_Dequeue(produceQueue, consumeQueue, consumeQSize,
+                              (void *)iov, iovSize, VMCIMemcpyFromQueueV);
+}
+#endif
+
+#endif /* !_VMCI_QUEUE_PAIR_H_ */
--- kernel/linux-2.6.26.3/drivers/misc/vmci/vmciQueuePairInt.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmci/vmciQueuePairInt.h	2008-09-03 10:01:42.000000000 -0500
@@ -0,0 +1,34 @@
+/*********************************************************
+ * Copyright (C) 2007 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * vmciQueuePairInt.h --
+ *
+ *     Helper function declarations for VMCI QueuePair API.
+ */
+
+#ifndef _VMCI_QUEUE_PAIR_INT_H_
+#define _VMCI_QUEUE_PAIR_INT_H_
+
+#include "vmci_queue_pair.h"
+#include "vmciGuestKernelAPI.h"
+
+void VMCIQueuePair_Init(void);
+void VMCIQueuePair_Exit(void);
+
+#endif /* !_VMCI_QUEUE_PAIR_INT_H_ */
--- kernel/linux-2.6.26.3/drivers/misc/vmci/vmciUtil.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmci/vmciUtil.c	2008-09-03 10:01:42.000000000 -0500
@@ -0,0 +1,538 @@
+/*********************************************************
+ * Copyright (C) 2006 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * vmciUtil.c
+ *
+ * Small utility function for allocating kernel memory and copying data.
+ *
+ */
+
+#ifdef __linux__
+#  include "driver-config.h"
+
+#  define EXPORT_SYMTAB
+
+#  include <linux/module.h>
+#  include <linux/module.h>
+#  include "compat_kernel.h"
+#  include "compat_slab.h"
+#  include "compat_wait.h"
+#  include "compat_interrupt.h"
+#elif defined(_WIN32)
+#  ifndef WINNT_DDK
+#     error  This file only works with the NT ddk 
+#  endif // WINNT_DDK
+#  include <ntddk.h>
+#elif defined(SOLARIS)
+#  include <sys/ddi.h>
+#  include <sys/sunddi.h>
+#  include <sys/disp.h>
+#else 
+#error "platform not supported."
+#endif //linux
+
+#define LGPFX "VMCIUtil: "
+
+#include "vmware.h"
+#include "vm_atomic.h"
+#include "vmci_defs.h"
+#include "vmci_kernel_if.h"
+#include "vmciGuestKernelIf.h"
+#include "vmciInt.h"
+#include "vmciProcess.h"
+#include "vmciDatagram.h"
+#include "vmciUtil.h"
+#include "vmciEvent.h"
+
+static void VMCIUtilCidUpdate(VMCIId subID, VMCI_EventData *eventData,
+                              void *clientData);
+
+static VMCIId ctxUpdateSubID = VMCI_INVALID_ID;
+static Atomic_uint32 vmContextID = { VMCI_INVALID_ID };
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VMCIUtil_Init --
+ *
+ *      Subscribe to context id update event.
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+void
+VMCIUtil_Init(void)
+{
+   /* 
+    * We subscribe to the VMCI_EVENT_CTX_ID_UPDATE here so we can update the
+    * internal context id when needed.
+    */
+   if (VMCIEvent_Subscribe(VMCI_EVENT_CTX_ID_UPDATE, VMCIUtilCidUpdate, NULL,
+                           &ctxUpdateSubID) < VMCI_SUCCESS) {
+      VMCI_LOG(("VMCIUtil: Failed to subscribe to event %d.\n", 
+                VMCI_EVENT_CTX_ID_UPDATE));
+   }
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VMCIUtil_Exit --
+ *
+ *      Cleanup 
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+void
+VMCIUtil_Exit(void)
+{
+   if (VMCIEvent_Unsubscribe(ctxUpdateSubID) < VMCI_SUCCESS) {
+      VMCI_LOG(("VMCIUtil: Failed to unsubscribe to event %d with subscriber "
+                "id %d.\n", VMCI_EVENT_CTX_ID_UPDATE, ctxUpdateSubID));
+   }
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VMCIUtilCidUpdate --
+ *
+ *      Gets called with the new context id if updated or resumed.
+ *
+ * Results:
+ *      Context id.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static void
+VMCIUtilCidUpdate(VMCIId subID,               // IN:
+                  VMCI_EventData *eventData,  // IN:
+                  void *clientData)           // IN:
+{
+   VMCIEventPayload_Context *evPayload = VMCIEventDataPayload(eventData);
+
+   if (subID != ctxUpdateSubID) {
+      VMCI_LOG(("VMCIUtil: Invalid subscriber id. %d.\n", subID));
+      return;
+   }
+   if (eventData == NULL || evPayload->contextID == VMCI_INVALID_ID) {
+      VMCI_LOG(("VMCIUtil: Invalid event data.\n"));
+      return;
+   }
+   VMCI_LOG(("VMCIUtil: Updating context id from 0x%x to 0x%x on event %d.\n",
+             Atomic_Read(&vmContextID),
+             evPayload->contextID,
+             eventData->event));
+   Atomic_Write(&vmContextID, evPayload->contextID);
+}
+
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VMCIUtil_CheckHostCapabilities --
+ *
+ *      Verify that the host supports the hypercalls we need. If it does not,
+ *      try to find fallback hypercalls and use those instead.
+ *
+ * Results:
+ *      TRUE if required hypercalls (or fallback hypercalls) are
+ *      supported by the host, FALSE otherwise.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+#define VMCI_UTIL_NUM_RESOURCES 1
+
+Bool
+VMCIUtil_CheckHostCapabilities(void)
+{
+   int result;
+   VMCIResourcesQueryMsg *msg;
+   uint32 msgSize = sizeof(VMCIResourcesQueryHdr) + 
+      VMCI_UTIL_NUM_RESOURCES * sizeof(VMCI_Resource);
+   VMCIDatagram *checkMsg = VMCI_AllocKernelMem(msgSize, VMCI_MEMORY_NONPAGED);
+
+   if (checkMsg == NULL) {
+      VMCI_LOG((LGPFX"Check host: Insufficient memory.\n"));
+      return FALSE;
+   }
+
+   checkMsg->dst = VMCI_MAKE_HANDLE(VMCI_HYPERVISOR_CONTEXT_ID, 
+                                    VMCI_RESOURCES_QUERY);
+   checkMsg->src = VMCI_ANON_SRC_HANDLE;
+   checkMsg->payloadSize = msgSize - VMCI_DG_HEADERSIZE;
+   msg = (VMCIResourcesQueryMsg *)VMCI_DG_PAYLOAD(checkMsg);
+
+   msg->numResources = VMCI_UTIL_NUM_RESOURCES;
+   msg->resources[0] = VMCI_GET_CONTEXT_ID;
+
+   result = VMCI_SendDatagram(checkMsg);
+   VMCI_FreeKernelMem(checkMsg, msgSize);
+
+   /* We need the vector. There are no fallbacks. */
+   return (result == 0x1);
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VMCI_GetContextID --
+ *
+ *      Returns the context id. 
+ *
+ * Results:
+ *      Context id.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+#ifdef __linux__
+EXPORT_SYMBOL(VMCI_GetContextID);
+#endif
+
+VMCIId
+VMCI_GetContextID(void)
+{
+   if (Atomic_Read(&vmContextID) == VMCI_INVALID_ID) {
+      uint32 result;
+      VMCIDatagram getCidMsg;
+      getCidMsg.dst =  VMCI_MAKE_HANDLE(VMCI_HYPERVISOR_CONTEXT_ID,
+                                        VMCI_GET_CONTEXT_ID);
+      getCidMsg.src = VMCI_ANON_SRC_HANDLE;
+      getCidMsg.payloadSize = 0;
+      result = VMCI_SendDatagram(&getCidMsg);
+      Atomic_Write(&vmContextID, result);
+   }
+   return Atomic_Read(&vmContextID);
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VMCI_CheckHostCapabilities --
+ *
+ *      Tell host which guestcalls we support and let each API check
+ *      that the host supports the hypercalls it needs. If a hypercall
+ *      is not supported, the API can check for a fallback hypercall,
+ *      or fail the check.
+ *
+ * Results:
+ *      TRUE if successful, FALSE otherwise.
+ *
+ * Side effects:
+ *      Fallback mechanisms may be enabled in the API and vmmon.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+Bool
+VMCI_CheckHostCapabilities(void)
+{
+   Bool result = VMCIEvent_CheckHostCapabilities();
+   result &= VMCIProcess_CheckHostCapabilities();
+   result &= VMCIDatagram_CheckHostCapabilities();
+   result &= VMCIUtil_CheckHostCapabilities();
+
+   VMCI_LOG((LGPFX"Host capability check: %s\n", result ? "PASSED" : "FAILED"));
+
+   return result;
+}
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * VMCI_Version --
+ *
+ *     Returns the version of the VMCI guest driver.
+ *
+ * Results: 
+ *      Returns a version number.
+ *
+ * Side effects:
+ *      None.
+ *
+ *----------------------------------------------------------------------
+ */
+
+#ifdef __linux__
+EXPORT_SYMBOL(VMCI_Version);
+#endif
+
+uint32
+VMCI_Version()
+{
+   return VMCI_VERSION_NUMBER;
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * VMCI_InInterrupt --
+ *
+ *     Determines if we are running in tasklet/dispatch level or above.
+ *
+ * Results: 
+ *      TRUE if tasklet/dispatch or above, FALSE otherwise.
+ *
+ * Side effects:
+ *      None.
+ *
+ *----------------------------------------------------------------------
+ */
+
+Bool
+VMCI_InInterrupt()
+{
+#if defined(_WIN32)
+   return KeGetCurrentIrql() >= DISPATCH_LEVEL;
+#elif defined(__linux__)
+   return in_interrupt();
+#elif defined(SOLARIS)
+   return servicing_interrupt();   /* servicing_interrupt is not part of DDI. */
+#endif //
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * VMCI_DeviceGet --
+ *
+ *      Verifies that a valid VMCI device is present, and indicates
+ *      the callers intention to use the device until it calls
+ *      VMCI_DeviceRelease().
+ *
+ * Results: 
+ *      TRUE if a valid VMCI device is present, FALSE otherwise.
+ *
+ * Side effects:
+ *      None.
+ *
+ *----------------------------------------------------------------------
+ */
+
+#ifdef __linux__
+EXPORT_SYMBOL(VMCI_DeviceGet);
+#endif
+
+Bool
+VMCI_DeviceGet(void)
+{
+   return VMCI_DeviceEnabled();
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * VMCI_DeviceRelease --
+ *
+ *      Indicates that the caller is done using the VMCI device.
+ *
+ * Results: 
+ *      None.
+ *
+ * Side effects:
+ *      None.
+ *
+ *----------------------------------------------------------------------
+ */
+
+#ifdef __linux__
+EXPORT_SYMBOL(VMCI_DeviceRelease);
+#endif
+
+void
+VMCI_DeviceRelease(void)
+{
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * VMCI_ReadDatagramsFromPort --
+ *
+ *      Reads datagrams from the data in port and dispatches them. We
+ *      always start reading datagrams into only the first page of the
+ *      datagram buffer. If the datagrams don't fit into one page, we
+ *      use the maximum datagram buffer size for the remainder of the
+ *      invocation. This is a simple heuristic for not penalizing
+ *      small datagrams.
+ *
+ *      This function assumes that it has exclusive access to the data
+ *      in port for the duration of the call.
+ *
+ * Results:
+ *      No result.
+ *
+ * Side effects:
+ *      Datagram handlers may be invoked.
+ *
+ *----------------------------------------------------------------------
+ */
+
+void
+VMCI_ReadDatagramsFromPort(VMCIIoHandle ioHandle,  // IN
+                           VMCIIoPort dgInPort,    // IN
+                           uint8 *dgInBuffer,      // IN
+                           size_t dgInBufferSize)  // IN
+{
+   VMCIDatagram *dg;
+   size_t currentDgInBufferSize = PAGE_SIZE;
+   size_t remainingBytes;
+
+   ASSERT(dgInBufferSize >= PAGE_SIZE);
+
+   VMCI_ReadPortBytes(ioHandle, dgInPort, dgInBuffer, currentDgInBufferSize);
+   dg = (VMCIDatagram *)dgInBuffer; 
+   remainingBytes = currentDgInBufferSize;
+   
+   while (dg->dst.resource != VMCI_ERROR_INVALID_RESOURCE || remainingBytes > PAGE_SIZE) {
+      unsigned dgInSize;
+      
+      /*
+       * When the input buffer spans multiple pages, a datagram can
+       * start on any page boundary in the buffer. 
+       */
+
+      if (dg->dst.resource == VMCI_ERROR_INVALID_RESOURCE) {
+         ASSERT(remainingBytes > PAGE_SIZE);
+         dg = (VMCIDatagram *)ROUNDUP((uintptr_t)dg + 1, PAGE_SIZE);
+         ASSERT((uint8 *)dg < dgInBuffer + currentDgInBufferSize);
+         remainingBytes = (size_t)(dgInBuffer + currentDgInBufferSize - (uint8 *)dg);
+         continue;
+      }
+
+      dgInSize = VMCI_DG_SIZE_ALIGNED(dg);
+      
+      if (dgInSize <= dgInBufferSize) {
+         int result;
+
+         /*
+          * If the remaining bytes in the datagram buffer doesn't
+          * contain the complete datagram, we first make sure we have
+          * enough room for it and then we read the reminder of the
+          * datagram and possibly any following datagrams.
+          */
+ 
+         if (dgInSize > remainingBytes) {
+
+            if (remainingBytes != currentDgInBufferSize) {
+
+               /*
+                * We move the partial datagram to the front and read
+                * the reminder of the datagram and possibly following
+                * calls into the following bytes.
+                */
+       
+               memmove(dgInBuffer, dgInBuffer + currentDgInBufferSize - remainingBytes,
+                       remainingBytes);
+
+               dg = (VMCIDatagram *)dgInBuffer; 
+            }
+
+            if (currentDgInBufferSize != dgInBufferSize) {
+               currentDgInBufferSize = dgInBufferSize;
+            }
+
+            VMCI_ReadPortBytes(ioHandle, dgInPort, dgInBuffer + remainingBytes,
+                               currentDgInBufferSize - remainingBytes);
+         }
+         
+         /* We special case event datagrams from the hypervisor. */
+         if (dg->src.context == VMCI_HYPERVISOR_CONTEXT_ID && 
+             dg->dst.resource == VMCI_EVENT_HANDLER) {
+            result = VMCIEvent_Dispatch(dg);
+         } else {
+            result = VMCIDatagram_Dispatch(dg->src.context, dg);
+         }
+         if (result < VMCI_SUCCESS) {
+            VMCI_LOG(("Datagram with resource %d failed with err %x.\n",
+                      dg->dst.resource, result));
+         }
+         
+         /* On to the next datagram. */
+         dg = (VMCIDatagram *)((uint8 *)dg + dgInSize);
+      } else {
+         size_t bytesToSkip;
+         
+         /*
+          * Datagram doesn't fit in datagram buffer of maximal size. We drop it.
+          */
+
+         VMCI_LOG(("Failed to receive datagram of size %u.\n",
+                   dgInSize));
+         
+         bytesToSkip = dgInSize - remainingBytes;
+         if (currentDgInBufferSize != dgInBufferSize) {
+            currentDgInBufferSize = dgInBufferSize;
+         }
+         for (;;) {
+            VMCI_ReadPortBytes(ioHandle, dgInPort, dgInBuffer, currentDgInBufferSize);
+            if (bytesToSkip <= currentDgInBufferSize) {
+               break;
+            }
+            bytesToSkip -= currentDgInBufferSize;
+         }
+         dg = (VMCIDatagram *)(dgInBuffer + bytesToSkip);
+      }
+      
+      remainingBytes = (size_t) (dgInBuffer + currentDgInBufferSize - (uint8 *)dg);
+      
+      if (remainingBytes < VMCI_DG_HEADERSIZE) {
+         /* Get the next batch of datagrams. */
+         
+         VMCI_ReadPortBytes(ioHandle, dgInPort, dgInBuffer, currentDgInBufferSize);
+         dg = (VMCIDatagram *)dgInBuffer;
+         remainingBytes = currentDgInBufferSize;
+      }
+   }
+}
--- kernel/linux-2.6.26.3/drivers/misc/vmci/vmciUtil.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmci/vmciUtil.h	2008-09-03 10:01:42.000000000 -0500
@@ -0,0 +1,53 @@
+/*********************************************************
+ * Copyright (C) 2006 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/* 
+ * vmciUtil.h --
+ *
+ *      Helper functions.
+ */
+
+#ifndef __VMCI_UTIL_H__
+#define __VMCI_UTIL_H__
+
+#define INCLUDE_ALLOW_MODULE
+#include "includeCheck.h"
+
+#include "vmciGuestKernelIf.h"
+#include "vmci_infrastructure.h"
+#include "vmciGuestKernelAPI.h"
+
+#define VMCI_MAJOR_VERSION_NUMBER   1
+#define VMCI_MINOR_VERSION_NUMBER   0
+#define VMCI_VERSION_NUMBER         \
+         ((VMCI_MAJOR_VERSION_NUMBER << 16) | (VMCI_MINOR_VERSION_NUMBER))
+
+typedef struct VMCIGuestDeviceHandle {
+   void *obj;
+   VMCIObjType objType;
+} VMCIGuestDeviceHandle;
+
+void VMCIUtil_Init(void);
+void VMCIUtil_Exit(void);
+Bool VMCIUtil_CheckHostCapabilities(void);
+Bool VMCI_CheckHostCapabilities(void);
+Bool VMCI_InInterrupt(void);
+void VMCI_ReadDatagramsFromPort(VMCIIoHandle ioHandle, VMCIIoPort dgInPort,
+				uint8 *dgInBuffer, size_t dgInBufferSize);
+
+#endif //__VMCI_UTIL_H__
--- kernel/linux-2.6.26.3/drivers/misc/vmci/vmci_version.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmci/vmci_version.h	2008-09-03 10:01:42.000000000 -0500
@@ -0,0 +1,32 @@
+/*********************************************************
+ * Copyright (C) 2007 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * vmci_version.h --
+ *
+ * Version definitions for the Linux vmci driver.
+ */
+
+#ifndef _VMCI_VERSION_H_
+#define _VMCI_VERSION_H_
+
+#define VMCI_DRIVER_VERSION          1.0.14.0
+#define VMCI_DRIVER_VERSION_COMMAS   1,0,14,0
+#define VMCI_DRIVER_VERSION_STRING   "1.0.14.0"
+
+#endif /* _VMCI_VERSION_H_ */
--- kernel/linux-2.6.26.3/drivers/misc/vmci/vm_device_version.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmci/vm_device_version.h	2008-09-03 10:01:42.000000000 -0500
@@ -0,0 +1,186 @@
+/*********************************************************
+ * Copyright (C) 1998 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef VM_DEVICE_VERSION_H
+#define VM_DEVICE_VERSION_H
+
+#define INCLUDE_ALLOW_USERLEVEL
+#define INCLUDE_ALLOW_VMMEXT
+#define INCLUDE_ALLOW_MODULE
+#define INCLUDE_ALLOW_VMKERNEL
+#define INCLUDE_ALLOW_VMCORE
+#include "includeCheck.h"
+
+#ifdef _WIN32
+#include "guiddef.h"
+#endif
+
+/* Our own PCI IDs
+ *    VMware SVGA II (Unified VGA)
+ *    VMware SVGA (PCI Accelerator)
+ *    VMware vmxnet (Idealized NIC)
+ *    VMware vmxscsi (Abortive idealized SCSI controller)
+ *    VMware chipset (Subsystem ID for our motherboards)
+ *    VMware e1000 (Subsystem ID)
+ *    VMware vmxnet3 (Uniform Pass Through NIC)
+ */
+#define PCI_VENDOR_ID_VMWARE            0x15AD
+#define PCI_DEVICE_ID_VMWARE_SVGA2      0x0405
+#define PCI_DEVICE_ID_VMWARE_SVGA       0x0710
+#define PCI_DEVICE_ID_VMWARE_NET        0x0720
+#define PCI_DEVICE_ID_VMWARE_SCSI       0x0730
+#define PCI_DEVICE_ID_VMWARE_VMCI       0x0740
+#define PCI_DEVICE_ID_VMWARE_CHIPSET    0x1976
+#define PCI_DEVICE_ID_VMWARE_82545EM    0x0750 /* single port */
+#define PCI_DEVICE_ID_VMWARE_82546EB    0x0760 /* dual port   */
+#define PCI_DEVICE_ID_VMWARE_EHCI       0x0770
+#define PCI_DEVICE_ID_VMWARE_1394       0x0780
+#define PCI_DEVICE_ID_VMWARE_BRIDGE     0x0790
+#define PCI_DEVICE_ID_VMWARE_ROOTPORT   0x07A0
+#define PCI_DEVICE_ID_VMWARE_VMXNET3    0x07B0
+#define PCI_DEVICE_ID_VMWARE_PVSCSI     0x07C0
+
+/* The hypervisor device might grow.  Please leave room
+ * for 7 more subfunctions.
+ */
+#define PCI_DEVICE_ID_VMWARE_HYPER      0x0800
+#define PCI_DEVICE_ID_VMWARE_VMI        0x0801
+
+#define PCI_DEVICE_VMI_CLASS            0x05
+#define PCI_DEVICE_VMI_SUBCLASS         0x80
+#define PCI_DEVICE_VMI_INTERFACE        0x00
+#define PCI_DEVICE_VMI_REVISION         0x01
+
+/* From linux/pci_ids.h:
+ *   AMD Lance Ethernet controller
+ *   BusLogic SCSI controller
+ *   Ensoniq ES1371 sound controller
+ */
+#define PCI_VENDOR_ID_AMD               0x1022
+#define PCI_DEVICE_ID_AMD_VLANCE        0x2000
+#define PCI_VENDOR_ID_BUSLOGIC			0x104B
+#define PCI_DEVICE_ID_BUSLOGIC_MULTIMASTER_NC	0x0140
+#define PCI_DEVICE_ID_BUSLOGIC_MULTIMASTER	0x1040
+#define PCI_VENDOR_ID_ENSONIQ           0x1274
+#define PCI_DEVICE_ID_ENSONIQ_ES1371    0x1371
+
+/* From linux/pci_ids.h:
+ *    Intel 82439TX (430 HX North Bridge)
+ *    Intel 82371AB (PIIX4 South Bridge)
+ *    Intel 82443BX (440 BX North Bridge and AGP Bridge)
+ *    Intel 82545EM (e1000, server adapter, single port)
+ *    Intel 82546EB (e1000, server adapter, dual port)
+ */
+#define PCI_VENDOR_ID_INTEL             0x8086
+#define PCI_DEVICE_ID_INTEL_82439TX     0x7100
+#define PCI_DEVICE_ID_INTEL_82371AB_0   0x7110
+#define PCI_DEVICE_ID_INTEL_82371AB_2   0x7112
+#define PCI_DEVICE_ID_INTEL_82371AB_3   0x7113
+#define PCI_DEVICE_ID_INTEL_82371AB     0x7111
+#define PCI_DEVICE_ID_INTEL_82443BX     0x7190
+#define PCI_DEVICE_ID_INTEL_82443BX_1   0x7191
+#define PCI_DEVICE_ID_INTEL_82443BX_2   0x7192 /* Used when no AGP support */
+#define PCI_DEVICE_ID_INTEL_82545EM     0x100f
+#define PCI_DEVICE_ID_INTEL_82546EB     0x1010
+
+
+/************* Strings for IDE Identity Fields **************************/
+#define VIDE_ID_SERIAL_STR	"00000000000000000001"	/* Must be 20 Bytes */
+#define VIDE_ID_FIRMWARE_STR	"00000001"		/* Must be 8 Bytes */
+
+/* No longer than 40 Bytes */
+#define VIDE_ATA_MODEL_STR PRODUCT_GENERIC_NAME " Virtual IDE Hard Drive"
+#define VIDE_ATAPI_MODEL_STR PRODUCT_GENERIC_NAME " Virtual IDE CDROM Drive"
+
+#define ATAPI_VENDOR_ID	"NECVMWar"		/* Must be 8 Bytes */
+#define ATAPI_PRODUCT_ID PRODUCT_GENERIC_NAME " IDE CDROM"	/* Must be 16 Bytes */
+#define ATAPI_REV_LEVEL	"1.00"			/* Must be 4 Bytes */
+
+#define IDE_NUM_INTERFACES   2	/* support for two interfaces */
+#define IDE_DRIVES_PER_IF    2
+
+/************* Strings for SCSI Identity Fields **************************/
+#define SCSI_DISK_MODEL_STR PRODUCT_GENERIC_NAME " Virtual SCSI Hard Drive"
+#define SCSI_DISK_VENDOR_NAME COMPANY_NAME
+#define SCSI_DISK_REV_LEVEL "1.0"
+#define SCSI_CDROM_MODEL_STR PRODUCT_GENERIC_NAME " Virtual SCSI CDROM Drive"
+#define SCSI_CDROM_VENDOR_NAME COMPANY_NAME
+#define SCSI_CDROM_REV_LEVEL "1.0"
+
+/************* SCSI implementation limits ********************************/
+#define SCSI_MAX_CONTROLLERS	 4	  // Need more than 1 for MSCS clustering
+#define	SCSI_MAX_DEVICES	 16	  // BT-958 emulates only 16
+#define SCSI_IDE_CHANNEL         SCSI_MAX_CONTROLLERS
+#define SCSI_IDE_HOSTED_CHANNEL  (SCSI_MAX_CONTROLLERS + 1)
+#define SCSI_MAX_CHANNELS        (SCSI_MAX_CONTROLLERS + 2)
+
+/************* Strings for the VESA BIOS Identity Fields *****************/
+#define VBE_OEM_STRING COMPANY_NAME " SVGA"
+#define VBE_VENDOR_NAME COMPANY_NAME
+#define VBE_PRODUCT_NAME PRODUCT_GENERIC_NAME
+
+/************* PCI implementation limits ********************************/
+#define PCI_MAX_BRIDGES         15
+
+/************* Ethernet implementation limits ***************************/
+#define MAX_ETHERNET_CARDS      10
+
+/************* PCI Passthrough implementation limits ********************/
+#define MAX_PCI_PASSTHRU_DEVICES 2
+
+/************* USB implementation limits ********************************/
+#define MAX_USB_DEVICES_PER_HOST_CONTROLLER 127
+
+/************* Strings for Host USB Driver *******************************/
+
+#ifdef _WIN32
+
+/*
+ * Globally unique ID for the VMware device interface. Define INITGUID before including
+ * this header file to instantiate the variable.
+ */
+DEFINE_GUID(GUID_DEVICE_INTERFACE_VMWARE_USB_DEVICES, 
+0x2da1fe75, 0xaab3, 0x4d2c, 0xac, 0xdf, 0x39, 0x8, 0x8c, 0xad, 0xa6, 0x65);
+
+/*
+ * Globally unique ID for the VMware device setup class.
+ */
+DEFINE_GUID(GUID_CLASS_VMWARE_USB_DEVICES, 
+0x3b3e62a5, 0x3556, 0x4d7e, 0xad, 0xad, 0xf5, 0xfa, 0x3a, 0x71, 0x2b, 0x56);
+
+/*
+ * This string defines the device ID string of a VMware USB device.
+ * The format is USB\Vid_XXXX&Pid_YYYY, where XXXX and YYYY are the
+ * hexadecimal representations of the vendor and product ids, respectively.
+ *
+ * The official vendor ID for VMware, Inc. is 0x0E0F.
+ * The product id for USB generic devices is 0x0001.
+ */
+#define USB_VMWARE_DEVICE_ID_WIDE L"USB\\Vid_0E0F&Pid_0001"
+#define USB_DEVICE_ID_LENGTH (sizeof(USB_VMWARE_DEVICE_ID_WIDE) / sizeof(WCHAR))
+
+#ifdef UNICODE
+#define USB_PNP_SETUP_CLASS_NAME L"VMwareUSBDevices"
+#define USB_PNP_DRIVER_NAME L"vmusb"
+#else
+#define USB_PNP_SETUP_CLASS_NAME "VMwareUSBDevices"
+#define USB_PNP_DRIVER_NAME "vmusb"
+#endif
+#endif
+
+#endif /* VM_DEVICE_VERSION_H */
--- kernel/linux-2.6.26.3/drivers/misc/vmci/vmware.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmci/vmware.h	2008-09-03 10:01:42.000000000 -0500
@@ -0,0 +1,58 @@
+/*********************************************************
+ * Copyright (C) 2003 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * vmware.h --
+ *
+ *	Standard include file for VMware source code.
+ */
+
+#ifndef _VMWARE_H_
+#define _VMWARE_H_
+
+#define INCLUDE_ALLOW_USERLEVEL
+#define INCLUDE_ALLOW_VMCORE
+#define INCLUDE_ALLOW_MODULE
+#define INCLUDE_ALLOW_VMMON
+#define INCLUDE_ALLOW_VMNIXMOD
+#define INCLUDE_ALLOW_VMKERNEL
+#define INCLUDE_ALLOW_VMK_MODULE
+#define INCLUDE_ALLOW_DISTRIBUTE
+#include "includeCheck.h"
+
+#include "vm_basic_types.h"
+#include "vm_basic_defs.h"
+#include "vm_assert.h"
+
+/*
+ * Global error codes. Currently used internally, but may be exported
+ * to customers one day, like VM_E_XXX in vmcontrol_constants.h
+ */
+
+typedef enum VMwareStatus {
+   VMWARE_STATUS_SUCCESS,  /* success */
+   VMWARE_STATUS_ERROR,    /* generic error */
+   VMWARE_STATUS_NOMEM,    /* generic memory allocation error */
+   VMWARE_STATUS_INSUFFICIENT_RESOURCES, /* internal or system resource limit exceeded */
+   VMWARE_STATUS_INVALID_ARGS  /* invalid arguments */
+} VMwareStatus;
+
+#define VMWARE_SUCCESS(s) ((s) == VMWARE_STATUS_SUCCESS)
+
+
+#endif // ifndef _VMWARE_H_
--- kernel/linux-2.6.26.3/drivers/misc/vmci/vmware_pack_begin.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmci/vmware_pack_begin.h	2008-09-03 10:01:42.000000000 -0500
@@ -0,0 +1,43 @@
+/*********************************************************
+ * Copyright (C) 2002 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * vmware_pack_begin.h --
+ *
+ *    Begin of structure packing. See vmware_pack_init.h for details.
+ *
+ *    Note that we do not use the following construct in this include file,
+ *    because we want to emit the code every time the file is included --hpreg
+ *
+ *    #ifndef foo
+ *    #   define foo
+ *    ...
+ *    #endif
+ *
+ */
+
+
+#include "vmware_pack_init.h"
+
+
+#ifdef _MSC_VER
+#   pragma pack(push, 1)
+#elif __GNUC__
+#else
+#   error Compiler packing...
+#endif
--- kernel/linux-2.6.26.3/drivers/misc/vmci/vmware_pack_end.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmci/vmware_pack_end.h	2008-09-03 10:01:42.000000000 -0500
@@ -0,0 +1,44 @@
+/*********************************************************
+ * Copyright (C) 2002 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * vmware_pack_end.h --
+ *
+ *    End of structure packing. See vmware_pack_init.h for details.
+ *
+ *    Note that we do not use the following construct in this include file,
+ *    because we want to emit the code every time the file is included --hpreg
+ *
+ *    #ifndef foo
+ *    #   define foo
+ *    ...
+ *    #endif
+ *
+ */
+
+
+#include "vmware_pack_init.h"
+
+
+#ifdef _MSC_VER
+#   pragma pack(pop)
+#elif __GNUC__
+__attribute__((__packed__))
+#else
+#   error Compiler packing...
+#endif
--- kernel/linux-2.6.26.3/drivers/misc/vmci/vmware_pack_init.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmci/vmware_pack_init.h	2008-09-03 10:01:42.000000000 -0500
@@ -0,0 +1,65 @@
+/*********************************************************
+ * Copyright (C) 2002 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __VMWARE_PACK_INIT_H__
+#   define __VMWARE_PACK_INIT_H__
+
+
+/*
+ * vmware_pack_init.h --
+ *
+ *    Platform-independent code to make the compiler pack (i.e. have them
+ *    occupy the smallest possible space) structure definitions. The following
+ *    constructs are known to work --hpreg
+ *
+ *    #include "vmware_pack_begin.h"
+ *    struct foo {
+ *       ...
+ *    }
+ *    #include "vmware_pack_end.h"
+ *    ;
+ *
+ *    typedef
+ *    #include "vmware_pack_begin.h"
+ *    struct foo {
+ *       ...
+ *    }
+ *    #include "vmware_pack_end.h"
+ *    foo;
+ */
+
+
+#ifdef _MSC_VER
+/*
+ * MSVC 6.0 emits warning 4103 when the pack push and pop pragma pairing is
+ * not balanced within 1 included file. That is annoying because our scheme
+ * is based on the pairing being balanced between 2 included files.
+ *
+ * So we disable this warning, but this is safe because the compiler will also
+ * emit warning 4161 when there is more pops than pushes within 1 main
+ * file --hpreg
+ */
+
+#   pragma warning(disable:4103)
+#elif __GNUC__
+#else
+#   error Compiler packing...
+#endif
+
+
+#endif /* __VMWARE_PACK_INIT_H__ */
--- kernel/linux-2.6.26.3/drivers/misc/vmmemctl/backdoor_balloon.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmmemctl/backdoor_balloon.h	2008-09-03 10:02:10.000000000 -0500
@@ -0,0 +1,39 @@
+/*********************************************************
+ * Copyright (C) 2007 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * backdoor_balloon.h --
+ *
+ *    This file provides a wrapper for using the more generic backdoor library
+ *    together with the vmballoon-specific backdoor.
+ */
+
+#ifndef _BACKDOOR_BALLOON_H_
+#define _BACKDOOR_BALLOON_H_
+
+#include "backdoor.h"
+#include "balloon_def.h"
+
+static INLINE
+void Backdoor_Balloon(Backdoor_proto *myBp) {
+   myBp->in.ax.word = BALLOON_BDOOR_MAGIC;
+   myBp->in.dx.halfs.low = BALLOON_BDOOR_PORT;
+   Backdoor_InOut(myBp);
+}
+
+#endif /* _BACKDOOR_BALLOON_H_ */
--- kernel/linux-2.6.26.3/drivers/misc/vmmemctl/backdoor_def.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmmemctl/backdoor_def.h	2008-09-03 10:02:10.000000000 -0500
@@ -0,0 +1,172 @@
+/*********************************************************
+ * Copyright (C) 1998 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * backdoor_def.h --
+ *
+ * This contains backdoor defines that can be included from
+ * an assembly language file.
+ */
+
+
+
+#ifndef _BACKDOOR_DEF_H_
+#define _BACKDOOR_DEF_H_
+
+#define INCLUDE_ALLOW_MODULE
+#define INCLUDE_ALLOW_USERLEVEL
+#define INCLUDE_ALLOW_VMMEXT
+#define INCLUDE_ALLOW_VMCORE
+#define INCLUDE_ALLOW_VMKERNEL
+#include "includeCheck.h"
+
+/*
+ * If you want to add a new low-level backdoor call for a guest userland
+ * application, please consider using the GuestRpc mechanism instead. --hpreg
+ */
+
+#define BDOOR_MAGIC 0x564D5868
+
+/* Low-bandwidth backdoor port. --hpreg */
+
+#define BDOOR_PORT 0x5658
+
+#define BDOOR_CMD_GETMHZ      		   1
+/*
+ * BDOOR_CMD_APMFUNCTION is used by:
+ *
+ * o The FrobOS code, which instead should either program the virtual chipset
+ *   (like the new BIOS code does, matthias offered to implement that), or not
+ *   use any VM-specific code (which requires that we correctly implement
+ *   "power off on CLI HLT" for SMP VMs, boris offered to implement that)
+ *
+ * o The old BIOS code, which will soon be jettisoned
+ *
+ *  --hpreg
+ */
+#define BDOOR_CMD_APMFUNCTION 		   2
+#define BDOOR_CMD_GETDISKGEO  		   3
+#define BDOOR_CMD_GETPTRLOCATION	      4
+#define BDOOR_CMD_SETPTRLOCATION	      5
+#define BDOOR_CMD_GETSELLENGTH		   6
+#define BDOOR_CMD_GETNEXTPIECE		   7
+#define BDOOR_CMD_SETSELLENGTH		   8
+#define BDOOR_CMD_SETNEXTPIECE		   9
+#define BDOOR_CMD_GETVERSION		      10
+#define BDOOR_CMD_GETDEVICELISTELEMENT	11
+#define BDOOR_CMD_TOGGLEDEVICE		   12
+#define BDOOR_CMD_GETGUIOPTIONS		   13
+#define BDOOR_CMD_SETGUIOPTIONS		   14
+#define BDOOR_CMD_GETSCREENSIZE		   15
+#define BDOOR_CMD_MONITOR_CONTROL       16
+#define BDOOR_CMD_GETHWVERSION          17
+#define BDOOR_CMD_OSNOTFOUND            18
+#define BDOOR_CMD_GETUUID               19
+#define BDOOR_CMD_GETMEMSIZE            20
+#define BDOOR_CMD_HOSTCOPY              21 /* Devel only */
+#define BDOOR_CMD_SERVICE_VM            22 /* prototype only */         
+#define BDOOR_CMD_GETTIME               23 /* Deprecated. Use GETTIMEFULL. */
+#define BDOOR_CMD_STOPCATCHUP           24
+#define BDOOR_CMD_PUTCHR	        25 /* Devel only */
+#define BDOOR_CMD_ENABLE_MSG	        26 /* Devel only */
+#define BDOOR_CMD_GOTO_TCL	        27 /* Devel only */
+#define BDOOR_CMD_INITPCIOPROM		28
+#define BDOOR_CMD_INT13			29
+#define BDOOR_CMD_MESSAGE               30
+#define BDOOR_CMD_RSVD0                 31
+#define BDOOR_CMD_RSVD1                 32
+#define BDOOR_CMD_RSVD2                 33
+#define BDOOR_CMD_ISACPIDISABLED	34
+#define BDOOR_CMD_TOE			35 /* Not in use */
+/* BDOOR_CMD_INITLSIOPROM, 36, was merged with 28. Reuse. */
+#define BDOOR_CMD_PATCH_SMBIOS_STRUCTS  37
+#define BDOOR_CMD_MAPMEM                38 /* Devel only */
+#define BDOOR_CMD_ABSPOINTER_DATA	39
+#define BDOOR_CMD_ABSPOINTER_STATUS	40
+#define BDOOR_CMD_ABSPOINTER_COMMAND	41
+#define BDOOR_CMD_TIMER_SPONGE          42
+#define BDOOR_CMD_PATCH_ACPI_TABLES	43
+/* Catch-all to allow synchronous tests */
+#define BDOOR_CMD_DEVEL_FAKEHARDWARE	44 /* Debug only - needed in beta */
+#define BDOOR_CMD_GETHZ      		45
+#define BDOOR_CMD_GETTIMEFULL           46
+#define BDOOR_CMD_STATELOGGER           47
+#define BDOOR_CMD_CHECKFORCEBIOSSETUP	48
+#define BDOOR_CMD_LAZYTIMEREMULATION    49
+#define BDOOR_CMD_BIOSBBS               50
+#define BDOOR_CMD_VASSERT               51
+#define BDOOR_CMD_ISGOSDARWIN           52
+#define BDOOR_CMD_DEBUGEVENT            53
+#define BDOOR_CMD_OSNOTMACOSXSERVER     54
+#define BDOOR_CMD_MAX                   55
+
+/* 
+ * IMPORTANT NOTE: When modifying the behavior of an existing backdoor command,
+ * you must adhere to the semantics expected by the oldest Tools who use that
+ * command. Specifically, do not alter the way in which the command modifies 
+ * the registers. Otherwise backwards compatibility will suffer.
+ */
+
+/* High-bandwidth backdoor port. --hpreg */
+
+#define BDOORHB_PORT 0x5659
+
+#define BDOORHB_CMD_MESSAGE 0
+#define BDOORHB_CMD_VASSERT 1
+#define BDOORHB_CMD_MAX 2
+
+/*
+ * There is another backdoor which allows access to certain TSC-related
+ * values using otherwise illegal PMC indices when the pseudo_perfctr
+ * control flag is set.
+ */
+
+#define BDOOR_PMC_HW_TSC      0x10000
+#define BDOOR_PMC_REAL_NS     0x10001
+#define BDOOR_PMC_APPARENT_NS 0x10002
+
+#define IS_BDOOR_PMC(index)  (((index) | 3) == 0x10003)
+#define BDOOR_CMD(ecx)       ((ecx) & 0xffff)
+
+
+#ifdef VMM
+/*
+ *----------------------------------------------------------------------
+ *
+ * Backdoor_CmdRequiresFullyValidVCPU --
+ *
+ *    A few backdoor commands require the full VCPU to be valid
+ *    (including GDTR, IDTR, TR and LDTR). The rest get read/write
+ *    access to GPRs and read access to Segment registers (selectors).
+ *
+ * Result:
+ *    True iff VECX contains a command that require the full VCPU to
+ *    be valid.
+ *
+ *----------------------------------------------------------------------
+ */
+static INLINE Bool
+Backdoor_CmdRequiresFullyValidVCPU(unsigned cmd)
+{
+   return cmd == BDOOR_CMD_RSVD0 ||
+          cmd == BDOOR_CMD_RSVD1 ||
+          cmd == BDOOR_CMD_RSVD2;
+}
+#endif
+
+#endif
--- kernel/linux-2.6.26.3/drivers/misc/vmmemctl/backdoorGcc32.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmmemctl/backdoorGcc32.c	2008-09-03 10:02:10.000000000 -0500
@@ -0,0 +1,221 @@
+/*********************************************************
+ * Copyright (C) 2005 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * backdoorGcc32.c --
+ *
+ *      Implements the real work for guest-side backdoor for GCC, 32-bit
+ *      target (supports inline ASM, GAS syntax). The asm sections are marked
+ *      volatile since vmware can change the registers content without the
+ *      compiler knowing it.
+ *
+ *      XXX
+ *      I tried to write this more cleanly, but:
+ *        - There is no way to specify an "ebp" constraint
+ *        - "ebp" is ignored when specified as cloberred register
+ *        - gas barfs when there is more than 10 operands
+ *        - gas 2.7.2.3, depending on the order of the operands, can
+ *          mis-assemble without any warning
+ *      --hpreg
+ *
+ *      Note that the problems with gas noted above might longer be relevant
+ *      now that we've upgraded most of our compiler versions.
+ *      --rrdharan
+ */
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+#include "backdoor.h"
+#include "backdoorInt.h"
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * Backdoor_InOut --
+ *
+ *      Send a low-bandwidth basic request (16 bytes) to vmware, and return its
+ *      reply (24 bytes).
+ *
+ * Results:
+ *      Host-side response returned in bp IN/OUT parameter.
+ *
+ * Side effects:
+ *      Pokes the backdoor.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+void
+Backdoor_InOut(Backdoor_proto *myBp) // IN/OUT
+{
+   uint32 dummy;
+
+   __asm__ __volatile__(
+#ifdef __PIC__
+        "pushl %%ebx"           "\n\t"
+#endif
+        "pushl %%eax"           "\n\t"
+        "movl 20(%%eax), %%edi" "\n\t"
+        "movl 16(%%eax), %%esi" "\n\t"
+        "movl 12(%%eax), %%edx" "\n\t"
+        "movl  8(%%eax), %%ecx" "\n\t"
+        "movl  4(%%eax), %%ebx" "\n\t"
+        "movl   (%%eax), %%eax" "\n\t"
+        "inl %%dx, %%eax"       "\n\t"
+        "xchgl %%eax, (%%esp)"  "\n\t"
+        "movl %%edi, 20(%%eax)" "\n\t"
+        "movl %%esi, 16(%%eax)" "\n\t"
+        "movl %%edx, 12(%%eax)" "\n\t"
+        "movl %%ecx,  8(%%eax)" "\n\t"
+        "movl %%ebx,  4(%%eax)" "\n\t"
+        "popl          (%%eax)" "\n\t"
+#ifdef __PIC__
+        "popl %%ebx"            "\n\t"
+#endif
+      : "=a" (dummy)
+      : "0" (myBp)
+      /*
+       * vmware can modify the whole VM state without the compiler knowing
+       * it. So far it does not modify EFLAGS. --hpreg
+       */
+      :
+#ifndef __PIC__
+        "ebx",
+#endif
+        "ecx", "edx", "esi", "edi", "memory"
+   );
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * BackdoorHbIn  --
+ * BackdoorHbOut --
+ *
+ *      Send a high-bandwidth basic request to vmware, and return its
+ *      reply.
+ *
+ * Results:
+ *      Host-side response returned in bp IN/OUT parameter.
+ *
+ * Side-effects:
+ *      Pokes the high-bandwidth backdoor port.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+void
+BackdoorHbIn(Backdoor_proto_hb *myBp) // IN/OUT
+{
+   uint32 dummy;
+
+   __asm__ __volatile__(
+#ifdef __PIC__
+        "pushl %%ebx"           "\n\t"
+#endif
+        "pushl %%ebp"           "\n\t"
+
+        "pushl %%eax"           "\n\t"
+        "movl 24(%%eax), %%ebp" "\n\t"
+        "movl 20(%%eax), %%edi" "\n\t"
+        "movl 16(%%eax), %%esi" "\n\t"
+        "movl 12(%%eax), %%edx" "\n\t"
+        "movl  8(%%eax), %%ecx" "\n\t"
+        "movl  4(%%eax), %%ebx" "\n\t"
+        "movl   (%%eax), %%eax" "\n\t"
+        "cld"                   "\n\t"
+        "rep; insb"             "\n\t"
+        "xchgl %%eax, (%%esp)"  "\n\t"
+        "movl %%ebp, 24(%%eax)" "\n\t"
+        "movl %%edi, 20(%%eax)" "\n\t"
+        "movl %%esi, 16(%%eax)" "\n\t"
+        "movl %%edx, 12(%%eax)" "\n\t"
+        "movl %%ecx,  8(%%eax)" "\n\t"
+        "movl %%ebx,  4(%%eax)" "\n\t"
+        "popl          (%%eax)" "\n\t"
+
+        "popl %%ebp"            "\n\t"
+#ifdef __PIC__
+        "popl %%ebx"            "\n\t"
+#endif
+      : "=a" (dummy)
+      : "0" (myBp)
+      /*
+       * vmware can modify the whole VM state without the compiler knowing
+       * it. --hpreg
+       */
+      : 
+#ifndef __PIC__
+        "ebx", 
+#endif
+        "ecx", "edx", "esi", "edi", "memory", "cc"
+   );
+}
+
+
+void
+BackdoorHbOut(Backdoor_proto_hb *myBp) // IN/OUT
+{
+   uint32 dummy;
+
+   __asm__ __volatile__(
+#ifdef __PIC__
+        "pushl %%ebx"           "\n\t"
+#endif
+        "pushl %%ebp"           "\n\t"
+
+        "pushl %%eax"           "\n\t"
+        "movl 24(%%eax), %%ebp" "\n\t"
+        "movl 20(%%eax), %%edi" "\n\t"
+        "movl 16(%%eax), %%esi" "\n\t"
+        "movl 12(%%eax), %%edx" "\n\t"
+        "movl  8(%%eax), %%ecx" "\n\t"
+        "movl  4(%%eax), %%ebx" "\n\t"
+        "movl   (%%eax), %%eax" "\n\t"
+        "cld"                   "\n\t"
+        "rep; outsb"            "\n\t"
+        "xchgl %%eax, (%%esp)"  "\n\t"
+        "movl %%ebp, 24(%%eax)" "\n\t"
+        "movl %%edi, 20(%%eax)" "\n\t"
+        "movl %%esi, 16(%%eax)" "\n\t"
+        "movl %%edx, 12(%%eax)" "\n\t"
+        "movl %%ecx,  8(%%eax)" "\n\t"
+        "movl %%ebx,  4(%%eax)" "\n\t"
+        "popl          (%%eax)" "\n\t"
+
+        "popl %%ebp"            "\n\t"
+#ifdef __PIC__
+        "popl %%ebx"            "\n\t"
+#endif
+      : "=a" (dummy)
+      : "0" (myBp)
+      :
+#ifndef __PIC__
+        "ebx",
+#endif
+        "ecx", "edx", "esi", "edi", "memory", "cc"
+   );
+}
+
+#ifdef __cplusplus
+}
+#endif
+
--- kernel/linux-2.6.26.3/drivers/misc/vmmemctl/backdoorGcc64.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmmemctl/backdoorGcc64.c	2008-09-03 10:02:10.000000000 -0500
@@ -0,0 +1,185 @@
+/*********************************************************
+ * Copyright (C) 2005 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * backdoorGcc64.c --
+ *
+ *      Implements the real work for guest-side backdoor for GCC, 64-bit
+ *      target (supports inline ASM, GAS syntax). The asm sections are marked
+ *      volatile since vmware can change the registers content without the
+ *      compiler knowing it.
+ *
+ *      See backdoorGCC32.c (from which this code was mostly copied) for
+ *      details on why the ASM is written this way. Also note that it might be
+ *      possible to write the asm blocks using the symbolic operand specifiers
+ *      in such a way that the same asm would generate correct code for both
+ *      32-bit and 64-bit targets, but I'm too lazy to figure it all out.
+ *      --rrdharan
+ */
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+#include "backdoor.h"
+#include "backdoorInt.h"
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * Backdoor_InOut --
+ *
+ *      Send a low-bandwidth basic request (16 bytes) to vmware, and return its
+ *      reply (24 bytes).
+ *
+ * Results:
+ *      Host-side response returned in bp IN/OUT parameter.
+ *
+ * Side effects:
+ *      Pokes the backdoor.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+void
+Backdoor_InOut(Backdoor_proto *myBp) // IN/OUT
+{
+   uint64 dummy;
+
+   __asm__ __volatile__(
+        "pushq %%rax"           "\n\t"
+        "movq 40(%%rax), %%rdi" "\n\t"
+        "movq 32(%%rax), %%rsi" "\n\t"
+        "movq 24(%%rax), %%rdx" "\n\t"
+        "movq 16(%%rax), %%rcx" "\n\t"
+        "movq  8(%%rax), %%rbx" "\n\t"
+        "movq   (%%rax), %%rax" "\n\t"
+        "inl %%dx, %%eax"       "\n\t"  /* NB: There is no inq instruction */
+        "xchgq %%rax, (%%rsp)"  "\n\t"
+        "movq %%rdi, 40(%%rax)" "\n\t"
+        "movq %%rsi, 32(%%rax)" "\n\t"
+        "movq %%rdx, 24(%%rax)" "\n\t"
+        "movq %%rcx, 16(%%rax)" "\n\t"
+        "movq %%rbx,  8(%%rax)" "\n\t"
+        "popq          (%%rax)"
+      : "=a" (dummy)
+      : "0" (myBp)
+      /*
+       * vmware can modify the whole VM state without the compiler knowing
+       * it. So far it does not modify EFLAGS. --hpreg
+       */
+      : "rbx", "rcx", "rdx", "rsi", "rdi", "memory"
+   );
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * BackdoorHbIn  --
+ * BackdoorHbOut --
+ *
+ *      Send a high-bandwidth basic request to vmware, and return its
+ *      reply.
+ *
+ * Results:
+ *      Host-side response returned in bp IN/OUT parameter.
+ *
+ * Side-effects:
+ *      Pokes the high-bandwidth backdoor port.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+void
+BackdoorHbIn(Backdoor_proto_hb *myBp) // IN/OUT
+{
+   uint32 dummy;
+
+   __asm__ __volatile__(
+        "pushq %%rbp"           "\n\t"
+
+        "pushq %%rax"           "\n\t"
+        "movq 48(%%rax), %%rbp" "\n\t"
+        "movq 40(%%rax), %%rdi" "\n\t"
+        "movq 32(%%rax), %%rsi" "\n\t"
+        "movq 24(%%rax), %%rdx" "\n\t"
+        "movq 16(%%rax), %%rcx" "\n\t"
+        "movq  8(%%rax), %%rbx" "\n\t"
+        "movq   (%%rax), %%rax" "\n\t"
+        "cld"                   "\n\t"
+        "rep; insb"             "\n\t"
+        "xchgq %%rax, (%%rsp)"  "\n\t"
+        "movq %%rbp, 48(%%rax)" "\n\t"
+        "movq %%rdi, 40(%%rax)" "\n\t"
+        "movq %%rsi, 32(%%rax)" "\n\t"
+        "movq %%rdx, 24(%%rax)" "\n\t"
+        "movq %%rcx, 16(%%rax)" "\n\t"
+        "movq %%rbx,  8(%%rax)" "\n\t"
+        "popq          (%%rax)" "\n\t"
+
+        "popq %%rbp"
+      : "=a" (dummy)
+      : "0" (myBp)
+      /*
+       * vmware can modify the whole VM state without the compiler knowing
+       * it. --hpreg
+       */
+      : "rbx", "rcx", "rdx", "rsi", "rdi", "memory", "cc"
+   );
+}
+
+
+void
+BackdoorHbOut(Backdoor_proto_hb *myBp) // IN/OUT
+{
+   uint64 dummy;
+
+   __asm__ __volatile__(
+        "pushq %%rbp"           "\n\t"
+
+        "pushq %%rax"           "\n\t"
+        "movq 48(%%rax), %%rbp" "\n\t"
+        "movq 40(%%rax), %%rdi" "\n\t"
+        "movq 32(%%rax), %%rsi" "\n\t"
+        "movq 24(%%rax), %%rdx" "\n\t"
+        "movq 16(%%rax), %%rcx" "\n\t"
+        "movq  8(%%rax), %%rbx" "\n\t"
+        "movq   (%%rax), %%rax" "\n\t"
+        "cld"                   "\n\t"
+        "rep; outsb"            "\n\t"
+        "xchgq %%rax, (%%rsp)"  "\n\t"
+        "movq %%rbp, 48(%%rax)" "\n\t"
+        "movq %%rdi, 40(%%rax)" "\n\t"
+        "movq %%rsi, 32(%%rax)" "\n\t"
+        "movq %%rdx, 24(%%rax)" "\n\t"
+        "movq %%rcx, 16(%%rax)" "\n\t"
+        "movq %%rbx,  8(%%rax)" "\n\t"
+        "popq          (%%rax)" "\n\t"
+
+        "popq %%rbp"
+      : "=a" (dummy)
+      : "0" (myBp)
+      : "rbx", "rcx", "rdx", "rsi", "rdi", "memory", "cc"
+   );
+}
+
+
+#ifdef __cplusplus
+}
+#endif
--- kernel/linux-2.6.26.3/drivers/misc/vmmemctl/backdoor.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmmemctl/backdoor.h	2008-09-03 10:02:10.000000000 -0500
@@ -0,0 +1,46 @@
+/*********************************************************
+ * Copyright (C) 1999 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * backdoor.h --
+ *
+ *    First layer of the internal communication channel between guest
+ *    applications and vmware
+ */
+
+#ifndef _BACKDOOR_H_
+#define _BACKDOOR_H_
+
+#include "vm_basic_types.h"
+#include "vm_assert.h"
+
+#include "backdoor_types.h"
+
+void
+Backdoor(Backdoor_proto *bp); // IN/OUT
+
+void 
+Backdoor_InOut(Backdoor_proto *bp); // IN/OUT
+
+void
+Backdoor_HbOut(Backdoor_proto_hb *bp); // IN/OUT
+
+void
+Backdoor_HbIn(Backdoor_proto_hb *bp); // IN/OUT
+
+#endif /* _BACKDOOR_H_ */
--- kernel/linux-2.6.26.3/drivers/misc/vmmemctl/backdoorInt.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmmemctl/backdoorInt.h	2008-09-03 10:02:10.000000000 -0500
@@ -0,0 +1,26 @@
+/*********************************************************
+ * Copyright (C) 2005 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * backdoorInt.h --
+ *
+ *      Internal function prototypes for the real backdoor work.
+ */
+
+void BackdoorHbIn(Backdoor_proto_hb *bp);
+void BackdoorHbOut(Backdoor_proto_hb *bp);
--- kernel/linux-2.6.26.3/drivers/misc/vmmemctl/backdoor_types.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmmemctl/backdoor_types.h	2008-09-03 10:02:10.000000000 -0500
@@ -0,0 +1,118 @@
+/*********************************************************
+ * Copyright (C) 1999 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * backdoor_types.h --
+ *
+ *    Type definitions for backdoor interaction code.
+ */
+
+#ifndef _BACKDOOR_TYPES_H_
+#define _BACKDOOR_TYPES_H_
+
+#ifndef VM_I386
+#error The backdoor protocol is only supported on x86 architectures.
+#endif
+
+/*
+ * These #defines are intended for defining register structs as part of
+ * existing named unions. If the union should encapsulate the register
+ * (and nothing else), use DECLARE_REG_NAMED_STRUCT defined below.
+ */
+
+#define DECLARE_REG32_STRUCT \
+   struct { \
+      uint16 low; \
+      uint16 high; \
+   } halfs; \
+   uint32 word
+
+#define DECLARE_REG64_STRUCT \
+   DECLARE_REG32_STRUCT; \
+   struct { \
+      uint32 low; \
+      uint32 high; \
+   } words; \
+   uint64 quad
+
+#ifndef VM_X86_64
+#define DECLARE_REG_STRUCT DECLARE_REG32_STRUCT
+#else
+#define DECLARE_REG_STRUCT DECLARE_REG64_STRUCT
+#endif
+
+#define DECLARE_REG_NAMED_STRUCT(_r) \
+   union { DECLARE_REG_STRUCT; } _r
+
+/*
+ * Some of the registers are expressed by semantic name, because if they were
+ * expressed as register structs declared above, we could only address them
+ * by fixed size (half-word, word, quad, etc.) instead of by varying size
+ * (size_t, uintptr_t).
+ *
+ * To be cleaner, these registers are expressed ONLY by semantic name,
+ * rather than by a union of the semantic name and a register struct.
+ */
+typedef union {
+   struct {
+      DECLARE_REG_NAMED_STRUCT(ax);
+      size_t size; /* Register bx. */
+      DECLARE_REG_NAMED_STRUCT(cx);
+      DECLARE_REG_NAMED_STRUCT(dx);
+      DECLARE_REG_NAMED_STRUCT(si);
+      DECLARE_REG_NAMED_STRUCT(di);
+   } in;
+   struct {
+      DECLARE_REG_NAMED_STRUCT(ax);
+      DECLARE_REG_NAMED_STRUCT(bx);
+      DECLARE_REG_NAMED_STRUCT(cx);
+      DECLARE_REG_NAMED_STRUCT(dx);
+      DECLARE_REG_NAMED_STRUCT(si);
+      DECLARE_REG_NAMED_STRUCT(di);
+   } out;
+} Backdoor_proto;
+
+typedef union {
+   struct {
+      DECLARE_REG_NAMED_STRUCT(ax);
+      DECLARE_REG_NAMED_STRUCT(bx);
+      size_t size; /* Register cx. */
+      DECLARE_REG_NAMED_STRUCT(dx);
+      uintptr_t srcAddr; /* Register si. */
+      uintptr_t dstAddr; /* Register di. */
+      DECLARE_REG_NAMED_STRUCT(bp);
+   } in;
+   struct {
+      DECLARE_REG_NAMED_STRUCT(ax);
+      DECLARE_REG_NAMED_STRUCT(bx);
+      DECLARE_REG_NAMED_STRUCT(cx);
+      DECLARE_REG_NAMED_STRUCT(dx);
+      DECLARE_REG_NAMED_STRUCT(si);
+      DECLARE_REG_NAMED_STRUCT(di);
+      DECLARE_REG_NAMED_STRUCT(bp);
+   } out;
+} Backdoor_proto_hb;
+
+MY_ASSERTS(BACKDOOR_STRUCT_SIZES,
+           ASSERT_ON_COMPILE(sizeof(Backdoor_proto) == 6 * sizeof(uintptr_t));
+           ASSERT_ON_COMPILE(sizeof(Backdoor_proto_hb) == 7 * sizeof(uintptr_t));
+)
+
+#undef DECLARE_REG_STRUCT
+
+#endif /* _BACKDOOR_TYPES_H_ */
--- kernel/linux-2.6.26.3/drivers/misc/vmmemctl/balloon_def.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmmemctl/balloon_def.h	2008-09-03 10:02:10.000000000 -0500
@@ -0,0 +1,74 @@
+/*********************************************************
+ * Copyright (C) 2000 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * balloon_def.h -- 
+ *
+ *	Definitions for server "balloon" mechanism for reclaiming
+ *	physical memory from a VM.
+ */
+
+#ifndef	_BALLOON_DEF_H
+#define	_BALLOON_DEF_H
+
+#define INCLUDE_ALLOW_VMCORE
+#define INCLUDE_ALLOW_VMKERNEL
+#define	INCLUDE_ALLOW_MODULE
+#include "includeCheck.h"
+
+#include "vm_basic_types.h"
+
+/*
+ * constants
+ */
+
+/* backdoor port */
+#define	BALLOON_BDOOR_PORT		(0x5670)
+#define	BALLOON_BDOOR_MAGIC		(0x456c6d6f)
+
+/* backdoor command numbers */
+#define	BALLOON_BDOOR_CMD_START		(0)
+#define	BALLOON_BDOOR_CMD_TARGET	(1)
+#define	BALLOON_BDOOR_CMD_LOCK		(2)
+#define	BALLOON_BDOOR_CMD_UNLOCK	(3)
+#define	BALLOON_BDOOR_CMD_GUEST_ID	(4)
+
+/* use config value for max balloon size */
+#define BALLOON_MAX_SIZE_USE_CONFIG	(0)
+
+/* guest identities */
+#define BALLOON_GUEST_UNKNOWN		(0)
+#define BALLOON_GUEST_LINUX		(1)
+#define BALLOON_GUEST_BSD		(2)
+#define BALLOON_GUEST_WINDOWS_NT4	(3)
+#define BALLOON_GUEST_WINDOWS_NT5	(4)
+#define BALLOON_GUEST_SOLARIS		(5)
+
+/* error codes */
+#define	BALLOON_SUCCESS			(0)
+#define	BALLOON_FAILURE			(-1)
+#define	BALLOON_ERROR_CMD_INVALID	(1)
+#define	BALLOON_ERROR_PPN_INVALID	(2)
+#define	BALLOON_ERROR_PPN_LOCKED	(3)
+#define	BALLOON_ERROR_PPN_UNLOCKED	(4)
+#define	BALLOON_ERROR_PPN_PINNED	(5)
+#define	BALLOON_ERROR_PPN_TRANSPARENT	(6)
+#define	BALLOON_ERROR_RESET		(7)
+#define	BALLOON_ERROR_BUSY		(8)
+
+#endif	/* _BALLOON_DEF_H */
--- kernel/linux-2.6.26.3/drivers/misc/vmmemctl/compat_completion.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmmemctl/compat_completion.h	2008-09-03 10:02:10.000000000 -0500
@@ -0,0 +1,175 @@
+/*********************************************************
+ * Copyright (C) 2004 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_COMPLETION_H__
+#   define __COMPAT_COMPLETION_H__
+
+/*
+ * The kernel's completion objects were made available for module use in 2.4.9.
+ * 
+ * Between 2.4.0 and 2.4.9, we implement completions on our own using 
+ * waitqueues and counters. This was done so that we could safely support
+ * functions like complete_all(), which cannot be implemented using semaphores.
+ *
+ * Prior to that, the waitqueue API is substantially different, and since none 
+ * of our modules that are built against older kernels need complete_all(), 
+ * we fallback on a simple semaphore-based implementation. 
+ */
+
+/* 
+ * Native completions.
+ */ 
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 4, 9)
+
+#include <linux/completion.h>
+#define compat_completion struct completion
+#define compat_init_completion(comp) init_completion(comp)
+#define COMPAT_DECLARE_COMPLETION DECLARE_COMPLETION
+#define compat_wait_for_completion(comp) wait_for_completion(comp)
+#define compat_complete(comp) complete(comp)
+
+/* complete_all() was exported in 2.6.6. */
+# if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 6)
+#  include "compat_wait.h"
+#  include "compat_list.h"
+#  include "compat_spinlock.h"
+#  include "compat_sched.h"
+#  define compat_complete_all(x)         \
+      ({                                 \
+          struct list_head *currLinks;   \
+          spin_lock(&(x)->wait.lock);    \
+          (x)->done += UINT_MAX/2;       \
+                                         \
+          list_for_each(currLinks, &(x)->wait.task_list) { \
+             wait_queue_t *currQueue = list_entry(currLinks, wait_queue_t, task_list); \
+             wake_up_process(currQueue->task); \
+          }                              \
+          spin_unlock(&(x)->wait.lock);  \
+      })
+# else
+#  define compat_complete_all complete_all
+# endif
+
+/* 
+ * Completions via waitqueues.
+ */
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(2, 4, 0)
+
+/*
+ * Kernel completions in 2.4.9 and beyond use a counter and a waitqueue, and 
+ * our implementation is quite similar. Because __wake_up_common() is not 
+ * exported, our implementations of compat_complete() and compat_complete_all()
+ * are somewhat racy: the counter is incremented outside of the waitqueue's 
+ * lock. 
+ *
+ * As a result, our completion cannot guarantee in-order wake ups. For example,
+ * suppose thread A is entering compat_complete(), thread B is sleeping inside
+ * compat_wait_for_completion(), and thread C is just now entering
+ * compat_wait_for_completion(). If Thread A is scheduled first and increments 
+ * the counter, then gets swapped out, thread C may get scheduled and will 
+ * quickly go through compat_wait_for_completion() (since done != 0) while 
+ * thread B continues to sleep, even though thread B should have been the one 
+ * to wake up.
+ */
+
+#include <asm/current.h>
+#include "compat_sched.h"
+#include "compat_list.h"
+#include <linux/smp_lock.h> // for lock_kernel()/unlock_kernel()
+#include "compat_wait.h"
+
+typedef struct compat_completion {
+   unsigned int done;
+   wait_queue_head_t wq;
+} compat_completion;
+
+#define compat_init_completion(comp) do { \
+   (comp)->done = 0; \
+   init_waitqueue_head(&(comp)->wq); \
+} while (0)
+#define COMPAT_DECLARE_COMPLETION(comp) \
+   compat_completion comp = { \
+     .done = 0, \
+     .wq = __WAIT_QUEUE_HEAD_INITIALIZER((comp).wq), \
+   }
+
+/*
+ * Locking and unlocking the kernel lock here ensures that the thread
+ * is no longer running in module code: compat_complete_and_exit
+ * performs the sequence { lock_kernel(); up(comp); compat_exit(); }, with
+ * the final unlock_kernel performed implicitly by the resident kernel
+ * in do_exit.
+ */
+#define compat_wait_for_completion(comp) do { \
+   spin_lock_irq(&(comp)->wq.lock); \
+   if (!(comp)->done) { \
+      DECLARE_WAITQUEUE(wait, current); \
+      wait.flags |= WQ_FLAG_EXCLUSIVE; \
+      __add_wait_queue_tail(&(comp)->wq, &wait); \
+      do { \
+         __set_current_state(TASK_UNINTERRUPTIBLE); \
+         spin_unlock_irq(&(comp)->wq.lock); \
+         schedule(); \
+         spin_lock_irq(&(comp)->wq.lock); \
+      } while (!(comp)->done); \
+      __remove_wait_queue(&(comp)->wq, &wait); \
+   } \
+   (comp)->done--; \
+   spin_unlock_irq(&(comp)->wq.lock); \
+   lock_kernel(); \
+   unlock_kernel(); \
+} while (0)
+
+/* XXX: I don't think I need to touch the BKL. */
+#define compat_complete(comp) do { \
+   unsigned long flags; \
+   spin_lock_irqsave(&(comp)->wq.lock, flags); \
+   (comp)->done++; \
+   spin_unlock_irqrestore(&(comp)->wq.lock, flags); \
+   wake_up(&(comp)->wq); \
+} while (0)
+
+#define compat_complete_all(comp) do { \
+   unsigned long flags; \
+   spin_lock_irqsave(&(comp)->wq.lock, flags); \
+   (comp)->done += UINT_MAX / 2; \
+   spin_unlock_irqrestore(&(comp)->wq.lock, flags); \
+   wake_up_all(&(comp)->wq); \
+} while (0)
+
+/*
+ * Completions via semaphores.
+ */ 
+#else
+
+#include "compat_semaphore.h"
+#define compat_completion struct semaphore 
+#define compat_init_completion(comp) init_MUTEX_LOCKED(comp)
+#define COMPAT_DECLARE_COMPLETION(comp) DECLARE_MUTEX_LOCKED(comp) 
+
+#define compat_wait_for_completion(comp) do { \
+   down(comp); \
+   lock_kernel(); \
+   unlock_kernel(); \
+} while (0)
+
+#define compat_complete(comp) up(comp)
+
+#endif
+
+#endif /* __COMPAT_COMPLETION_H__ */
--- kernel/linux-2.6.26.3/drivers/misc/vmmemctl/compat_file.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmmemctl/compat_file.h	2008-09-03 10:02:10.000000000 -0500
@@ -0,0 +1,56 @@
+/*********************************************************
+ * Copyright (C) 2002 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_FILE_H__
+#   define __COMPAT_FILE_H__
+
+
+/* The fput() API is modified in 2.2.0 --hpreg */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 2, 0)
+#   define compat_fput(_file) fput(_file)
+#else
+#   define compat_fput(_file) fput(_file, (_file)->f_inode)
+#endif
+
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 4, 0)
+#   define compat_get_file(_file) get_file(_file)
+#   define compat_file_count(_file) file_count(_file)
+#else
+#   define compat_get_file(_file) (_file)->f_count++
+#   define compat_file_count(_file) (_file)->f_count
+#endif
+
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 2, 4)
+#   define compat_filp_close(_file, _files) filp_close(_file, _files)
+#else
+static inline void compat_filp_close(struct file* filp, fl_owner_t files) {
+   if (filp->f_op && filp->f_op->flush) {
+      filp->f_op->flush(filp);
+   }
+   /*
+    * Hopefully there are no locks to release on this filp. 
+    * locks_remove_posix is not exported so we cannot use it...
+    */
+   fput(filp);
+}
+#endif
+
+
+#endif /* __COMPAT_FILE_H__ */
--- kernel/linux-2.6.26.3/drivers/misc/vmmemctl/compat_kernel.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmmemctl/compat_kernel.h	2008-09-03 10:02:10.000000000 -0500
@@ -0,0 +1,83 @@
+/*********************************************************
+ * Copyright (C) 2004 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_KERNEL_H__
+#   define __COMPAT_KERNEL_H__
+
+#include <asm/unistd.h>
+#include <linux/kernel.h>
+
+/*
+ * container_of was introduced in 2.5.28 but it's easier to check like this.
+ */
+#ifndef container_of
+#define container_of(ptr, type, member) ({			\
+        const typeof( ((type *)0)->member ) *__mptr = (ptr);	\
+        (type *)( (char *)__mptr - offsetof(type,member) );})
+#endif
+
+/*
+ * wait_for_completion and friends did not exist before 2.4.9.
+ */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 4, 9)
+
+#define compat_complete_and_exit(comp, status) complete_and_exit(comp, status)
+
+#else
+
+#include "compat_completion.h"
+
+/*
+ * Used by _syscallX macros. Note that this is global variable, so
+ * do not rely on its contents too much. As exit() is only function
+ * we use, and we never check return value from exit(), we have
+ * no problem...
+ */
+extern int errno;
+
+/*
+ * compat_exit() provides an access to the exit() function. It must 
+ * be named compat_exit(), as exit() (with different signature) is 
+ * provided by x86-64, arm and other (but not by i386).
+ */
+#define __NR_compat_exit __NR_exit
+static inline _syscall1(int, compat_exit, int, exit_code);
+
+/*
+ * See compat_wait_for_completion in compat_completion.h.
+ * compat_exit implicitly performs an unlock_kernel, in resident code,
+ * ensuring that the thread is no longer running in module code when the
+ * module is unloaded.
+ */
+#define compat_complete_and_exit(comp, status) do { \
+   lock_kernel(); \
+   compat_complete(comp); \
+   compat_exit(status); \
+} while (0)
+
+#endif
+
+/*
+ * vsnprintf became available in 2.4.10. For older kernels, just fall back on
+ * vsprintf.
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 10)
+#define vsnprintf(str, size, fmt, args) vsprintf(str, fmt, args)
+#endif
+
+#endif /* __COMPAT_KERNEL_H__ */
--- kernel/linux-2.6.26.3/drivers/misc/vmmemctl/compat_kthread.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmmemctl/compat_kthread.h	2008-09-03 10:02:10.000000000 -0500
@@ -0,0 +1,223 @@
+/*********************************************************
+ * Copyright (C) 2008 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_KTHREAD_H__
+#   define __COMPAT_KTHREAD_H__
+
+/*
+ * The kthread interface for managing kernel threads appeared in 2.6.4, but was
+ * only exported for module use in 2.6.7.
+ */
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 7)
+# include <linux/kthread.h>
+
+# define COMPAT_KTHREAD_DECLARE_STOP_INFO()
+# define compat_kthread_stop(_tsk) kthread_stop(_tsk)
+# define compat_kthread_should_stop() kthread_should_stop()
+# define compat_kthread_run(_fn, _data, _namefmt, ...)                         \
+   kthread_run(_fn, _data, _namefmt, ## __VA_ARGS__)
+# define compat_kthread_create(_fn, _data, _namefmt, ...)                      \
+   kthread_create(_fn, _data, _namefmt, ## __VA_ARGS__)
+#else
+
+/*
+ * When the kthread interface isn't available, we do our best to emulate it,
+ * with a few notable exceptions:
+ *
+ * 1: We use semaphores instead of mutexes for locking, because mutexes aren't
+ *    available in kernels where kthread isn't available.
+ * 2: The real kthread interface uses the kthreadd kernel_thread to broker the
+ *    creation of new kernel threads. This makes sense because kthreadd is part
+ *    of the kernel, but doesn't make sense at all in the context of an
+ *    individual module. So in our emulation, thread creation occurs in the
+ *    context of a kthread_create call.
+ * 3: Because kthreadd is responsible for creating kernel threads in the real
+ *    kthread interface, there's no need to explicitly reparent any of them. We
+ *    aren't using kthreadd, so we call daemonize to reparent, which also sets
+ *    the name of the new kernel thread. That's why we don't set the name as
+ *    the real kthread interface does (within kthread_create). Furthermore, to
+ *    get the name to daemonize, we're forced to pass it through the
+ *    kthread_start_info struct.
+ * 4: Since our interface isn't in the kernel proper, we can't make use of
+ *    get_task_struct/put_task_struct so as to acquire references to kernel
+ *    threads that we're managing. To prevent races, we use an extra completion
+ *    when stopping kernel threads. See the comments in compat_kthread_stop for
+ *    more details.
+ *
+ * Like the real kthread interface, ours must be globally available so that we
+ * can emulate functions like kthread_should_stop without using different
+ * signatures.
+ */
+
+# include "compat_completion.h"
+# include "compat_kernel.h"
+# include "compat_sched.h"
+
+struct compat_kthread_start_info {
+   int (*fn)(void *);
+   void *data;
+   compat_completion created;
+   char comm[TASK_COMM_LEN];
+};
+
+struct compat_kthread_stop_info {
+   struct semaphore lock;
+   struct task_struct *task;
+   compat_completion woken;
+   compat_completion stopped;
+   int ret;
+};
+
+extern struct compat_kthread_stop_info compat_kthread_stop_info;
+
+# define COMPAT_KTHREAD_DECLARE_STOP_INFO()                                    \
+   struct compat_kthread_stop_info compat_kthread_stop_info = {                \
+      .lock = __SEMAPHORE_INITIALIZER(compat_kthread_stop_info.lock, 1),       \
+      .task = NULL,                                                            \
+   }
+
+
+static inline int
+compat_kthread_should_stop(void)
+{
+   return (compat_kthread_stop_info.task == current);
+}
+
+
+static inline int
+compat_kthread_stop(struct task_struct *_task)
+{
+   int ret;
+
+   down(&compat_kthread_stop_info.lock);
+
+   /*
+    * We use a write memory barrier to ensure that all CPUs see _task after
+    * the completions have been initialized.
+    *
+    * There's a race between kernel threads managed by kthread and the upcoming
+    * call to wake_up_process. If the kernel thread wakes up after we set task
+    * but before the call to wake_up_process, the thread's call to
+    * compat_kthread_should_stop will return true and the thread will exit. At
+    * that point, the call to wake_up_process will be on a dead task_struct.
+    *
+    * XXX: The real kthread interface protects against this race by grabbing
+    * and releasing a reference to _task. We don't have that luxury, because
+    * there is a range of kernels where put_task_struct isn't exported to
+    * modules. In fact, no other modules call get_task_struct or
+    * put_task_struct, so to do so from this context may be unwise. Instead,
+    * we'll use an extra completion to ensure that the kernel thread only exits
+    * after wake_up_process has been called.
+    */
+   compat_init_completion(&compat_kthread_stop_info.woken);
+   compat_init_completion(&compat_kthread_stop_info.stopped);
+   smp_wmb();
+
+   compat_kthread_stop_info.task = _task;
+   wake_up_process(_task);
+   compat_complete(&compat_kthread_stop_info.woken);
+
+   compat_wait_for_completion(&compat_kthread_stop_info.stopped);
+   compat_kthread_stop_info.task = NULL;
+   ret = compat_kthread_stop_info.ret;
+   up(&compat_kthread_stop_info.lock);
+   return ret;
+}
+
+
+# define compat_kthread_run(_fn, _data, _namefmt, ...)                         \
+({                                                                             \
+   struct task_struct *tsk;                                                    \
+   tsk = compat_kthread_create(_fn, _data, _namefmt, ## __VA_ARGS__);          \
+   if (!IS_ERR(tsk)) {                                                         \
+      wake_up_process(tsk);                                                    \
+   }                                                                           \
+   tsk;                                                                        \
+})
+
+
+static inline int
+compat_kthread(void *_data)
+{
+   int ret = -EINTR;
+   struct compat_kthread_start_info *info;
+   int (*fn)(void *data);
+   void *data;
+
+   info = (struct compat_kthread_start_info *)_data;
+   fn = info->fn;
+   data = info->data;
+
+   compat_daemonize(info->comm);
+   __set_current_state(TASK_UNINTERRUPTIBLE);
+   compat_complete(&info->created);
+   schedule();
+
+   if (!compat_kthread_should_stop()) {
+      ret = fn(data);
+   }
+
+   if (compat_kthread_should_stop()) {
+      compat_wait_for_completion(&compat_kthread_stop_info.woken);
+      compat_kthread_stop_info.ret = ret;
+      compat_complete_and_exit(&compat_kthread_stop_info.stopped, 0);
+      BUG();
+   }
+   return 0;
+}
+
+
+static inline struct task_struct *
+compat_kthread_create(int (*_fn)(void *data),
+                      void *_data,
+                      const char _namefmt[],
+                      ...)
+{
+   pid_t pid;
+   struct task_struct *task = NULL;
+   struct compat_kthread_start_info info;
+   va_list args;
+
+   info.fn = _fn;
+   info.data = _data;
+   compat_init_completion(&info.created);
+   va_start(args, _namefmt);
+   vsnprintf(info.comm, sizeof info.comm, _namefmt, args);
+   va_end(args);
+   pid = kernel_thread(compat_kthread, &info, CLONE_KERNEL);
+   if (pid >= 0) {
+      compat_wait_for_completion(&info.created);
+
+      /*
+       * find_task_by_pid must be called with tasklist_lock held or under
+       * rcu_read_lock. As the latter doesn't exist in old kernels, we use the
+       * former for convenience.
+       */
+      read_lock(&tasklist_lock);
+      task = find_task_by_pid(pid);
+      read_unlock(&tasklist_lock);
+
+      /* XXX: Do we need to get a reference on task? */
+   }
+   return task;
+}
+
+#endif
+
+#endif /* __COMPAT_KTHREAD_H__ */
--- kernel/linux-2.6.26.3/drivers/misc/vmmemctl/compat_list.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmmemctl/compat_list.h	2008-09-03 10:02:10.000000000 -0500
@@ -0,0 +1,55 @@
+/*********************************************************
+ * Copyright (C) 2006 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_LIST_H__
+#   define __COMPAT_LIST_H__
+
+#include <linux/list.h>
+
+/*
+ * list_add_tail is with us since 2.4.0, or something like that.
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 0)
+#define list_add_tail(newe, head) do {  \
+   struct list_head *__h = (head);      \
+   __list_add((newe), __h->prev, __h);  \
+} while (0)
+#endif
+
+/*
+ * list_for_each_safe() showed up in 2.4.10, but it may be backported so we
+ * just check for its existence.
+ */
+#ifndef list_for_each_safe
+# define list_for_each_safe(pos, n, head) \
+         for (pos = (head)->next, n = pos->next; pos != (head); \
+                 pos = n, n = pos->next)
+#endif
+
+/*
+ * list_for_each_entry() showed up in 2.4.20, but it may be backported so we
+ * just check for its existence.
+ */
+#ifndef list_for_each_entry
+# define list_for_each_entry(pos, head, member) \
+         for (pos = list_entry((head)->next, typeof(*pos), member); \
+              &pos->member != (head); \
+              pos = list_entry(pos->member.next, typeof(*pos), member))
+#endif
+
+#endif /* __COMPAT_LIST_H__ */
--- kernel/linux-2.6.26.3/drivers/misc/vmmemctl/compat_mm.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmmemctl/compat_mm.h	2008-09-03 10:02:10.000000000 -0500
@@ -0,0 +1,134 @@
+/*********************************************************
+ * Copyright (C) 2002 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_MM_H__
+#   define __COMPAT_MM_H__
+
+
+#include <linux/mm.h>
+
+
+/* The get_page() API appeared in 2.3.7 --hpreg */
+/* Sometime during development it became function instead of macro --petr */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 0) && !defined(get_page) 
+#   define get_page(_page) atomic_inc(&(_page)->count)
+/* The __free_page() API is exported in 2.1.67 --hpreg */
+#   if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 1, 67)
+#      define put_page __free_page
+#   else
+#      include "compat_page.h"
+
+#      define page_to_phys(_page) (page_to_pfn(_page) << PAGE_SHIFT)
+#      define put_page(_page) free_page(page_to_phys(_page))
+#   endif
+#endif
+
+
+/* page_count() is 2.4.0 invention. Unfortunately unavailable in some RedHat 
+ * kernels (for example 2.4.21-4-RHEL3). */
+/* It is function since 2.6.0, and hopefully RedHat will not play silly games
+ * with mm_inline.h again... */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 0) && !defined(page_count)
+#  define page_count(page) atomic_read(&(page)->count)
+#endif
+
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 0)
+#  define compat_vm_pgoff(vma) ((vma)->vm_offset >> PAGE_SHIFT)
+
+static inline unsigned long compat_do_mmap_pgoff(struct file *file, unsigned long addr,
+   unsigned long len, unsigned long prot,
+   unsigned long flag, unsigned long pgoff)
+{
+   unsigned long ret = -EINVAL;
+
+   if (pgoff < 1 << (32 - PAGE_SHIFT)) {
+      ret = do_mmap(file, addr, len, prot, flag, pgoff << PAGE_SHIFT);
+   }
+   return ret;
+}
+
+#else
+#  define compat_vm_pgoff(vma) (vma)->vm_pgoff
+#  ifdef VMW_SKAS_MMAP
+#    define compat_do_mmap_pgoff(f, a, l, p, g, o) \
+				do_mmap_pgoff(current->mm, f, a, l, p, g, o)
+#  else
+#    define compat_do_mmap_pgoff(f, a, l, p, g, o) \
+				do_mmap_pgoff(f, a, l, p, g, o)
+#  endif
+#endif
+
+
+/* 2.2.x uses 0 instead of some define */
+#ifndef NOPAGE_SIGBUS
+#define NOPAGE_SIGBUS (0)
+#endif
+
+
+/* 2.2.x does not have HIGHMEM support */
+#ifndef GFP_HIGHUSER
+#define GFP_HIGHUSER (GFP_USER)
+#endif
+
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 0)
+
+#include "compat_page.h"
+
+static inline struct page * alloc_pages(unsigned int gfp_mask, unsigned int order)
+{
+   unsigned long addr;
+   
+   addr = __get_free_pages(gfp_mask, order);
+   if (!addr) {
+      return NULL;
+   }
+   return virt_to_page(addr);
+}
+#define alloc_page(gfp_mask) alloc_pages(gfp_mask, 0)
+
+#endif
+
+/*
+ * In 2.4.14, the logic behind the UnlockPage macro was moved to the 
+ * unlock_page() function. Later (in 2.5.12), the UnlockPage macro was removed
+ * altogether, and nowadays everyone uses unlock_page().
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 14)
+#define compat_unlock_page(page) UnlockPage(page)
+#else
+#define compat_unlock_page(page) unlock_page(page)
+#endif
+
+/*
+ * In 2.4.10, vmtruncate was changed from returning void to returning int.
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 10)
+#define compat_vmtruncate(inode, size)                                        \
+({                                                                            \
+   int result = 0;                                                            \
+   vmtruncate(inode, size);                                                   \
+   result;                                                                    \
+})
+#else
+#define compat_vmtruncate(inode, size) vmtruncate(inode, size)
+#endif
+
+
+#endif /* __COMPAT_MM_H__ */
--- kernel/linux-2.6.26.3/drivers/misc/vmmemctl/compat_module.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmmemctl/compat_module.h	2008-09-03 10:02:10.000000000 -0500
@@ -0,0 +1,72 @@
+/*********************************************************
+ * Copyright (C) 2007 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * compat_module.h --
+ */
+
+#ifndef __COMPAT_MODULE_H__
+#   define __COMPAT_MODULE_H__
+
+
+#include <linux/module.h>
+
+
+/*
+ * Modules wishing to use the GPL license are required to include a
+ * MODULE_LICENSE definition in their module source as of 2.4.10.
+ */
+#ifndef MODULE_LICENSE
+#define MODULE_LICENSE(license)
+#endif
+
+/*
+ * To make use of our own home-brewed MODULE_INFO, we need macros to
+ * concatenate two expressions to "__mod_", and and to convert an
+ * expression into a string. I'm sure we've got these in our codebase,
+ * but I'd rather not introduce such a dependency in a compat header.
+ */
+#ifndef __module_cat
+#define __module_cat_1(a, b) __mod_ ## a ## b
+#define __module_cat(a, b) __module_cat_1(a, b)
+#endif
+
+#ifndef __stringify
+#define __stringify_1(x) #x
+#define __stringify(x) __stringify_1(x)
+#endif
+
+/*
+ * MODULE_INFO was born in 2.5.69.
+ */
+#ifndef MODULE_INFO
+#define MODULE_INFO(tag, info)                                                \
+static const char __module_cat(tag, __LINE__)[]                               \
+  __attribute__((section(".modinfo"), unused)) = __stringify(tag) "=" info
+#endif
+
+/*
+ * MODULE_VERSION was born in 2.6.4. The earlier form appends a long "\0xxx"
+ * string to the module's version, but that was removed in 2.6.10, so we'll
+ * ignore it in our wrapper.
+ */
+#ifndef MODULE_VERSION
+#define MODULE_VERSION(_version) MODULE_INFO(version, _version)
+#endif
+
+#endif /* __COMPAT_MODULE_H__ */
--- kernel/linux-2.6.26.3/drivers/misc/vmmemctl/compat_page.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmmemctl/compat_page.h	2008-09-03 10:02:10.000000000 -0500
@@ -0,0 +1,75 @@
+/*********************************************************
+ * Copyright (C) 2002 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_PAGE_H__
+#   define __COMPAT_PAGE_H__
+
+
+#include <linux/mm.h>
+#include <asm/page.h>
+
+
+/* The pfn_to_page() API appeared in 2.5.14 and changed to function during 2.6.x */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 0) && !defined(pfn_to_page)
+#   define pfn_to_page(_pfn) (mem_map + (_pfn))
+#   define page_to_pfn(_page) ((_page) - mem_map)
+#endif
+
+
+/* The virt_to_page() API appeared in 2.4.0 --hpreg */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 0) && !defined(virt_to_page)
+#   define virt_to_page(_kvAddr) pfn_to_page(MAP_NR(_kvAddr))
+#endif
+
+
+/*
+ * The get_order() API appeared at some point in 2.3.x, and was then backported
+ * in 2.2.17-21mdk and in the stock 2.2.18. Because we can only detect its
+ * definition through makefile tricks, we provide our own for now --hpreg
+ */
+static inline int
+compat_get_order(unsigned long size) // IN
+{
+   int order;
+
+   size = (size - 1) >> (PAGE_SHIFT - 1);
+   order = -1;
+   do {
+      size >>= 1;
+      order++;
+   } while (size);
+
+   return order;
+}
+
+/* 
+ * BUG() was added to <asm/page.h> in 2.2.18, and was moved to <asm/bug.h>
+ * in 2.5.58.
+ * 
+ * XXX: Technically, this belongs in some sort of "compat_asm_page.h" file, but
+ * since our compatibility wrappers don't distinguish between <asm/xxx.h> and
+ * <linux/xxx.h>, putting it here is reasonable.
+ */
+#ifndef BUG
+#define BUG() do {                                                            \
+   printk("kernel BUG at %s:%d!\n", __FILE__, __LINE__);                      \
+  __asm__ __volatile__(".byte 0x0f,0x0b");                                    \
+} while (0)
+#endif
+
+#endif /* __COMPAT_PAGE_H__ */
--- kernel/linux-2.6.26.3/drivers/misc/vmmemctl/compat_sched.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmmemctl/compat_sched.h	2008-09-03 10:02:10.000000000 -0500
@@ -0,0 +1,291 @@
+/*********************************************************
+ * Copyright (C) 2002 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_SCHED_H__
+#   define __COMPAT_SCHED_H__
+
+
+#include <linux/sched.h>
+
+/* CLONE_KERNEL available in 2.5.35 and higher. */
+#ifndef CLONE_KERNEL
+#define CLONE_KERNEL CLONE_FILES | CLONE_FS | CLONE_SIGHAND
+#endif
+
+/* TASK_COMM_LEN become available in 2.6.11. */
+#ifndef TASK_COMM_LEN
+#define TASK_COMM_LEN 16
+#endif
+
+/* The capable() API appeared in 2.1.92 --hpreg */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 1, 92)
+#   define capable(_capability) suser()
+#endif
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 2, 0)
+#   define need_resched() need_resched
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 3)
+#   define need_resched() (current->need_resched)
+#endif
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 3)
+#   define cond_resched() (need_resched() ? schedule() : (void) 0)
+#endif
+
+/* Oh well.  We need yield...  Happy us! */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 20)
+#   ifdef __x86_64__
+#      define compat_yield() there_is_nothing_like_yield()
+#   else
+#      include <linux/unistd.h>
+#      include <linux/kernel.h>
+
+/*
+ * Used by _syscallX macros. Note that this is global variable, so
+ * do not rely on its contents too much. As exit() is only function
+ * we use, and we never check return value from exit(), we have
+ * no problem...
+ */
+extern int errno;
+
+/*
+ * compat_exit() provides an access to the exit() function. It must 
+ * be named compat_exit(), as exit() (with different signature) is 
+ * provided by x86-64, arm and other (but not by i386).
+ */
+#      define __NR_compat_yield __NR_sched_yield
+static inline _syscall0(int, compat_yield);
+#   endif
+#else
+#   define compat_yield() yield()
+#endif
+
+
+/*
+ * Since 2.5.34 there are two methods to enumerate tasks:
+ * for_each_process(p) { ... } which enumerates only tasks and
+ * do_each_thread(g,t) { ... } while_each_thread(g,t) which enumerates
+ *     also threads even if they share same pid.
+ */
+#ifndef for_each_process
+#   define for_each_process(p) for_each_task(p)
+#endif
+
+#ifndef do_each_thread
+#   define do_each_thread(g, t) for_each_task(g) { t = g; do
+#   define while_each_thread(g, t) while (0) }
+#endif
+
+
+/*
+ * Lock for signal mask is moving target...
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 40) && defined(CLONE_PID)
+/* 2.4.x without NPTL patches or early 2.5.x */
+#define compat_sigmask_lock sigmask_lock
+#define compat_dequeue_signal_current(siginfo_ptr) \
+   dequeue_signal(&current->blocked, (siginfo_ptr))
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 60) && !defined(INIT_SIGHAND)
+/* RedHat's 2.4.x with first version of NPTL support, or 2.5.40 to 2.5.59 */
+#define compat_sigmask_lock sig->siglock
+#define compat_dequeue_signal_current(siginfo_ptr) \
+   dequeue_signal(&current->blocked, (siginfo_ptr))
+#else
+/* RedHat's 2.4.x with second version of NPTL support, or 2.5.60+. */
+#define compat_sigmask_lock sighand->siglock
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 0)
+#define compat_dequeue_signal_current(siginfo_ptr) \
+   dequeue_signal(&current->blocked, (siginfo_ptr))
+#else
+#define compat_dequeue_signal_current(siginfo_ptr) \
+   dequeue_signal(current, &current->blocked, (siginfo_ptr))
+#endif
+#endif
+
+/*
+ * recalc_sigpending() had task argument in the past
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 29) && defined(CLONE_PID)
+/* 2.4.x without NPTL patches or early 2.5.x */
+#define compat_recalc_sigpending() recalc_sigpending(current)
+#else
+/* RedHat's 2.4.x with NPTL support, or 2.5.29+ */
+#define compat_recalc_sigpending() recalc_sigpending()
+#endif
+
+
+/*
+ * reparent_to_init() was introduced in 2.4.8.  In 2.5.38 (or possibly
+ * earlier, but later than 2.5.31) a call to it was added into
+ * daemonize(), so compat_daemonize no longer needs to call it.
+ *
+ * In 2.4.x kernels reparent_to_init() forgets to do correct refcounting
+ * on current->user. It is better to count one too many than one too few...
+ */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 4, 8) && LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 38)
+#define compat_reparent_to_init() do { \
+					reparent_to_init(); \
+					atomic_inc(&current->user->__count); \
+				  } while (0)
+#else
+#define compat_reparent_to_init() do {} while (0)
+#endif
+
+
+/*
+ * daemonize appeared in 2.2.18. Except 2.2.17-4-RH7.0, which has it too.
+ * Fortunately 2.2.17-4-RH7.0 uses versioned symbols, so we can check
+ * its existence with defined().
+ */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2, 2, 18)) && !defined(daemonize)
+static inline void daemonize(void) {
+   struct fs_struct *fs;
+
+   exit_mm(current);
+   current->session = 1;
+   current->pgrp = 1;
+   exit_fs(current);
+   fs = init_task.fs;
+   current->fs = fs;
+   atomic_inc(&fs->count);
+}
+#endif
+
+
+/*
+ * flush_signals acquires sighand->siglock since 2.5.61... Verify RH's kernels!
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 61)
+#define compat_flush_signals(task) do { \
+				      spin_lock_irq(&task->compat_sigmask_lock); \
+				      flush_signals(task); \
+				      spin_unlock_irq(&task->compat_sigmask_lock); \
+				   } while (0)
+#else
+#define compat_flush_signals(task) flush_signals(task)
+#endif
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 61)
+#define compat_allow_signal(signr) do { \
+                                      spin_lock_irq(&current->compat_sigmask_lock); \
+                                      sigdelset(&current->blocked, signr); \
+                                      compat_recalc_sigpending(); \
+                                      spin_unlock_irq(&current->compat_sigmask_lock); \
+                                   } while (0)
+#else
+#define compat_allow_signal(signr) allow_signal(signr)
+#endif
+
+/*
+ * daemonize can set process name since 2.5.61. Prior to 2.5.61, daemonize
+ * didn't block signals on our behalf.
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 61)
+#define compat_daemonize(x...)                                                \
+({                                                                            \
+   /* Beware! No snprintf here, so verify arguments! */                       \
+   sprintf(current->comm, x);                                                 \
+                                                                              \
+   /* Block all signals. */                                                   \
+   spin_lock_irq(&current->compat_sigmask_lock);                              \
+   sigfillset(&current->blocked);                                             \
+   compat_recalc_sigpending();                                                \
+   spin_unlock_irq(&current->compat_sigmask_lock);                            \
+   compat_flush_signals(current);                                             \
+                                                                              \
+   daemonize();                                                               \
+   compat_reparent_to_init();                                                 \
+})
+#else
+#define compat_daemonize(x...) daemonize(x)
+#endif
+
+
+/*
+ * set priority for specified thread. Exists on 2.6.x kernels and some
+ * 2.4.x vendor's kernels.
+ */
+#if defined(VMW_HAVE_SET_USER_NICE)
+#define compat_set_user_nice(task, n) set_user_nice((task), (n))
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 0)
+#define compat_set_user_nice(task, n) do { (task)->priority = 20 - (n); } while (0)
+#elif !defined(VMW_HAVE_SET_USER_NICE)
+#define compat_set_user_nice(task, n) do { (task)->nice = (n); } while (0)
+#endif
+
+/*
+ * try to freeze a process. For kernels 2.6.11 or newer, we know how to choose
+ * the interface. The problem is that the oldest interface, introduced in
+ * 2.5.18, was backported to 2.4.x kernels. So if we're older than 2.6.11,
+ * we'll decide what to do based on whether or not swsusp was configured
+ * for the kernel.  For kernels 2.6.20 and newer, we'll also need to include
+ * freezer.h since the try_to_freeze definition was pulled out of sched.h.
+ */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 20)
+#include <linux/freezer.h>
+#endif
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 13) || defined(VMW_TL10S64_WORKAROUND)
+#define compat_try_to_freeze() try_to_freeze()
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 11)
+#define compat_try_to_freeze() try_to_freeze(PF_FREEZE)
+#elif defined(CONFIG_SOFTWARE_SUSPEND) || defined(CONFIG_SOFTWARE_SUSPEND2)
+#include "compat_mm.h"
+#include <linux/errno.h>
+#include <linux/suspend.h>
+static inline int compat_try_to_freeze(void)  { 
+   if (current->flags & PF_FREEZE) {
+      refrigerator(PF_FREEZE); 
+      return 1;
+   } else {
+      return 0;
+   }
+}
+#else
+static inline int compat_try_to_freeze(void) { return 0; }
+#endif
+
+/*
+ * As of 2.6.23-rc1, kernel threads are no longer freezable by
+ * default. Instead, kernel threads that need to be frozen must opt-in
+ * by calling set_freezable() as soon as the thread is created.
+ */
+
+#if LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 22)
+#define compat_set_freezable() do { set_freezable(); } while (0)
+#else
+#define compat_set_freezable() do {} while (0)
+#endif
+
+/*
+ * Since 2.6.27-rc2 kill_proc() is gone... Replacement (GPL-only!)
+ * API is available since 2.6.19.  Use them from 2.6.27-rc1 up.
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 27)
+typedef int compat_pid;
+#define compat_find_get_pid(pid) (pid)
+#define compat_put_pid(pid) do { } while (0)
+#define compat_kill_pid(pid, sig, flag) kill_proc(pid, sig, flag)
+#else
+typedef struct pid * compat_pid;
+#define compat_find_get_pid(pid) find_get_pid(pid)
+#define compat_put_pid(pid) put_pid(pid)
+#define compat_kill_pid(pid, sig, flag) kill_pid(pid, sig, flag)
+#endif
+
+
+#endif /* __COMPAT_SCHED_H__ */
--- kernel/linux-2.6.26.3/drivers/misc/vmmemctl/compat_semaphore.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmmemctl/compat_semaphore.h	2008-09-03 10:02:10.000000000 -0500
@@ -0,0 +1,49 @@
+/*********************************************************
+ * Copyright (C) 2002 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_SEMAPHORE_H__
+#   define __COMPAT_SEMAPHORE_H__
+
+
+/* <= 2.6.25 have asm only, 2.6.26 has both, and 2.6.27-rc2+ has linux only. */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 27)
+#   include <asm/semaphore.h>
+#else
+#   include <linux/semaphore.h>
+#endif
+
+
+/*
+* The init_MUTEX_LOCKED() API appeared in 2.2.18, and is also in
+* 2.2.17-21mdk --hpreg
+*/
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 2, 18)
+   #ifndef init_MUTEX_LOCKED
+      #define init_MUTEX_LOCKED(_sem) *(_sem) = MUTEX_LOCKED
+   #endif
+   #ifndef DECLARE_MUTEX
+      #define DECLARE_MUTEX(name) struct semaphore name = MUTEX
+   #endif
+   #ifndef DECLARE_MUTEX_LOCKED
+      #define DECLARE_MUTEX_LOCKED(name) struct semaphore name = MUTEX_LOCKED
+   #endif
+#endif
+
+
+#endif /* __COMPAT_SEMAPHORE_H__ */
--- kernel/linux-2.6.26.3/drivers/misc/vmmemctl/compat_spinlock.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmmemctl/compat_spinlock.h	2008-09-03 10:02:10.000000000 -0500
@@ -0,0 +1,68 @@
+/*********************************************************
+ * Copyright (C) 2005 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_SPINLOCK_H__
+#   define __COMPAT_SPINLOCK_H__
+
+
+/*
+ * The spin_lock() API appeared in 2.1.25 in asm/smp_lock.h
+ * It moved in 2.1.30 to asm/spinlock.h
+ * It moved again in 2.3.18 to linux/spinlock.h
+ *
+ *   --hpreg
+ */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 3, 18)
+#   include <linux/spinlock.h>
+#else
+#   if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 1, 30)
+#      include <asm/spinlock.h>
+#   else
+typedef struct {} spinlock_t;
+#      define spin_lock_init(lock)
+#      define spin_lock(lock)
+#      define spin_unlock(lock)
+#      define spin_lock_irqsave(lock, flags) do {      \
+                    save_flags(flags);                 \
+                    cli();                             \
+                    spin_lock(lock);                   \
+                 } while (0)
+#      define spin_unlock_irqrestore(lock, flags) do { \
+                    spin_unlock(lock);                 \
+                    restore_flags(flags);              \
+                 } while (0)
+#   endif
+#endif
+
+
+/*
+ * Preempt support was added during 2.5.x development cycle, and later
+ * it was backported to 2.4.x.  In 2.4.x backport these definitions
+ * live in linux/spinlock.h, that's why we put them here (in 2.6.x they
+ * are defined in linux/preempt.h which is included by linux/spinlock.h).
+ */
+#ifdef CONFIG_PREEMPT
+#define compat_preempt_disable() preempt_disable()
+#define compat_preempt_enable()  preempt_enable()
+#else
+#define compat_preempt_disable() do { } while (0)
+#define compat_preempt_enable()  do { } while (0)
+#endif
+
+
+#endif /* __COMPAT_SPINLOCK_H__ */
--- kernel/linux-2.6.26.3/drivers/misc/vmmemctl/compat_version.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmmemctl/compat_version.h	2008-09-03 10:02:10.000000000 -0500
@@ -0,0 +1,121 @@
+/*********************************************************
+ * Copyright (C) 1998 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_VERSION_H__
+#   define __COMPAT_VERSION_H__
+
+#define INCLUDE_ALLOW_VMMON
+#define INCLUDE_ALLOW_MODULE
+#define INCLUDE_ALLOW_VMCORE
+#define INCLUDE_ALLOW_VMNIXMOD
+#define INCLUDE_ALLOW_DISTRIBUTE
+#include "includeCheck.h"
+
+
+#ifndef __linux__
+#   error "linux-version.h"
+#endif
+
+
+#include <linux/version.h>
+
+/* Appeared in 2.1.90 --hpreg */
+#ifndef KERNEL_VERSION
+#   define KERNEL_VERSION(a, b, c) (((a) << 16) + ((b) << 8) + (c))
+#endif
+
+
+/*
+ * Distinguish relevant classes of Linux kernels.
+ *
+ * The convention is that version X defines all
+ * the KERNEL_Y symbols where Y <= X.
+ *
+ * XXX Do not add more definitions here. This way of doing things does not
+ *     scale, and we are going to phase it out soon --hpreg
+ */
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 1, 0)
+#   define KERNEL_2_1
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 2, 0)
+#   define KERNEL_2_2
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 3, 1)
+#   define KERNEL_2_3_1
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 3, 15)
+/*   new networking */
+#   define KERNEL_2_3_15
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 3, 25)
+/*  new procfs */
+#   define KERNEL_2_3_25
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 3, 29)
+/*  even newer procfs */
+#   define KERNEL_2_3_29
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 3, 43)
+/*  softnet changes */
+#   define KERNEL_2_3_43
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 3, 47)
+/*  more softnet changes */
+#   define KERNEL_2_3_47
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 3, 99)
+/*  name in netdevice struct is array and not pointer */
+#   define KERNEL_2_3_99
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 4, 0)
+/*  New 'owner' member at the beginning of struct file_operations */
+#      define KERNEL_2_4_0
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 4, 8)
+/*  New netif_rx_ni() --hpreg */
+#   define KERNEL_2_4_8
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 4, 22)
+/*  New vmap() */
+#   define KERNEL_2_4_22
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 5, 2)
+/*  New kdev_t, major()/minor() API --hpreg */
+#   define KERNEL_2_5_2
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 5, 5)
+/*  New sk_alloc(), pte_offset_map()/pte_unmap() --hpreg */
+#   define KERNEL_2_5_5
+#endif
+
+
+#endif /* __COMPAT_VERSION_H__ */
--- kernel/linux-2.6.26.3/drivers/misc/vmmemctl/compat_wait.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmmemctl/compat_wait.h	2008-09-03 10:02:10.000000000 -0500
@@ -0,0 +1,225 @@
+/*********************************************************
+ * Copyright (C) 2002 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_WAIT_H__
+#   define __COMPAT_WAIT_H__
+
+
+#include <linux/wait.h>
+#include <linux/poll.h>
+#include <linux/file.h>
+
+#include "compat_file.h"
+
+
+/*
+ * The DECLARE_WAITQUEUE() API appeared in 2.3.1
+ * It was back ported in 2.2.18
+ *
+ *  --hpreg
+ */
+
+#ifndef DECLARE_WAITQUEUE
+
+typedef struct wait_queue *wait_queue_head_t;
+#   define init_waitqueue_head(_headPtr) *(_headPtr) = NULL
+#   define DECLARE_WAITQUEUE(_var, _task) \
+   struct wait_queue _var = {_task, NULL, }
+
+typedef struct wait_queue wait_queue_t;
+#   define init_waitqueue_entry(_wait, _task) ((_wait)->task = (_task))
+
+#endif
+
+/*
+ * The 'struct poll_wqueues' appeared in 2.5.48, when global
+ * /dev/epoll interface was added.  It was backported to the
+ * 2.4.20-wolk4.0s.
+ */
+
+#ifdef VMW_HAVE_EPOLL // {
+#define compat_poll_wqueues struct poll_wqueues
+#else // } {
+#define compat_poll_wqueues poll_table
+#endif // }
+
+#ifdef VMW_HAVE_EPOLL // {
+
+/* If prototype does not match, build will abort here */
+extern void poll_initwait(compat_poll_wqueues *);
+
+#define compat_poll_initwait(wait, table) ( \
+   poll_initwait((table)), \
+   (wait) = &(table)->pt \
+)
+
+#define compat_poll_freewait(wait, table) ( \
+   poll_freewait((table)) \
+)
+
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(2, 4, 0) // {
+
+/* If prototype does not match, build will abort here */
+extern void poll_initwait(compat_poll_wqueues *);
+
+#define compat_poll_initwait(wait, table) ( \
+   (wait) = (table), \
+   poll_initwait(wait) \
+)
+
+#define compat_poll_freewait(wait, table) ( \
+   poll_freewait((table)) \
+)
+
+#else // } {
+
+#define compat_poll_initwait(wait, table) ( \
+   (wait) = (table), /* confuse compiler */ \
+   (wait) = (poll_table *) __get_free_page(GFP_KERNEL), \
+   (wait)->nr = 0, \
+   (wait)->entry = (struct poll_table_entry *)((wait) + 1), \
+   (wait)->next = NULL \
+)
+
+static inline void
+poll_freewait(poll_table *wait)
+{
+   while (wait) {
+      struct poll_table_entry * entry;
+      poll_table *old;
+
+      entry = wait->entry + wait->nr;
+      while (wait->nr > 0) {
+	 wait->nr--;
+	 entry--;
+	 remove_wait_queue(entry->wait_address, &entry->wait);
+	 compat_fput(entry->filp);
+      }
+      old = wait;
+      wait = wait->next;
+      free_page((unsigned long) old);
+   }
+}
+
+#define compat_poll_freewait(wait, table) ( \
+   poll_freewait((wait)) \
+)
+
+#endif // }
+
+/*
+ * The wait_event_interruptible_timeout() interface is not
+ * defined in pre-2.6 kernels.
+ */
+#ifndef wait_event_interruptible_timeout
+#define __wait_event_interruptible_timeout(wq, condition, ret)		\
+do {									\
+   wait_queue_t __wait;						        \
+   init_waitqueue_entry(&__wait, current);				\
+									\
+   add_wait_queue(&wq, &__wait);					\
+   for (;;) {							        \
+      set_current_state(TASK_INTERRUPTIBLE);			        \
+      if (condition)						        \
+	 break;						                \
+      if (!signal_pending(current)) {				        \
+	 ret = schedule_timeout(ret);			                \
+	 if (!ret)					                \
+	    break;					                \
+	 continue;					                \
+      }							                \
+      ret = -ERESTARTSYS;					        \
+      break;							        \
+   }								        \
+   set_current_state(TASK_RUNNING);				        \
+   remove_wait_queue(&wq, &__wait);				        \
+} while (0)
+
+#define wait_event_interruptible_timeout(wq, condition, timeout)	\
+({									\
+   long __ret = timeout;						\
+   if (!(condition))						        \
+      __wait_event_interruptible_timeout(wq, condition, __ret);         \
+   __ret;								\
+})
+#endif
+
+/*
+ * The wait_event_timeout() interface is not
+ * defined in pre-2.6 kernels.
+ */
+#ifndef wait_event_timeout
+#define __wait_event_timeout(wq, condition, ret)        		\
+do {									\
+   wait_queue_t __wait;						        \
+   init_waitqueue_entry(&__wait, current);				\
+									\
+   add_wait_queue(&wq, &__wait);					\
+   for (;;) {							        \
+      set_current_state(TASK_UNINTERRUPTIBLE);        	                \
+      if (condition)						        \
+         break;						                \
+      ret = schedule_timeout(ret);			                \
+      if (!ret)					                        \
+         break;					                        \
+   }								        \
+   set_current_state(TASK_RUNNING);				        \
+   remove_wait_queue(&wq, &__wait);				        \
+} while (0)
+
+#define wait_event_timeout(wq, condition, timeout)	                \
+({									\
+   long __ret = timeout;						\
+   if (!(condition))						        \
+      __wait_event_timeout(wq, condition, __ret);                       \
+   __ret;								\
+})
+#endif
+
+/*
+ * DEFINE_WAIT() and friends were added in 2.5.39 and backported to 2.4.28.
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 28) || \
+   (LINUX_VERSION_CODE >= KERNEL_VERSION(2, 5, 0) && \
+    LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 39))
+# define COMPAT_DEFINE_WAIT(_wait)                              \
+   DECLARE_WAITQUEUE(_wait, current)
+# define compat_init_prepare_to_wait(_sleep, _wait, _state)     \
+   do {                                                         \
+      __set_current_state(_state);                              \
+      add_wait_queue(_sleep, _wait);                            \
+   } while (0)
+# define compat_cont_prepare_to_wait(_sleep, _wait, _state)     \
+   set_current_state(_state)
+# define compat_finish_wait(_sleep, _wait, _state)              \
+   do {                                                         \
+      __set_current_state(_state);                              \
+      remove_wait_queue(_sleep, _wait);                         \
+   } while (0)
+#else
+# define COMPAT_DEFINE_WAIT(_wait)                              \
+   DEFINE_WAIT(_wait)
+# define compat_init_prepare_to_wait(_sleep, _wait, _state)     \
+   prepare_to_wait(_sleep, _wait, _state)
+# define compat_cont_prepare_to_wait(_sleep, _wait, _state)     \
+   prepare_to_wait(_sleep, _wait, _state)
+# define compat_finish_wait(_sleep, _wait, _state)              \
+   finish_wait(_sleep, _wait)
+#endif
+
+#endif /* __COMPAT_WAIT_H__ */
--- kernel/linux-2.6.26.3/drivers/misc/vmmemctl/COPYING	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmmemctl/COPYING	2008-09-03 09:57:34.000000000 -0500
@@ -0,0 +1,339 @@
+		    GNU GENERAL PUBLIC LICENSE
+		       Version 2, June 1991
+
+ Copyright (C) 1989, 1991 Free Software Foundation, Inc.,
+ 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ Everyone is permitted to copy and distribute verbatim copies
+ of this license document, but changing it is not allowed.
+
+			    Preamble
+
+  The licenses for most software are designed to take away your
+freedom to share and change it.  By contrast, the GNU General Public
+License is intended to guarantee your freedom to share and change free
+software--to make sure the software is free for all its users.  This
+General Public License applies to most of the Free Software
+Foundation's software and to any other program whose authors commit to
+using it.  (Some other Free Software Foundation software is covered by
+the GNU Lesser General Public License instead.)  You can apply it to
+your programs, too.
+
+  When we speak of free software, we are referring to freedom, not
+price.  Our General Public Licenses are designed to make sure that you
+have the freedom to distribute copies of free software (and charge for
+this service if you wish), that you receive source code or can get it
+if you want it, that you can change the software or use pieces of it
+in new free programs; and that you know you can do these things.
+
+  To protect your rights, we need to make restrictions that forbid
+anyone to deny you these rights or to ask you to surrender the rights.
+These restrictions translate to certain responsibilities for you if you
+distribute copies of the software, or if you modify it.
+
+  For example, if you distribute copies of such a program, whether
+gratis or for a fee, you must give the recipients all the rights that
+you have.  You must make sure that they, too, receive or can get the
+source code.  And you must show them these terms so they know their
+rights.
+
+  We protect your rights with two steps: (1) copyright the software, and
+(2) offer you this license which gives you legal permission to copy,
+distribute and/or modify the software.
+
+  Also, for each author's protection and ours, we want to make certain
+that everyone understands that there is no warranty for this free
+software.  If the software is modified by someone else and passed on, we
+want its recipients to know that what they have is not the original, so
+that any problems introduced by others will not reflect on the original
+authors' reputations.
+
+  Finally, any free program is threatened constantly by software
+patents.  We wish to avoid the danger that redistributors of a free
+program will individually obtain patent licenses, in effect making the
+program proprietary.  To prevent this, we have made it clear that any
+patent must be licensed for everyone's free use or not licensed at all.
+
+  The precise terms and conditions for copying, distribution and
+modification follow.
+
+		    GNU GENERAL PUBLIC LICENSE
+   TERMS AND CONDITIONS FOR COPYING, DISTRIBUTION AND MODIFICATION
+
+  0. This License applies to any program or other work which contains
+a notice placed by the copyright holder saying it may be distributed
+under the terms of this General Public License.  The "Program", below,
+refers to any such program or work, and a "work based on the Program"
+means either the Program or any derivative work under copyright law:
+that is to say, a work containing the Program or a portion of it,
+either verbatim or with modifications and/or translated into another
+language.  (Hereinafter, translation is included without limitation in
+the term "modification".)  Each licensee is addressed as "you".
+
+Activities other than copying, distribution and modification are not
+covered by this License; they are outside its scope.  The act of
+running the Program is not restricted, and the output from the Program
+is covered only if its contents constitute a work based on the
+Program (independent of having been made by running the Program).
+Whether that is true depends on what the Program does.
+
+  1. You may copy and distribute verbatim copies of the Program's
+source code as you receive it, in any medium, provided that you
+conspicuously and appropriately publish on each copy an appropriate
+copyright notice and disclaimer of warranty; keep intact all the
+notices that refer to this License and to the absence of any warranty;
+and give any other recipients of the Program a copy of this License
+along with the Program.
+
+You may charge a fee for the physical act of transferring a copy, and
+you may at your option offer warranty protection in exchange for a fee.
+
+  2. You may modify your copy or copies of the Program or any portion
+of it, thus forming a work based on the Program, and copy and
+distribute such modifications or work under the terms of Section 1
+above, provided that you also meet all of these conditions:
+
+    a) You must cause the modified files to carry prominent notices
+    stating that you changed the files and the date of any change.
+
+    b) You must cause any work that you distribute or publish, that in
+    whole or in part contains or is derived from the Program or any
+    part thereof, to be licensed as a whole at no charge to all third
+    parties under the terms of this License.
+
+    c) If the modified program normally reads commands interactively
+    when run, you must cause it, when started running for such
+    interactive use in the most ordinary way, to print or display an
+    announcement including an appropriate copyright notice and a
+    notice that there is no warranty (or else, saying that you provide
+    a warranty) and that users may redistribute the program under
+    these conditions, and telling the user how to view a copy of this
+    License.  (Exception: if the Program itself is interactive but
+    does not normally print such an announcement, your work based on
+    the Program is not required to print an announcement.)
+
+These requirements apply to the modified work as a whole.  If
+identifiable sections of that work are not derived from the Program,
+and can be reasonably considered independent and separate works in
+themselves, then this License, and its terms, do not apply to those
+sections when you distribute them as separate works.  But when you
+distribute the same sections as part of a whole which is a work based
+on the Program, the distribution of the whole must be on the terms of
+this License, whose permissions for other licensees extend to the
+entire whole, and thus to each and every part regardless of who wrote it.
+
+Thus, it is not the intent of this section to claim rights or contest
+your rights to work written entirely by you; rather, the intent is to
+exercise the right to control the distribution of derivative or
+collective works based on the Program.
+
+In addition, mere aggregation of another work not based on the Program
+with the Program (or with a work based on the Program) on a volume of
+a storage or distribution medium does not bring the other work under
+the scope of this License.
+
+  3. You may copy and distribute the Program (or a work based on it,
+under Section 2) in object code or executable form under the terms of
+Sections 1 and 2 above provided that you also do one of the following:
+
+    a) Accompany it with the complete corresponding machine-readable
+    source code, which must be distributed under the terms of Sections
+    1 and 2 above on a medium customarily used for software interchange; or,
+
+    b) Accompany it with a written offer, valid for at least three
+    years, to give any third party, for a charge no more than your
+    cost of physically performing source distribution, a complete
+    machine-readable copy of the corresponding source code, to be
+    distributed under the terms of Sections 1 and 2 above on a medium
+    customarily used for software interchange; or,
+
+    c) Accompany it with the information you received as to the offer
+    to distribute corresponding source code.  (This alternative is
+    allowed only for noncommercial distribution and only if you
+    received the program in object code or executable form with such
+    an offer, in accord with Subsection b above.)
+
+The source code for a work means the preferred form of the work for
+making modifications to it.  For an executable work, complete source
+code means all the source code for all modules it contains, plus any
+associated interface definition files, plus the scripts used to
+control compilation and installation of the executable.  However, as a
+special exception, the source code distributed need not include
+anything that is normally distributed (in either source or binary
+form) with the major components (compiler, kernel, and so on) of the
+operating system on which the executable runs, unless that component
+itself accompanies the executable.
+
+If distribution of executable or object code is made by offering
+access to copy from a designated place, then offering equivalent
+access to copy the source code from the same place counts as
+distribution of the source code, even though third parties are not
+compelled to copy the source along with the object code.
+
+  4. You may not copy, modify, sublicense, or distribute the Program
+except as expressly provided under this License.  Any attempt
+otherwise to copy, modify, sublicense or distribute the Program is
+void, and will automatically terminate your rights under this License.
+However, parties who have received copies, or rights, from you under
+this License will not have their licenses terminated so long as such
+parties remain in full compliance.
+
+  5. You are not required to accept this License, since you have not
+signed it.  However, nothing else grants you permission to modify or
+distribute the Program or its derivative works.  These actions are
+prohibited by law if you do not accept this License.  Therefore, by
+modifying or distributing the Program (or any work based on the
+Program), you indicate your acceptance of this License to do so, and
+all its terms and conditions for copying, distributing or modifying
+the Program or works based on it.
+
+  6. Each time you redistribute the Program (or any work based on the
+Program), the recipient automatically receives a license from the
+original licensor to copy, distribute or modify the Program subject to
+these terms and conditions.  You may not impose any further
+restrictions on the recipients' exercise of the rights granted herein.
+You are not responsible for enforcing compliance by third parties to
+this License.
+
+  7. If, as a consequence of a court judgment or allegation of patent
+infringement or for any other reason (not limited to patent issues),
+conditions are imposed on you (whether by court order, agreement or
+otherwise) that contradict the conditions of this License, they do not
+excuse you from the conditions of this License.  If you cannot
+distribute so as to satisfy simultaneously your obligations under this
+License and any other pertinent obligations, then as a consequence you
+may not distribute the Program at all.  For example, if a patent
+license would not permit royalty-free redistribution of the Program by
+all those who receive copies directly or indirectly through you, then
+the only way you could satisfy both it and this License would be to
+refrain entirely from distribution of the Program.
+
+If any portion of this section is held invalid or unenforceable under
+any particular circumstance, the balance of the section is intended to
+apply and the section as a whole is intended to apply in other
+circumstances.
+
+It is not the purpose of this section to induce you to infringe any
+patents or other property right claims or to contest validity of any
+such claims; this section has the sole purpose of protecting the
+integrity of the free software distribution system, which is
+implemented by public license practices.  Many people have made
+generous contributions to the wide range of software distributed
+through that system in reliance on consistent application of that
+system; it is up to the author/donor to decide if he or she is willing
+to distribute software through any other system and a licensee cannot
+impose that choice.
+
+This section is intended to make thoroughly clear what is believed to
+be a consequence of the rest of this License.
+
+  8. If the distribution and/or use of the Program is restricted in
+certain countries either by patents or by copyrighted interfaces, the
+original copyright holder who places the Program under this License
+may add an explicit geographical distribution limitation excluding
+those countries, so that distribution is permitted only in or among
+countries not thus excluded.  In such case, this License incorporates
+the limitation as if written in the body of this License.
+
+  9. The Free Software Foundation may publish revised and/or new versions
+of the General Public License from time to time.  Such new versions will
+be similar in spirit to the present version, but may differ in detail to
+address new problems or concerns.
+
+Each version is given a distinguishing version number.  If the Program
+specifies a version number of this License which applies to it and "any
+later version", you have the option of following the terms and conditions
+either of that version or of any later version published by the Free
+Software Foundation.  If the Program does not specify a version number of
+this License, you may choose any version ever published by the Free Software
+Foundation.
+
+  10. If you wish to incorporate parts of the Program into other free
+programs whose distribution conditions are different, write to the author
+to ask for permission.  For software which is copyrighted by the Free
+Software Foundation, write to the Free Software Foundation; we sometimes
+make exceptions for this.  Our decision will be guided by the two goals
+of preserving the free status of all derivatives of our free software and
+of promoting the sharing and reuse of software generally.
+
+			    NO WARRANTY
+
+  11. BECAUSE THE PROGRAM IS LICENSED FREE OF CHARGE, THERE IS NO WARRANTY
+FOR THE PROGRAM, TO THE EXTENT PERMITTED BY APPLICABLE LAW.  EXCEPT WHEN
+OTHERWISE STATED IN WRITING THE COPYRIGHT HOLDERS AND/OR OTHER PARTIES
+PROVIDE THE PROGRAM "AS IS" WITHOUT WARRANTY OF ANY KIND, EITHER EXPRESSED
+OR IMPLIED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
+MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE.  THE ENTIRE RISK AS
+TO THE QUALITY AND PERFORMANCE OF THE PROGRAM IS WITH YOU.  SHOULD THE
+PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF ALL NECESSARY SERVICING,
+REPAIR OR CORRECTION.
+
+  12. IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING
+WILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MAY MODIFY AND/OR
+REDISTRIBUTE THE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES,
+INCLUDING ANY GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING
+OUT OF THE USE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED
+TO LOSS OF DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY
+YOU OR THIRD PARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER
+PROGRAMS), EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE
+POSSIBILITY OF SUCH DAMAGES.
+
+		     END OF TERMS AND CONDITIONS
+
+	    How to Apply These Terms to Your New Programs
+
+  If you develop a new program, and you want it to be of the greatest
+possible use to the public, the best way to achieve this is to make it
+free software which everyone can redistribute and change under these terms.
+
+  To do so, attach the following notices to the program.  It is safest
+to attach them to the start of each source file to most effectively
+convey the exclusion of warranty; and each file should have at least
+the "copyright" line and a pointer to where the full notice is found.
+
+    <one line to give the program's name and a brief idea of what it does.>
+    Copyright (C) <year>  <name of author>
+
+    This program is free software; you can redistribute it and/or modify
+    it under the terms of the GNU General Public License as published by
+    the Free Software Foundation; either version 2 of the License, or
+    (at your option) any later version.
+
+    This program is distributed in the hope that it will be useful,
+    but WITHOUT ANY WARRANTY; without even the implied warranty of
+    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+    GNU General Public License for more details.
+
+    You should have received a copy of the GNU General Public License along
+    with this program; if not, write to the Free Software Foundation, Inc.,
+    51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA.
+
+Also add information on how to contact you by electronic and paper mail.
+
+If the program is interactive, make it output a short notice like this
+when it starts in an interactive mode:
+
+    Gnomovision version 69, Copyright (C) year name of author
+    Gnomovision comes with ABSOLUTELY NO WARRANTY; for details type `show w'.
+    This is free software, and you are welcome to redistribute it
+    under certain conditions; type `show c' for details.
+
+The hypothetical commands `show w' and `show c' should show the appropriate
+parts of the General Public License.  Of course, the commands you use may
+be called something other than `show w' and `show c'; they could even be
+mouse-clicks or menu items--whatever suits your program.
+
+You should also get your employer (if you work as a programmer) or your
+school, if any, to sign a "copyright disclaimer" for the program, if
+necessary.  Here is a sample; alter the names:
+
+  Yoyodyne, Inc., hereby disclaims all copyright interest in the program
+  `Gnomovision' (which makes passes at compilers) written by James Hacker.
+
+  <signature of Ty Coon>, 1 April 1989
+  Ty Coon, President of Vice
+
+This General Public License does not permit incorporating your program into
+proprietary programs.  If your program is a subroutine library, you may
+consider it more useful to permit linking proprietary applications with the
+library.  If this is what you want to do, use the GNU Lesser General
+Public License instead of this License.
--- kernel/linux-2.6.26.3/drivers/misc/vmmemctl/driver-config.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmmemctl/driver-config.h	2008-09-03 10:02:10.000000000 -0500
@@ -0,0 +1,78 @@
+/*********************************************************
+ * Copyright (C) 1998 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * Sets the proper defines from the Linux header files
+ *
+ * This file must be included before the inclusion of any kernel header file,
+ * with the exception of linux/autoconf.h and linux/version.h --hpreg
+ */
+
+#ifndef __VMX_CONFIG_H__
+#define __VMX_CONFIG_H__
+
+#define INCLUDE_ALLOW_VMCORE
+#define INCLUDE_ALLOW_VMMON
+#define INCLUDE_ALLOW_MODULE
+#define INCLUDE_ALLOW_VMNIXMOD
+#include "includeCheck.h"
+
+#include <linux/autoconf.h>
+#include "compat_version.h"
+
+/*
+ * We rely on Kernel Module support.  Check here.
+ */
+#ifndef CONFIG_MODULES
+#   error "No Module support in this kernel.  Please configure with CONFIG_MODULES"
+#endif
+
+/*
+ * 2.2 kernels still use __SMP__ (derived from CONFIG_SMP
+ * in the main Makefile), so we do it here.
+ */
+
+#ifdef CONFIG_SMP
+#   define __SMP__ 1
+#endif
+
+#if defined(CONFIG_MODVERSIONS) && defined(KERNEL_2_1)
+#   if LINUX_VERSION_CODE < KERNEL_VERSION(2,5,60)
+/*
+ * MODVERSIONS might be already defined when using kernel's Makefiles.
+ */
+#      ifndef MODVERSIONS
+#         define MODVERSIONS
+#      endif
+#      include <linux/modversions.h>
+#   endif
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 24)
+/*
+ * Force the uintptr_t definition to come from linux/types.h instead of vm_basic_types.h.
+ */
+#   include <linux/types.h>
+#   define _STDINT_H 1
+#endif
+
+#ifndef __KERNEL__
+#   define __KERNEL__
+#endif
+
+#endif
--- kernel/linux-2.6.26.3/drivers/misc/vmmemctl/includeCheck.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmmemctl/includeCheck.h	2008-09-03 10:02:10.000000000 -0500
@@ -0,0 +1,132 @@
+/*********************************************************
+ * Copyright (C) 1998 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * includeCheck.h --
+ *
+ *	Restrict include file use.
+ *
+ * In every .h file, define one or more of these
+ *
+ *	INCLUDE_ALLOW_VMX 
+ *	INCLUDE_ALLOW_USERLEVEL 
+ *	INCLUDE_ALLOW_VMMEXT
+ *	INCLUDE_ALLOW_VMCORE
+ *	INCLUDE_ALLOW_MODULE
+ *      INCLUDE_ALLOW_VMNIXMOD 
+ *	INCLUDE_ALLOW_VMKERNEL 
+ *	INCLUDE_ALLOW_DISTRIBUTE
+ *	INCLUDE_ALLOW_VMK_MODULE
+ *      INCLUDE_ALLOW_VMKDRIVERS
+ *      INCLUDE_ALLOW_VMIROM
+ *
+ * Then include this file.
+ *
+ * Any file that has INCLUDE_ALLOW_DISTRIBUTE defined will potentially
+ * be distributed in source form along with GPLed code.  Ensure
+ * that this is acceptable.
+ */
+
+
+/*
+ * Declare a VMCORE-only variable to help classify object
+ * files.  The variable goes in the common block and does
+ * not create multiple definition link-time conflicts.
+ */
+
+#if defined VMCORE && defined VMX86_DEVEL && defined VMX86_DEBUG && \
+    defined linux && !defined MODULE && \
+    !defined COMPILED_WITH_VMCORE
+#define COMPILED_WITH_VMCORE compiled_with_vmcore
+#ifdef ASM
+        .comm   compiled_with_vmcore, 0
+#else
+        asm(".comm compiled_with_vmcore, 0");
+#endif /* ASM */
+#endif
+
+
+#if defined VMCORE && \
+    !(defined VMX86_VMX || defined VMM || \
+      defined MONITOR_APP || defined VMMON)
+#error "Makefile problem: VMCORE without VMX86_VMX or \
+        VMM or MONITOR_APP or MODULE."
+#endif
+
+#if defined VMCORE && !defined INCLUDE_ALLOW_VMCORE
+#error "The surrounding include file is not allowed in vmcore."
+#endif
+#undef INCLUDE_ALLOW_VMCORE
+
+#if defined VMX86_VMX && !defined VMCORE && \
+    !(defined INCLUDE_ALLOW_VMX || defined INCLUDE_ALLOW_USERLEVEL)
+#error "The surrounding include file is not allowed in the VMX."
+#endif
+#undef INCLUDE_ALLOW_VMX
+
+#if defined USERLEVEL && !defined VMX86_VMX && !defined VMCORE && \
+    !defined INCLUDE_ALLOW_USERLEVEL
+#error "The surrounding include file is not allowed at userlevel."
+#endif
+#undef INCLUDE_ALLOW_USERLEVEL
+
+#if defined VMM && !defined VMCORE && \
+    !defined INCLUDE_ALLOW_VMMEXT
+#error "The surrounding include file is not allowed in the monitor."
+#endif
+#undef INCLUDE_ALLOW_VMMEXT
+
+#if defined MODULE && !defined VMKERNEL_MODULE && !defined VMNIXMOD && \
+    !defined VMMON && !defined INCLUDE_ALLOW_MODULE
+#error "The surrounding include file is not allowed in driver modules."
+#endif
+#undef INCLUDE_ALLOW_MODULE
+
+#if defined VMMON && !defined INCLUDE_ALLOW_VMMON
+#error "The surrounding include file is not allowed in vmmon."
+#endif
+#undef INCLUDE_ALLOW_VMMON
+
+#if defined VMKERNEL && !defined INCLUDE_ALLOW_VMKERNEL
+#error "The surrounding include file is not allowed in the vmkernel."
+#endif
+#undef INCLUDE_ALLOW_VMKERNEL
+
+#if defined GPLED_CODE && !defined INCLUDE_ALLOW_DISTRIBUTE
+#error "The surrounding include file is not allowed in GPL code."
+#endif
+#undef INCLUDE_ALLOW_DISTRIBUTE
+
+#if defined VMKERNEL_MODULE && !defined VMKERNEL && \
+    !defined INCLUDE_ALLOW_VMK_MODULE && !defined INCLUDE_ALLOW_VMKDRIVERS
+#error "The surrounding include file is not allowed in vmkernel modules."
+#endif
+#undef INCLUDE_ALLOW_VMK_MODULE
+#undef INCLUDE_ALLOW_VMKDRIVERS
+
+#if defined VMNIXMOD && !defined INCLUDE_ALLOW_VMNIXMOD
+#ifndef VMNIXMOD_VM
+#error "The surrounding include file is not allowed in vmnixmod."
+#endif
+#endif
+#undef INCLUDE_ALLOW_VMNIXMOD
+
+#if defined VMIROM && ! defined INCLUDE_ALLOW_VMIROM
+#error "The surrounding include file is not allowed in vmirom."
+#endif
+#undef INCLUDE_ALLOW_VMIROM
--- kernel/linux-2.6.26.3/drivers/misc/vmmemctl/Makefile	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmmemctl/Makefile	2008-09-03 09:57:34.000000000 -0500
@@ -0,0 +1,36 @@
+#############################################################
+# Copyright 1998 VMware, Inc.  All rights reserved. 
+#############################################################
+####
+#### This program is free software; you can redistribute it and/or modify it
+#### under the terms of the GNU General Public License as published by the
+#### Free Software Foundation version 2 and no later version.
+####
+#### This program is distributed in the hope that it will be useful, but
+#### WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+#### or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+#### for more details.
+####
+#### You should have received a copy of the GNU General Public License along
+#### with this program; if not, write to the Free Software Foundation, Inc.,
+#### 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+
+####
+####  VMware vmballoon Makefile to be distributed externally
+####
+####
+
+obj-$(CONFIG_VMMEMCTL) += vmmemctl.o
+
+vmmemctl-objs := os.o vmballoon.o
+
+#
+# On a 32-bit machine, strip out 64-bit backdoor code, and vice versa.
+#
+ifeq ($(CONFIG_X86_64),y)
+vmmemctl-objs += backdoorGcc64.o
+else
+vmmemctl-objs += backdoorGcc32.o
+endif
+
+EXTRA_CFLAGS += -DVMW_USING_KBUILD -DVMW_HAVE_EPOLL -DVMW_HAVE_SET_USER_NICE
--- kernel/linux-2.6.26.3/drivers/misc/vmmemctl/os.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmmemctl/os.c	2008-09-03 10:02:10.000000000 -0500
@@ -0,0 +1,654 @@
+/*********************************************************
+ * Copyright (C) 2000 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/* 
+ * os.c --
+ *
+ * 	Wrappers for Linux system functions required by "vmmemctl".
+ *	This allows customers to build their own vmmemctl driver for
+ *	custom versioned kernels without the need for source code.
+ */
+
+/*
+ * Compile-Time Options
+ */
+
+#define	OS_DISABLE_UNLOAD	(0)
+#define	OS_DEBUG		(1)
+
+/*
+ * Includes
+ */
+
+#include "driver-config.h"
+
+#include "compat_module.h"
+#include <linux/types.h>
+#include "compat_kernel.h"
+#include "compat_completion.h"
+#include "compat_mm.h"
+#include <linux/fs.h>
+#include <linux/timer.h>
+#include <linux/interrupt.h>
+#include "compat_sched.h"
+#include <asm/uaccess.h>
+#include "compat_page.h"
+#include "compat_wait.h"
+#include "vmmemctl_version.h"
+
+#ifdef	CONFIG_PROC_FS
+#include <linux/stat.h>
+#include <linux/proc_fs.h>
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 26)
+/*
+ * The get_info callback of proc_dir_entry was removed in 2.6.26.
+ * We must therefore use the seq_file interface from that point on.
+ */
+#define VMW_USE_SEQ_FILE
+#include <linux/seq_file.h>
+#endif
+#endif	/* CONFIG_PROC_FS */
+
+#if	LINUX_VERSION_CODE >= KERNEL_VERSION(2,4,0)
+#include <linux/smp_lock.h>
+#include "compat_kthread.h"
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 9)
+int errno;  /* compat_exit() needs global errno variable. */
+#endif
+
+/*
+ * Compatibility definitions.
+ */
+
+/*
+ * Execute as a separate kernel thread on 2.4.x kernels.
+ * Allow allocations from high memory  on 2.4.x kernels.
+ */
+#define	OS_KTHREAD	(1)
+COMPAT_KTHREAD_DECLARE_STOP_INFO();
+#endif
+
+#include "os.h"
+
+
+/*
+ * Constants
+ */
+
+#ifdef	OS_KTHREAD
+/*
+ * Use __GFP_HIGHMEM to allow pages from HIGHMEM zone. We don't
+ * allow wait (__GFP_WAIT) for NOSLEEP page allocations. Use 
+ * __GFP_NOWARN, if available, to suppress page allocation failure
+ * warnings.
+ */
+#ifdef __GFP_NOWARN
+#define OS_PAGE_ALLOC_NOSLEEP	(__GFP_HIGHMEM|__GFP_NOWARN)
+#else
+#define OS_PAGE_ALLOC_NOSLEEP	(__GFP_HIGHMEM)
+#endif
+
+/*
+ * GFP_ATOMIC allocations dig deep for free pages. Maybe it is
+ * okay because balloon driver uses os_kmalloc_*() to only allocate
+ * few bytes, and the allocation requires a new page only occasionally. 
+ * Still if __GFP_NOMEMALLOC flag is available, then use it to inform
+ * the guest's page allocator not to use emergency pools,
+ */
+#ifdef __GFP_NOWARN
+
+#ifdef __GFP_NOMEMALLOC
+#define OS_KMALLOC_NOSLEEP	(GFP_ATOMIC|__GFP_NOMEMALLOC|__GFP_NOWARN)
+#else
+#define OS_KMALLOC_NOSLEEP	(GFP_ATOMIC|__GFP_NOWARN)
+#endif
+
+#else
+
+#ifdef __GFP_NOMEMALLOC
+#define OS_KMALLOC_NOSLEEP	(GFP_ATOMIC|__GFP_NOMEMALLOC)
+#else
+#define OS_KMALLOC_NOSLEEP	(GFP_ATOMIC)
+#endif
+
+#endif
+/*
+ * Use GFP_HIGHUSER when executing in a separate kernel thread 
+ * context and allocation can sleep.  This is less stressful to
+ * the guest memory system, since it allows the thread to block
+ * while memory is reclaimed, and won't take pages from emergency
+ * low-memory pools.
+ */
+#define	OS_PAGE_ALLOC_CANSLEEP	(GFP_HIGHUSER)
+
+#else /* OS_KTHREAD not defined */
+
+/* 2.2.x kernel is a special case. The balloon driver is unable
+ * to block (sleep) because it is not executing in a separate kernel 
+ * thread. Therefore, the driver can only use NOSLEEP page 
+ * allocations. 
+ *
+ * Use __GFP_LOW when available (2.2.x kernels) to avoid stressing
+ * the guest memory system, otherwise simply use GFP_ATOMIC, which
+ * is always defined (normally as __GFP_HIGH).
+ */
+#ifdef	__GFP_LOW
+#define	OS_PAGE_ALLOC_NOSLEEP	(__GFP_LOW)
+#define OS_KMALLOC_NOSLEEP	(GFP_ATOMIC)
+#else
+#define	OS_PAGE_ALLOC_NOSLEEP	(GFP_ATOMIC)
+#define OS_KMALLOC_NOSLEEP	(GFP_ATOMIC)
+#endif
+
+#endif
+
+/*
+ * Types
+ */
+
+typedef struct {
+   /* registered state */
+   os_timer_handler handler;
+   void *data;
+   int period;
+
+   /* system structures */
+#ifdef	OS_KTHREAD   
+   wait_queue_head_t delay;
+   struct task_struct *task;
+#else
+   /* termination flag */
+   atomic_t stop;
+
+   struct timer_list timer;
+   struct tq_struct task;
+#endif
+} os_timer;
+
+typedef struct {
+   /* registered state */
+   os_status_handler handler;
+   const char *name_verbose;
+   const char *name;
+} os_status;
+
+typedef struct {
+   os_status status;
+   os_timer timer;
+   unsigned int totalMemoryPages;
+} os_state;
+
+/*
+ * Globals
+ */
+
+#ifdef	CONFIG_PROC_FS
+#if	LINUX_VERSION_CODE >= KERNEL_VERSION(2,4,0)
+static struct proc_dir_entry *global_proc_entry;
+#ifdef VMW_USE_SEQ_FILE
+static int os_proc_open(struct inode *, struct file *);
+static struct file_operations global_proc_fops = {
+   .open = os_proc_open,
+   .read = seq_read,
+   .llseek = seq_lseek,
+   .release = single_release,
+};
+#else
+static int os_proc_read(char *, char **, off_t, int);
+#endif /* VMW_USE_SEQ_FILE */
+#else
+static int os_proc_read(char *, char **, off_t, int, int);
+static struct proc_dir_entry global_proc_entry = {
+   0, 8, "vmmemctl", S_IFREG | S_IRUGO, 1, 0, 0, 0, NULL, os_proc_read,
+};
+#endif
+#endif	/* CONFIG_PROC_FS */
+
+static os_state global_state;
+
+/*
+ * Simple Wrappers
+ */
+
+void * CDECL
+os_kmalloc_nosleep(unsigned int size)
+{
+   return(kmalloc(size, OS_KMALLOC_NOSLEEP));
+}
+
+void CDECL
+os_kfree(void *obj, unsigned int size)
+{
+   kfree(obj);
+}
+
+void CDECL
+os_bzero(void *s, unsigned int n)
+{
+   memset(s, 0, n);
+}
+
+void CDECL
+os_memcpy(void *dest, const void *src, unsigned int size)
+{
+   memcpy(dest, src, size);
+}
+
+int CDECL
+os_sprintf(char *str, const char *format, ...)
+{
+   int result;
+   va_list args;
+
+   va_start(args, format);
+   result = vsprintf(str, format, args);
+   va_end(args);
+
+   return(result);
+}
+
+/*
+ * System-Dependent Operations
+ */
+
+char * CDECL
+os_identity(void)
+{
+   return("linux");
+}
+
+/*
+ * Predict the maximum achievable balloon size.
+ *
+ * In 2.4.x and 2.6.x kernels, the balloon driver can guess the number of pages
+ * that can be ballooned. But, for now let us just pass the totalram-size as the 
+ * maximum achievable balloon size. Note that normally (unless guest kernel is
+ * booted with a mem=XX parameter) the totalram-size is equal to alloc.max.
+ *
+ * Returns the maximum achievable balloon size in pages
+ */  
+unsigned int CDECL
+os_predict_max_balloon_pages(void)
+{
+   struct sysinfo info;
+   os_state *state = &global_state;
+
+#if	LINUX_VERSION_CODE >= KERNEL_VERSION(2,4,0)
+
+   /* 
+    * In 2.4.0 and later, si_meminfo() is cheap. Moreover, we want to provide
+    * dynamic max balloon size later. So let us call si_meminfo() every 
+    * iteration. 
+    */
+   si_meminfo(&info);
+   
+   /* In 2.4.x and later kernels, info.totalram is in pages */
+   state->totalMemoryPages = info.totalram;
+   return(state->totalMemoryPages);
+
+#else 
+
+   /* 2.2.x kernel */
+   if (!state->totalMemoryPages) {
+      si_meminfo(&info); /* In 2.2.x, si_meminfo() is a costly operation */
+      /* In 2.2.x kernels, info.totalram is in bytes */
+      state->totalMemoryPages = info.totalram >> PAGE_SHIFT;
+   }
+   return(state->totalMemoryPages);
+
+#endif
+}
+
+/*
+ * Use newer alloc_page() interface on 2.4.x kernels.
+ * Use "struct page *" value as page handle for clients.
+ */
+unsigned long CDECL
+os_addr_to_ppn(unsigned long addr)
+{
+   struct page *page = (struct page *) addr;
+   return(page_to_pfn(page));
+}
+
+unsigned long CDECL
+os_alloc_reserved_page(int can_sleep)
+{
+   struct page *page;
+   /* allocate page */
+   if (can_sleep) {
+#ifdef OS_KTHREAD
+      page = alloc_page(OS_PAGE_ALLOC_CANSLEEP);
+#else
+      return 0;
+#endif
+   } else {
+      page = alloc_page(OS_PAGE_ALLOC_NOSLEEP);
+   }
+   return((unsigned long) page);
+}
+
+void CDECL
+os_free_reserved_page(unsigned long addr)
+{
+   /* deallocate page */
+   struct page *page = (struct page *) addr;
+   __free_page(page);
+}
+
+#ifndef	OS_KTHREAD
+static void os_timer_add(os_timer *t)
+{
+   /* schedule timer callback */
+   struct timer_list *timer = &t->timer;
+   timer->expires = jiffies + t->period;
+   add_timer(timer);
+}
+
+static void os_timer_remove(os_timer *t)
+{
+   /* deschedule timer callback */
+   struct timer_list *timer = &t->timer;
+   (void) del_timer(timer);
+}
+
+static void os_timer_bh(void *data)
+{
+   os_timer *t = (os_timer *) data;
+
+   if (!atomic_read(&t->stop)) {
+      /* execute registered handler, rearm timer */
+      (*(t->handler))(t->data);
+      os_timer_add(t);
+   }
+}
+
+static void os_timer_internal(ulong data)
+{
+   os_timer *t = (os_timer *) data;
+
+   /* perform real work in registered bottom-half handler */
+   queue_task(&t->task, &tq_immediate);
+   mark_bh(IMMEDIATE_BH);
+}
+#endif
+
+void CDECL
+os_timer_init(os_timer_handler handler, void *data, int period)
+{
+   os_timer *t = &global_state.timer;
+   t->handler = handler;
+   t->data = data;
+   t->period = period;
+#ifndef OS_KTHREAD
+   atomic_set(&t->stop, 0);
+   t->task.routine = os_timer_bh;
+   t->task.data = t;
+   /* initialize timer state */
+   init_timer(&t->timer);
+   t->timer.function = os_timer_internal;
+   t->timer.data = (ulong) t;
+#endif
+}
+
+#ifdef	OS_KTHREAD
+static int os_timer_thread_loop(void *data)
+{
+   os_timer *t = (os_timer *) data;
+
+   /* we are running */
+   compat_set_freezable();
+
+   /* main loop */
+   while (1) {
+      /* sleep for specified period */
+      wait_event_interruptible_timeout(t->delay, compat_kthread_should_stop(),
+                                       t->period);
+      compat_try_to_freeze();
+      if (compat_kthread_should_stop()) {
+         break;
+      }
+
+      /* execute registered handler */
+      (*(t->handler))(t->data);
+   }
+
+   /* terminate */
+   return(0);
+}
+
+static int os_timer_thread_start(os_timer *t)
+{
+   os_status *s = &global_state.status;
+
+   /* initialize sync objects */
+   init_waitqueue_head(&t->delay);
+
+   /* create kernel thread */
+   t->task = compat_kthread_run(os_timer_thread_loop, t, "vmmemctl");
+   if (IS_ERR(t->task)) {
+      /* fail */
+      printk(KERN_WARNING "%s: unable to create kernel thread\n", s->name);
+      return(-1);
+   }
+
+   if (OS_DEBUG) {
+      printk(KERN_DEBUG "%s: started kernel thread pid=%d\n", s->name,
+             t->task->pid);
+   }
+
+   return(0);
+}
+
+static void os_timer_thread_stop(os_timer *t)
+{
+   compat_kthread_stop(t->task);
+}
+#endif
+
+void CDECL
+os_timer_start(void)
+{
+   os_timer *t = &global_state.timer;
+
+#ifdef	OS_KTHREAD
+   os_timer_thread_start(t);
+#else
+   /* clear termination flag */
+   atomic_set(&t->stop, 0);
+
+   os_timer_add(t);
+#endif
+}
+
+void CDECL
+os_timer_stop(void)
+{
+   os_timer *t = &global_state.timer;
+
+#ifdef	OS_KTHREAD
+   os_timer_thread_stop(t);
+#else
+   /* set termination flag */
+   atomic_set(&t->stop, 1);
+
+   os_timer_remove(t);
+#endif
+}
+
+unsigned int CDECL
+os_timer_hz(void)
+{
+   return HZ;
+}
+
+void CDECL
+os_yield(void)
+{
+#ifdef OS_KTHREAD
+   cond_resched();
+#else
+   /* Do nothing.  Timer callbacks should not sleep. */
+#endif
+}
+
+#ifdef	CONFIG_PROC_FS
+#ifdef VMW_USE_SEQ_FILE
+static int os_proc_show(struct seq_file *f,
+			void *data)
+{
+   os_status *s = &global_state.status;
+   char *buf = NULL;
+   int err = -1;
+
+   if (s->handler == NULL) {
+      err = 0;
+      goto out;
+   }
+
+   buf = kmalloc(PAGE_SIZE, GFP_KERNEL);
+   if (buf == NULL) {
+      err = -ENOMEM;
+      goto out;
+   }
+
+   s->handler(buf);
+   
+   if (seq_puts(f, buf) != 0) {
+      err = -ENOSPC;
+      goto out;
+   }
+
+   err = 0;
+
+  out:
+   kfree(buf);
+
+   return err;
+}
+
+static int os_proc_open(struct inode *inode,
+			struct file *file)
+{
+   return single_open(file, os_proc_show, NULL);
+}
+
+#else
+#if	LINUX_VERSION_CODE >= KERNEL_VERSION(2,4,0)
+static int os_proc_read(char *buf,
+                        char **start,
+                        off_t offset,
+                        int length)
+#else
+static int os_proc_read(char *buf,
+                        char **start,
+                        off_t offset,
+                        int length,
+                        int unused)
+#endif
+{
+   os_status *s = &global_state.status;
+
+   /* done if no handler */
+   if (s->handler == NULL) {
+      return(0);
+   }
+
+   /* invoke registered handler */
+   return(s->handler(buf));
+}
+#endif /* VMW_USE_SEQ_FILE */
+#endif
+
+void CDECL
+os_init(const char *name,
+        const char *name_verbose,
+        os_status_handler handler)
+{
+   os_state *state = &global_state;
+   static int initialized = 0;
+
+   /* initialize only once */
+   if (initialized++) {
+      return;
+   }
+
+   /* prevent module unload with extra reference */
+   if (OS_DISABLE_UNLOAD) {
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 48)
+      MOD_INC_USE_COUNT;
+#else
+      try_module_get(THIS_MODULE);
+#endif
+   }
+
+   /* zero global state */
+   memset(state, 0, sizeof(global_state));
+
+   /* initialize status state */
+   state->status.handler = handler;
+   state->status.name = name;
+   state->status.name_verbose = name_verbose;
+
+#ifdef	CONFIG_PROC_FS
+   /* register procfs device */
+#if	LINUX_VERSION_CODE >= KERNEL_VERSION(2,4,0)
+   global_proc_entry = create_proc_entry("vmmemctl", S_IFREG | S_IRUGO, NULL);
+   if (global_proc_entry != NULL) {
+#ifdef VMW_USE_SEQ_FILE
+      global_proc_entry->proc_fops = &global_proc_fops;
+#else
+      global_proc_entry->get_info = os_proc_read;
+#endif /* VMW_USE_SEQ_FILE */
+   }
+#else
+   proc_register(&proc_root, &global_proc_entry);
+#endif
+#endif	/* CONFIG_PROC_FS */
+
+   /* log device load */
+   printk(KERN_INFO "%s initialized\n", state->status.name_verbose);
+}
+
+void CDECL
+os_cleanup(void)
+{
+   os_status *s = &global_state.status;
+   int err;
+
+#ifdef	CONFIG_PROC_FS
+   /* unregister procfs entry */
+#if	LINUX_VERSION_CODE >= KERNEL_VERSION(2,4,0)
+   remove_proc_entry("vmmemctl", NULL);
+   err = 0;
+#else
+   if ((err = proc_unregister(&proc_root, global_proc_entry.low_ino)) != 0) {
+      printk(KERN_WARNING "%s: unable to unregister procfs entry (%d)\n", s->name, err);
+   }
+#endif
+#endif	/* CONFIG_PROC_FS */
+
+   /* log device unload */
+   printk(KERN_INFO "%s unloaded\n", s->name_verbose);
+}
+
+/* Module information. */
+MODULE_AUTHOR("VMware, Inc.");
+MODULE_DESCRIPTION("VMware Memory Control Driver");
+MODULE_LICENSE("GPL v2");
+MODULE_VERSION(VMMEMCTL_DRIVER_VERSION_STRING);
--- kernel/linux-2.6.26.3/drivers/misc/vmmemctl/os.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmmemctl/os.h	2008-09-03 10:02:10.000000000 -0500
@@ -0,0 +1,77 @@
+/*********************************************************
+ * Copyright (C) 2000 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/* 
+ * os.h --
+ *
+ * 	Definitions for OS-specific wrapper functions required
+ *	by "vmmemctl".  This allows customers to build their own
+ *	vmmemctl driver for custom versioned kernels without the
+ *	need for source code. 
+ */
+
+#ifndef	OS_H
+#define	OS_H
+
+/*
+ * Needs fixing for 64bit OSes
+ */
+#ifndef __x86_64__
+#define CDECL __attribute__((cdecl, regparm(0)))
+#else
+#define CDECL
+#endif
+
+/*
+ * Types
+ */
+
+typedef void CDECL (*os_timer_handler)(void *);
+typedef int  CDECL (*os_status_handler)(char *);
+
+/*
+ * Operations
+ */
+
+extern void CDECL *os_kmalloc_nosleep(unsigned int size);
+extern void CDECL os_kfree(void *obj, unsigned int size);
+extern void CDECL os_yield(void);
+extern void CDECL os_bzero(void *s, unsigned int n);
+extern void CDECL os_memcpy(void *dest, const void *src, unsigned int size);
+extern int  CDECL os_sprintf(char *str, const char *format, ...);
+
+extern unsigned long CDECL os_addr_to_ppn(unsigned long addr);
+extern unsigned long CDECL os_alloc_reserved_page(int can_sleep);
+extern void          CDECL os_free_reserved_page(unsigned long page);
+
+extern void CDECL os_timer_init(os_timer_handler handler, void *data, int period);
+extern void CDECL os_timer_start(void);
+extern void CDECL os_timer_stop(void);
+
+extern void CDECL os_init(const char *name,
+                          const char *name_verbose,
+                          os_status_handler handler);
+extern void CDECL os_cleanup(void);
+
+extern char CDECL *os_identity(void);
+
+extern unsigned int CDECL os_predict_max_balloon_pages(void);
+
+extern unsigned int CDECL os_timer_hz(void);
+
+#endif  /* OS_H */
--- kernel/linux-2.6.26.3/drivers/misc/vmmemctl/README	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmmemctl/README	2008-09-03 09:57:34.000000000 -0500
@@ -0,0 +1,11 @@
+The files in this directory are the source files for the VMware
+Memory Control driver.  In order to build, make certain the
+Makefile is correct, especially about whether or not your system is
+multi-processor or not, and then just type:
+
+	make
+
+from this directory.  A copy of the module will be left in 'vmmemctl.o',
+which can then be installed in /lib/modules/<kernel-name>/misc.
+
+If you have any problems or questions, send mail to support@vmware.com
--- kernel/linux-2.6.26.3/drivers/misc/vmmemctl/vm_assert.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmmemctl/vm_assert.h	2008-09-03 10:02:10.000000000 -0500
@@ -0,0 +1,317 @@
+/*********************************************************
+ * Copyright (C) 1998-2004 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * vm_assert.h --
+ *
+ *	The basic assertion facility for all VMware code.
+ *
+ *	For proper use, see
+ *	http://vmweb.vmware.com/~mts/WebSite/guide/programming/asserts.html
+ */
+
+#ifndef _VM_ASSERT_H_
+#define _VM_ASSERT_H_
+
+#define INCLUDE_ALLOW_USERLEVEL
+#define INCLUDE_ALLOW_VMMEXT
+#define INCLUDE_ALLOW_MODULE
+#define INCLUDE_ALLOW_VMMON
+#define INCLUDE_ALLOW_VMNIXMOD
+#define INCLUDE_ALLOW_VMKERNEL
+#define INCLUDE_ALLOW_VMKDRIVERS
+#define INCLUDE_ALLOW_VMK_MODULE
+#define INCLUDE_ALLOW_DISTRIBUTE
+#define INCLUDE_ALLOW_VMCORE
+#define INCLUDE_ALLOW_VMIROM
+#include "includeCheck.h"
+
+// XXX not necessary except some places include vm_assert.h improperly
+#include "vm_basic_types.h"
+#include "vm_basic_defs.h"
+
+
+/*
+ * XXX old file code
+ */
+
+#ifdef FILECODEINT
+#error "Don't define FILECODEINT.  It is obsolete."
+#endif
+#ifdef FILECODE
+#error "Don't define FILECODE.  It is obsolete."
+#endif
+
+
+/*
+ * Panic and log functions
+ */
+
+EXTERN void Log(const char *fmt, ...) PRINTF_DECL(1, 2);
+EXTERN void Warning(const char *fmt, ...) PRINTF_DECL(1, 2);
+EXTERN NORETURN void Panic(const char *fmt, ...) PRINTF_DECL(1, 2);
+
+EXTERN void LogThrottled(uint32 *count, const char *fmt, ...)
+            PRINTF_DECL(2, 3);
+EXTERN void WarningThrottled(uint32 *count, const char *fmt, ...)
+            PRINTF_DECL(2, 3);
+
+/* DB family:  messages which are parsed by logfile database system */
+#define WarningDB Warning
+#define LogDB Log
+#define WarningThrottledDB WarningThrottled
+#define LogThrottledDB LogThrottled
+
+
+/*
+ * Stress testing: redefine ASSERT_IFNOT() to taste
+ */
+
+#ifndef ASSERT_IFNOT
+   #ifdef __cplusplus
+      #define ASSERT_IFNOT(cond, panic) (UNLIKELY(!(cond)) ? (panic) : (void)0)
+   #else
+      #define ASSERT_IFNOT(cond, panic) (UNLIKELY(!(cond)) ? (panic) : 0)
+   #endif
+#endif
+
+
+/*
+ * Assert, panic, and log macros
+ *
+ * Some of these are redefined below undef !VMX86_DEBUG.
+ * ASSERT() is special cased because of interaction with Windows DDK.
+ */
+
+#if defined VMX86_DEBUG || defined ASSERT_ALWAYS_AVAILABLE
+#undef ASSERT
+#define ASSERT(cond) \
+           ASSERT_IFNOT(cond, _ASSERT_PANIC(AssertAssert))
+#endif
+#define ASSERT_BUG(bug, cond) \
+           ASSERT_IFNOT(cond, _ASSERT_PANIC_BUG(bug, AssertAssert))
+#define ASSERT_BUG_DEBUGONLY(bug, cond) ASSERT_BUG(bug, cond)
+
+#define PANIC()        _ASSERT_PANIC(AssertPanic)
+#define PANIC_BUG(bug) _ASSERT_PANIC_BUG(bug, AssertPanic)
+
+#define ASSERT_NOT_IMPLEMENTED(cond) \
+           ASSERT_IFNOT(cond, NOT_IMPLEMENTED())
+#define ASSERT_NOT_IMPLEMENTED_BUG(bug, cond) \
+           ASSERT_IFNOT(cond, NOT_IMPLEMENTED_BUG(bug))
+
+#define NOT_IMPLEMENTED()        _ASSERT_PANIC(AssertNotImplemented)
+#define NOT_IMPLEMENTED_BUG(bug) _ASSERT_PANIC_BUG(bug, AssertNotImplemented)
+
+#define NOT_REACHED()            _ASSERT_PANIC(AssertNotReached)
+#define NOT_REACHED_BUG(bug)     _ASSERT_PANIC_BUG(bug, AssertNotReached)
+
+#define ASSERT_MEM_ALLOC(cond) \
+           ASSERT_IFNOT(cond, _ASSERT_PANIC(AssertMemAlloc))
+
+#ifdef VMX86_DEVEL
+   #define ASSERT_LENGTH(real, expected) \
+              ASSERT_IFNOT((real) == (expected), \
+                 Panic(AssertLengthFmt, __FILE__, __LINE__, real, expected))
+#else
+   #define ASSERT_LENGTH(real, expected) ASSERT((real) == (expected))
+#endif
+
+#ifdef VMX86_DEVEL
+   #define ASSERT_DEVEL(cond) ASSERT(cond)
+#else
+   #define ASSERT_DEVEL(cond) ((void) 0)
+#endif
+
+#define ASSERT_NO_INTERRUPTS()  ASSERT(!INTERRUPTS_ENABLED())
+#define ASSERT_HAS_INTERRUPTS() ASSERT(INTERRUPTS_ENABLED())
+
+#define ASSERT_LOG_UNEXPECTED(bug, cond) \
+           (UNLIKELY(!(cond)) ? LOG_UNEXPECTED(bug) : 0)
+#ifdef VMX86_DEVEL
+   #define LOG_UNEXPECTED(bug) \
+              Warning(AssertUnexpectedFmt, __FILE__, __LINE__, bug)
+#else
+   #define LOG_UNEXPECTED(bug) \
+              Log(AssertUnexpectedFmt, __FILE__, __LINE__, bug)
+#endif
+
+#define ASSERT_NOT_TESTED(cond) (UNLIKELY(!(cond)) ? NOT_TESTED() : 0)
+#ifdef VMX86_DEVEL
+   #define NOT_TESTED() Warning(AssertNotTestedFmt, __FILE__, __LINE__)
+#else
+   #define NOT_TESTED() Log(AssertNotTestedFmt, __FILE__, __LINE__)
+#endif
+
+#define NOT_TESTED_ONCE()                                               \
+   do {                                                                 \
+      static Bool alreadyPrinted = FALSE;                               \
+      if (UNLIKELY(!alreadyPrinted)) {                                  \
+	 alreadyPrinted = TRUE;                                         \
+	 NOT_TESTED();                                                  \
+      }                                                                 \
+   } while (0)
+
+#define NOT_TESTED_1024()                                               \
+   do {                                                                 \
+      static uint16 count = 0;                                          \
+      if (UNLIKELY(count == 0)) { NOT_TESTED(); }                       \
+      count = (count + 1) & 1023;                                       \
+   } while (0)
+
+#define LOG_ONCE(_s)                                                    \
+   do {                                                                 \
+      static Bool logged = FALSE;                                       \
+      if (!logged) {                                                    \
+	 Log _s;                                                        \
+         logged = TRUE;                                                 \
+      }                                                                 \
+   } while (0)
+
+
+/*
+ * Redefine macros that are only in debug versions
+ */
+
+#if !defined VMX86_DEBUG && !defined ASSERT_ALWAYS_AVAILABLE // {
+
+#undef  ASSERT
+#define ASSERT(cond) ((void) 0)
+
+#undef  ASSERT_BUG_DEBUGONLY
+#define ASSERT_BUG_DEBUGONLY(bug, cond) ((void) 0)
+
+#undef  ASSERT_LENGTH
+#define ASSERT_LENGTH(real, expected) ((void) 0)
+
+/*
+ * Expand NOT_REACHED() as appropriate for each situation.
+ *
+ * Mainly, we want the compiler to infer the same control-flow
+ * information as it would from Panic().  Otherwise, different
+ * compilation options will lead to different control-flow-derived
+ * errors, causing some make targets to fail while others succeed.
+ *
+ * VC++ has the __assume() built-in function which we don't trust
+ * (see bug 43485); gcc has no such construct; we just panic in
+ * userlevel code.  The monitor doesn't want to pay the size penalty
+ * (measured at 212 bytes for the release vmm for a minimal infinite
+ * loop; panic would cost even more) so it does without and lives
+ * with the inconsistency.
+ */
+
+#ifdef VMM
+#undef  NOT_REACHED
+#define NOT_REACHED() ((void) 0)
+#else
+// keep debug definition
+#endif
+
+#undef  ASSERT_LOG_UNEXPECTED
+#define ASSERT_LOG_UNEXPECTED(bug, cond) ((void) 0)
+
+#undef LOG_UNEXPECTED
+#define LOG_UNEXPECTED(bug) ((void) 0)
+
+#undef  ASSERT_NOT_TESTED
+#define ASSERT_NOT_TESTED(cond) ((void) 0)
+#undef  NOT_TESTED
+#define NOT_TESTED() ((void) 0)
+#undef  NOT_TESTED_ONCE
+#define NOT_TESTED_ONCE() ((void) 0)
+#undef  NOT_TESTED_1024
+#define NOT_TESTED_1024() ((void) 0)
+
+#endif // !VMX86_DEBUG }
+
+
+/*
+ * Compile-time assertions.
+ *
+ * ASSERT_ON_COMPILE does not use the common
+ * switch (0) { case 0: case (e): ; } trick because some compilers (e.g. MSVC)
+ * generate code for it.
+ *
+ * The implementation uses both enum and typedef because the typedef alone is
+ * insufficient; gcc allows arrays to be declared with non-constant expressions
+ * (even in typedefs, where it makes no sense).
+ */
+
+#define ASSERT_ON_COMPILE(e) \
+   do { \
+      enum { AssertOnCompileMisused = ((e) ? 1 : -1) }; \
+      typedef char AssertOnCompileFailed[AssertOnCompileMisused]; \
+   } while (0)
+
+
+/*
+ * To put an ASSERT_ON_COMPILE() outside a function, wrap it
+ * in MY_ASSERTS().  The first parameter must be unique in
+ * each .c file where it appears.  For example,
+ *
+ * MY_ASSERTS(FS3_INT,
+ *    ASSERT_ON_COMPILE(sizeof(FS3_DiskLock) == 128);
+ *    ASSERT_ON_COMPILE(sizeof(FS3_DiskLockReserved) == DISK_BLOCK_SIZE);
+ *    ASSERT_ON_COMPILE(sizeof(FS3_DiskBlock) == DISK_BLOCK_SIZE);
+ *    ASSERT_ON_COMPILE(sizeof(Hardware_DMIUUID) == 16);
+ * )
+ *
+ * Caution: ASSERT() within MY_ASSERTS() is silently ignored.
+ * The same goes for anything else not evaluated at compile time.
+ */
+
+#define MY_ASSERTS(name, assertions) \
+   static INLINE void name(void) { \
+      assertions \
+   }
+
+
+/*
+ * Internal macros, functions, and strings
+ *
+ * The monitor wants to save space at call sites, so it has specialized
+ * functions for each situation.  User level wants to save on implementation
+ * so it uses generic functions.
+ */
+
+#if !defined VMM || defined MONITOR_APP // {
+
+#define _ASSERT_PANIC(name) \
+           Panic(_##name##Fmt "\n", __FILE__, __LINE__)
+#define _ASSERT_PANIC_BUG(bug, name) \
+           Panic(_##name##Fmt " bugNr=%d\n", __FILE__, __LINE__, bug)
+
+#define AssertLengthFmt     _AssertLengthFmt
+#define AssertUnexpectedFmt _AssertUnexpectedFmt
+#define AssertNotTestedFmt  _AssertNotTestedFmt
+
+#endif // }
+
+// these don't have newline so a bug can be tacked on
+#define _AssertPanicFmt            "PANIC %s:%d"
+#define _AssertAssertFmt           "ASSERT %s:%d"
+#define _AssertNotImplementedFmt   "NOT_IMPLEMENTED %s:%d"
+#define _AssertNotReachedFmt       "NOT_REACHED %s:%d"
+#define _AssertMemAllocFmt         "MEM_ALLOC %s:%d"
+
+// these are complete formats with newline
+#define _AssertLengthFmt           "LENGTH %s:%d r=%#x e=%#x\n"
+#define _AssertUnexpectedFmt       "UNEXPECTED %s:%d bugNr=%d\n"
+#define _AssertNotTestedFmt        "NOT_TESTED %s:%d\n"
+
+#endif /* ifndef _VM_ASSERT_H_ */
--- kernel/linux-2.6.26.3/drivers/misc/vmmemctl/vmballoon.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmmemctl/vmballoon.c	2008-09-03 10:02:10.000000000 -0500
@@ -0,0 +1,1546 @@
+/*********************************************************
+ * Copyright (C) 2000 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/* 
+ * vmballoon.c --
+ *
+ * 	VMware server physical memory management driver for Unix-ish
+ * 	(Linux, FreeBSD, Solaris) guests.  The driver acts like a
+ * 	"balloon" that can be inflated to reclaim physical pages by
+ * 	reserving them in the guest and invalidating them in the
+ * 	monitor, freeing up the underlying machine pages so they can
+ * 	be allocated to other guests.  The balloon can also be
+ * 	deflated to allow the guest to use more physical memory.
+ * 	Higher level policies can control the sizes of balloons in VMs
+ * 	in order to manage physical memory resources.
+ */
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+/*
+ * Compile-Time Options
+ */
+
+#define	BALLOON_RATE_ADAPT	(1)
+
+#define	BALLOON_DEBUG		(1)
+#define	BALLOON_DEBUG_VERBOSE	(0)
+
+#define	BALLOON_STATS
+#define BALLOON_STATS_PROCFS
+
+/*
+ * Includes
+ */
+
+#include "balloon_def.h"
+#include "os.h"
+#include "backdoor.h"
+#include "backdoor_balloon.h"
+
+#include "vmballoon.h"
+
+/*
+ * Constants
+ */
+
+#ifndef NULL
+#define NULL 0
+#endif
+
+#define	BALLOON_NAME			"vmmemctl"
+#define	BALLOON_NAME_VERBOSE		"VMware memory control driver"
+
+#define	BALLOON_PROTOCOL_VERSION	(2)
+
+#define	BALLOON_CHUNK_PAGES		(1000)
+
+#define BALLOON_NOSLEEP_ALLOC_MAX	(16384)
+
+#define	BALLOON_RATE_ALLOC_MIN		(512)
+#define	BALLOON_RATE_ALLOC_MAX		(2048)
+#define	BALLOON_RATE_ALLOC_INC		(16)
+
+#define	BALLOON_RATE_FREE_MIN		(512)
+#define	BALLOON_RATE_FREE_MAX		(16384)
+#define	BALLOON_RATE_FREE_INC		(16)
+
+#define	BALLOON_ERROR_PAGES		(16)
+
+/* 
+ * When guest is under memory pressure, use a reduced page allocation
+ * rate for next several cycles.
+ */
+#define SLOW_PAGE_ALLOCATION_CYCLES	(4)
+
+/* 
+ * Move it to bora/public/balloon_def.h later, if needed. Note that
+ * BALLOON_PAGE_ALLOC_FAILURE is an internal error code used for
+ * distinguishing page allocation failures from monitor-backdoor errors.
+ * We use value 1000 because all monitor-backdoor error codes are < 1000.
+ */
+#define BALLOON_PAGE_ALLOC_FAILURE	(1000)
+
+// Maximum number of page allocations without yielding processor
+#define BALLOON_ALLOC_YIELD_THRESHOLD   (1024)
+
+
+/*
+ * Types
+ */
+
+typedef struct BalloonChunk {
+   unsigned long page[BALLOON_CHUNK_PAGES];
+   uint32 nextPage;
+   struct BalloonChunk *prev, *next;
+} BalloonChunk;
+
+typedef struct {
+   unsigned long page[BALLOON_ERROR_PAGES];
+   uint32 nextPage;
+} BalloonErrorPages;
+
+typedef struct {
+   /* sets of reserved physical pages */
+   BalloonChunk *chunks;
+   int nChunks;
+
+   /* transient list of non-balloonable pages */
+   BalloonErrorPages errors;
+
+   /* balloon size */
+   int nPages;
+   int nPagesTarget;
+
+   /* reset flag */
+   int resetFlag;
+
+   /* adjustment rates (pages per second) */
+   int rateAlloc;
+   int rateFree;
+
+   /* slowdown page allocations for next few cycles */
+   int slowPageAllocationCycles;
+
+   /* statistics */
+   BalloonStats stats;
+} Balloon;
+
+/*
+ * Globals
+ */
+
+static Balloon globalBalloon;
+
+/*
+ * Forward Declarations
+ */
+
+static int BalloonGuestType(void);
+
+static unsigned long BalloonPrimAllocPage(BalloonPageAllocType canSleep);
+static void   BalloonPrimFreePage(unsigned long page);
+
+static int  Balloon_AllocPage(Balloon *b, BalloonPageAllocType allocType);
+static int  Balloon_FreePage(Balloon *b, int monitorUnlock);
+static int  Balloon_AdjustSize(Balloon *b, uint32 target);
+static void Balloon_Reset(Balloon *b);
+
+static void Balloon_StartTimer(Balloon *b);
+static void Balloon_StopTimer(Balloon *b);
+static void CDECL Balloon_BH(void *data);
+
+static int Balloon_MonitorStart(Balloon *b);
+static int Balloon_MonitorGuestType(Balloon *b);
+static int Balloon_MonitorGetTarget(Balloon *b, uint32 *nPages);
+static int Balloon_MonitorLockPage(Balloon *b, unsigned long addr);
+static int Balloon_MonitorUnlockPage(Balloon *b, unsigned long addr);
+
+/*
+ * Macros
+ */
+
+#ifndef	MIN
+#define	MIN(a, b)	(((a) < (b)) ? (a) : (b))
+#endif
+#ifndef	MAX
+#define	MAX(a, b)	(((a) > (b)) ? (a) : (b))
+#endif
+
+#ifdef	BALLOON_STATS
+#define	STATS_INC(stat)	(stat)++
+#else
+#define	STATS_INC(stat)
+#endif
+
+/*
+ * Macros to generate operations for simple lists of OBJ.
+ * OBJ must contain next and prev fields.
+ * 
+ */
+
+#define	GENERATE_LIST_INSERT(OBJ)			\
+static void OBJ ## _Insert(OBJ **head, OBJ *obj)	\
+{							\
+   OBJ *h = *head;					\
+							\
+   /* add element to head of list */			\
+   obj->next = h;					\
+   if (h != NULL) {					\
+      h->prev = obj;					\
+   } 							\
+   *head = obj;						\
+   obj->prev = NULL;					\
+}
+
+#define	GENERATE_LIST_REMOVE(OBJ)			\
+static void OBJ ## _Remove(OBJ **head, OBJ *obj)	\
+{							\
+    /* splice element out of list */		  	\
+    if (obj->prev != NULL) {				\
+      obj->prev->next = obj->next;			\
+    } else {						\
+      *head = obj->next;				\
+    }							\
+    if (obj->next != NULL) {				\
+      obj->next->prev = obj->prev;			\
+    }							\
+}
+
+/*
+ * List Operations
+ */
+
+GENERATE_LIST_INSERT(BalloonChunk);
+GENERATE_LIST_REMOVE(BalloonChunk);
+
+/*
+ * Procfs Operations
+ */
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * BalloonProcRead --
+ *
+ *      Ballon driver status reporting routine.  Note that this is only
+ *	used for Linux.
+ *
+ * Results:
+ *      Writes ASCII status information into "buf".
+ *	Returns number of bytes written.
+ *
+ * Side effects:
+ *      None.
+ *
+ *----------------------------------------------------------------------
+ */
+static int CDECL
+BalloonProcRead(char *buf)
+{
+   int len = 0;
+   BalloonStats stats;
+
+   BalloonGetStats(&stats);
+
+   /* format size info */
+   len += os_sprintf(buf + len,
+                     "target:             %8d pages\n"
+                     "current:            %8d pages\n",
+                     stats.nPagesTarget,
+                     stats.nPages);
+
+   /* format rate info */
+   len += os_sprintf(buf + len,
+                     "rateNoSleepAlloc:   %8d pages/sec\n"
+                     "rateSleepAlloc:     %8d pages/sec\n"
+                     "rateFree:           %8d pages/sec\n",
+                     BALLOON_NOSLEEP_ALLOC_MAX,
+                     stats.rateAlloc,
+                     stats.rateFree);
+
+#ifdef	BALLOON_STATS_PROCFS
+   len += os_sprintf(buf + len,
+                     "\n"
+                     "timer:              %8u\n"
+                     "start:              %8u (%4u failed)\n"
+                     "guestType:          %8u (%4u failed)\n"
+                     "lock:               %8u (%4u failed)\n"
+                     "unlock:             %8u (%4u failed)\n"
+                     "target:             %8u (%4u failed)\n"
+                     "primNoSleepAlloc:   %8u (%4u failed)\n"
+                     "primCanSleepAlloc:  %8u (%4u failed)\n"
+                     "primFree:           %8u\n"
+                     "errAlloc:           %8u\n"
+                     "errFree:            %8u\n",
+                     stats.timer,
+                     stats.start, stats.startFail,
+                     stats.guestType, stats.guestTypeFail,
+                     stats.lock,  stats.lockFail,
+                     stats.unlock, stats.unlockFail,
+                     stats.target, stats.targetFail,
+                     stats.primAlloc[BALLOON_PAGE_ALLOC_NOSLEEP],
+                     stats.primAllocFail[BALLOON_PAGE_ALLOC_NOSLEEP],
+                     stats.primAlloc[BALLOON_PAGE_ALLOC_CANSLEEP],
+                     stats.primAllocFail[BALLOON_PAGE_ALLOC_CANSLEEP],
+                     stats.primFree,
+                     stats.primErrorPageAlloc,
+                     stats.primErrorPageFree);
+#endif
+
+   return(len);
+}
+
+/*
+ * Utility Operations
+ */
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * AddrToPPN --
+ *
+ *      Return the physical page number corresponding to the specified
+ *	Linux kernel-mapped address.
+ *
+ * Results:
+ *      Returns PPN for "addr".
+ *
+ * Side effects:
+ *      None.
+ *
+ *----------------------------------------------------------------------
+ */
+static inline unsigned long
+AddrToPPN(unsigned long addr)
+{
+   return(os_addr_to_ppn(addr));
+}
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * BalloonPrimAllocPage --
+ *
+ *      Attempts to allocate and reserve a physical page.
+ *
+ *	If canSleep == 1, i.e., BALLOON_PAGE_ALLOC_CANSLEEP:
+ *	   The allocation can wait (sleep) for page writeout (swap)
+ *	   by the guest.
+ *	otherwise canSleep == 0, i.e., BALLOON_PAGE_ALLOC_NOSLEEP:
+ *	   If allocation of a page requires disk writeout, then
+ *	   just fail. DON'T sleep.
+ *
+ * Results:
+ *      Returns the physical address of the allocated page, or 0 if error.
+ *
+ * Side effects:
+ *      None.
+ *
+ *----------------------------------------------------------------------
+ */
+static unsigned long
+BalloonPrimAllocPage(BalloonPageAllocType canSleep)
+{
+   return(os_alloc_reserved_page(canSleep));
+}
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * BalloonPrimFreePage --
+ *
+ *      Unreserves and deallocates specified physical page.
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      None.
+ *
+ *----------------------------------------------------------------------
+ */
+static void
+BalloonPrimFreePage(unsigned long page)
+{
+   return(os_free_reserved_page(page));
+}
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * BalloonGuestType --
+ *
+ *      Return balloon guest OS identifier obtained by parsing
+ *	system-dependent identity string.
+ *
+ * Results:
+ *      Returns one of BALLOON_GUEST_{LINUX,BSD,SOLARIS,UNKNOWN}.
+ *
+ * Side effects:
+ *      None.
+ *
+ *----------------------------------------------------------------------
+ */
+static int
+BalloonGuestType(void)
+{
+   char *identity;
+
+   /* obtain OS identify string */
+   identity = os_identity();
+   
+   /* unknown if not specified */
+   if (identity == NULL) {
+      return(BALLOON_GUEST_UNKNOWN);
+   }
+
+   /* classify based on first letter (avoid defining strcmp) */
+   switch (identity[0]) {
+   case 'l':
+   case 'L':
+      return(BALLOON_GUEST_LINUX);
+   case 'b':
+   case 'B':
+      return(BALLOON_GUEST_BSD);
+   case 's':
+   case 'S':
+      return(BALLOON_GUEST_SOLARIS);
+   default:
+      break;
+   }
+
+   /* unknown */
+   return(BALLOON_GUEST_UNKNOWN);
+}
+
+/*
+ * Returns information about balloon state, including the current and
+ * target size, rates for allocating and freeing pages, and statistics
+ * about past activity.
+ */
+void BalloonGetStats(BalloonStats *stats)
+{
+   Balloon *b = &globalBalloon;
+
+   /*
+    * Copy statistics out of global structure.
+    */
+   os_memcpy(stats, &b->stats, sizeof (BalloonStats));
+
+   /*
+    * Fill in additional information about size and rates, which is
+    * normally kept in the Balloon structure itself.
+    */
+   stats->nPages = b->nPages;
+   stats->nPagesTarget = b->nPagesTarget;
+   stats->rateAlloc = b->rateAlloc;
+   stats->rateFree = b->rateFree;
+}
+
+/*
+ * BalloonChunk Operations
+ */
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * BalloonChunk_Create --
+ *
+ *      Creates a new BalloonChunk object capable of tracking
+ *	BALLOON_CHUNK_PAGES PPNs.
+ *
+ *	We do not bother to define two versions (NOSLEEP and CANSLEEP)
+ *	of os_kmalloc because Chunk_Create does not require a new page
+ *	often.
+ *
+ * Results:
+ *      Returns initialized BalloonChunk, or NULL if error.
+ *
+ * Side effects:
+ *      None.
+ *
+ *----------------------------------------------------------------------
+ */
+static BalloonChunk *
+BalloonChunk_Create(void)
+{
+   BalloonChunk *chunk;
+
+   /* allocate memory, fail if unable */
+   if ((chunk = (BalloonChunk *) os_kmalloc_nosleep(sizeof(BalloonChunk))) == NULL) {
+      return(NULL);
+   }
+
+   /* initialize */
+   os_bzero(chunk, sizeof(BalloonChunk));
+
+   /* everything OK */
+   return(chunk);
+}
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * BalloonChunk_Destroy --
+ *
+ *      Reclaims all storage associated with specified BalloonChunk.
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      None.
+ *
+ *----------------------------------------------------------------------
+ */
+static void
+BalloonChunk_Destroy(BalloonChunk *chunk)
+{
+   /* reclaim storage */
+   os_kfree(chunk, sizeof (BalloonChunk));
+}
+
+/*
+ * Balloon operations
+ */
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * Balloon_Init --
+ *
+ *      Initializes device state for balloon "b".
+ *
+ * Results:
+ *      Returns BALLOON_SUCCESS.
+ *
+ * Side effects:
+ *      None.
+ *
+ *----------------------------------------------------------------------
+ */
+static int
+Balloon_Init(Balloon *b)
+{
+   /* clear state */
+   os_bzero(b, sizeof(Balloon));
+
+   /* initialize rates */
+   b->rateAlloc = BALLOON_RATE_ALLOC_MAX;
+   b->rateFree  = BALLOON_RATE_FREE_MAX;
+
+   /* initialize reset flag */
+   b->resetFlag = 1;
+
+   /* everything OK */
+   return(BALLOON_SUCCESS);
+}
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * Balloon_Deallocate --
+ *
+ *      Frees all allocated pages.
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      None.
+ *
+ *----------------------------------------------------------------------
+ */
+static void
+Balloon_Deallocate(Balloon *b)
+{
+   unsigned int cnt = 0;
+
+   /* free all pages, skipping monitor unlock */
+   while (b->nChunks > 0) {
+      (void) Balloon_FreePage(b, FALSE);
+      if (++cnt >= b->rateFree) {
+         cnt = 0;
+         os_yield();
+      }
+   }
+}
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * Balloon_Reset --
+ *
+ *      Resets balloon "b" to empty state.  Frees all allocated pages
+ *	and attempts to reset contact with the monitor. 
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      Schedules next execution of balloon timer handler.
+ *
+ *----------------------------------------------------------------------
+ */
+static void
+Balloon_Reset(Balloon *b)
+{
+   uint32 status;
+
+   /* free all pages, skipping monitor unlock */
+   Balloon_Deallocate(b);
+
+   /* send start command */
+   status = Balloon_MonitorStart(b);
+   if (status == BALLOON_SUCCESS) {
+      /* clear flag */
+      b->resetFlag = 0;
+
+      /* report guest type */
+      (void) Balloon_MonitorGuestType(b);
+   }
+}
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * Balloon_BH --
+ *
+ *      Balloon bottom half handler.  Contacts monitor via backdoor
+ *	to obtain balloon size target, and starts adjusting balloon
+ *	size to achieve target by allocating or deallocating pages.
+ *	Resets balloon if requested by the monitor.
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      Schedules next execution of balloon timer handler.
+ *
+ *----------------------------------------------------------------------
+ */
+static void CDECL
+Balloon_BH(void *data)
+{
+   Balloon *b = (Balloon *) data;
+   uint32 target;
+   int status;
+
+   /* update stats */
+   STATS_INC(b->stats.timer);
+
+   /* reset, if specified */
+   if (b->resetFlag) {
+      Balloon_Reset(b);
+   }
+
+   /* contact monitor via backdoor */
+   status = Balloon_MonitorGetTarget(b, &target);
+
+   /* decrement slowPageAllocationCycles counter */
+   if (b->slowPageAllocationCycles > 0) {
+      b->slowPageAllocationCycles--;
+   }
+
+   if (status == BALLOON_SUCCESS) {
+      /* update target, adjust size */
+      b->nPagesTarget = target;
+      (void) Balloon_AdjustSize(b, target);
+   }
+}
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * Balloon_StartTimer --
+ *
+ *      Schedules next execution of balloon timer handler.
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *	None.
+ *
+ *----------------------------------------------------------------------
+ */
+static void
+Balloon_StartTimer(Balloon *b)
+{
+   os_timer_start();
+}
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * Balloon_StopTimer --
+ *
+ *      Deschedules balloon timer handler.
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *	None.
+ *
+ *----------------------------------------------------------------------
+ */
+static void
+Balloon_StopTimer(Balloon *b)
+{
+   os_timer_stop();
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * Balloon_ErrorPagesAlloc --
+ *
+ *      Attempt to add "page" to list of non-balloonable pages
+ *	associated with "b".
+ *
+ * Results:
+ *      Returns BALLOON_SUCCESS iff successful, or BALLOON_FAILURE
+ *	if non-balloonable page list is already full.
+ *
+ * Side effects:
+ *	None.
+ *
+ *----------------------------------------------------------------------
+ */
+static int
+Balloon_ErrorPagesAlloc(Balloon *b, unsigned long page)
+{
+   /* fail if list already full */
+   if (b->errors.nextPage >= BALLOON_ERROR_PAGES) {
+      return(BALLOON_FAILURE);
+   }
+
+   /* add page to list */
+   b->errors.page[b->errors.nextPage] = page;
+   b->errors.nextPage++;
+   STATS_INC(b->stats.primErrorPageAlloc);
+   return(BALLOON_SUCCESS);
+}
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * Balloon_ErrorPagesFree --
+ *
+ *      Deallocates all pages on the list of non-balloonable pages
+ *	associated with "b".
+ *
+ * Results:
+ *	None.
+ *
+ * Side effects:
+ *	None.
+ *
+ *----------------------------------------------------------------------
+ */
+static void
+Balloon_ErrorPagesFree(Balloon *b)
+{
+   int i;
+
+   /* free all non-balloonable "error" pages */
+   for (i = 0; i < b->errors.nextPage; i++) {
+      BalloonPrimFreePage(b->errors.page[i]);      
+      b->errors.page[i] = 0;
+      STATS_INC(b->stats.primErrorPageFree);
+   }
+   b->errors.nextPage = 0;
+}
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * Balloon_AllocPage --
+ *
+ *      Attempts to allocate a physical page, inflating balloon "b".
+ *	Informs monitor of PPN for allocated page via backdoor.
+ *
+ * Results:
+ *      Returns BALLOON_SUCCESS if successful, otherwise error code.
+ *
+ * Side effects:
+ *	None.
+ *
+ *----------------------------------------------------------------------
+ */
+static int
+Balloon_AllocPage(Balloon *b, BalloonPageAllocType allocType)
+{
+   BalloonChunk *chunk;
+   unsigned long page;
+   int status;
+
+ retry:
+
+   /* allocate page, fail if unable */
+   STATS_INC(b->stats.primAlloc[allocType]);
+
+   page = BalloonPrimAllocPage(allocType);
+
+   if (page == 0) {
+      STATS_INC(b->stats.primAllocFail[allocType]);
+      return(BALLOON_PAGE_ALLOC_FAILURE);
+   }
+
+   /* find chunk with space, create if necessary */
+   chunk = b->chunks;
+   if ((chunk == NULL) || (chunk->nextPage >= BALLOON_CHUNK_PAGES)) {
+      /* create new chunk */
+      if ((chunk = BalloonChunk_Create()) == NULL) {
+         /* reclaim storage, fail */
+         BalloonPrimFreePage(page);
+         return(BALLOON_PAGE_ALLOC_FAILURE);
+      }
+      BalloonChunk_Insert(&b->chunks, chunk);
+
+      /* update stats */
+      b->nChunks++;
+   }
+
+   /* inform monitor via backdoor */
+   status = Balloon_MonitorLockPage(b, page);
+   if (status != BALLOON_SUCCESS) {
+      /* place on list of non-balloonable pages, retry allocation */
+      if ((status != BALLOON_ERROR_RESET) &&
+          (Balloon_ErrorPagesAlloc(b, page) == BALLOON_SUCCESS)) {
+         goto retry;
+      }
+
+      /* reclaim storage, fail */
+      BalloonPrimFreePage(page);
+      return(status);
+   }
+
+   /* track allocated page */
+   chunk->page[chunk->nextPage] = page;
+   chunk->nextPage++;
+
+   /* update balloon size */
+   b->nPages++;
+
+   /* everything OK */
+   return(BALLOON_SUCCESS);
+}
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * Balloon_FreePage --
+ *
+ *      Attempts to deallocate a physical page, deflating balloon "b".
+ *	Informs monitor of PPN for deallocated page via backdoor if
+ *	"monitorUnlock" is specified.
+ *
+ * Results:
+ *      Returns BALLOON_SUCCESS if successful, otherwise error code.
+ *
+ * Side effects:
+ *	None.
+ *
+ *----------------------------------------------------------------------
+ */
+static int
+Balloon_FreePage(Balloon *b, int monitorUnlock)
+{
+   BalloonChunk *chunk;
+   unsigned long page;
+   int status;
+
+   chunk = b->chunks;
+
+   while ((chunk != NULL) && (chunk->nextPage == 0)) {
+      /* destroy empty chunk */
+      BalloonChunk_Remove(&b->chunks, chunk);
+      BalloonChunk_Destroy(chunk);
+
+      /* update stats */
+      b->nChunks--;
+
+      chunk = b->chunks;
+   }
+
+   if (chunk == NULL) {
+      return(BALLOON_FAILURE);
+   }
+
+   /* select page to deallocate */
+   chunk->nextPage--;
+   page = chunk->page[chunk->nextPage];
+
+   /* inform monitor via backdoor */
+   if (monitorUnlock) {
+      status = Balloon_MonitorUnlockPage(b, page);
+      if (status != BALLOON_SUCCESS) {
+         /* reset next pointer, fail */
+         chunk->nextPage++;
+         return(status);
+      }
+   }
+
+   /* deallocate page */
+   BalloonPrimFreePage(page);
+   STATS_INC(b->stats.primFree);
+
+   /* update balloon size */
+   b->nPages--;
+
+   /* reclaim chunk, if empty */
+   if (chunk->nextPage == 0) {
+      /* destroy empty chunk */
+      BalloonChunk_Remove(&b->chunks, chunk);
+      BalloonChunk_Destroy(chunk);
+
+      /* update stats */
+      b->nChunks--;
+   }
+
+   /* everything OK */
+   return(BALLOON_SUCCESS);
+}
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * BalloonDecreaseRateAlloc --
+ *
+ *	Wrapper to quickly reduce the page allocation rate. This function
+ *	is called only when a CANSLEEP allocation fails. This implies severe 
+ *	memory pressure inside the guest, so quickly decrease the rateAlloc.
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *	None.
+ *
+ *----------------------------------------------------------------------
+ */
+static void
+BalloonDecreaseRateAlloc(Balloon *b)
+{
+   if (BALLOON_RATE_ADAPT) {
+      b->rateAlloc = MAX(b->rateAlloc / 2, BALLOON_RATE_ALLOC_MIN);
+   }
+}
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * BalloonIncreaseRateAlloc --
+ *
+ *	Wrapper to increase the page allocation rate. 
+ *
+ *	This function is called when the balloon target is met or
+ *	b->rateAlloc (or more) pages have been successfully allocated.
+ *	This implies that the guest may not be under high memory 
+ *	pressure. So let us increase the rateAlloc.
+ *
+ *	If meeting balloon target requires less than b->rateAlloc
+ *	pages, then we do not change the page allocation rate.
+ *
+ *	If the number of pages successfully allocated (nAlloc) is far
+ *	higher than b->rateAlloc, then it implies that NOSLEEP 
+ *	allocations are highly successful. Therefore, we predict that
+ *	the guest is under no memory pressure, and so increase
+ *	b->rateAlloc quickly.
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *	None.
+ *
+ *----------------------------------------------------------------------
+ */
+static void
+BalloonIncreaseRateAlloc(Balloon *b, uint32 nAlloc)
+{
+   if (BALLOON_RATE_ADAPT) {
+      if (nAlloc >= b->rateAlloc) {
+         uint32 mult = nAlloc / b->rateAlloc; 
+         b->rateAlloc = MIN(b->rateAlloc + mult * BALLOON_RATE_ALLOC_INC,
+                            BALLOON_RATE_ALLOC_MAX);
+      }
+   }
+}
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * BalloonInflate--
+ *
+ *      Attempts to allocate physical pages to inflate balloon.
+ *
+ * Results:
+ *      Returns BALLOON_SUCCESS if successful, otherwise error code.
+ *
+ * Side effects:
+ *	None.
+ *
+ *----------------------------------------------------------------------
+ */
+static int
+BalloonInflate(Balloon *b, uint32 target)
+{
+   int status, allocations = 0;
+   uint32 i, nAllocNoSleep, nAllocCanSleep;
+
+   /* 
+    * First try NOSLEEP page allocations to inflate balloon.
+    *
+    * If we do not throttle nosleep allocations, we can drain all
+    * free pages in the guest quickly (if the balloon target is high).
+    * As a side-effect, draining free pages helps to inform (force)
+    * the guest to start swapping if balloon target is not met yet,
+    * which is a desired behavior. However, balloon driver can consume
+    * all available CPU cycles if too many pages are allocated in a 
+    * second. Therefore, we throttle nosleep allocations even when 
+    * the guest is not under memory pressure. OTOH, if we have already 
+    * predicted that the guest is under memory pressure, then we 
+    * slowdown page allocations considerably.
+    */
+   if (b->slowPageAllocationCycles > 0) {
+      nAllocNoSleep = MIN(target - b->nPages, b->rateAlloc);
+   } else {
+      nAllocNoSleep = MIN(target - b->nPages, BALLOON_NOSLEEP_ALLOC_MAX);
+   }
+
+   for (i = 0; i < nAllocNoSleep; i++) {
+      /* Try NOSLEEP allocation */
+      status = Balloon_AllocPage(b, BALLOON_PAGE_ALLOC_NOSLEEP);
+      if (status != BALLOON_SUCCESS) {
+         if (status != BALLOON_PAGE_ALLOC_FAILURE) {
+            /* 
+             * Not a page allocation failure, so release non-balloonable
+             * pages, and fail.
+             */
+            Balloon_ErrorPagesFree(b);
+            return(status);
+         }
+         /* 
+          * NOSLEEP page allocation failed, so the guest is under memory 
+          * pressure. Let us slowdown page allocations for next few 
+          * cycles so that the guest gets out of memory pressure.
+          */
+         b->slowPageAllocationCycles = SLOW_PAGE_ALLOCATION_CYCLES;
+         break;
+      }
+
+      if (++allocations > BALLOON_ALLOC_YIELD_THRESHOLD) {
+         os_yield();
+         allocations = 0;
+      }
+   }
+
+   /* 
+    * Check whether nosleep allocation successfully zapped nAllocNoSleep
+    * pages.
+    */
+   if (i == nAllocNoSleep) {
+      BalloonIncreaseRateAlloc(b, nAllocNoSleep);
+      /* release non-balloonable pages, succeed */
+      Balloon_ErrorPagesFree(b);
+      return(BALLOON_SUCCESS);
+   } else {
+      /* 
+       * NOSLEEP allocation failed, so the guest is under memory pressure.
+       * If already b->rateAlloc pages were zapped, then succeed. Otherwise,
+       * try CANSLEEP allocation.
+       */
+      if (i > b->rateAlloc) {
+         BalloonIncreaseRateAlloc(b, i);
+         /* release non-balloonable pages, succeed */
+         Balloon_ErrorPagesFree(b);
+         return(BALLOON_SUCCESS);
+      } else {
+         /* update successful NOSLEEP allocations, and proceed */
+         nAllocNoSleep = i;
+      }
+   }
+
+   /* 
+    * Use CANSLEEP page allocation to inflate balloon if below target.
+    *
+    * Sleep allocations are required only when nosleep allocation fails.
+    * This implies that the guest is already under memory pressure, so
+    * let us always throttle canSleep allocations. The total number pages
+    * allocated using noSleep and canSleep methods is throttled at 
+    * b->rateAlloc per second when the guest is under memory pressure. 
+    */
+   nAllocCanSleep = target - b->nPages;
+   nAllocCanSleep = MIN(nAllocCanSleep, b->rateAlloc - nAllocNoSleep);
+
+   for (i = 0; i < nAllocCanSleep; i++) {
+      /* Try CANSLEEP allocation */
+      status = Balloon_AllocPage(b, BALLOON_PAGE_ALLOC_CANSLEEP);
+      if(status != BALLOON_SUCCESS) {
+         if (status == BALLOON_PAGE_ALLOC_FAILURE) {
+            /* 
+             * CANSLEEP page allocation failed, so guest is under severe
+             * memory pressure. Quickly decrease rateAlloc.
+             */
+            BalloonDecreaseRateAlloc(b);
+         }
+         /* release non-balloonable pages, fail */
+         Balloon_ErrorPagesFree(b);
+         return(status);
+      }
+
+      if (++allocations > BALLOON_ALLOC_YIELD_THRESHOLD) {
+         os_yield();
+         allocations = 0;
+      }
+   }
+
+   /* 
+    * Either met the balloon target or b->rateAlloc pages have been
+    * successfully zapped.
+    */
+   BalloonIncreaseRateAlloc(b, nAllocNoSleep + nAllocCanSleep);
+                            
+   /* release non-balloonable pages, succeed */
+   Balloon_ErrorPagesFree(b);
+   return(BALLOON_SUCCESS);
+}
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * BalloonDeflate --
+ *
+ *      Frees physical pages to deflate balloon.
+ *
+ * Results:
+ *      Returns BALLOON_SUCCESS if successful, otherwise error code.
+ *
+ * Side effects:
+ *	None.
+ *
+ *----------------------------------------------------------------------
+ */
+static int
+BalloonDeflate(Balloon *b, uint32 target)
+{
+   int status, i;
+   uint32 nFree = b->nPages - target;
+      
+   /* limit deallocation rate */
+   nFree = MIN(nFree, b->rateFree);
+
+   /* free pages to reach target */
+   for (i = 0; i < nFree; i++) {
+      if ((status = Balloon_FreePage(b, TRUE)) != BALLOON_SUCCESS) {
+         if (BALLOON_RATE_ADAPT) {
+            /* quickly decrease rate if error */
+            b->rateFree = MAX(b->rateFree / 2, BALLOON_RATE_FREE_MIN);
+         }
+         return(status);
+      }
+   }
+
+   if (BALLOON_RATE_ADAPT) {
+      /* slowly increase rate if no errors */
+      b->rateFree = MIN(b->rateFree + BALLOON_RATE_FREE_INC,
+                        BALLOON_RATE_FREE_MAX);
+   }
+
+   /* everything OK */
+   return(BALLOON_SUCCESS);
+}
+ 
+/*
+ *----------------------------------------------------------------------
+ *
+ * Balloon_AdjustSize --
+ *
+ *      Attempts to allocate or deallocate physical pages in order
+ *	to reach desired "target" size for balloon "b".
+ *
+ * Results:
+ *      Returns BALLOON_SUCCESS if successful, otherwise error code.
+ *
+ * Side effects:
+ *	None.
+ *
+ *----------------------------------------------------------------------
+ */
+static int
+Balloon_AdjustSize(Balloon *b, uint32 target)
+{
+   /* done if already at target */
+   if (b->nPages == target) {
+      return(BALLOON_SUCCESS);
+   }
+
+   /* inflate balloon if below target */
+   if (b->nPages < target) {
+      return BalloonInflate(b, target);
+   }
+
+   /* deflate balloon if above target */
+   if (b->nPages > target) {
+      return BalloonDeflate(b, target);
+   }
+
+   /* not reached */
+   return(BALLOON_FAILURE);
+}
+
+/*
+ * Backdoor Operations
+ */
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * Balloon_MonitorStart --
+ *
+ *      Attempts to contact monitor via backdoor to begin operation.
+ *
+ * Results:
+ *	Returns BALLOON_SUCCESS if successful, otherwise error code.
+ *
+ * Side effects:
+ *	None.
+ *
+ *----------------------------------------------------------------------
+ */
+static int
+Balloon_MonitorStart(Balloon *b)
+{
+   uint32 status, target;
+   Backdoor_proto bp;
+
+   /* prepare backdoor args */
+   bp.in.cx.halfs.low = BALLOON_BDOOR_CMD_START;
+   bp.in.size = BALLOON_PROTOCOL_VERSION;
+
+   /* invoke backdoor */
+   Backdoor_Balloon(&bp);
+
+   /* parse return values */
+   status = bp.out.ax.word;
+   target = bp.out.bx.word;
+
+   /* update stats */
+   STATS_INC(b->stats.start);
+   if (status != BALLOON_SUCCESS) {
+      STATS_INC(b->stats.startFail);
+   }
+
+   /* everything OK */
+   return(status);
+}
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * Balloon_MonitorGuestType --
+ *
+ *      Attempts to contact monitor and report guest OS identity.
+ *
+ * Results:
+ *	Returns BALLOON_SUCCESS if successful, otherwise error code.
+ *
+ * Side effects:
+ *	None.
+ *
+ *----------------------------------------------------------------------
+ */
+static int
+Balloon_MonitorGuestType(Balloon *b)
+{
+   uint32 status, target;
+   Backdoor_proto bp;
+
+   /* prepare backdoor args */
+   bp.in.cx.halfs.low = BALLOON_BDOOR_CMD_GUEST_ID;
+   bp.in.size = BalloonGuestType();
+
+   /* invoke backdoor */
+   Backdoor_Balloon(&bp);
+
+   /* parse return values */
+   status = bp.out.ax.word;
+   target = bp.out.bx.word;
+
+   /* set flag if reset requested */
+   if (status == BALLOON_ERROR_RESET) {
+      b->resetFlag = 1;
+   }
+
+   /* update stats */
+   STATS_INC(b->stats.guestType);
+   if (status != BALLOON_SUCCESS) {
+      STATS_INC(b->stats.guestTypeFail);
+   }
+
+   /* everything OK */
+   return(status);
+}
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * Balloon_MonitorGetTarget --
+ *
+ *      Attempts to contact monitor via backdoor to obtain desired
+ *	balloon size.
+ *
+ *	Predicts the maximum achievable balloon size and sends it 
+ *	to vmm => vmkernel via vEbx register.
+ *
+ *	os_predict_max_balloon_pages() returns either predicted max balloon
+ *	pages or BALLOON_MAX_SIZE_USE_CONFIG. In the later scenario,
+ *	vmkernel uses global config options for determining a guest's max
+ *	balloon size. Note that older vmballoon drivers set vEbx to 
+ *	BALLOON_MAX_SIZE_USE_CONFIG, i.e., value 0 (zero). So vmkernel
+ *	will fallback to config-based max balloon size estimation.
+ *
+ * Results:
+ *	If successful, sets "target" to value obtained from monitor,
+ *      and returns BALLOON_SUCCESS. Otherwise returns error code.
+ *
+ * Side effects:
+ *	None.
+ *
+ *----------------------------------------------------------------------
+ */
+static int
+Balloon_MonitorGetTarget(Balloon *b, uint32 *target)
+{
+   Backdoor_proto bp;
+   uint32 status;
+
+   /* prepare backdoor args */
+   bp.in.cx.halfs.low = BALLOON_BDOOR_CMD_TARGET;
+   bp.in.size = os_predict_max_balloon_pages();
+
+   /* invoke backdoor */
+   Backdoor_Balloon(&bp);
+
+   /* parse return values */
+   status  = bp.out.ax.word;
+   *target = bp.out.bx.word;
+
+   /* set flag if reset requested */
+   if (status == BALLOON_ERROR_RESET) {
+      b->resetFlag = 1;
+   }
+
+   /* update stats */
+   STATS_INC(b->stats.target);
+   if (status != BALLOON_SUCCESS) {
+      STATS_INC(b->stats.targetFail);
+   }
+
+   /* everything OK */
+   return(status);
+}
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * Balloon_MonitorLockPage --
+ *
+ *      Attempts to contact monitor and add PPN containing "addr" 
+ *	to set of "balloon locked" pages.
+ *
+ * Results:
+ *	Returns BALLOON_SUCCESS if successful, otherwise error code.
+ *
+ * Side effects:
+ *	None.
+ *
+ *----------------------------------------------------------------------
+ */
+static int
+Balloon_MonitorLockPage(Balloon *b, unsigned long addr)
+{
+   unsigned long ppn;
+   uint32 ppn32;
+   uint32 status, target;
+   Backdoor_proto bp;
+
+   /* convert kernel-mapped "physical addr" to ppn */
+   ppn = AddrToPPN(addr);
+
+   /* Ensure PPN fits in 32-bits, i.e. guest memory is limited to 16TB. */
+   ppn32 = (uint32)ppn;
+   if (ppn32 != ppn) {
+      return BALLOON_ERROR_PPN_INVALID;
+   }
+
+   /* prepare backdoor args */
+   bp.in.cx.halfs.low = BALLOON_BDOOR_CMD_LOCK;
+   bp.in.size = ppn32;
+
+   /* invoke backdoor */
+   Backdoor_Balloon(&bp);
+
+   /* parse return values */
+   status = bp.out.ax.word;
+   target = bp.out.bx.word;
+
+   /* set flag if reset requested */
+   if (status == BALLOON_ERROR_RESET) {
+      b->resetFlag = 1;
+   }
+
+   /* update stats */
+   STATS_INC(b->stats.lock);
+   if (status != BALLOON_SUCCESS) {
+      STATS_INC(b->stats.lockFail);
+   }
+
+   /* everything OK */
+   return(status);
+}
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * Balloon_MonitorUnlockPage --
+ *
+ *      Attempts to contact monitor and remove PPN containing "addr" 
+ *	from set of "balloon locked" pages.
+ *
+ * Results:
+ *	Returns BALLOON_SUCCESS if successful, otherwise error code.
+ *
+ * Side effects:
+ *	None.
+ *
+ *----------------------------------------------------------------------
+ */
+static int
+Balloon_MonitorUnlockPage(Balloon *b, unsigned long addr)
+{
+   unsigned long ppn;
+   uint32 ppn32;
+   uint32 status, target;
+   Backdoor_proto bp;
+
+   /* convert kernel-mapped "physical addr" to ppn */
+   ppn = AddrToPPN(addr);
+
+   /* Ensure PPN fits in 32-bits, i.e. guest memory is limited to 16TB. */
+   ppn32 = (uint32)ppn;
+   if (ppn32 != ppn) {
+      return BALLOON_ERROR_PPN_INVALID;
+   }
+
+   /* prepare backdoor args */
+   bp.in.cx.halfs.low = BALLOON_BDOOR_CMD_UNLOCK;
+   bp.in.size = ppn32;
+
+   /* invoke backdoor */
+   Backdoor_Balloon(&bp);
+
+   /* parse return values */
+   status = bp.out.ax.word;
+   target = bp.out.bx.word;
+
+   /* set flag if reset requested */
+   if (status == BALLOON_ERROR_RESET) {
+      b->resetFlag = 1;
+   }
+
+   /* update stats */
+   STATS_INC(b->stats.unlock);
+   if (status != BALLOON_SUCCESS) {
+      STATS_INC(b->stats.unlockFail);
+   }
+
+   /* everything OK */
+   return(status);
+}
+
+/*
+ * Module Operations
+ */
+
+static int
+BalloonModuleInit(void)
+{
+   static int initialized = 0;
+   Balloon *b = &globalBalloon;
+
+   /* initialize only once */
+   if (initialized++) {
+      return(BALLOON_FAILURE);
+   }
+
+   /* initialize global state */
+   Balloon_Init(b);
+
+   /* os-specific initialization */
+   os_init(BALLOON_NAME, BALLOON_NAME_VERBOSE, BalloonProcRead);
+   os_timer_init(Balloon_BH, (void *) b, os_timer_hz());
+
+   /* start timer */
+   Balloon_StartTimer(b);
+
+   /* everything OK */
+   return(BALLOON_SUCCESS);
+}
+
+static void
+BalloonModuleCleanup(void)
+{
+   Balloon *b = &globalBalloon;
+
+   /* stop timer */
+   Balloon_StopTimer(b);
+
+   /*
+    * Deallocate all reserved memory, and reset connection with monitor.
+    * Reset connection before deallocating memory to avoid potential for
+    * additional spurious resets from guest touching deallocated pages.
+    */
+   (void) Balloon_MonitorStart(b);
+   Balloon_Deallocate(b);
+
+   /* os-specific cleanup */
+   os_cleanup();
+}   
+
+int init_module(void)
+{
+   return(BalloonModuleInit());
+}
+
+void cleanup_module(void)
+{
+   BalloonModuleCleanup();
+}
+
+#ifdef __cplusplus
+}
+#endif
--- kernel/linux-2.6.26.3/drivers/misc/vmmemctl/vmballoon.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmmemctl/vmballoon.h	2008-09-03 10:02:10.000000000 -0500
@@ -0,0 +1,81 @@
+/*********************************************************
+ * Copyright (C) 2000 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/* 
+ * vmballoon.h: Definitions and macros for vmballoon driver.
+ */
+
+#ifndef	VMBALLOON_H
+#define	VMBALLOON_H
+
+#include "vm_basic_types.h"
+
+/*
+ * Page allocation flags
+ */
+typedef enum BalloonPageAllocType {
+   BALLOON_PAGE_ALLOC_NOSLEEP = 0,
+   BALLOON_PAGE_ALLOC_CANSLEEP = 1,
+   BALLOON_PAGE_ALLOC_TYPES_NR,	// total number of alloc types
+} BalloonPageAllocType;
+
+/*
+ * Types
+ */
+
+typedef struct {
+   /* current status */
+   uint32 nPages;
+   uint32 nPagesTarget;
+
+   /* adjustment rates */
+   uint32 rateAlloc;
+   uint32 rateFree;
+
+   /* high-level operations */
+   uint32 timer;
+
+   /* primitives */
+   uint32 primAlloc[BALLOON_PAGE_ALLOC_TYPES_NR];
+   uint32 primAllocFail[BALLOON_PAGE_ALLOC_TYPES_NR];
+   uint32 primFree;
+   uint32 primErrorPageAlloc;
+   uint32 primErrorPageFree;
+
+   /* monitor operations */
+   uint32 lock;
+   uint32 lockFail;
+   uint32 unlock;
+   uint32 unlockFail;
+   uint32 target;
+   uint32 targetFail;
+   uint32 start;
+   uint32 startFail;
+   uint32 guestType;
+   uint32 guestTypeFail;
+} BalloonStats;
+
+/*
+ * Operations
+ */
+
+extern void BalloonGetStats(BalloonStats *stats);
+extern int  init_module(void);
+extern void cleanup_module(void);
+
+#endif	/* VMBALLOON_H */
--- kernel/linux-2.6.26.3/drivers/misc/vmmemctl/vm_basic_defs.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmmemctl/vm_basic_defs.h	2008-09-03 10:02:10.000000000 -0500
@@ -0,0 +1,606 @@
+/*********************************************************
+ * Copyright (C) 2003 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * vm_basic_defs.h --
+ *
+ *	Standard macros for VMware source code.
+ */
+
+#ifndef _VM_BASIC_DEFS_H_
+#define _VM_BASIC_DEFS_H_
+
+#define INCLUDE_ALLOW_USERLEVEL
+#define INCLUDE_ALLOW_VMMEXT
+#define INCLUDE_ALLOW_MODULE
+#define INCLUDE_ALLOW_VMMON
+#define INCLUDE_ALLOW_VMNIXMOD
+#define INCLUDE_ALLOW_VMKERNEL
+#define INCLUDE_ALLOW_VMKDRIVERS
+#define INCLUDE_ALLOW_VMK_MODULE
+#define INCLUDE_ALLOW_DISTRIBUTE
+#define INCLUDE_ALLOW_VMCORE
+#define INCLUDE_ALLOW_VMIROM
+#include "includeCheck.h"
+#include "vm_basic_types.h" // For INLINE.
+
+/* Checks for FreeBSD, filtering out VMKERNEL. */
+#define __IS_FREEBSD__ (!defined(VMKERNEL) && defined(__FreeBSD__))
+#define __IS_FREEBSD_VER__(ver) (__IS_FREEBSD__ && __FreeBSD_version >= (ver))
+
+#if defined _WIN32 && defined USERLEVEL
+   #include <stddef.h>  /*
+                         * We re-define offsetof macro from stddef, make 
+                         * sure that its already defined before we do it
+                         */
+   #include <windows.h>	// for Sleep() and LOWORD() etc.
+#endif
+
+
+/*
+ * Simple macros
+ */
+
+#if (defined __APPLE__ || defined __FreeBSD__) && \
+    (!defined KERNEL && !defined _KERNEL && !defined VMKERNEL && !defined __KERNEL__)
+#   include <stddef.h>
+#else
+// XXX the __cplusplus one matches that of VC++, to prevent redefinition warning
+// XXX the other one matches that of gcc3.3.3/glibc2.2.4 to prevent redefinition warnings
+#ifndef offsetof
+#ifdef __cplusplus
+#define offsetof(s,m)   (size_t)&(((s *)0)->m)
+#else
+#define offsetof(TYPE, MEMBER) ((size_t) &((TYPE *)0)->MEMBER)
+#endif
+#endif
+#endif // __APPLE__
+
+#ifndef ARRAYSIZE
+#define ARRAYSIZE(a) (sizeof (a) / sizeof *(a))
+#endif
+
+#ifndef MIN
+#define MIN(_a, _b)   (((_a) < (_b)) ? (_a) : (_b))
+#endif
+
+/* The Solaris 9 cross-compiler complains about these not being used */
+#ifndef sun
+static INLINE int 
+Min(int a, int b)
+{
+   return a < b ? a : b;
+}
+#endif
+
+#ifndef MAX
+#define MAX(_a, _b)   (((_a) > (_b)) ? (_a) : (_b))
+#endif
+
+#ifndef sun
+static INLINE int 
+Max(int a, int b)
+{
+   return a > b ? a : b;
+}
+#endif
+
+#define ROUNDUP(x,y)		(((x) + (y) - 1) / (y) * (y))
+#define ROUNDDOWN(x,y)		((x) / (y) * (y))
+#define ROUNDUPBITS(x, bits)	(((uintptr_t) (x) + MASK(bits)) & ~MASK(bits))
+#define ROUNDDOWNBITS(x, bits)	((uintptr_t) (x) & ~MASK(bits))
+#define CEILING(x, y)		(((x) + (y) - 1) / (y))
+#if defined __APPLE__
+#include <machine/param.h>
+#undef MASK
+#endif
+#define MASK(n)			((1 << (n)) - 1)	/* make an n-bit mask */
+#define DWORD_ALIGN(x)          ((((x)+3) >> 2) << 2)
+#define QWORD_ALIGN(x)          ((((x)+4) >> 3) << 3)
+
+#define IMPLIES(a,b) (!(a) || (b))
+
+/*
+ * Not everybody (e.g., the monitor) has NULL
+ */
+
+#ifndef NULL
+#ifdef  __cplusplus
+#define NULL    0
+#else
+#define NULL    ((void *)0)
+#endif
+#endif
+
+
+/* 
+ * Token concatenation
+ *
+ * The C preprocessor doesn't prescan arguments when they are
+ * concatenated or stringified.  So we need extra levels of
+ * indirection to convince the preprocessor to expand its
+ * arguments.
+ */
+
+#define CONC(x, y)              x##y
+#define XCONC(x, y)             CONC(x, y)
+#define XXCONC(x, y)            XCONC(x, y)
+#define MAKESTR(x)              #x
+#define XSTR(x)                 MAKESTR(x)
+
+
+/*
+ * Page operations
+ *
+ * It has been suggested that these definitions belong elsewhere
+ * (like x86types.h).  However, I deem them common enough
+ * (since even regular user-level programs may want to do
+ * page-based memory manipulation) to be here.
+ * -- edward
+ */
+
+#ifndef PAGE_SHIFT // {
+#if defined VM_I386
+   #define PAGE_SHIFT    12
+#elif defined __APPLE__
+   #define PAGE_SHIFT    12
+#else
+   #error
+#endif
+#endif // }
+
+#ifndef PAGE_SIZE
+#define PAGE_SIZE     (1<<PAGE_SHIFT)
+#endif
+
+#ifndef PAGE_MASK
+#define PAGE_MASK     (PAGE_SIZE - 1)
+#endif
+
+#ifndef PAGE_OFFSET
+#define PAGE_OFFSET(_addr)  ((uintptr_t)(_addr)&(PAGE_SIZE-1))
+#endif
+
+#ifndef VM_PAGE_BASE
+#define VM_PAGE_BASE(_addr)  ((_addr)&~(PAGE_SIZE-1))
+#endif
+
+#ifndef VM_PAGES_SPANNED
+#define VM_PAGES_SPANNED(_addr, _size) \
+   ((((_addr) & (PAGE_SIZE - 1)) + (_size) + (PAGE_SIZE - 1)) >> PAGE_SHIFT)
+#endif
+
+#ifndef BYTES_2_PAGES
+#define BYTES_2_PAGES(_nbytes) ((_nbytes) >> PAGE_SHIFT)
+#endif
+
+#ifndef PAGES_2_BYTES
+#define PAGES_2_BYTES(_npages) (((uint64)(_npages)) << PAGE_SHIFT)
+#endif
+
+#ifndef MBYTES_2_PAGES
+#define MBYTES_2_PAGES(_nbytes) ((_nbytes) << (20 - PAGE_SHIFT))
+#endif
+
+#ifndef PAGES_2_MBYTES
+#define PAGES_2_MBYTES(_npages) ((_npages) >> (20 - PAGE_SHIFT))
+#endif
+
+#ifndef VM_PAE_LARGE_PAGE_SHIFT
+#define VM_PAE_LARGE_PAGE_SHIFT 21
+#endif 
+
+#ifndef VM_PAE_LARGE_PAGE_SIZE
+#define VM_PAE_LARGE_PAGE_SIZE (1 << VM_PAE_LARGE_PAGE_SHIFT)
+#endif
+
+#ifndef VM_PAE_LARGE_PAGE_MASK
+#define VM_PAE_LARGE_PAGE_MASK (VM_PAE_LARGE_PAGE_SIZE - 1)
+#endif
+
+#ifndef VM_PAE_LARGE_2_SMALL_PAGES
+#define VM_PAE_LARGE_2_SMALL_PAGES (BYTES_2_PAGES(VM_PAE_LARGE_PAGE_SIZE))
+#endif
+
+/*
+ * Word operations
+ */
+
+#ifndef LOWORD
+#define LOWORD(_dw)   ((_dw) & 0xffff)
+#endif
+#ifndef HIWORD
+#define HIWORD(_dw)   (((_dw) >> 16) & 0xffff)
+#endif
+
+#ifndef LOBYTE
+#define LOBYTE(_w)    ((_w) & 0xff)
+#endif
+#ifndef HIBYTE
+#define HIBYTE(_w)    (((_w) >> 8) & 0xff)
+#endif
+
+#define HIDWORD(_qw)   ((uint32)((_qw) >> 32))
+#define LODWORD(_qw)   ((uint32)(_qw))
+#define QWORD(_hi, _lo)   ((((uint64)(_hi)) << 32) | ((uint32)(_lo)))
+
+
+/*
+ * Deposit a field _src at _pos bits from the right,
+ * with a length of _len, into the integer _target.
+ */
+
+#define DEPOSIT_BITS(_src,_pos,_len,_target) { \
+	unsigned mask = ((1 << _len) - 1); \
+	unsigned shiftedmask = ((1 << _len) - 1) << _pos; \
+	_target = (_target & ~shiftedmask) | ((_src & mask) << _pos); \
+}
+
+
+/*
+ * Get return address.
+ */
+
+#ifdef _MSC_VER
+#ifdef __cplusplus
+extern "C"
+#endif 
+void *_ReturnAddress(void);
+#pragma intrinsic(_ReturnAddress)
+#define GetReturnAddress() _ReturnAddress()
+#elif __GNUC__
+#define GetReturnAddress() __builtin_return_address(0)
+#endif
+
+
+#ifdef __GNUC__
+#ifndef sun
+
+/*
+ * Get the frame pointer. We use this assembly hack instead of
+ * __builtin_frame_address() due to a bug introduced in gcc 4.1.1
+ */
+static INLINE_SINGLE_CALLER uintptr_t
+GetFrameAddr(void)
+{
+   uintptr_t bp;
+#if (__GNUC__ < 4 || (__GNUC__ == 4 && __GNUC_MINOR__ == 0))
+   bp = (uintptr_t)__builtin_frame_address(0);
+#elif (__GNUC__ == 4 && __GNUC_MINOR__ == 1 && __GNUC_PATCHLEVEL__ <= 3)
+#  if defined(VMM64) || defined(VM_X86_64)
+     __asm__ __volatile__("movq %%rbp, %0\n" : "=g" (bp));
+#  else
+     __asm__ __volatile__("movl %%ebp, %0\n" : "=g" (bp));
+#  endif
+#else
+   __asm__ __volatile__(
+#ifdef __linux__
+      ".print \"This newer version of GCC may or may not have the "
+               "__builtin_frame_address bug.  Need to update this. "
+               "See bug 147638.\"\n"
+      ".abort"
+#else /* MacOS */
+      ".abort \"This newer version of GCC may or may not have the "
+               "__builtin_frame_address bug.  Need to update this. "
+               "See bug 147638.\"\n"
+#endif
+      : "=g" (bp)
+   );
+#endif
+   return bp;
+}
+
+
+/*
+ * Returns the frame pointer of the calling function.
+ * Equivalent to __builtin_frame_address(1).
+ */
+static INLINE_SINGLE_CALLER uintptr_t
+GetCallerFrameAddr(void)
+{
+   return *(uintptr_t*)GetFrameAddr();
+}
+
+#endif // sun
+#endif // __GNUC__
+
+/*
+ * Data prefetch was added in gcc 3.1.1
+ * http://www.gnu.org/software/gcc/gcc-3.1/changes.html
+ */
+#ifdef __GNUC__
+#  if ((__GNUC__ > 3) || (__GNUC__ == 3 && __GNUC_MINOR__ > 1) || \
+       (__GNUC__ == 3 && __GNUC_MINOR__ == 1 && __GNUC_PATCHLEVEL__ >= 1))
+#     define PREFETCH_R(var) __builtin_prefetch((var), 0 /* read */, \
+                                                3 /* high temporal locality */)
+#     define PREFETCH_W(var) __builtin_prefetch((var), 1 /* write */, \
+                                                3 /* high temporal locality */)
+#  else
+#     define PREFETCH_R(var) ((void)(var))
+#     define PREFETCH_W(var) ((void)(var))
+#  endif
+#endif /* __GNUC__ */
+
+
+#ifdef USERLEVEL // {
+
+/*
+ * Note this might be a problem on NT b/c while sched_yield guarantees it
+ * moves you to the end of your priority list, Sleep(0) offers no such
+ * guarantee.  Bummer.  --Jeremy.
+ */
+
+#if defined(N_PLAT_NLM)
+/* We do not have YIELD() as we do not need it yet... */
+#elif defined(_WIN32)
+#      define YIELD()		Sleep(0)
+#else
+#      include <sched.h>        // For sched_yield.  Don't ask.  --Jeremy.
+#      define YIELD()		sched_yield()
+#endif 
+
+
+/*
+ * Standardize some Posix names on Windows.
+ */
+
+#ifdef _WIN32 // {
+
+#define  snprintf  _snprintf
+#define	vsnprintf _vsnprintf
+
+static INLINE void
+sleep(unsigned int sec)
+{
+   Sleep(sec * 1000);
+}
+
+static INLINE void
+usleep(unsigned long usec)
+{
+   Sleep(CEILING(usec, 1000));
+}
+
+typedef int pid_t;
+#define       F_OK          0
+#define       X_OK          1
+#define       W_OK          2
+#define       R_OK          4
+
+#endif // }
+
+/*
+ * Macro for username comparison.
+ */
+
+#ifdef _WIN32 // {
+#define USERCMP(x,y)  Str_Strcasecmp(x,y)
+#else
+#define USERCMP(x,y)  strcmp(x,y)
+#endif // }
+
+
+#endif // }
+
+#ifndef va_copy
+
+#ifdef _WIN32
+
+/*
+ * Windows needs va_copy. This works for both 32 and 64-bit Windows
+ * based on inspection of how varags.h from the Visual C CRTL is
+ * implemented. (Future versions of the RTL may break this).
+ */
+
+#define va_copy(dest, src) ((dest) = (src))
+
+#elif defined(__APPLE__) && defined(KERNEL)
+
+/*
+ * MacOS kernel-mode needs va_copy. Based on inspection of stdarg.h
+ * from the MacOSX10.4u.sdk kernel framework, this should work.
+ * (Future versions of the SDK may break this).
+ */
+
+#define va_copy(dest, src) ((dest) = (src))
+
+#elif defined(__GNUC__) && (__GNUC__ < 3)
+
+/*
+ * Old versions of gcc recognize __va_copy, but not va_copy.
+ */
+
+#define va_copy(dest, src) __va_copy(dest, src)
+
+#endif // _WIN32
+
+#endif // va_copy
+
+/*
+ * This one is outside USERLEVEL because it's used by
+ * files compiled into the Windows hgfs driver or the display
+ * driver.
+ */
+
+#ifdef _WIN32
+#define PATH_MAX 256
+#ifndef strcasecmp
+#define strcasecmp(_s1,_s2)   _stricmp((_s1),(_s2))
+#endif
+#ifndef strncasecmp
+#define strncasecmp(_s1,_s2,_n)   _strnicmp((_s1),(_s2),(_n))
+#endif
+#endif
+
+/* 
+ * Convenience macro for COMMUNITY_SOURCE
+ */
+#undef EXCLUDE_COMMUNITY_SOURCE
+#ifdef COMMUNITY_SOURCE
+   #define EXCLUDE_COMMUNITY_SOURCE(x) 
+#else
+   #define EXCLUDE_COMMUNITY_SOURCE(x) x
+#endif
+
+#undef COMMUNITY_SOURCE_INTEL_SECRET
+#if !defined(COMMUNITY_SOURCE) || defined(INTEL_SOURCE)
+/*
+ * It's ok to include INTEL_SECRET source code for non-commsrc,
+ * or for drops directed at Intel.
+ */
+   #define COMMUNITY_SOURCE_INTEL_SECRET
+#endif
+
+/*
+ * Convenience macros and definitions. Can often be used instead of #ifdef.
+ */
+
+#undef DEBUG_ONLY
+#undef SL_DEBUG_ONLY
+#undef VMX86_SL_DEBUG
+#ifdef VMX86_DEBUG
+#define vmx86_debug      1
+#define DEBUG_ONLY(x)    x
+/*
+ * Be very, very, very careful with SL_DEBUG. Pls ask ganesh or min before 
+ * using it.
+ */
+#define VMX86_SL_DEBUG
+#define vmx86_sl_debug   1
+#define SL_DEBUG_ONLY(x) x
+#else
+#define vmx86_debug      0
+#define DEBUG_ONLY(x)
+#define vmx86_sl_debug   0
+#define SL_DEBUG_ONLY(x)
+#endif
+
+#ifdef VMX86_STATS
+#define vmx86_stats   1
+#define STATS_ONLY(x) x
+#else
+#define vmx86_stats   0
+#define STATS_ONLY(x)
+#endif
+
+#ifdef VMX86_DEVEL
+#define vmx86_devel   1
+#define DEVEL_ONLY(x) x
+#else
+#define vmx86_devel   0
+#define DEVEL_ONLY(x)
+#endif
+
+#ifdef VMX86_LOG
+#define vmx86_log     1
+#define LOG_ONLY(x)   x
+#else
+#define vmx86_log     0
+#define LOG_ONLY(x)
+#endif
+
+#ifdef VMX86_VMM_SERIAL_LOGGING
+#define vmx86_vmm_serial_log     1
+#define VMM_SERIAL_LOG_ONLY(x)   x
+#else
+#define vmx86_vmm_serial_log     0
+#define VMM_SERIAL_LOG_ONLY(x)
+#endif
+
+#ifdef VMX86_SERVER
+#define vmx86_server 1
+#define SERVER_ONLY(x) x
+#define HOSTED_ONLY(x)
+#else
+#define vmx86_server 0
+#define SERVER_ONLY(x)
+#define HOSTED_ONLY(x) x
+#endif
+
+#ifdef VMX86_WGS
+#define vmx86_wgs 1
+#define WGS_ONLY(x) x
+#else
+#define vmx86_wgs 0
+#define WGS_ONLY(x) 
+#endif
+
+#ifdef VMKERNEL
+#define vmkernel 1
+#define VMKERNEL_ONLY(x) x
+#else
+#define vmkernel 0
+#define VMKERNEL_ONLY(x)
+#endif
+
+#ifdef _WIN32
+#define WIN32_ONLY(x) x
+#define POSIX_ONLY(x)
+#else
+#define WIN32_ONLY(x)
+#define POSIX_ONLY(x) x
+#endif
+
+#ifdef VMM
+#define VMM_ONLY(x) x
+#define USER_ONLY(x)
+#else
+#define VMM_ONLY(x)
+#define USER_ONLY(x) x
+#endif
+
+/* VMVISOR ifdef only allowed in the vmkernel */
+#ifdef VMKERNEL
+#ifdef VMVISOR
+#define vmvisor 1
+#define VMVISOR_ONLY(x) x
+#else
+#define vmvisor 0
+#define VMVISOR_ONLY(x)
+#endif
+#endif
+
+#ifdef _WIN32
+#define VMW_INVALID_HANDLE INVALID_HANDLE_VALUE
+#else
+#define VMW_INVALID_HANDLE (-1)
+#endif
+
+#ifdef _WIN32
+#define fsync(fd) _commit(fd)
+#define fileno(f) _fileno(f)
+#else
+#endif
+
+/*
+ * Debug output macros for Windows drivers (the Eng variant is for
+ * display/printer drivers only.
+ */
+#ifdef _WIN32
+#ifndef USES_OLD_WINDDK
+#if defined(VMX86_DEBUG) || defined(ASSERT_ALWAYS_AVAILABLE)
+#define WinDrvPrint(arg, ...) DbgPrint(arg, __VA_ARGS__)
+#define WinDrvEngPrint(arg, ...) EngDbgPrint(arg, __VA_ARGS__)
+#else
+#define WinDrvPrint(arg, ...)
+#define WinDrvEngPrint(arg, ...)
+#endif
+#endif
+#endif // _WIN32
+
+#endif // ifndef _VM_BASIC_DEFS_H_
--- kernel/linux-2.6.26.3/drivers/misc/vmmemctl/vm_basic_types.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmmemctl/vm_basic_types.h	2008-09-03 10:02:10.000000000 -0500
@@ -0,0 +1,866 @@
+/*********************************************************
+ * Copyright (C) 1998-2008 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ *
+ * vm_basic_types.h --
+ *
+ *    basic data types.
+ */
+
+
+#ifndef _VM_BASIC_TYPES_H_
+#define _VM_BASIC_TYPES_H_
+
+#define INCLUDE_ALLOW_USERLEVEL
+#define INCLUDE_ALLOW_VMMEXT
+#define INCLUDE_ALLOW_MODULE
+#define INCLUDE_ALLOW_VMMON
+#define INCLUDE_ALLOW_VMNIXMOD
+#define INCLUDE_ALLOW_VMKERNEL
+#define INCLUDE_ALLOW_VMKDRIVERS
+#define INCLUDE_ALLOW_VMK_MODULE
+#define INCLUDE_ALLOW_DISTRIBUTE
+#define INCLUDE_ALLOW_VMCORE
+#define INCLUDE_ALLOW_VMIROM
+#include "includeCheck.h"
+
+/* STRICT ANSI means the Xserver build and X defines Bool differently. */
+#if !defined(__STRICT_ANSI__) || defined(__FreeBSD__)
+typedef char           Bool;
+#endif
+
+#ifndef FALSE
+#define FALSE          0
+#endif
+
+#ifndef TRUE
+#define TRUE           1
+#endif
+
+#define IsBool(x)      (((x) & ~1) == 0)
+#define IsBool2(x, y)  ((((x) | (y)) & ~1) == 0)
+
+/*
+ * Macros __i386__ and __ia64 are intrinsically defined by GCC
+ */
+#ifdef __i386__
+#define VM_I386
+#endif
+
+#ifdef _WIN64
+#define __x86_64__
+#endif
+
+#ifdef __x86_64__
+#define VM_X86_64
+#define VM_I386
+#define vm_x86_64 (1)
+#else
+#define vm_x86_64 (0)
+#endif
+
+
+
+#ifdef _WIN32
+/* safe assumption for a while */
+#define VM_I386
+#endif
+
+#ifdef _MSC_VER
+typedef unsigned __int64 uint64;
+typedef signed __int64 int64;
+
+#pragma warning (3 :4505) // unreferenced local function
+#pragma warning (disable :4018) // signed/unsigned mismatch
+#pragma warning (disable :4761) // integral size mismatch in argument; conversion supplied
+#pragma warning (disable :4305) // truncation from 'const int' to 'short'
+#pragma warning (disable :4244) // conversion from 'unsigned short' to 'unsigned char'
+#pragma warning (disable :4267) // truncation of 'size_t'
+#pragma warning (disable :4146) // unary minus operator applied to unsigned type, result still unsigned
+#pragma warning (disable :4142) // benign redefinition of type
+
+#elif __GNUC__
+/* The Xserver source compiles with -ansi -pendantic */
+#ifndef __STRICT_ANSI__
+#if defined(VM_X86_64)
+typedef unsigned long uint64;
+typedef long int64;
+#else
+typedef unsigned long long uint64;
+typedef long long int64;
+#endif
+#elif __FreeBSD__
+typedef unsigned long long uint64;
+typedef long long int64;
+#endif
+#else
+#error - Need compiler define for int64/uint64
+#endif
+
+typedef unsigned int       uint32;
+typedef unsigned short     uint16;
+typedef unsigned char      uint8;
+
+typedef int       int32;
+typedef short     int16;
+typedef char      int8;
+
+/*
+ * FreeBSD (for the tools build) unconditionally defines these in
+ * sys/inttypes.h so don't redefine them if this file has already
+ * been included. [greg]
+ *
+ * This applies to Solaris as well.
+ */
+
+/*
+ * Before trying to do the includes based on OS defines, see if we can use
+ * feature-based defines to get as much functionality as possible
+ */
+
+#ifdef HAVE_INTTYPES_H
+#include <inttypes.h>
+#endif
+#ifdef HAVE_SYS_TYPES_H
+#include <sys/types.h>
+#endif
+#ifdef HAVE_SYS_INTTYPES_H
+#include <sys/inttypes.h>
+#endif
+#ifdef HAVE_STDINT_H
+#include <stdint.h>
+#endif
+#ifdef HAVE_STDLIB_H
+#include <stdlib.h>
+#endif
+
+#ifdef __FreeBSD__
+#include <sys/param.h> /* For __FreeBSD_version */         
+#endif
+
+#if !defined(USING_AUTOCONF)
+#   if defined(__FreeBSD__) || defined(sun)
+#      ifdef KLD_MODULE
+#         include <sys/types.h>
+#      else
+#         if !defined(VMKERNEL) && (__FreeBSD_version >= 500043)
+#            include <inttypes.h>
+#            include <sys/types.h>
+#         else
+#            include <sys/inttypes.h>
+#         endif
+#      endif
+#   elif defined __APPLE__
+#      if KERNEL
+#         include <sys/unistd.h>
+#         include <sys/types.h> /* mostly for size_t */
+#         include <stdint.h>
+#      else
+#         include <unistd.h>
+#         include <inttypes.h>
+#         include <stdlib.h>
+#         include <stdint.h>
+#      endif
+#   else
+#      if !defined(__intptr_t_defined) && !defined(intptr_t)
+#         define __intptr_t_defined
+#         define intptr_t  intptr_t
+#         ifdef VM_I386
+#            ifdef VM_X86_64
+typedef int64     intptr_t;
+#            else
+typedef int32     intptr_t;
+#            endif
+#         endif
+#      endif
+
+#      ifndef _STDINT_H
+#         ifdef VM_I386
+#            ifdef VM_X86_64
+typedef uint64    uintptr_t;
+#            else
+typedef uint32    uintptr_t;
+#            endif
+#         endif
+#      endif
+#   endif
+#endif
+
+
+/*
+ * Time
+ * XXX These should be cleaned up.  -- edward
+ */
+
+typedef int64 VmTimeType;          /* Time in microseconds */
+typedef int64 VmTimeRealClock;     /* Real clock kept in microseconds */
+typedef int64 VmTimeVirtualClock;  /* Virtual Clock kept in CPU cycles */
+
+/*
+ * Printf format specifiers for size_t and 64-bit number.
+ * Use them like this:
+ *    printf("%"FMT64"d\n", big);
+ *
+ * FMTH is for handles/fds.
+ */
+
+#ifdef _MSC_VER
+   #define FMT64      "I64"
+   #ifdef VM_X86_64
+      #define FMTSZ      "I64"
+      #define FMTPD      "I64"
+      #define FMTH       "I64"
+   #else
+      #define FMTSZ      "I"
+      #define FMTPD      "I"
+      #define FMTH       "I"
+   #endif
+#elif __GNUC__
+   #define FMTH ""
+   #if defined(N_PLAT_NLM) || defined(sun) || \
+       (defined(__FreeBSD__) && (__FreeBSD__ + 0) && ((__FreeBSD__ + 0) < 5))
+      /*
+       * Why (__FreeBSD__ + 0)?  See bug 141008.
+       * Yes, we really need to test both (__FreeBSD__ + 0) and
+       * ((__FreeBSD__ + 0) < 5).  No, we can't remove "+ 0" from
+       * ((__FreeBSD__ + 0) < 5).
+       */
+      #ifdef VM_X86_64
+         #define FMTSZ  "l"
+         #define FMTPD  "l"
+      #else
+         #define FMTSZ  ""
+         #define FMTPD  ""
+      #endif
+   #elif defined(__linux__) \
+      || (defined(_POSIX_C_SOURCE) && _POSIX_C_SOURCE >= 200112L) \
+      || (defined(_POSIX_VERSION) && _POSIX_VERSION >= 200112L) \
+      || (defined(_POSIX2_VERSION) && _POSIX2_VERSION >= 200112L)
+      /* BSD/Darwin, Linux */
+      #define FMTSZ     "z"
+
+      #ifdef VM_X86_64
+         #define FMTPD  "l"
+      #else
+         #define FMTPD  ""
+      #endif
+   #else
+      /* Systems with a pre-C99 libc */
+      #define FMTSZ     "Z"
+      #ifdef VM_X86_64
+         #define FMTPD  "l"
+      #else
+         #define FMTPD  ""
+      #endif
+   #endif
+   #ifdef VM_X86_64
+      #define FMT64     "l"
+   #elif defined(sun) || defined(__APPLE__) || defined(__FreeBSD__)
+      #define FMT64     "ll"
+   #else
+      #define FMT64     "L"
+   #endif
+#else
+   #error - Need compiler define for FMT64 and FMTSZ
+#endif
+
+/*
+ * Suffix for 64-bit constants.  Use it like this:
+ *    CONST64(0x7fffffffffffffff) for signed or
+ *    CONST64U(0x7fffffffffffffff) for unsigned.
+ *
+ * 2004.08.30(thutt):
+ *   The vmcore/asm64/gen* programs are compiled as 32-bit
+ *   applications, but must handle 64 bit constants.  If the
+ *   64-bit-constant defining macros are already defined, the
+ *   definition will not be overwritten.
+ */
+
+#if !defined(CONST64) || !defined(CONST64U)
+#ifdef _MSC_VER
+#define CONST64(c) c##I64
+#define CONST64U(c) c##uI64
+#elif __GNUC__
+#ifdef VM_X86_64
+#define CONST64(c) c##L
+#define CONST64U(c) c##uL
+#else
+#define CONST64(c) c##LL
+#define CONST64U(c) c##uLL
+#endif
+#else
+#error - Need compiler define for CONST64
+#endif
+#endif
+
+/*
+ * Use CONST3264/CONST3264U if you want a constant to be
+ * treated as a 32-bit number on 32-bit compiles and
+ * a 64-bit number on 64-bit compiles. Useful in the case
+ * of shifts, like (CONST3264U(1) << x), where x could be
+ * more than 31 on a 64-bit compile.
+ */
+
+#ifdef VM_X86_64
+    #define CONST3264(a) CONST64(a)
+    #define CONST3264U(a) CONST64U(a)
+#else
+    #define CONST3264(a) (a)
+    #define CONST3264U(a) (a)
+#endif
+
+#define MIN_INT32  ((int32)0x80000000)
+#define MAX_INT32  ((int32)0x7fffffff)
+
+#define MIN_UINT32 ((uint32)0)
+#define MAX_UINT32 ((uint32)0xffffffff)
+
+#define MIN_INT64  (CONST64(0x8000000000000000))
+#define MAX_INT64  (CONST64(0x7fffffffffffffff))
+
+#define MIN_UINT64 (CONST64U(0))
+#define MAX_UINT64 (CONST64U(0xffffffffffffffff))
+
+typedef uint8 *TCA;  /* Pointer into TC (usually). */
+
+/*
+ * Type big enough to hold an integer between 0..100
+ */
+typedef uint8 Percent;
+#define AsPercent(v)	((Percent)(v))
+#define CHOOSE_PERCENT  AsPercent(101)
+
+
+typedef uintptr_t VA;
+typedef uintptr_t VPN;
+
+typedef uint64    PA;
+typedef uint32    PPN;
+
+typedef uint64    PhysMemOff;
+typedef uint64    PhysMemSize;
+
+/* The Xserver source compiles with -ansi -pendantic */
+#ifndef __STRICT_ANSI__
+typedef uint64    BA;
+#endif
+typedef uint32    BPN;
+typedef uint32    PageNum;
+typedef unsigned  MemHandle;
+typedef int32     World_ID;
+
+#define INVALID_WORLD_ID ((World_ID)0)
+
+typedef World_ID User_CartelID;
+#define INVALID_CARTEL_ID INVALID_WORLD_ID
+
+typedef User_CartelID User_SessionID;
+#define INVALID_SESSION_ID INVALID_CARTEL_ID
+
+typedef User_CartelID User_CartelGroupID;
+#define INVALID_CARTELGROUP_ID INVALID_CARTEL_ID
+
+typedef uint32 Worldlet_ID;
+#define INVALID_WORLDLET_ID ((Worldlet_ID)0)
+
+/* world page number */
+typedef uint32    WPN;
+
+/* The Xserver source compiles with -ansi -pendantic */
+#ifndef __STRICT_ANSI__
+typedef uint64     MA;
+typedef uint32     MPN;
+#endif
+
+/*
+ * This type should be used for variables that contain sector
+ * position/quantity.
+ */
+typedef uint64 SectorType;
+
+/*
+ * Linear address
+ */
+
+typedef uintptr_t LA;
+typedef uintptr_t LPN;
+#define LA_2_LPN(_la)     ((_la) >> PAGE_SHIFT)
+#define LPN_2_LA(_lpn)    ((_lpn) << PAGE_SHIFT)
+
+#define LAST_LPN   ((((LA)  1) << (8 * sizeof(LA)   - PAGE_SHIFT)) - 1)
+#define LAST_LPN32 ((((LA32)1) << (8 * sizeof(LA32) - PAGE_SHIFT)) - 1)
+#define LAST_LPN64 ((((LA64)1) << (8 * sizeof(LA64) - PAGE_SHIFT)) - 1)
+
+/* Valid bits in a LPN. */
+#define LPN_MASK   LAST_LPN
+#define LPN_MASK32 LAST_LPN32
+#define LPN_MASK64 LAST_LPN64
+
+/*
+ * On 64 bit platform, address and page number types default
+ * to 64 bit. When we need to represent a 32 bit address, we use
+ * types defined below.
+ *
+ * On 32 bit platform, the following types are the same as the
+ * default types.
+ */
+typedef uint32 VA32;
+typedef uint32 VPN32;
+typedef uint32 LA32;
+typedef uint32 LPN32;
+typedef uint32 PA32;
+typedef uint32 PPN32;
+typedef uint32 MA32;
+typedef uint32 MPN32;
+
+/*
+ * On 64 bit platform, the following types are the same as the
+ * default types.
+ */
+typedef uint64 VA64;
+typedef uint64 VPN64;
+typedef uint64 LA64;
+typedef uint64 LPN64;
+typedef uint64 PA64;
+typedef uint64 PPN64;
+typedef uint64 MA64;
+typedef uint64 MPN64;
+
+/*
+ * VA typedefs for user world apps.
+ */
+typedef VA32 UserVA32;
+typedef VA64 UserVA64;
+typedef UserVA32 UserVAConst; /* Userspace ptr to data that we may only read. */
+typedef UserVA64 UserVA64Const; /* Used by 64-bit syscalls until conversion is finished. */
+#ifdef VMKERNEL
+typedef UserVA32 UserVA;
+#else
+typedef void * UserVA;
+#endif
+
+
+/*
+ * Maximal possible PPN value (errors too) that PhysMem can handle.
+ * Must be at least as large as MAX_PPN which is the maximum PPN
+ * for any region other than buserror.
+ */
+#define PHYSMEM_MAX_PPN ((PPN)0xffffffff)
+#define MAX_PPN         ((PPN)0x1fffffff)   /* Maximal observable PPN value. */
+#define INVALID_PPN     ((PPN)0xffffffff)
+
+#define INVALID_BPN  ((BPN) 0x1fffffff)
+
+#define INVALID_MPN  ((MPN)-1)
+#define MEMREF_MPN   ((MPN)-2)
+#define RESERVED_MPN ((MPN) 0)
+/* Support 39 bits of address space, minus one page. */
+#define MAX_MPN      ((MPN) 0x07ffffff)
+
+#define INVALID_LPN ((LPN)-1)
+#define INVALID_VPN ((VPN)-1)
+#define INVALID_LPN64 ((LPN64)-1)
+#define INVALID_PAGENUM ((PageNum)-1)
+#define INVALID_WPN ((WPN) -1)
+
+
+/*
+ * Format modifier for printing VA, LA, and VPN.
+ * Use them like this: Log("%#"FMTLA"x\n", laddr)
+ */
+
+#if defined(VMM64) || defined(FROBOS64) || vm_x86_64 || defined __APPLE__
+#   define FMTLA "l"
+#   define FMTVA "l"
+#   define FMTVPN "l"
+#else
+#   define FMTLA ""
+#   define FMTVA ""
+#   define FMTVPN ""
+#endif
+
+#ifndef EXTERN
+#define EXTERN        extern
+#endif
+#define CONST         const
+
+
+#ifndef INLINE
+#   ifdef _MSC_VER
+#      define INLINE        __inline
+#   else
+#      define INLINE        inline
+#   endif
+#endif
+
+
+/*
+ * Annotation for data that may be exported into a DLL and used by other
+ * apps that load that DLL and import the data.
+ */
+#if defined(_WIN32) && defined(VMX86_IMPORT_DLLDATA)
+#  define VMX86_EXTERN_DATA       extern __declspec(dllimport)
+#else // !_WIN32
+#  define VMX86_EXTERN_DATA       extern
+#endif
+
+#if defined(_WIN32) && !defined(VMX86_NO_THREADS)
+#define THREADSPECIFIC __declspec(thread)
+#else
+#define THREADSPECIFIC
+#endif
+
+/*
+ * Due to the wonderful "registry redirection" feature introduced in
+ * 64-bit Windows, if you access any key under HKLM\Software in 64-bit
+ * code, you need to open/create/delete that key with
+ * VMKEY_WOW64_32KEY if you want a consistent view with 32-bit code.
+ */
+
+#ifdef _WIN32
+#ifdef _WIN64
+#define VMW_KEY_WOW64_32KEY KEY_WOW64_32KEY
+#else
+#define VMW_KEY_WOW64_32KEY 0x0
+#endif
+#endif
+
+
+/*
+ * Consider the following reasons functions are inlined:
+ *
+ *  1) inlined for performance reasons
+ *  2) inlined because it's a single-use function
+ *
+ * Functions which meet only condition 2 should be marked with this
+ * inline macro; It is not critical to be inlined (but there is a
+ * code-space & runtime savings by doing so), so when other callers
+ * are added the inline-ness should be removed.
+ */
+
+#if __GNUC__ > 3 || (__GNUC__ == 3 && __GNUC_MINOR__ >= 3)
+/*
+ * Starting at version 3.3, gcc does not always inline functions marked
+ * 'inline' (it depends on their size). To force gcc to do so, one must use the
+ * extra __always_inline__ attribute.
+ */
+#   define INLINE_SINGLE_CALLER INLINE __attribute__((__always_inline__))
+#   if    defined(VMM) \
+       && (__GNUC__ > 4 || (__GNUC__ == 4 && __GNUC_MINOR__ > 1))
+#      warning Verify INLINE_SINGLE_CALLER '__always_inline__' attribute (did \
+             monitor size change?)
+#   endif
+#else
+#   define INLINE_SINGLE_CALLER INLINE
+#endif
+
+/*
+ * Used when a hard guaranteed of no inlining is needed. Very few
+ * instances need this since the absence of INLINE is a good hint
+ * that gcc will not do inlining.
+ */
+
+#if defined(__GNUC__) && defined(VMM)
+#define ABSOLUTELY_NOINLINE __attribute__((__noinline__))
+#endif
+
+/*
+ * Attributes placed on function declarations to tell the compiler
+ * that the function never returns.
+ */
+
+#ifdef _MSC_VER
+#define NORETURN __declspec(noreturn)
+#elif __GNUC__ > 2 || (__GNUC__ == 2 && __GNUC_MINOR__ >= 9)
+#define NORETURN __attribute__((__noreturn__))
+#else
+#define NORETURN
+#endif
+
+/*
+ * GCC 3.2 inline asm needs the + constraint for input/ouput memory operands.
+ * Older GCCs don't know about it --hpreg
+ */
+
+#if __GNUC__ > 3 || (__GNUC__ == 3 && __GNUC_MINOR__ >= 2)
+#   define VM_ASM_PLUS 1
+#else
+#   define VM_ASM_PLUS 0
+#endif
+
+/*
+ * Branch prediction hints:
+ *     LIKELY(exp)   - Expression exp is likely TRUE.
+ *     UNLIKELY(exp) - Expression exp is likely FALSE.
+ *   Usage example:
+ *        if (LIKELY(excCode == EXC_NONE)) {
+ *               or
+ *        if (UNLIKELY(REAL_MODE(vc))) {
+ *
+ * We know how to predict branches on gcc3 and later (hopefully),
+ * all others we don't so we do nothing.
+ */
+
+#if (__GNUC__ >= 3)
+/*
+ * gcc3 uses __builtin_expect() to inform the compiler of an expected value.
+ * We use this to inform the static branch predictor. The '!!' in LIKELY
+ * will convert any !=0 to a 1.
+ */
+#define LIKELY(_exp)     __builtin_expect(!!(_exp), 1)
+#define UNLIKELY(_exp)   __builtin_expect((_exp), 0)
+#else
+#define LIKELY(_exp)      (_exp)
+#define UNLIKELY(_exp)    (_exp)
+#endif
+
+/*
+ * GCC's argument checking for printf-like functions
+ * This is conditional until we have replaced all `"%x", void *'
+ * with `"0x%08x", (uint32) void *'. Note that %p prints different things
+ * on different platforms.  Argument checking is enabled for the
+ * vmkernel, which has already been cleansed.
+ *
+ * fmtPos is the position of the format string argument, beginning at 1
+ * varPos is the position of the variable argument, beginning at 1
+ */
+
+#if defined(__GNUC__)
+# define PRINTF_DECL(fmtPos, varPos) __attribute__((__format__(__printf__, fmtPos, varPos)))
+#else
+# define PRINTF_DECL(fmtPos, varPos)
+#endif
+
+#if defined(__GNUC__)
+# define SCANF_DECL(fmtPos, varPos) __attribute__((__format__(__scanf__, fmtPos, varPos)))
+#else
+# define SCANF_DECL(fmtPos, varPos)
+#endif
+
+/*
+ * UNUSED_PARAM should surround the parameter name and type declaration,
+ * e.g. "int MyFunction(int var1, UNUSED_PARAM(int var2))"
+ *
+ */
+
+#ifndef UNUSED_PARAM
+# if defined(__GNUC__)
+#  define UNUSED_PARAM(_parm) _parm  __attribute__((__unused__))
+# else
+#  define UNUSED_PARAM(_parm) _parm
+# endif
+#endif
+
+/*
+ * REGPARM defaults to REGPARM3, i.e., a requent that gcc
+ * puts the first three arguments in registers.  (It is fine
+ * if the function has fewer than three args.)  Gcc only.
+ * Syntactically, put REGPARM where you'd put INLINE or NORETURN.
+ */
+
+#if defined(__GNUC__)
+# define REGPARM0 __attribute__((regparm(0)))
+# define REGPARM1 __attribute__((regparm(1)))
+# define REGPARM2 __attribute__((regparm(2)))
+# define REGPARM3 __attribute__((regparm(3)))
+# define REGPARM REGPARM3
+#else
+# define REGPARM0
+# define REGPARM1
+# define REGPARM2
+# define REGPARM3
+# define REGPARM
+#endif
+
+/*
+ * ALIGNED specifies minimum alignment in "n" bytes.
+ */
+
+#ifdef __GNUC__
+#define ALIGNED(n) __attribute__((__aligned__(n)))
+#else
+#define ALIGNED(n)
+#endif
+
+/*
+ * __func__ is a stringified function name that is part of the C99 standard. The block
+ * below defines __func__ on older systems where the compiler does not support that
+ * macro.
+ */
+#if defined(__GNUC__) \
+   && ((__GNUC__ == 2 && __GNUC_MINOR < 96) \
+       || (__GNUC__ < 2))
+#   define __func__ __FUNCTION__
+#endif
+
+/*
+ * Once upon a time, this was used to silence compiler warnings that
+ * get generated when the compiler thinks that a function returns
+ * when it is marked noreturn.  Don't do it.  Use NOT_REACHED().
+ */
+
+#define INFINITE_LOOP()           do { } while (1)
+
+/*
+ * On FreeBSD (for the tools build), size_t is typedef'd if _BSD_SIZE_T_
+ * is defined. Use the same logic here so we don't define it twice. [greg]
+ */
+#ifdef __FreeBSD__
+#   ifdef _BSD_SIZE_T_
+#      undef _BSD_SIZE_T_
+#      ifdef VM_I386
+#         ifdef VM_X86_64
+             typedef uint64 size_t;
+#         else
+             typedef uint32 size_t;
+#         endif
+#      endif /* VM_I386 */
+#   endif
+
+#   ifdef _BSD_SSIZE_T_
+#      undef _BSD_SSIZE_T_
+#      define _SSIZE_T
+#      define __ssize_t_defined
+#      define _SSIZE_T_DECLARED
+#      ifdef VM_I386
+#         ifdef VM_X86_64
+             typedef int64 ssize_t;
+#         else
+             typedef int32 ssize_t;
+#         endif
+#      endif /* VM_I386 */
+#   endif
+
+#else
+#   ifndef _SIZE_T
+#      define _SIZE_T
+#      ifdef VM_I386
+#         ifdef VM_X86_64
+             typedef uint64 size_t;
+#         else
+             typedef uint32 size_t;
+#         endif
+#      endif /* VM_I386 */
+#   endif
+
+#   if !defined(FROBOS) && !defined(_SSIZE_T) && !defined(ssize_t) && \
+       !defined(__ssize_t_defined) && !defined(_SSIZE_T_DECLARED)
+#      define _SSIZE_T
+#      define __ssize_t_defined
+#      define _SSIZE_T_DECLARED
+#      ifdef VM_I386
+#         ifdef VM_X86_64
+             typedef int64 ssize_t;
+#         else
+             typedef int32 ssize_t;
+#         endif
+#      endif /* VM_I386 */
+#   endif
+
+#endif
+
+/*
+ * Format modifier for printing pid_t.  On sun the pid_t is a ulong, but on
+ * Linux it's an int.
+ * Use this like this: printf("The pid is %"FMTPID".\n", pid);
+ */
+#ifdef sun
+#   ifdef VM_X86_64
+#      define FMTPID "d"
+#   else
+#      define FMTPID "lu"
+#   endif
+#else
+# define FMTPID "d"
+#endif
+
+/*
+ * Format modifier for printing uid_t.  On sun the uid_t is a ulong, but on
+ * Linux it's an int.
+ * Use this like this: printf("The uid is %"FMTUID".\n", uid);
+ */
+#ifdef sun
+#   ifdef VM_X86_64
+#      define FMTUID "u"
+#   else
+#      define FMTUID "lu"
+#   endif
+#else
+# define FMTUID "u"
+#endif
+
+/*
+ * Format modifier for printing mode_t.  On sun the mode_t is a ulong, but on
+ * Linux it's an int.
+ * Use this like this: printf("The mode is %"FMTMODE".\n", mode);
+ */
+#ifdef sun
+#   ifdef VM_X86_64
+#      define FMTMODE "o"
+#   else
+#      define FMTMODE "lo"
+#   endif
+#else
+# define FMTMODE "o"
+#endif
+
+/*
+ * Format modifier for printing time_t. Most platforms define a time_t to be
+ * a long int, but on FreeBSD (as of 5.0, it seems), the time_t is a signed
+ * size quantity. Refer to the definition of FMTSZ to see why we need silly
+ * preprocessor arithmetic.
+ * Use this like this: printf("The mode is %"FMTTIME".\n", time);
+ */
+#if defined(__FreeBSD__) && (__FreeBSD__ + 0) && ((__FreeBSD__ + 0) >= 5)
+#   define FMTTIME FMTSZ"d"
+#else
+#   define FMTTIME "ld"
+#endif
+
+/*
+ * Define MXSemaHandle here so both vmmon and vmx see this definition.
+ */
+
+#ifdef _WIN32
+typedef uintptr_t MXSemaHandle;
+#else
+typedef int MXSemaHandle;
+#endif
+
+/*
+ * Define type for poll device handles.
+ */
+
+#ifdef _WIN32
+typedef uintptr_t PollDevHandle;
+#else
+typedef int PollDevHandle;
+#endif
+
+/*
+ * Define the utf16_t type.
+ */
+
+#if defined(_WIN32) && defined(_NATIVE_WCHAR_T_DEFINED)
+typedef wchar_t utf16_t;
+#else
+typedef uint16 utf16_t;
+#endif
+
+#endif  /* _VM_BASIC_TYPES_H_ */
--- kernel/linux-2.6.26.3/drivers/misc/vmmemctl/vmmemctl_version.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmmemctl/vmmemctl_version.h	2008-09-03 10:02:10.000000000 -0500
@@ -0,0 +1,32 @@
+/*********************************************************
+ * Copyright (C) 2007 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * vmmemctl_version.h --
+ *
+ * Version definitions for the Linux memory ballooning driver.
+ */
+
+#ifndef _VMMEMCTL_VERSION_H_
+#define _VMMEMCTL_VERSION_H_
+
+#define VMMEMCTL_DRIVER_VERSION          1.2.1.0
+#define VMMEMCTL_DRIVER_VERSION_COMMAS   1,2,1,0
+#define VMMEMCTL_DRIVER_VERSION_STRING   "1.2.1.0"
+
+#endif /* _VMMEMCTL_VERSION_H_ */
--- kernel/linux-2.6.26.3/drivers/misc/vmsync/compat_fs.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmsync/compat_fs.h	2008-09-03 10:02:32.000000000 -0500
@@ -0,0 +1,247 @@
+/*********************************************************
+ * Copyright (C) 2006 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_FS_H__
+#   define __COMPAT_FS_H__
+
+#include <linux/fs.h>
+
+/*
+ * 2.6.5+ kernels define FS_BINARY_MOUNTDATA. Since it didn't exist and
+ * wasn't used prior, it's safe to define it to zero.
+ */
+
+#ifndef FS_BINARY_MOUNTDATA
+#define FS_BINARY_MOUNTDATA 0
+#endif
+
+/*
+ * MAX_LFS_FILESIZE wasn't defined until 2.5.4.
+ */
+#ifndef MAX_LFS_FILESIZE
+#   include <linux/pagemap.h>
+#   if BITS_PER_LONG == 32
+#      define MAX_LFS_FILESIZE       (((u64)PAGE_CACHE_SIZE << (BITS_PER_LONG - 1)) - 1)
+#   elif BITS_PER_LONG == 64
+#      define MAX_LFS_FILESIZE       0x7fffffffffffffffUL
+#   endif
+#endif
+
+
+/*
+ * sendfile as a VFS op was born in 2.5.30. Unfortunately, it also changed
+ * signatures, first in 2.5.47, then again in 2.5.70, then again in 2.6.8.
+ * Luckily, the 2.6.8+ signature is the same as the 2.5.47 signature.  And
+ * as of 2.6.23-rc1 sendfile is gone, replaced by splice_read...
+ *
+ * Let's not support sendfile from 2.5.30 to 2.5.47, because the 2.5.30
+ * signature is much different and file_send_actor isn't externed.
+ */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 23)
+#define VMW_SENDFILE_NONE
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 8)
+#define VMW_SENDFILE_NEW
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(2, 5, 70)
+#define VMW_SENDFILE_OLD
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(2, 5, 47)
+#define VMW_SENDFILE_NEW
+#else
+#define VMW_SENDFILE_NONE
+#endif
+
+/*
+ * splice_read is there since 2.6.17, but let's avoid 2.6.17-rcX kernels...
+ * After all nobody is using splice system call until 2.6.23 using it to
+ * implement sendfile.
+ */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 18)
+#define VMW_SPLICE_READ 1
+#endif
+
+/*
+ * Filesystems wishing to use generic page cache read/write routines are
+ * supposed to implement aio_read and aio_write (calling into
+ * generic_file_aio_read() and generic_file_aio_write() if necessary).
+ *
+ * The VFS exports do_sync_read() and do_sync_write() as the "new"
+ * generic_file_read() and generic_file_write(), but filesystems need not
+ * actually implement read and write- the VFS will automatically call
+ * do_sync_write() and do_sync_read() when applications invoke the standard
+ * read() and write() system calls.
+ *
+ * In 2.6.19, generic_file_read() and generic_file_write() were removed,
+ * necessitating this change. AIO dates as far back as 2.5.42, but the API has
+ * changed over time, so for simplicity, we'll only enable it from 2.6.19 and
+ * on.
+ */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 19)
+# define VMW_USE_AIO
+#endif
+
+
+/*
+ * The alloc_inode and destroy_inode VFS ops didn't exist prior to 2.4.21.
+ * Without these functions, file systems can't embed inodes.
+ */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 4, 21)
+# define VMW_EMBED_INODE
+#endif
+
+
+/*
+ * iget() was removed from the VFS as of 2.6.25-rc1. The replacement for iget()
+ * is iget_locked() which was added in 2.5.17.
+ */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 5, 17)
+# define VMW_USE_IGET_LOCKED
+#endif
+
+/*
+ * parent_ino was born in 2.5.5. For older kernels, let's use 2.5.5
+ * implementation. It uses the dcache lock which is OK because per-dentry
+ * locking appeared after 2.5.5.
+ */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 5, 5)
+#define compat_parent_ino(dentry) parent_ino(dentry)
+#else
+#define compat_parent_ino(dentry)                                             \
+({                                                                            \
+   ino_t res;                                                                 \
+   spin_lock(&dcache_lock);                                                   \
+   res = dentry->d_parent->d_inode->i_ino;                                    \
+   spin_unlock(&dcache_lock);                                                 \
+   res;                                                                       \
+})
+#endif
+
+
+/*
+ * putname changed to __putname in 2.6.6.
+ */
+#define compat___getname() __getname()
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 6)
+#define compat___putname(name) putname(name)
+#else
+#define compat___putname(name) __putname(name)
+#endif
+
+
+/*
+ * inc_nlink, drop_nlink, and clear_nlink were added in 2.6.19.
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 19)
+#define compat_inc_nlink(inode) ((inode)->i_nlink++)
+#define compat_drop_nlink(inode) ((inode)->i_nlink--)
+#define compat_clear_nlink(inode) ((inode)->i_nlink = 0)
+#else
+#define compat_inc_nlink(inode) inc_nlink(inode)
+#define compat_drop_nlink(inode) drop_nlink(inode)
+#define compat_clear_nlink(inode) clear_nlink(inode)
+#endif
+
+
+/*
+ * i_size_write and i_size_read were introduced in 2.6.0-test1 
+ * (though we'll look for them as of 2.6.1). They employ slightly different
+ * locking in order to guarantee atomicity, depending on the length of a long,
+ * whether the kernel is SMP, or whether the kernel is preemptible. Prior to
+ * i_size_write and i_size_read, there was no such locking, so that's the
+ * behavior we'll emulate.
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 1)
+#define compat_i_size_read(inode) ((inode)->i_size)
+#define compat_i_size_write(inode, size) ((inode)->i_size = size)
+#else
+#define compat_i_size_read(inode) i_size_read(inode)
+#define compat_i_size_write(inode, size) i_size_write(inode, size)
+#endif
+
+
+/*
+ * filemap_fdatawrite was introduced in 2.5.12. Prior to that, modules used
+ * filemap_fdatasync instead. In 2.4.18, both filemap_fdatawrite and 
+ * filemap_fdatawait began returning status codes. Prior to that, they were 
+ * void functions, so we'll just have them return 0.
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 18)
+#define compat_filemap_fdatawrite(mapping)                                    \
+({                                                                            \
+   int result = 0;                                                            \
+   filemap_fdatasync(mapping);                                                \
+   result;                                                                    \
+})
+#define compat_filemap_fdatawait(mapping)                                     \
+({                                                                            \
+   int result = 0;                                                            \
+   filemap_fdatawait(mapping);                                                \
+   result;                                                                    \
+})
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 12)
+#define compat_filemap_fdatawrite(mapping) filemap_fdatasync(mapping)
+#define compat_filemap_fdatawait(mapping) filemap_fdatawait(mapping)
+#else
+#define compat_filemap_fdatawrite(mapping) filemap_fdatawrite(mapping)
+#define compat_filemap_fdatawait(mapping) filemap_fdatawait(mapping)
+#endif
+
+
+/*
+ * filemap_write_and_wait was introduced in 2.6.6 and exported for module use
+ * in 2.6.16. It's really just a simple wrapper around filemap_fdatawrite and 
+ * and filemap_fdatawait, which initiates a flush of all dirty pages, then 
+ * waits for the pages to flush. The implementation here is a simplified form 
+ * of the one found in 2.6.20-rc3.
+ *
+ * Unfortunately, it just isn't possible to implement this prior to 2.4.5, when
+ * neither filemap_fdatawait nor filemap_fdatasync were exported for module
+ * use. So we'll define it out and hope for the best.
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 5)
+#define compat_filemap_write_and_wait(mapping)
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 16)
+#define compat_filemap_write_and_wait(mapping)                                \
+({                                                                            \
+   int result = 0;                                                            \
+   if (mapping->nrpages) {                                                    \
+      result = compat_filemap_fdatawrite(mapping);                            \
+      if (result != -EIO) {                                                   \
+         int result2 = compat_filemap_fdatawait(mapping);                     \
+         if (!result) {                                                       \
+            result = result2;                                                 \
+         }                                                                    \
+      }                                                                       \
+   }                                                                          \
+   result;                                                                    \
+})
+#else
+#define compat_filemap_write_and_wait(mapping) filemap_write_and_wait(mapping)
+#endif
+
+
+/*
+ * invalidate_remote_inode was introduced in 2.6.0-test5. Prior to that, 
+ * filesystems wishing to invalidate pages belonging to an inode called 
+ * invalidate_inode_pages.
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 0)
+#define compat_invalidate_remote_inode(inode) invalidate_inode_pages(inode)
+#else
+#define compat_invalidate_remote_inode(inode) invalidate_remote_inode(inode)
+#endif
+
+#endif /* __COMPAT_FS_H__ */
--- kernel/linux-2.6.26.3/drivers/misc/vmsync/compat_module.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmsync/compat_module.h	2008-09-03 10:02:32.000000000 -0500
@@ -0,0 +1,72 @@
+/*********************************************************
+ * Copyright (C) 2007 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * compat_module.h --
+ */
+
+#ifndef __COMPAT_MODULE_H__
+#   define __COMPAT_MODULE_H__
+
+
+#include <linux/module.h>
+
+
+/*
+ * Modules wishing to use the GPL license are required to include a
+ * MODULE_LICENSE definition in their module source as of 2.4.10.
+ */
+#ifndef MODULE_LICENSE
+#define MODULE_LICENSE(license)
+#endif
+
+/*
+ * To make use of our own home-brewed MODULE_INFO, we need macros to
+ * concatenate two expressions to "__mod_", and and to convert an
+ * expression into a string. I'm sure we've got these in our codebase,
+ * but I'd rather not introduce such a dependency in a compat header.
+ */
+#ifndef __module_cat
+#define __module_cat_1(a, b) __mod_ ## a ## b
+#define __module_cat(a, b) __module_cat_1(a, b)
+#endif
+
+#ifndef __stringify
+#define __stringify_1(x) #x
+#define __stringify(x) __stringify_1(x)
+#endif
+
+/*
+ * MODULE_INFO was born in 2.5.69.
+ */
+#ifndef MODULE_INFO
+#define MODULE_INFO(tag, info)                                                \
+static const char __module_cat(tag, __LINE__)[]                               \
+  __attribute__((section(".modinfo"), unused)) = __stringify(tag) "=" info
+#endif
+
+/*
+ * MODULE_VERSION was born in 2.6.4. The earlier form appends a long "\0xxx"
+ * string to the module's version, but that was removed in 2.6.10, so we'll
+ * ignore it in our wrapper.
+ */
+#ifndef MODULE_VERSION
+#define MODULE_VERSION(_version) MODULE_INFO(version, _version)
+#endif
+
+#endif /* __COMPAT_MODULE_H__ */
--- kernel/linux-2.6.26.3/drivers/misc/vmsync/compat_namei.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmsync/compat_namei.h	2008-09-03 10:02:32.000000000 -0500
@@ -0,0 +1,57 @@
+/*********************************************************
+ * Copyright (C) 2006 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_NAMEI_H__
+#   define __COMPAT_NAMEI_H__
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 5, 18)
+#include <linux/namei.h>
+#endif
+
+/*
+ * In 2.6.25-rc2, dentry and mount objects were removed from the nameidata
+ * struct. They were both replaced with a struct path.
+ */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 25)
+#define compat_vmw_nd_to_dentry(nd) (nd).path.dentry
+#else
+#define compat_vmw_nd_to_dentry(nd) (nd).dentry
+#endif
+
+/* In 2.6.25-rc2, path_release(&nd) was replaced with path_put(&nd.path). */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 25)
+#define compat_path_release(nd) path_put(&(nd)->path)
+#else
+#define compat_path_release(nd) path_release(nd)
+#endif
+
+/* path_lookup was exported in 2.4.25 */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 4, 25)
+#define compat_path_lookup(path, flags, nd)     path_lookup(path, flags, nd)
+#else
+#define compat_path_lookup(path, flags, nd)     \
+         ({                                     \
+            int ret = 0;                        \
+            if (path_init(path, flags, nd)) {   \
+               ret = path_walk(path, nd);       \
+            }                                   \
+            ret;                                \
+         })
+#endif
+
+#endif /* __COMPAT_NAMEI_H__ */
--- kernel/linux-2.6.26.3/drivers/misc/vmsync/compat_semaphore.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmsync/compat_semaphore.h	2008-09-03 10:02:32.000000000 -0500
@@ -0,0 +1,49 @@
+/*********************************************************
+ * Copyright (C) 2002 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_SEMAPHORE_H__
+#   define __COMPAT_SEMAPHORE_H__
+
+
+/* <= 2.6.25 have asm only, 2.6.26 has both, and 2.6.27-rc2+ has linux only. */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 27)
+#   include <asm/semaphore.h>
+#else
+#   include <linux/semaphore.h>
+#endif
+
+
+/*
+* The init_MUTEX_LOCKED() API appeared in 2.2.18, and is also in
+* 2.2.17-21mdk --hpreg
+*/
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 2, 18)
+   #ifndef init_MUTEX_LOCKED
+      #define init_MUTEX_LOCKED(_sem) *(_sem) = MUTEX_LOCKED
+   #endif
+   #ifndef DECLARE_MUTEX
+      #define DECLARE_MUTEX(name) struct semaphore name = MUTEX
+   #endif
+   #ifndef DECLARE_MUTEX_LOCKED
+      #define DECLARE_MUTEX_LOCKED(name) struct semaphore name = MUTEX_LOCKED
+   #endif
+#endif
+
+
+#endif /* __COMPAT_SEMAPHORE_H__ */
--- kernel/linux-2.6.26.3/drivers/misc/vmsync/compat_slab.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmsync/compat_slab.h	2008-09-03 10:02:32.000000000 -0500
@@ -0,0 +1,85 @@
+/*********************************************************
+ * Copyright (C) 2005 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_SLAB_H__
+#   define __COMPAT_SLAB_H__
+
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 2, 0)
+#   include <linux/slab.h>
+#else
+#   include <linux/malloc.h>
+#endif
+
+/*
+ * Before 2.6.20, kmem_cache_t was the accepted way to refer to a kmem_cache
+ * structure.  Prior to 2.6.15, this structure was called kmem_cache_s, and
+ * afterwards it was renamed to kmem_cache.  Here we keep things simple and use
+ * the accepted typedef until it became deprecated, at which point we switch
+ * over to the kmem_cache name.
+ */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 20)
+#   define compat_kmem_cache struct kmem_cache
+#else
+#   define compat_kmem_cache kmem_cache_t
+#endif
+
+/*
+ * Up to 2.6.22 kmem_cache_create has 6 arguments - name, size, alignment, flags,
+ * constructor, and destructor.  Then for some time kernel was asserting that
+ * destructor is NULL, and since 2.6.23-pre1 kmem_cache_create takes only 5
+ * arguments - destructor is gone.
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 22) || defined(VMW_KMEMCR_HAS_DTOR)
+#define compat_kmem_cache_create(name, size, align, flags, ctor) \
+		kmem_cache_create(name, size, align, flags, ctor, NULL)
+#else
+#define compat_kmem_cache_create(name, size, align, flags, ctor) \
+		kmem_cache_create(name, size, align, flags, ctor)
+#endif
+
+/*
+ * Up to 2.6.23 kmem_cache constructor has three arguments - pointer to block to
+ * prepare (aka "this"), from which cache it came, and some unused flags.  After
+ * 2.6.23 flags were removed, and order of "this" and cache parameters was swapped...
+ * Since 2.6.27-rc2 everything is different again, and ctor has only one argument.
+ *
+ * HAS_3_ARGS has precedence over HAS_2_ARGS if both are defined.
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 23) && !defined(VMW_KMEMCR_CTOR_HAS_3_ARGS)
+#  define VMW_KMEMCR_CTOR_HAS_3_ARGS
+#endif
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 26) && !defined(VMW_KMEMCR_CTOR_HAS_2_ARGS)
+#  define VMW_KMEMCR_CTOR_HAS_2_ARGS
+#endif
+
+#if defined(VMW_KMEMCR_CTOR_HAS_3_ARGS)
+typedef void compat_kmem_cache_ctor(void *, compat_kmem_cache *, unsigned long);
+#define COMPAT_KMEM_CACHE_CTOR_ARGS(arg) void *arg, \
+                                         compat_kmem_cache *cache, \
+                                         unsigned long flags
+#elif defined(VMW_KMEMCR_CTOR_HAS_2_ARGS)
+typedef void compat_kmem_cache_ctor(compat_kmem_cache *, void *);
+#define COMPAT_KMEM_CACHE_CTOR_ARGS(arg) compat_kmem_cache *cache, \
+                                         void *arg
+#else
+typedef void compat_kmem_cache_ctor(void *);
+#define COMPAT_KMEM_CACHE_CTOR_ARGS(arg) void *arg
+#endif
+
+#endif /* __COMPAT_SLAB_H__ */
--- kernel/linux-2.6.26.3/drivers/misc/vmsync/compat_version.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmsync/compat_version.h	2008-09-03 10:02:32.000000000 -0500
@@ -0,0 +1,121 @@
+/*********************************************************
+ * Copyright (C) 1998 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_VERSION_H__
+#   define __COMPAT_VERSION_H__
+
+#define INCLUDE_ALLOW_VMMON
+#define INCLUDE_ALLOW_MODULE
+#define INCLUDE_ALLOW_VMCORE
+#define INCLUDE_ALLOW_VMNIXMOD
+#define INCLUDE_ALLOW_DISTRIBUTE
+#include "includeCheck.h"
+
+
+#ifndef __linux__
+#   error "linux-version.h"
+#endif
+
+
+#include <linux/version.h>
+
+/* Appeared in 2.1.90 --hpreg */
+#ifndef KERNEL_VERSION
+#   define KERNEL_VERSION(a, b, c) (((a) << 16) + ((b) << 8) + (c))
+#endif
+
+
+/*
+ * Distinguish relevant classes of Linux kernels.
+ *
+ * The convention is that version X defines all
+ * the KERNEL_Y symbols where Y <= X.
+ *
+ * XXX Do not add more definitions here. This way of doing things does not
+ *     scale, and we are going to phase it out soon --hpreg
+ */
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 1, 0)
+#   define KERNEL_2_1
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 2, 0)
+#   define KERNEL_2_2
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 3, 1)
+#   define KERNEL_2_3_1
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 3, 15)
+/*   new networking */
+#   define KERNEL_2_3_15
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 3, 25)
+/*  new procfs */
+#   define KERNEL_2_3_25
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 3, 29)
+/*  even newer procfs */
+#   define KERNEL_2_3_29
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 3, 43)
+/*  softnet changes */
+#   define KERNEL_2_3_43
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 3, 47)
+/*  more softnet changes */
+#   define KERNEL_2_3_47
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 3, 99)
+/*  name in netdevice struct is array and not pointer */
+#   define KERNEL_2_3_99
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 4, 0)
+/*  New 'owner' member at the beginning of struct file_operations */
+#      define KERNEL_2_4_0
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 4, 8)
+/*  New netif_rx_ni() --hpreg */
+#   define KERNEL_2_4_8
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 4, 22)
+/*  New vmap() */
+#   define KERNEL_2_4_22
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 5, 2)
+/*  New kdev_t, major()/minor() API --hpreg */
+#   define KERNEL_2_5_2
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 5, 5)
+/*  New sk_alloc(), pte_offset_map()/pte_unmap() --hpreg */
+#   define KERNEL_2_5_5
+#endif
+
+
+#endif /* __COMPAT_VERSION_H__ */
--- kernel/linux-2.6.26.3/drivers/misc/vmsync/compat_workqueue.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmsync/compat_workqueue.h	2008-09-03 10:02:32.000000000 -0500
@@ -0,0 +1,165 @@
+/*********************************************************
+ * Copyright (C) 2007 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_WORKQUEUE_H__
+# define __COMPAT_WORKQUEUE_H__
+
+#include <linux/kernel.h>
+
+#if LINUX_VERSION_CODE > KERNEL_VERSION(2, 5, 41)
+# include <linux/workqueue.h>
+#endif
+
+/*
+ *
+ * Work queues and delayed work queues.
+ *
+ * Prior to 2.5.41, the notion of work queues did not exist.  Taskqueues are
+ * used for work queues and timers are used for delayed work queues.
+ *
+ * After 2.6.20, normal work structs ("work_struct") and delayed work
+ * ("delayed_work") structs were separated so that the work_struct could be
+ * slimmed down.  The interface was also changed such that the address of the
+ * work_struct itself is passed in as the argument to the work function.  This
+ * requires that one embed the work struct in the larger struct containing the
+ * information necessary to complete the work and use container_of() to obtain
+ * the address of the containing structure.
+ *
+ * Users of these macros should embed a compat_work or compat_delayed_work in
+ * a larger structure, then specify the larger structure as the _data argument
+ * for the initialization functions, specify the work function to take
+ * a compat_work_arg or compat_delayed_work_arg, then use the appropriate
+ * _GET_DATA macro to obtain the reference to the structure passed in as _data.
+ * An example is below.
+ *
+ *
+ *   typedef struct WorkData {
+ *      int data;
+ *      compat_work work;
+ *   } WorkData;
+ *
+ *
+ *   void
+ *   WorkFunc(compat_work_arg data)
+ *   {
+ *      WorkData *workData = COMPAT_WORK_GET_DATA(data, WorkData, work);
+ *
+ *      ...
+ *   }
+ *
+ *
+ *   {
+ *      WorkData *workData = kmalloc(sizeof *workData, GFP_EXAMPLE);
+ *      if (!workData) {
+ *         return -ENOMEM;
+ *      }
+ *
+ *      COMPAT_INIT_WORK(&workData->work, WorkFunc, workData);
+ *      compat_schedule_work(&workData->work);
+ *   }
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 41)  /* { */
+typedef struct tq_struct compat_work;
+typedef struct compat_delayed_work {
+   struct tq_struct work;
+   struct timer_list timer;
+} compat_delayed_work;
+typedef void * compat_work_arg;
+typedef void * compat_delayed_work_arg;
+
+/*
+ * Delayed work queues need to run at some point in the future in process
+ * context, but task queues don't support delaying the task one is scheduling.
+ * Timers allow us to delay the execution of our work queue until the future,
+ * but timer handlers run in bottom-half context.  As such, we use both a timer
+ * and task queue and use the timer handler below to schedule the task in
+ * process context immediately.  The timer lets us delay execution, and the
+ * task queue lets us run in process context.
+ *
+ * Note that this is similar to how delayed_work is implemented with work
+ * queues in later kernel versions.
+ */
+static inline void
+__compat_delayed_work_timer(unsigned long arg)
+{
+   compat_delayed_work *dwork = (compat_delayed_work *)arg;
+   if (dwork) {
+      schedule_task(&dwork->work);
+   }
+}
+
+# define COMPAT_INIT_WORK(_work, _func, _data)            \
+   INIT_LIST_HEAD(&(_work)->list);                        \
+   (_work)->sync = 0;                                     \
+   (_work)->routine = _func;                              \
+   (_work)->data = _data
+# define COMPAT_INIT_DELAYED_WORK(_work, _func, _data)    \
+   COMPAT_INIT_WORK(&(_work)->work, _func, _data);        \
+   init_timer(&(_work)->timer);                           \
+   (_work)->timer.expires = 0;                            \
+   (_work)->timer.function = __compat_delayed_work_timer; \
+   (_work)->timer.data = (unsigned long)_work
+# define compat_schedule_work(_work)                      \
+   schedule_task(_work)
+# define compat_schedule_delayed_work(_work, _delay)      \
+   (_work)->timer.expires = jiffies + _delay;             \
+   add_timer(&(_work)->timer)
+# define COMPAT_WORK_GET_DATA(_p, _type)                  \
+   (_type *)(_p)
+# define COMPAT_DELAYED_WORK_GET_DATA(_p, _type, _member) \
+   (_type *)(_p)
+
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 20)  /* } { */
+typedef struct work_struct compat_work;
+typedef struct work_struct compat_delayed_work;
+typedef void * compat_work_arg;
+typedef void * compat_delayed_work_arg;
+# define COMPAT_INIT_WORK(_work, _func, _data)            \
+   INIT_WORK(_work, _func, _data)
+# define COMPAT_INIT_DELAYED_WORK(_work, _func, _data)    \
+   INIT_WORK(_work, _func, _data)
+# define compat_schedule_work(_work)                      \
+   schedule_work(_work)
+# define compat_schedule_delayed_work(_work, _delay)      \
+   schedule_delayed_work(_work, _delay)
+# define COMPAT_WORK_GET_DATA(_p, _type)                  \
+   (_type *)(_p)
+# define COMPAT_DELAYED_WORK_GET_DATA(_p, _type, _member) \
+   (_type *)(_p)
+
+#else  /* } Linux >= 2.6.20 { */
+typedef struct work_struct compat_work;
+typedef struct delayed_work compat_delayed_work;
+typedef struct work_struct * compat_work_arg;
+typedef struct work_struct * compat_delayed_work_arg;
+# define COMPAT_INIT_WORK(_work, _func, _data)            \
+   INIT_WORK(_work, _func)
+# define COMPAT_INIT_DELAYED_WORK(_work, _func, _data)    \
+   INIT_DELAYED_WORK(_work, _func)
+# define compat_schedule_work(_work)                      \
+   schedule_work(_work)
+# define compat_schedule_delayed_work(_work, _delay)      \
+   schedule_delayed_work(_work, _delay)
+# define COMPAT_WORK_GET_DATA(_p, _type)                  \
+   container_of(_p, _type, work)
+# define COMPAT_DELAYED_WORK_GET_DATA(_p, _type, _member) \
+   container_of(_p, _type, _member.work)
+#endif /* } */
+
+#endif /* __COMPAT_WORKQUEUE_H__ */
+
--- kernel/linux-2.6.26.3/drivers/misc/vmsync/COPYING	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmsync/COPYING	2008-09-03 09:57:34.000000000 -0500
@@ -0,0 +1,339 @@
+		    GNU GENERAL PUBLIC LICENSE
+		       Version 2, June 1991
+
+ Copyright (C) 1989, 1991 Free Software Foundation, Inc.,
+ 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ Everyone is permitted to copy and distribute verbatim copies
+ of this license document, but changing it is not allowed.
+
+			    Preamble
+
+  The licenses for most software are designed to take away your
+freedom to share and change it.  By contrast, the GNU General Public
+License is intended to guarantee your freedom to share and change free
+software--to make sure the software is free for all its users.  This
+General Public License applies to most of the Free Software
+Foundation's software and to any other program whose authors commit to
+using it.  (Some other Free Software Foundation software is covered by
+the GNU Lesser General Public License instead.)  You can apply it to
+your programs, too.
+
+  When we speak of free software, we are referring to freedom, not
+price.  Our General Public Licenses are designed to make sure that you
+have the freedom to distribute copies of free software (and charge for
+this service if you wish), that you receive source code or can get it
+if you want it, that you can change the software or use pieces of it
+in new free programs; and that you know you can do these things.
+
+  To protect your rights, we need to make restrictions that forbid
+anyone to deny you these rights or to ask you to surrender the rights.
+These restrictions translate to certain responsibilities for you if you
+distribute copies of the software, or if you modify it.
+
+  For example, if you distribute copies of such a program, whether
+gratis or for a fee, you must give the recipients all the rights that
+you have.  You must make sure that they, too, receive or can get the
+source code.  And you must show them these terms so they know their
+rights.
+
+  We protect your rights with two steps: (1) copyright the software, and
+(2) offer you this license which gives you legal permission to copy,
+distribute and/or modify the software.
+
+  Also, for each author's protection and ours, we want to make certain
+that everyone understands that there is no warranty for this free
+software.  If the software is modified by someone else and passed on, we
+want its recipients to know that what they have is not the original, so
+that any problems introduced by others will not reflect on the original
+authors' reputations.
+
+  Finally, any free program is threatened constantly by software
+patents.  We wish to avoid the danger that redistributors of a free
+program will individually obtain patent licenses, in effect making the
+program proprietary.  To prevent this, we have made it clear that any
+patent must be licensed for everyone's free use or not licensed at all.
+
+  The precise terms and conditions for copying, distribution and
+modification follow.
+
+		    GNU GENERAL PUBLIC LICENSE
+   TERMS AND CONDITIONS FOR COPYING, DISTRIBUTION AND MODIFICATION
+
+  0. This License applies to any program or other work which contains
+a notice placed by the copyright holder saying it may be distributed
+under the terms of this General Public License.  The "Program", below,
+refers to any such program or work, and a "work based on the Program"
+means either the Program or any derivative work under copyright law:
+that is to say, a work containing the Program or a portion of it,
+either verbatim or with modifications and/or translated into another
+language.  (Hereinafter, translation is included without limitation in
+the term "modification".)  Each licensee is addressed as "you".
+
+Activities other than copying, distribution and modification are not
+covered by this License; they are outside its scope.  The act of
+running the Program is not restricted, and the output from the Program
+is covered only if its contents constitute a work based on the
+Program (independent of having been made by running the Program).
+Whether that is true depends on what the Program does.
+
+  1. You may copy and distribute verbatim copies of the Program's
+source code as you receive it, in any medium, provided that you
+conspicuously and appropriately publish on each copy an appropriate
+copyright notice and disclaimer of warranty; keep intact all the
+notices that refer to this License and to the absence of any warranty;
+and give any other recipients of the Program a copy of this License
+along with the Program.
+
+You may charge a fee for the physical act of transferring a copy, and
+you may at your option offer warranty protection in exchange for a fee.
+
+  2. You may modify your copy or copies of the Program or any portion
+of it, thus forming a work based on the Program, and copy and
+distribute such modifications or work under the terms of Section 1
+above, provided that you also meet all of these conditions:
+
+    a) You must cause the modified files to carry prominent notices
+    stating that you changed the files and the date of any change.
+
+    b) You must cause any work that you distribute or publish, that in
+    whole or in part contains or is derived from the Program or any
+    part thereof, to be licensed as a whole at no charge to all third
+    parties under the terms of this License.
+
+    c) If the modified program normally reads commands interactively
+    when run, you must cause it, when started running for such
+    interactive use in the most ordinary way, to print or display an
+    announcement including an appropriate copyright notice and a
+    notice that there is no warranty (or else, saying that you provide
+    a warranty) and that users may redistribute the program under
+    these conditions, and telling the user how to view a copy of this
+    License.  (Exception: if the Program itself is interactive but
+    does not normally print such an announcement, your work based on
+    the Program is not required to print an announcement.)
+
+These requirements apply to the modified work as a whole.  If
+identifiable sections of that work are not derived from the Program,
+and can be reasonably considered independent and separate works in
+themselves, then this License, and its terms, do not apply to those
+sections when you distribute them as separate works.  But when you
+distribute the same sections as part of a whole which is a work based
+on the Program, the distribution of the whole must be on the terms of
+this License, whose permissions for other licensees extend to the
+entire whole, and thus to each and every part regardless of who wrote it.
+
+Thus, it is not the intent of this section to claim rights or contest
+your rights to work written entirely by you; rather, the intent is to
+exercise the right to control the distribution of derivative or
+collective works based on the Program.
+
+In addition, mere aggregation of another work not based on the Program
+with the Program (or with a work based on the Program) on a volume of
+a storage or distribution medium does not bring the other work under
+the scope of this License.
+
+  3. You may copy and distribute the Program (or a work based on it,
+under Section 2) in object code or executable form under the terms of
+Sections 1 and 2 above provided that you also do one of the following:
+
+    a) Accompany it with the complete corresponding machine-readable
+    source code, which must be distributed under the terms of Sections
+    1 and 2 above on a medium customarily used for software interchange; or,
+
+    b) Accompany it with a written offer, valid for at least three
+    years, to give any third party, for a charge no more than your
+    cost of physically performing source distribution, a complete
+    machine-readable copy of the corresponding source code, to be
+    distributed under the terms of Sections 1 and 2 above on a medium
+    customarily used for software interchange; or,
+
+    c) Accompany it with the information you received as to the offer
+    to distribute corresponding source code.  (This alternative is
+    allowed only for noncommercial distribution and only if you
+    received the program in object code or executable form with such
+    an offer, in accord with Subsection b above.)
+
+The source code for a work means the preferred form of the work for
+making modifications to it.  For an executable work, complete source
+code means all the source code for all modules it contains, plus any
+associated interface definition files, plus the scripts used to
+control compilation and installation of the executable.  However, as a
+special exception, the source code distributed need not include
+anything that is normally distributed (in either source or binary
+form) with the major components (compiler, kernel, and so on) of the
+operating system on which the executable runs, unless that component
+itself accompanies the executable.
+
+If distribution of executable or object code is made by offering
+access to copy from a designated place, then offering equivalent
+access to copy the source code from the same place counts as
+distribution of the source code, even though third parties are not
+compelled to copy the source along with the object code.
+
+  4. You may not copy, modify, sublicense, or distribute the Program
+except as expressly provided under this License.  Any attempt
+otherwise to copy, modify, sublicense or distribute the Program is
+void, and will automatically terminate your rights under this License.
+However, parties who have received copies, or rights, from you under
+this License will not have their licenses terminated so long as such
+parties remain in full compliance.
+
+  5. You are not required to accept this License, since you have not
+signed it.  However, nothing else grants you permission to modify or
+distribute the Program or its derivative works.  These actions are
+prohibited by law if you do not accept this License.  Therefore, by
+modifying or distributing the Program (or any work based on the
+Program), you indicate your acceptance of this License to do so, and
+all its terms and conditions for copying, distributing or modifying
+the Program or works based on it.
+
+  6. Each time you redistribute the Program (or any work based on the
+Program), the recipient automatically receives a license from the
+original licensor to copy, distribute or modify the Program subject to
+these terms and conditions.  You may not impose any further
+restrictions on the recipients' exercise of the rights granted herein.
+You are not responsible for enforcing compliance by third parties to
+this License.
+
+  7. If, as a consequence of a court judgment or allegation of patent
+infringement or for any other reason (not limited to patent issues),
+conditions are imposed on you (whether by court order, agreement or
+otherwise) that contradict the conditions of this License, they do not
+excuse you from the conditions of this License.  If you cannot
+distribute so as to satisfy simultaneously your obligations under this
+License and any other pertinent obligations, then as a consequence you
+may not distribute the Program at all.  For example, if a patent
+license would not permit royalty-free redistribution of the Program by
+all those who receive copies directly or indirectly through you, then
+the only way you could satisfy both it and this License would be to
+refrain entirely from distribution of the Program.
+
+If any portion of this section is held invalid or unenforceable under
+any particular circumstance, the balance of the section is intended to
+apply and the section as a whole is intended to apply in other
+circumstances.
+
+It is not the purpose of this section to induce you to infringe any
+patents or other property right claims or to contest validity of any
+such claims; this section has the sole purpose of protecting the
+integrity of the free software distribution system, which is
+implemented by public license practices.  Many people have made
+generous contributions to the wide range of software distributed
+through that system in reliance on consistent application of that
+system; it is up to the author/donor to decide if he or she is willing
+to distribute software through any other system and a licensee cannot
+impose that choice.
+
+This section is intended to make thoroughly clear what is believed to
+be a consequence of the rest of this License.
+
+  8. If the distribution and/or use of the Program is restricted in
+certain countries either by patents or by copyrighted interfaces, the
+original copyright holder who places the Program under this License
+may add an explicit geographical distribution limitation excluding
+those countries, so that distribution is permitted only in or among
+countries not thus excluded.  In such case, this License incorporates
+the limitation as if written in the body of this License.
+
+  9. The Free Software Foundation may publish revised and/or new versions
+of the General Public License from time to time.  Such new versions will
+be similar in spirit to the present version, but may differ in detail to
+address new problems or concerns.
+
+Each version is given a distinguishing version number.  If the Program
+specifies a version number of this License which applies to it and "any
+later version", you have the option of following the terms and conditions
+either of that version or of any later version published by the Free
+Software Foundation.  If the Program does not specify a version number of
+this License, you may choose any version ever published by the Free Software
+Foundation.
+
+  10. If you wish to incorporate parts of the Program into other free
+programs whose distribution conditions are different, write to the author
+to ask for permission.  For software which is copyrighted by the Free
+Software Foundation, write to the Free Software Foundation; we sometimes
+make exceptions for this.  Our decision will be guided by the two goals
+of preserving the free status of all derivatives of our free software and
+of promoting the sharing and reuse of software generally.
+
+			    NO WARRANTY
+
+  11. BECAUSE THE PROGRAM IS LICENSED FREE OF CHARGE, THERE IS NO WARRANTY
+FOR THE PROGRAM, TO THE EXTENT PERMITTED BY APPLICABLE LAW.  EXCEPT WHEN
+OTHERWISE STATED IN WRITING THE COPYRIGHT HOLDERS AND/OR OTHER PARTIES
+PROVIDE THE PROGRAM "AS IS" WITHOUT WARRANTY OF ANY KIND, EITHER EXPRESSED
+OR IMPLIED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
+MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE.  THE ENTIRE RISK AS
+TO THE QUALITY AND PERFORMANCE OF THE PROGRAM IS WITH YOU.  SHOULD THE
+PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF ALL NECESSARY SERVICING,
+REPAIR OR CORRECTION.
+
+  12. IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING
+WILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MAY MODIFY AND/OR
+REDISTRIBUTE THE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES,
+INCLUDING ANY GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING
+OUT OF THE USE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED
+TO LOSS OF DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY
+YOU OR THIRD PARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER
+PROGRAMS), EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE
+POSSIBILITY OF SUCH DAMAGES.
+
+		     END OF TERMS AND CONDITIONS
+
+	    How to Apply These Terms to Your New Programs
+
+  If you develop a new program, and you want it to be of the greatest
+possible use to the public, the best way to achieve this is to make it
+free software which everyone can redistribute and change under these terms.
+
+  To do so, attach the following notices to the program.  It is safest
+to attach them to the start of each source file to most effectively
+convey the exclusion of warranty; and each file should have at least
+the "copyright" line and a pointer to where the full notice is found.
+
+    <one line to give the program's name and a brief idea of what it does.>
+    Copyright (C) <year>  <name of author>
+
+    This program is free software; you can redistribute it and/or modify
+    it under the terms of the GNU General Public License as published by
+    the Free Software Foundation; either version 2 of the License, or
+    (at your option) any later version.
+
+    This program is distributed in the hope that it will be useful,
+    but WITHOUT ANY WARRANTY; without even the implied warranty of
+    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+    GNU General Public License for more details.
+
+    You should have received a copy of the GNU General Public License along
+    with this program; if not, write to the Free Software Foundation, Inc.,
+    51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA.
+
+Also add information on how to contact you by electronic and paper mail.
+
+If the program is interactive, make it output a short notice like this
+when it starts in an interactive mode:
+
+    Gnomovision version 69, Copyright (C) year name of author
+    Gnomovision comes with ABSOLUTELY NO WARRANTY; for details type `show w'.
+    This is free software, and you are welcome to redistribute it
+    under certain conditions; type `show c' for details.
+
+The hypothetical commands `show w' and `show c' should show the appropriate
+parts of the General Public License.  Of course, the commands you use may
+be called something other than `show w' and `show c'; they could even be
+mouse-clicks or menu items--whatever suits your program.
+
+You should also get your employer (if you work as a programmer) or your
+school, if any, to sign a "copyright disclaimer" for the program, if
+necessary.  Here is a sample; alter the names:
+
+  Yoyodyne, Inc., hereby disclaims all copyright interest in the program
+  `Gnomovision' (which makes passes at compilers) written by James Hacker.
+
+  <signature of Ty Coon>, 1 April 1989
+  Ty Coon, President of Vice
+
+This General Public License does not permit incorporating your program into
+proprietary programs.  If your program is a subroutine library, you may
+consider it more useful to permit linking proprietary applications with the
+library.  If this is what you want to do, use the GNU Lesser General
+Public License instead of this License.
--- kernel/linux-2.6.26.3/drivers/misc/vmsync/driver-config.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmsync/driver-config.h	2008-09-03 10:02:32.000000000 -0500
@@ -0,0 +1,78 @@
+/*********************************************************
+ * Copyright (C) 1998 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * Sets the proper defines from the Linux header files
+ *
+ * This file must be included before the inclusion of any kernel header file,
+ * with the exception of linux/autoconf.h and linux/version.h --hpreg
+ */
+
+#ifndef __VMX_CONFIG_H__
+#define __VMX_CONFIG_H__
+
+#define INCLUDE_ALLOW_VMCORE
+#define INCLUDE_ALLOW_VMMON
+#define INCLUDE_ALLOW_MODULE
+#define INCLUDE_ALLOW_VMNIXMOD
+#include "includeCheck.h"
+
+#include <linux/autoconf.h>
+#include "compat_version.h"
+
+/*
+ * We rely on Kernel Module support.  Check here.
+ */
+#ifndef CONFIG_MODULES
+#   error "No Module support in this kernel.  Please configure with CONFIG_MODULES"
+#endif
+
+/*
+ * 2.2 kernels still use __SMP__ (derived from CONFIG_SMP
+ * in the main Makefile), so we do it here.
+ */
+
+#ifdef CONFIG_SMP
+#   define __SMP__ 1
+#endif
+
+#if defined(CONFIG_MODVERSIONS) && defined(KERNEL_2_1)
+#   if LINUX_VERSION_CODE < KERNEL_VERSION(2,5,60)
+/*
+ * MODVERSIONS might be already defined when using kernel's Makefiles.
+ */
+#      ifndef MODVERSIONS
+#         define MODVERSIONS
+#      endif
+#      include <linux/modversions.h>
+#   endif
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 24)
+/*
+ * Force the uintptr_t definition to come from linux/types.h instead of vm_basic_types.h.
+ */
+#   include <linux/types.h>
+#   define _STDINT_H 1
+#endif
+
+#ifndef __KERNEL__
+#   define __KERNEL__
+#endif
+
+#endif
--- kernel/linux-2.6.26.3/drivers/misc/vmsync/includeCheck.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmsync/includeCheck.h	2008-09-03 10:02:32.000000000 -0500
@@ -0,0 +1,132 @@
+/*********************************************************
+ * Copyright (C) 1998 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * includeCheck.h --
+ *
+ *	Restrict include file use.
+ *
+ * In every .h file, define one or more of these
+ *
+ *	INCLUDE_ALLOW_VMX 
+ *	INCLUDE_ALLOW_USERLEVEL 
+ *	INCLUDE_ALLOW_VMMEXT
+ *	INCLUDE_ALLOW_VMCORE
+ *	INCLUDE_ALLOW_MODULE
+ *      INCLUDE_ALLOW_VMNIXMOD 
+ *	INCLUDE_ALLOW_VMKERNEL 
+ *	INCLUDE_ALLOW_DISTRIBUTE
+ *	INCLUDE_ALLOW_VMK_MODULE
+ *      INCLUDE_ALLOW_VMKDRIVERS
+ *      INCLUDE_ALLOW_VMIROM
+ *
+ * Then include this file.
+ *
+ * Any file that has INCLUDE_ALLOW_DISTRIBUTE defined will potentially
+ * be distributed in source form along with GPLed code.  Ensure
+ * that this is acceptable.
+ */
+
+
+/*
+ * Declare a VMCORE-only variable to help classify object
+ * files.  The variable goes in the common block and does
+ * not create multiple definition link-time conflicts.
+ */
+
+#if defined VMCORE && defined VMX86_DEVEL && defined VMX86_DEBUG && \
+    defined linux && !defined MODULE && \
+    !defined COMPILED_WITH_VMCORE
+#define COMPILED_WITH_VMCORE compiled_with_vmcore
+#ifdef ASM
+        .comm   compiled_with_vmcore, 0
+#else
+        asm(".comm compiled_with_vmcore, 0");
+#endif /* ASM */
+#endif
+
+
+#if defined VMCORE && \
+    !(defined VMX86_VMX || defined VMM || \
+      defined MONITOR_APP || defined VMMON)
+#error "Makefile problem: VMCORE without VMX86_VMX or \
+        VMM or MONITOR_APP or MODULE."
+#endif
+
+#if defined VMCORE && !defined INCLUDE_ALLOW_VMCORE
+#error "The surrounding include file is not allowed in vmcore."
+#endif
+#undef INCLUDE_ALLOW_VMCORE
+
+#if defined VMX86_VMX && !defined VMCORE && \
+    !(defined INCLUDE_ALLOW_VMX || defined INCLUDE_ALLOW_USERLEVEL)
+#error "The surrounding include file is not allowed in the VMX."
+#endif
+#undef INCLUDE_ALLOW_VMX
+
+#if defined USERLEVEL && !defined VMX86_VMX && !defined VMCORE && \
+    !defined INCLUDE_ALLOW_USERLEVEL
+#error "The surrounding include file is not allowed at userlevel."
+#endif
+#undef INCLUDE_ALLOW_USERLEVEL
+
+#if defined VMM && !defined VMCORE && \
+    !defined INCLUDE_ALLOW_VMMEXT
+#error "The surrounding include file is not allowed in the monitor."
+#endif
+#undef INCLUDE_ALLOW_VMMEXT
+
+#if defined MODULE && !defined VMKERNEL_MODULE && !defined VMNIXMOD && \
+    !defined VMMON && !defined INCLUDE_ALLOW_MODULE
+#error "The surrounding include file is not allowed in driver modules."
+#endif
+#undef INCLUDE_ALLOW_MODULE
+
+#if defined VMMON && !defined INCLUDE_ALLOW_VMMON
+#error "The surrounding include file is not allowed in vmmon."
+#endif
+#undef INCLUDE_ALLOW_VMMON
+
+#if defined VMKERNEL && !defined INCLUDE_ALLOW_VMKERNEL
+#error "The surrounding include file is not allowed in the vmkernel."
+#endif
+#undef INCLUDE_ALLOW_VMKERNEL
+
+#if defined GPLED_CODE && !defined INCLUDE_ALLOW_DISTRIBUTE
+#error "The surrounding include file is not allowed in GPL code."
+#endif
+#undef INCLUDE_ALLOW_DISTRIBUTE
+
+#if defined VMKERNEL_MODULE && !defined VMKERNEL && \
+    !defined INCLUDE_ALLOW_VMK_MODULE && !defined INCLUDE_ALLOW_VMKDRIVERS
+#error "The surrounding include file is not allowed in vmkernel modules."
+#endif
+#undef INCLUDE_ALLOW_VMK_MODULE
+#undef INCLUDE_ALLOW_VMKDRIVERS
+
+#if defined VMNIXMOD && !defined INCLUDE_ALLOW_VMNIXMOD
+#ifndef VMNIXMOD_VM
+#error "The surrounding include file is not allowed in vmnixmod."
+#endif
+#endif
+#undef INCLUDE_ALLOW_VMNIXMOD
+
+#if defined VMIROM && ! defined INCLUDE_ALLOW_VMIROM
+#error "The surrounding include file is not allowed in vmirom."
+#endif
+#undef INCLUDE_ALLOW_VMIROM
--- kernel/linux-2.6.26.3/drivers/misc/vmsync/Makefile	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmsync/Makefile	2008-09-03 09:57:34.000000000 -0500
@@ -0,0 +1,29 @@
+#!/usr/bin/make -f
+##########################################################
+# Copyright (C) 1998 VMware, Inc. All rights reserved.
+#
+# This program is free software; you can redistribute it and/or modify it
+# under the terms of the GNU General Public License as published by the
+# Free Software Foundation version 2 and no later version.
+#
+# This program is distributed in the hope that it will be useful, but
+# WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+# or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+# for more details.
+#
+# You should have received a copy of the GNU General Public License along
+# with this program; if not, write to the Free Software Foundation, Inc.,
+# 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+#
+##########################################################
+
+####
+####  VMware vmsync Makefile to be distributed externally
+####
+
+obj-$(CONFIG_VMSYNC) += vmsync.o
+
+
+vmsync-objs := sync.o
+
+EXTRA_CFLAGS += -DVMW_USING_KBUILD -DVMW_KMEMCR_CTOR_HAS_3_ARGS
--- kernel/linux-2.6.26.3/drivers/misc/vmsync/sync.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmsync/sync.c	2008-09-03 10:02:32.000000000 -0500
@@ -0,0 +1,704 @@
+/*********************************************************
+ * Copyright (C) 2007 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * sync.c --
+ *
+ * Linux "sync driver" implementation.
+ *
+ * A typical user of vmsync will:
+ *
+ * - call ioctl() with the SYNC_IOC_FREEZE to freeze a list of paths.
+ *   The list should be a colon-separated list of paths to be frozen.
+ * - call ioctl() with the SYNC_IOC_THAW command.
+ *
+ * The driver has an internal timer that is set up as soon as devices
+ * are frozen (i.e., after a successful SYNC_IOC_FREEZE). Subsequent calls
+ * to SYNC_IOC_FREEZE will not reset the timer. This timer is not designed
+ * as a way to protect the driver from being an avenue for a DoS attack
+ * (after all, if the user already has CAP_SYS_ADMIN privileges...), but
+ * as a way to protect itself from faulty user level apps during testing.
+ */
+
+/* Must come before any kernel header file. */
+#include "driver-config.h"
+
+#include <asm/bug.h>
+#include <asm/uaccess.h>
+#include <asm/string.h>
+#include <linux/buffer_head.h>
+#include <linux/proc_fs.h>
+
+#include "compat_fs.h"
+#include "compat_module.h"
+#include "compat_namei.h"
+#include "compat_semaphore.h"
+#include "compat_slab.h"
+#include "compat_workqueue.h"
+
+#include "syncDriverIoc.h"
+#include "vmsync_version.h"
+
+/*
+ * After a successful SYNC_IOC_FREEZE ioctl, a timer will be enabled to thaw
+ * *all* frozen block devices after this delay.
+ */
+#define VMSYNC_THAW_TASK_DELAY (30 * HZ)
+
+/* Module information. */
+MODULE_AUTHOR("VMware, Inc.");
+MODULE_DESCRIPTION("VMware Sync Driver");
+MODULE_VERSION(VMSYNC_DRIVER_VERSION_STRING);
+MODULE_LICENSE("GPL v2");
+
+static int VmSyncRelease(struct inode* inode,
+                         struct file *file);
+
+static long VmSyncUnlockedIoctl(struct file *file,
+                                unsigned cmd,
+                                unsigned long arg);
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 11)
+static int VmSyncIoctl(struct inode *inode,
+                       struct file *file,
+                       unsigned cmd,
+                       unsigned long arg);
+#endif
+
+static int VmSyncOpen(struct inode *inode,
+                      struct file *f);
+
+static struct file_operations VmSyncFileOps = {
+   .owner            = THIS_MODULE,
+   .open             = VmSyncOpen,
+   .release          = VmSyncRelease,
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 11)
+   .unlocked_ioctl   = VmSyncUnlockedIoctl,
+#else
+   .ioctl            = VmSyncIoctl,
+#endif
+};
+
+
+typedef struct VmSyncBlockDevice {
+   struct list_head     list;
+   struct block_device  *bdev;
+   struct nameidata     nd;
+   struct super_block   *sb;
+} VmSyncBlockDevice;
+
+
+typedef struct VmSyncState {
+   struct list_head     devices;
+   struct semaphore     lock;
+   compat_delayed_work  thawTask;
+} VmSyncState;
+
+
+/*
+ * Serializes freeze operations. Used to make sure that two different
+ * fds aren't allowed to freeze the same device.
+ */
+static struct semaphore gFreezeLock;
+
+/* A global count of how many devices are currently frozen by the driver. */
+static atomic_t gFreezeCount;
+
+static compat_kmem_cache *gSyncStateCache;
+static compat_kmem_cache *gBlockDeviceCache;
+
+static compat_kmem_cache_ctor VmSyncBlockDeviceCtor;
+static compat_kmem_cache_ctor VmSyncStateCtor;
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VmSyncThawDevices --
+ *
+ *    Thaws all currently frozen devices.
+ *
+ * Results:
+ *    None.
+ *
+ * Side effects:
+ *    Devices are thawed, thaw task is cancelled.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static void
+VmSyncThawDevices(void  *_state)  // IN
+{
+   struct list_head *cur, *tmp;
+   VmSyncBlockDevice *dev;
+   VmSyncState *state;
+
+   state = (VmSyncState *) _state;
+
+   down(&state->lock);
+   cancel_delayed_work(&state->thawTask);
+   list_for_each_safe(cur, tmp, &state->devices) {
+      dev = list_entry(cur, VmSyncBlockDevice, list);
+      if (dev->sb != NULL && dev->sb->s_frozen != SB_UNFROZEN) {
+         thaw_bdev(dev->bdev, dev->sb);
+         atomic_dec(&gFreezeCount);
+      }
+      list_del_init(&dev->list);
+      kmem_cache_free(gBlockDeviceCache, dev);
+   }
+   up(&state->lock);
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VmSyncThawDevicesCallback --
+ *
+ *    Wrapper around VmSyncThawDevices used by the work queue.
+ *
+ * Results:
+ *    None.
+ *
+ * Side effects:
+ *    See VmSyncThawDevices.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static void
+VmSyncThawDevicesCallback(compat_delayed_work_arg data) // IN
+{
+   VmSyncState *state = COMPAT_DELAYED_WORK_GET_DATA(data,
+                                                     VmSyncState, thawTask);
+   VmSyncThawDevices(state);
+}
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VmSyncAddPath --
+ *
+ *    Adds the block device associated with the path to the internal list
+ *    of devices to be frozen.
+ *
+ * Results:
+ *    0 on success.
+ *    -EINVAL if path doesn't point to a freezable mount.
+ *    -EALREADY if path is already frozen.
+ *
+ * Side effects:
+ *    None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static int
+VmSyncAddPath(const VmSyncState *state,   // IN
+              const char *path,           // IN
+              struct list_head *pathList) // IN
+{
+   int result;
+   struct list_head *cur, *tmp;
+   struct inode *inode;
+   struct nameidata nd;
+   VmSyncBlockDevice *dev;
+
+   if ((result = path_lookup(path, LOOKUP_FOLLOW, &nd)) != 0) {
+      goto exit;
+   }
+   inode = compat_vmw_nd_to_dentry(nd)->d_inode;
+
+   /*
+    * Abort if the inode's superblock isn't backed by a block device, or if
+    * the superblock is already frozen.
+    */
+   if (inode->i_sb->s_bdev == NULL ||
+       inode->i_sb->s_frozen != SB_UNFROZEN) {
+      result = (inode->i_sb->s_bdev == NULL) ? -EINVAL : -EALREADY;
+      compat_path_release(&nd);
+      goto exit;
+   }
+
+   /*
+    * Check if we've already added the block device to the list.
+    */
+   list_for_each_safe(cur, tmp, &state->devices) {
+      dev = list_entry(cur, VmSyncBlockDevice, list);
+      if (dev->bdev == inode->i_sb->s_bdev) {
+         result = 0;
+         compat_path_release(&nd);
+         goto exit;
+      }
+   }
+
+   /*
+    * Allocate a new entry and add it to the list.
+    */
+   dev = kmem_cache_alloc(gBlockDeviceCache, GFP_KERNEL);
+   if (dev == NULL) {
+      result = -ENOMEM;
+      compat_path_release(&nd);
+      goto exit;
+   }
+
+   /*
+    * Whenever we add a device to the "freeze list", the reference to
+    * the nameidata struct is retained until the device is actually
+    * frozen; this ensures the kernel knows the path is being used.
+    * Here we copy the nameidata struct so we can release our reference
+    * at that time.
+    */
+   dev->bdev = inode->i_sb->s_bdev;
+   memcpy(&dev->nd, &nd, sizeof nd);
+   list_add_tail(&dev->list, pathList);
+   result = 0;
+
+exit:
+   return result;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VmSyncFreezeDevices --
+ *
+ *    Tries to freeze all the devices provided by the user.
+ *
+ * Results:
+ *    o on success, -errno on error.
+ *
+ * Side effects:
+ *    A task is scheduled to automatically thaw devices after a timeout.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static int
+VmSyncFreezeDevices(VmSyncState *state,            // IN
+                    const char __user *userPaths)  // IN
+{
+   int result = 0;
+   char *paths;
+   char *currPath;
+   char *nextSep;
+   struct list_head *cur, *tmp;
+   struct list_head pathList;
+   VmSyncBlockDevice *dev;
+
+   INIT_LIST_HEAD(&pathList);
+
+   /*
+    * XXX: Using getname() will restrict the list of paths to PATH_MAX.
+    * Although this is not ideal, it shouldn't be a problem. We need an
+    * upper bound anyway.
+    */
+   paths = getname(userPaths);
+   if (IS_ERR(paths)) {
+      return PTR_ERR(paths);
+   }
+
+   down(&gFreezeLock);
+   down(&state->lock);
+
+   /*
+    * First, try to add all paths to the list of paths to be frozen.
+    */
+   currPath = paths;
+   do {
+      nextSep = strchr(currPath, ':');
+      if (nextSep != NULL) {
+         *nextSep = '\0';
+      }
+      result = VmSyncAddPath(state, currPath, &pathList);
+      /*
+       * Due to the way our user level app decides which paths to freeze
+       * now, we need to ignore EINVAL since there's no way to detect
+       * from user-land which paths are freezable or not.
+       */
+      if (result != 0 && result != -EINVAL) {
+         break;
+      } else {
+         result = 0;
+      }
+      currPath = nextSep + 1;
+   } while (nextSep != NULL);
+
+   /*
+    * If adding all the requested paths worked, then freeze them.
+    * Otherwise, clean the list. Make sure we only touch the devices
+    * added in the current call.
+    */
+   list_for_each_safe(cur, tmp, &pathList) {
+      dev = list_entry(cur, VmSyncBlockDevice, list);
+      if (result == 0) {
+         dev->sb = freeze_bdev(dev->bdev);
+         compat_path_release(&dev->nd);
+         if (dev->sb != NULL) {
+            atomic_inc(&gFreezeCount);
+         }
+         list_move_tail(&dev->list, &state->devices);
+      } else {
+         list_del_init(&dev->list);
+         kmem_cache_free(gBlockDeviceCache, dev);
+      }
+   }
+
+   up(&state->lock);
+   up(&gFreezeLock);
+
+   if (result == 0) {
+      compat_schedule_delayed_work(&state->thawTask, VMSYNC_THAW_TASK_DELAY);
+   }
+   return result;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VmSyncQuery --
+ *
+ *    Writes the number of devices currently frozen by the driver to the
+ *    given address. The address should be in user space and be able to
+ *    hold an int32_t.
+ *
+ * Results:
+ *    0 on success, -errno on failure.
+ *
+ * Side effects:
+ *    None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static inline int
+VmSyncQuery(void __user *dst) // OUT
+{
+   int32_t active;
+   int result = 0;
+
+   active = (int32_t) atomic_read(&gFreezeCount);
+   if (copy_to_user(dst, &active, sizeof active)) {
+      result = -EFAULT;
+   }
+
+   return result;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VmSyncUnlockedIoctl --
+ *
+ *    Handles the IOCTLs recognized by the driver.
+ *
+ *    - SYNC_IOC_FREEZE: freezes the block device associated with the
+ *      path passed as a parameter.
+ *
+ *    - SYNC_IOC_THAW: thaws all currently frozen block devices.
+ *
+ *    - SYNC_IOC_QUERY: returns the number of block devices currently
+ *      frozen by the driver. This is a global view of the driver state
+ *      and doesn't reflect any fd-specific data.
+ *
+ * Results:
+ *    0 on success, -errno otherwise.
+ *
+ * Side effects:
+ *    See ioctl descriptions above.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static long
+VmSyncUnlockedIoctl(struct file *file,   // IN
+                    unsigned cmd,        // IN
+                    unsigned long arg)   // IN/OUT
+{
+   int result = -ENOTTY;
+   VmSyncState *state;
+
+   state = (VmSyncState *) file->private_data;
+
+   switch (cmd) {
+   case SYNC_IOC_FREEZE:
+      if (!capable(CAP_SYS_ADMIN)) {
+         result = -EPERM;
+         break;
+      }
+      result = VmSyncFreezeDevices(state, (const char __user *) arg);
+      break;
+
+   case SYNC_IOC_THAW:
+      if (!capable(CAP_SYS_ADMIN)) {
+         result = -EPERM;
+         break;
+      }
+      VmSyncThawDevices(state);
+      result = 0;
+      break;
+
+   case SYNC_IOC_QUERY:
+      result = VmSyncQuery((void __user *)arg);
+      break;
+
+   default:
+      printk(KERN_DEBUG "vmsync: unknown ioctl %d\n", cmd);
+      break;
+   }
+   return result;
+}
+
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 11)
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VmSyncIoctl --
+ *
+ *    Wrapper around VmSyncUnlockedIoctl for kernels < 2.6.11, which don't
+ *    support unlocked_ioctl.
+ *
+ * Results:
+ *    See VmSyncUnlockedIoctl.
+ *
+ * Side effects:
+ *    See VmSyncUnlockedIoctl.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static int
+VmSyncIoctl(struct inode *inode, // IN
+            struct file *file,   // IN
+            unsigned cmd,        // IN
+            unsigned long arg)   // IN/OUT
+{
+   return (int) VmSyncUnlockedIoctl(file, cmd, arg);
+}
+#endif
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VmSyncOpen --
+ *
+ *    Instantiates a new state object and attached it to the file struct.
+ *
+ * Results:
+ *    0, or -ENOMEM if can't allocate memory.
+ *
+ * Side effects:
+ *    None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static int
+VmSyncOpen(struct inode *inode,  // IN
+           struct file *f)       // IN
+{
+   if (capable(CAP_SYS_ADMIN)) {
+      f->private_data = kmem_cache_alloc(gSyncStateCache, GFP_KERNEL);
+      if (f->private_data == NULL) {
+         return -ENOMEM;
+      }
+   }
+   return 0;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VmSyncRelease --
+ *
+ *    If the fd was used to freeze devices, then thaw all frozen block devices.
+ *
+ * Results:
+ *    Returns 0.
+ *
+ * Side effects:
+ *    Calls VmSyncThawDevices.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static int
+VmSyncRelease(struct inode *inode,  // IN
+              struct file *file)    // IN
+{
+   if (capable(CAP_SYS_ADMIN)) {
+      VmSyncState *state = (VmSyncState *) file->private_data;
+      if (!cancel_delayed_work(&state->thawTask)) {
+         flush_scheduled_work();
+      }
+      VmSyncThawDevices(state);
+      kmem_cache_free(gSyncStateCache, state);
+   }
+   return 0;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VmSyncBlockDeviceCtor --
+ *
+ *    Constructor for VmSyncBlockDevice objects.
+ *
+ * Results:
+ *    None.
+ *
+ * Side effects:
+ *    None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static void
+VmSyncBlockDeviceCtor(COMPAT_KMEM_CACHE_CTOR_ARGS(slabelem))  // IN
+{
+   VmSyncBlockDevice *dev = slabelem;
+
+   INIT_LIST_HEAD(&dev->list);
+   dev->bdev = NULL;
+   dev->sb = NULL;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VmSyncStateCtor --
+ *
+ *    Constructor for VmSyncState objects.
+ *
+ * Results:
+ *    None.
+ *
+ * Side effects:
+ *    None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static void
+VmSyncStateCtor(COMPAT_KMEM_CACHE_CTOR_ARGS(slabelem))  // IN
+{
+   VmSyncState *state = slabelem;
+
+   INIT_LIST_HEAD(&state->devices);
+   COMPAT_INIT_DELAYED_WORK(&state->thawTask,
+                            VmSyncThawDevicesCallback, &state);
+   init_MUTEX(&state->lock);
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * init_module --
+ *
+ *    Initializes the structures used by the driver, and creates the
+ *    proc file used by the driver to receive commands.
+ *
+ * Results:
+ *    None.
+ *
+ * Side effects:
+ *    None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+int
+init_module(void)
+{
+   struct proc_dir_entry *controlProcEntry;
+
+   atomic_set(&gFreezeCount, 0);
+   init_MUTEX(&gFreezeLock);
+
+   /* Create the slab allocators for the module. */
+   gBlockDeviceCache = compat_kmem_cache_create("VmSyncBlockDeviceCache",
+                                                sizeof (VmSyncBlockDevice),
+                                                0,
+                                                SLAB_HWCACHE_ALIGN,
+                                                VmSyncBlockDeviceCtor);
+   if (gBlockDeviceCache == NULL) {
+      printk(KERN_ERR "vmsync: no memory for block dev slab allocator\n");
+      return -ENOMEM;
+   }
+
+   gSyncStateCache = compat_kmem_cache_create("VmSyncStateCache",
+                                              sizeof (VmSyncState),
+                                              0,
+                                              SLAB_HWCACHE_ALIGN,
+                                              VmSyncStateCtor);
+   if (gSyncStateCache == NULL) {
+      printk(KERN_ERR "vmsync: no memory for sync state slab allocator\n");
+      kmem_cache_destroy(gBlockDeviceCache);
+      return -ENOMEM;
+   }
+
+   /* Create /proc/driver/vmware-sync */
+   controlProcEntry = create_proc_entry("driver/vmware-sync",
+                                        S_IFREG | S_IRUSR | S_IRGRP | S_IROTH,
+                                        NULL);
+   if (!controlProcEntry) {
+      printk(KERN_ERR "vmsync: could not create /proc/driver/vmware-sync\n");
+      kmem_cache_destroy(gSyncStateCache);
+      kmem_cache_destroy(gBlockDeviceCache);
+      return -EINVAL;
+   }
+
+   controlProcEntry->proc_fops = &VmSyncFileOps;
+   return 0;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * cleanup_module --
+ *
+ *    Unregisters the proc file used by the driver.
+ *
+ * Results:
+ *    None.
+ *
+ * Side effects:
+ *    None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+void
+cleanup_module(void)
+{
+   remove_proc_entry("driver/vmware-sync", NULL);
+   kmem_cache_destroy(gSyncStateCache);
+   kmem_cache_destroy(gBlockDeviceCache);
+}
+
--- kernel/linux-2.6.26.3/drivers/misc/vmsync/syncDriverIoc.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmsync/syncDriverIoc.h	2008-09-03 10:02:32.000000000 -0500
@@ -0,0 +1,48 @@
+/*********************************************************
+ * Copyright (C) 2007 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * syncDriverIoc.h --
+ *
+ * ioctl commands used by the sync driver on Unix systems.
+ *
+ * SYNC_IOC_FREEZE:     Freezes the provided paths.
+ * SYNC_IOC_THAW:       Thaws frozen block devices after a FREEZE ioctl.
+ * SYNC_IOC_QUERY:      Returns the total number of frozen devices (not
+ *                      specific to the fd used).
+ */
+
+#ifndef _SYNCDRIVERIOC_H_
+#define _SYNCDRIVERIOC_H_
+
+#ifdef linux
+
+# include <linux/ioctl.h>
+
+# define SYNC_IOC_FREEZE      _IOW(0xF5,0x01,const char *)
+# define SYNC_IOC_THAW        _IO(0xF5,0x02)
+# define SYNC_IOC_QUERY       _IOR(0xF5,0x03,int)
+
+#else
+
+# error "Driver not yet implemented for this OS."
+
+#endif
+
+#endif /* _SYNCDRIVERIOC_H_ */
+
--- kernel/linux-2.6.26.3/drivers/misc/vmsync/vmsync_version.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vmsync/vmsync_version.h	2008-09-03 10:02:32.000000000 -0500
@@ -0,0 +1,32 @@
+/*********************************************************
+ * Copyright (C) 2007 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * vmsync_version.h --
+ *
+ * Version definitions for the Linux vmsync driver.
+ */
+
+#ifndef _VMSYNC_VERSION_H_
+#define _VMSYNC_VERSION_H_
+
+#define VMSYNC_DRIVER_VERSION          1.1.0.1
+#define VMSYNC_DRIVER_VERSION_COMMAS   1,1,0,1
+#define VMSYNC_DRIVER_VERSION_STRING   "1.1.0.1"
+
+#endif /* _VMSYNC_VERSION_H_ */
--- kernel/linux-2.6.26.3/drivers/misc/vsock/af_vsock.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vsock/af_vsock.c	2008-09-03 10:02:58.000000000 -0500
@@ -0,0 +1,5036 @@
+/*********************************************************
+ * Copyright (C) 2007 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * af_vsock.c --
+ *
+ *      Linux socket module for the VMCI Sockets protocol family.
+ */
+
+
+/*
+ * Implementation notes:
+ *
+ * - There are two kinds of sockets: those created by user action (such as
+ *   calling socket(2)) and those created by incoming connection request
+ *   packets.
+ *
+ * - There are two "global" tables, one for bound sockets (sockets that have
+ *   specified an address that they are responsible for) and one for connected
+ *   sockets (sockets that have established a connection with another socket).
+ *   These tables are "global" in that all sockets on the system are placed
+ *   within them.
+ *   - Note, though, that the bound table contains an extra entry for a list of
+ *     unbound sockets and SOCK_DGRAM sockets will always remain in that list.
+ *     The bound table is used solely for lookup of sockets when packets are
+ *     received and that's not necessary for SOCK_DGRAM sockets since we create
+ *     a datagram handle for each and need not perform a lookup.  Keeping
+ *     SOCK_DGRAM sockets out of the bound hash buckets will reduce the chance
+ *     of collisions when looking for SOCK_STREAM sockets and prevents us from
+ *     having to check the socket type in the hash table lookups.
+ *
+ * - Sockets created by user action will either be "client" sockets that
+ *   initiate a connection or "server" sockets that listen for connections; we
+ *   do not support simultaneous connects (two "client" sockets connecting).
+ *
+ * - "Server" sockets are referred to as listener sockets throughout this
+ *   implementation because they are in the SS_LISTEN state.  When a connection
+ *   request is received (the second kind of socket mentioned above), we create
+ *   a new socket and refer to it as a pending socket.  These pending sockets
+ *   are placed on the pending connection list of the listener socket.  When
+ *   future packets are received for the address the listener socket is bound
+ *   to, we check if the source of the packet is from one that has an existing
+ *   pending connection.  If it does, we process the packet for the pending
+ *   socket.  When that socket reaches the connected state, it is removed from
+ *   the listener socket's pending list and enqueued in the listener socket's
+ *   accept queue.  Callers of accept(2) will accept connected sockets from the
+ *   listener socket's accept queue.  If the socket cannot be accepted for some
+ *   reason then it is marked rejected.  Once the connection is accepted, it is
+ *   owned by the user process and the responsibility for cleanup falls with
+ *   that user process.
+ *
+ * - It is possible that these pending sockets will never reach the connected
+ *   state; in fact, we may never receive another packet after the connection
+ *   request.  Because of this, we must schedule a cleanup function to run in
+ *   the future, after some amount of time passes where a connection should
+ *   have been established.  This function ensures that the socket is off all
+ *   lists so it cannot be retrieved, then drops all references to the socket
+ *   so it is cleaned up (sock_put() -> sk_free() -> our sk_destruct
+ *   implementation).  Note this function will also cleanup rejected sockets,
+ *   those that reach the connected state but leave it before they have been
+ *   accepted.
+ *
+ * - Sockets created by user action will be cleaned up when the user
+ *   process calls close(2), causing our release implementation to be called.
+ *   Our release implementation will perform some cleanup then drop the
+ *   last reference so our sk_destruct implementation is invoked.  Our
+ *   sk_destruct implementation will perform additional cleanup that's common
+ *   for both types of sockets.
+ *
+ * - A socket's reference count is what ensures that the structure won't be
+ *   freed.  Each entry in a list (such as the "global" bound and connected
+ *   tables and the listener socket's pending list and connected queue) ensures
+ *   a reference.  When we defer work until process context and pass a socket
+ *   as our argument, we must ensure the reference count is increased to ensure
+ *   the socket isn't freed before the function is run; the deferred function
+ *   will then drop the reference.
+ *
+ */
+
+#include "driver-config.h"
+
+#include <linux/kmod.h>
+#include <linux/socket.h>
+#include <linux/net.h>
+#include <linux/skbuff.h>
+#include <linux/miscdevice.h>
+#include <linux/poll.h>
+#include <linux/smp.h>
+#include <linux/smp_lock.h>
+#include <asm/io.h>
+#if defined(__x86_64__) && LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 12)
+#   if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 0)
+#      include <asm/ioctl32.h>
+#   else
+#      include <linux/ioctl32.h>
+#   endif
+/* Use weak: not all kernels export sys_ioctl for use by modules */
+#   if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 5, 66)
+asmlinkage __attribute__((weak)) long
+sys_ioctl(unsigned int fd, unsigned int cmd, unsigned long arg);
+#   else
+asmlinkage __attribute__((weak)) int
+sys_ioctl(unsigned int fd, unsigned int cmd, unsigned long arg);
+#   endif
+#endif
+
+#include "compat_module.h"
+#include "compat_kernel.h"
+#include "compat_init.h"
+#include "compat_sock.h"
+#include "compat_wait.h"
+#include "compat_version.h"
+#include "compat_workqueue.h"
+#include "compat_list.h"
+#if defined(HAVE_COMPAT_IOCTL) || defined(HAVE_UNLOCKED_IOCTL)
+# include "compat_semaphore.h"
+#endif
+
+#include "vmware.h"
+
+#include "vsockCommon.h"
+#include "vsockPacket.h"
+#include "vsockVmci.h"
+
+#include "vmci_defs.h"
+#include "vmci_call_defs.h"
+#include "vmci_iocontrols.h"
+#ifdef VMX86_TOOLS
+# include "vmciGuestKernelAPI.h"
+#else
+# include "vmciDatagram.h"
+#endif
+
+#include "af_vsock.h"
+#include "util.h"
+#include "vsock_version.h"
+#include "driverLog.h"
+
+
+#define VSOCK_INVALID_FAMILY        NPROTO
+#define VSOCK_AF_IS_REGISTERED(val) ((val) >= 0 && (val) < NPROTO)
+
+/* Some kernel versions don't define __user. Define it ourself if so. */
+#ifndef __user
+#define __user
+#endif
+
+
+/*
+ * Prototypes
+ */
+
+int VSockVmci_GetAFValue(void);
+
+/* Internal functions. */
+static int VSockVmciRecvDgramCB(void *data, VMCIDatagram *dg);
+#ifdef VMX86_TOOLS
+static int VSockVmciRecvStreamCB(void *data, VMCIDatagram *dg);
+static void VSockVmciPeerAttachCB(VMCIId subId,
+                                  VMCI_EventData *ed, void *clientData);
+static void VSockVmciPeerDetachCB(VMCIId subId,
+                                  VMCI_EventData *ed, void *clientData);
+static int VSockVmciSendControlPktBH(struct sockaddr_vm *src,
+                                     struct sockaddr_vm *dst,
+                                     VSockPacketType type,
+                                     uint64 size,
+                                     uint64 mode,
+                                     VSockWaitingInfo *wait,
+                                     VMCIHandle handle);
+static int VSockVmciSendControlPkt(struct sock *sk, VSockPacketType type,
+                                   uint64 size, uint64 mode,
+                                   VSockWaitingInfo *wait, VMCIHandle handle);
+static void VSockVmciRecvPktWork(compat_work_arg work);
+static int VSockVmciRecvListen(struct sock *sk, VSockPacket *pkt);
+static int VSockVmciRecvConnectingServer(struct sock *sk,
+                                         struct sock *pending, VSockPacket *pkt);
+static int VSockVmciRecvConnectingClient(struct sock *sk, VSockPacket *pkt);
+static int VSockVmciRecvConnectingClientNegotiate(struct sock *sk,
+                                                  VSockPacket *pkt);
+static int VSockVmciRecvConnected(struct sock *sk, VSockPacket *pkt);
+#endif
+static int __VSockVmciBind(struct sock *sk, struct sockaddr_vm *addr);
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 14)
+static struct sock *__VSockVmciCreate(struct socket *sock, unsigned int priority);
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 24)
+static struct sock *__VSockVmciCreate(struct socket *sock, gfp_t priority);
+#else
+static struct sock *__VSockVmciCreate(struct net *net,
+                                      struct socket *sock, gfp_t priority);
+#endif
+static int VSockVmciRegisterAddressFamily(void);
+static void VSockVmciUnregisterAddressFamily(void);
+
+
+/* Socket operations. */
+static void VSockVmciSkDestruct(struct sock *sk);
+static int VSockVmciQueueRcvSkb(struct sock *sk, struct sk_buff *skb);
+static int VSockVmciRelease(struct socket *sock);
+static int VSockVmciBind(struct socket *sock,
+                         struct sockaddr *addr, int addrLen);
+static int VSockVmciDgramConnect(struct socket *sock,
+                                 struct sockaddr *addr, int addrLen, int flags);
+#ifdef VMX86_TOOLS
+static int VSockVmciStreamConnect(struct socket *sock,
+                                  struct sockaddr *addr, int addrLen, int flags);
+static int VSockVmciAccept(struct socket *sock, struct socket *newsock, int flags);
+#endif
+static int VSockVmciGetname(struct socket *sock,
+                            struct sockaddr *addr, int *addrLen, int peer);
+static unsigned int VSockVmciPoll(struct file *file,
+                                  struct socket *sock, poll_table *wait);
+#ifdef VMX86_TOOLS
+static int VSockVmciListen(struct socket *sock, int backlog);
+#endif
+static int VSockVmciShutdown(struct socket *sock, int mode);
+
+#ifdef VMX86_TOOLS
+static int VSockVmciStreamSetsockopt(struct socket *sock, int level, int optname,
+                                     char __user *optval, int optlen);
+static int VSockVmciStreamGetsockopt(struct socket *sock, int level, int optname,
+                                     char __user *optval, int __user * optlen);
+#endif
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 43)
+static int VSockVmciDgramSendmsg(struct socket *sock, struct msghdr *msg,
+                                 int len, struct scm_cookie *scm);
+static int VSockVmciDgramRecvmsg(struct socket *sock, struct msghdr *msg,
+                                 int len, int flags, struct scm_cookie *scm);
+# ifdef VMX86_TOOLS
+static int VSockVmciStreamSendmsg(struct socket *sock, struct msghdr *msg,
+                                  int len, struct scm_cookie *scm);
+static int VSockVmciStreamRecvmsg(struct socket *sock, struct msghdr *msg,
+                                  int len, int flags, struct scm_cookie *scm);
+# endif
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 65)
+static int VSockVmciDgramSendmsg(struct kiocb *kiocb, struct socket *sock,
+                                 struct msghdr *msg, int len,
+                                 struct scm_cookie *scm);
+static int VSockVmciDgramRecvmsg(struct kiocb *kiocb, struct socket *sock,
+                                 struct msghdr *msg, int len,
+                                 int flags, struct scm_cookie *scm);
+# ifdef VMX86_TOOLS
+static int VSockVmciStreamSendmsg(struct kiocb *kiocb, struct socket *sock,
+                                  struct msghdr *msg, int len,
+                                  struct scm_cookie *scm);
+static int VSockVmciStreamRecvmsg(struct kiocb *kiocb, struct socket *sock,
+                                  struct msghdr *msg, int len,
+                                  int flags, struct scm_cookie *scm);
+# endif
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 2)
+static int VSockVmciDgramSendmsg(struct kiocb *kiocb,
+                                 struct socket *sock, struct msghdr *msg, int len);
+static int VSockVmciDgramRecvmsg(struct kiocb *kiocb, struct socket *sock,
+                                 struct msghdr *msg, int len, int flags);
+# ifdef VMX86_TOOLS
+static int VSockVmciStreamSendmsg(struct kiocb *kiocb,
+                                  struct socket *sock, struct msghdr *msg, int len);
+static int VSockVmciStreamRecvmsg(struct kiocb *kiocb, struct socket *sock,
+                                  struct msghdr *msg, int len, int flags);
+# endif
+#else
+static int VSockVmciDgramSendmsg(struct kiocb *kiocb,
+                                 struct socket *sock, struct msghdr *msg, size_t len);
+static int VSockVmciDgramRecvmsg(struct kiocb *kiocb, struct socket *sock,
+                                 struct msghdr *msg, size_t len, int flags);
+# ifdef VMX86_TOOLS
+static int VSockVmciStreamSendmsg(struct kiocb *kiocb,
+                                 struct socket *sock, struct msghdr *msg, size_t len);
+static int VSockVmciStreamRecvmsg(struct kiocb *kiocb, struct socket *sock,
+                                 struct msghdr *msg, size_t len, int flags);
+# endif
+#endif
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 24)
+static int VSockVmciCreate(struct socket *sock, int protocol);
+#else
+static int VSockVmciCreate(struct net *net, struct socket *sock, int protocol);
+#endif
+
+/*
+ * Device operations.
+ */
+int VSockVmciDevOpen(struct inode *inode, struct file *file);
+int VSockVmciDevRelease(struct inode *inode, struct file *file);
+static int VSockVmciDevIoctl(struct inode *inode, struct file *filp,
+                             u_int iocmd, unsigned long ioarg);
+#if defined(HAVE_COMPAT_IOCTL) || defined(HAVE_UNLOCKED_IOCTL)
+static long VSockVmciDevUnlockedIoctl(struct file *filp,
+                                      u_int iocmd, unsigned long ioarg);
+#endif
+
+/*
+ * Variables.
+ */
+
+/* Protocol family.  We only use this for builds against 2.6.9 and later. */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 9)
+static struct proto vsockVmciProto = {
+   .name     = "AF_VMCI",
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 10)
+   /* Added in 2.6.10. */
+   .owner    = THIS_MODULE,
+#endif
+   /*
+    * Before 2.6.9, each address family created their own slab (by calling
+    * kmem_cache_create() directly).  From 2.6.9 until 2.6.11, these address
+    * families instead called sk_alloc_slab() and the allocated slab was
+    * assigned to the slab variable in the proto struct and was created of size
+    * slab_obj_size.  As of 2.6.12 and later, this slab allocation was moved
+    * into proto_register() and only done if you specified a non-zero value for
+    * the second argument (alloc_slab); the size of the slab element was
+    * changed to obj_size.
+    */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 9)
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 12)
+   .slab_obj_size = sizeof (VSockVmciSock),
+#else
+   .obj_size = sizeof (VSockVmciSock),
+#endif
+};
+#endif
+
+static struct net_proto_family vsockVmciFamilyOps = {
+   .family = VSOCK_INVALID_FAMILY,
+   .create = VSockVmciCreate,
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 5, 69)
+   .owner  = THIS_MODULE,
+#endif
+};
+
+/* Socket operations, split for DGRAM and STREAM sockets. */
+static struct proto_ops vsockVmciDgramOps = {
+   .family     = VSOCK_INVALID_FAMILY,
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 5, 69)
+   .owner      = THIS_MODULE,
+#endif
+   .release    = VSockVmciRelease,
+   .bind       = VSockVmciBind,
+   .connect    = VSockVmciDgramConnect,
+   .socketpair = sock_no_socketpair,
+   .accept     = sock_no_accept,
+   .getname    = VSockVmciGetname,
+   .poll       = VSockVmciPoll,
+   .ioctl      = sock_no_ioctl,
+   .listen     = sock_no_listen,
+   .shutdown   = VSockVmciShutdown,
+   .setsockopt = sock_no_setsockopt,
+   .getsockopt = sock_no_getsockopt,
+   .sendmsg    = VSockVmciDgramSendmsg,
+   .recvmsg    = VSockVmciDgramRecvmsg,
+   .mmap       = sock_no_mmap,
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 4, 4)
+   .sendpage   = sock_no_sendpage,
+#endif
+};
+
+#ifdef VMX86_TOOLS
+static struct proto_ops vsockVmciStreamOps = {
+   .family     = VSOCK_INVALID_FAMILY,
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 5, 69)
+   .owner      = THIS_MODULE,
+#endif
+   .release    = VSockVmciRelease,
+   .bind       = VSockVmciBind,
+   .connect    = VSockVmciStreamConnect,
+   .socketpair = sock_no_socketpair,
+   .accept     = VSockVmciAccept,
+   .getname    = VSockVmciGetname,
+   .poll       = VSockVmciPoll,
+   .ioctl      = sock_no_ioctl,
+   .listen     = VSockVmciListen,
+   .shutdown   = VSockVmciShutdown,
+   .setsockopt = VSockVmciStreamSetsockopt,
+   .getsockopt = VSockVmciStreamGetsockopt,
+   .sendmsg    = VSockVmciStreamSendmsg,
+   .recvmsg    = VSockVmciStreamRecvmsg,
+   .mmap       = sock_no_mmap,
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 4, 4)
+   .sendpage   = sock_no_sendpage,
+#endif
+};
+#endif
+
+static struct file_operations vsockVmciDeviceOps = {
+#ifdef HAVE_UNLOCKED_IOCTL
+   .unlocked_ioctl = VSockVmciDevUnlockedIoctl,
+#else
+   .ioctl = VSockVmciDevIoctl,
+#endif
+#ifdef HAVE_COMPAT_IOCTL
+   .compat_ioctl = VSockVmciDevUnlockedIoctl,
+#endif
+   .open = VSockVmciDevOpen,
+   .release = VSockVmciDevRelease,
+};
+
+static struct miscdevice vsockVmciDevice = {
+   .name = "vsock",
+   .minor = MISC_DYNAMIC_MINOR,
+   .fops = &vsockVmciDeviceOps,
+};
+
+typedef struct VSockRecvPktInfo {
+   compat_work work;
+   struct sock *sk;
+   VSockPacket pkt;
+} VSockRecvPktInfo;
+
+static DECLARE_MUTEX(registrationMutex);
+static int devOpenCount = 0;
+static int vsockVmciSocketCount = 0;
+#ifdef VMX86_TOOLS
+static VMCIHandle vmciStreamHandle = { VMCI_INVALID_ID, VMCI_INVALID_ID };
+static Bool vmciDevicePresent = FALSE;
+static VMCIId qpResumedSubId = VMCI_INVALID_ID;
+#endif
+
+/* Comment this out to compare with old protocol. */
+#define VSOCK_OPTIMIZATION_WAITING_NOTIFY 1
+#if defined(VMX86_TOOLS) && defined(VSOCK_OPTIMIZATION_WAITING_NOTIFY)
+/* Comment this out to remove flow control for "new" protocol */
+#  define VSOCK_OPTIMIZATION_FLOW_CONTROL 1
+#endif
+
+/* Comment this out to turn off datagram counting. */
+//#define VSOCK_CONTROL_PACKET_COUNT 1
+#ifdef VSOCK_CONTROL_PACKET_COUNT
+uint64 controlPacketCount[VSOCK_PACKET_TYPE_MAX];
+#endif
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 9)
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 5, 5)
+kmem_cache_t *vsockCachep;
+#endif
+#endif
+
+#define VSOCK_MAX_DGRAM_RESENDS       10
+
+/*
+ * 64k is hopefully a reasonable default, but we should do some real
+ * benchmarks. There are also some issues with resource limits on ESX.
+ */
+#define VSOCK_DEFAULT_QP_SIZE_MIN   128
+#define VSOCK_DEFAULT_QP_SIZE       65536
+#define VSOCK_DEFAULT_QP_SIZE_MAX   262144
+
+#define VSOCK_SEND_RESET_BH(_dst, _src, _pkt)                           \
+   ((_pkt)->type == VSOCK_PACKET_TYPE_RST) ?                            \
+      0 :                                                               \
+      VSockVmciSendControlPktBH(_dst, _src, VSOCK_PACKET_TYPE_RST, 0,   \
+                                0, NULL, VMCI_INVALID_HANDLE)
+#define VSOCK_SEND_INVALID_BH(_dst, _src)                               \
+   VSockVmciSendControlPktBH(_dst, _src, VSOCK_PACKET_TYPE_INVALID, 0,  \
+                             0, NULL, VMCI_INVALID_HANDLE)
+#define VSOCK_SEND_WROTE_BH(_dst, _src)                                 \
+   VSockVmciSendControlPktBH(_dst, _src, VSOCK_PACKET_TYPE_WROTE, 0,    \
+                             0, NULL, VMCI_INVALID_HANDLE)
+#define VSOCK_SEND_READ_BH(_dst, _src)                                  \
+   VSockVmciSendControlPktBH(_dst, _src, VSOCK_PACKET_TYPE_READ, 0,     \
+                             0, NULL, VMCI_INVALID_HANDLE)
+#define VSOCK_SEND_RESET(_sk, _pkt)                                     \
+   ((_pkt)->type == VSOCK_PACKET_TYPE_RST) ?                            \
+      0 :                                                               \
+      VSockVmciSendControlPkt(_sk, VSOCK_PACKET_TYPE_RST,               \
+                              0, 0, NULL, VMCI_INVALID_HANDLE)
+#define VSOCK_SEND_NEGOTIATE(_sk, _size)                                \
+   VSockVmciSendControlPkt(_sk, VSOCK_PACKET_TYPE_NEGOTIATE,            \
+                           _size, 0, NULL, VMCI_INVALID_HANDLE)
+#define VSOCK_SEND_QP_OFFER(_sk, _handle)                               \
+   VSockVmciSendControlPkt(_sk, VSOCK_PACKET_TYPE_OFFER,                \
+                           0, 0, NULL, _handle)
+#define VSOCK_SEND_CONN_REQUEST(_sk, _size)                             \
+   VSockVmciSendControlPkt(_sk, VSOCK_PACKET_TYPE_REQUEST,              \
+                           _size, 0, NULL, VMCI_INVALID_HANDLE)
+#define VSOCK_SEND_ATTACH(_sk, _handle)                                 \
+   VSockVmciSendControlPkt(_sk, VSOCK_PACKET_TYPE_ATTACH,               \
+                           0, 0, NULL, _handle)
+#define VSOCK_SEND_WROTE(_sk)                                           \
+   VSockVmciSendControlPkt(_sk, VSOCK_PACKET_TYPE_WROTE,                \
+                           0, 0, NULL, VMCI_INVALID_HANDLE)
+#define VSOCK_SEND_READ(_sk)                                            \
+   VSockVmciSendControlPkt(_sk, VSOCK_PACKET_TYPE_READ,                 \
+                           0, 0, NULL, VMCI_INVALID_HANDLE)
+#define VSOCK_SEND_SHUTDOWN(_sk, _mode)                                 \
+   VSockVmciSendControlPkt(_sk, VSOCK_PACKET_TYPE_SHUTDOWN,             \
+                           0, _mode, NULL, VMCI_INVALID_HANDLE)
+#define VSOCK_SEND_WAITING_WRITE(_sk, _waitInfo)                        \
+   VSockVmciSendControlPkt(_sk, VSOCK_PACKET_TYPE_WAITING_WRITE,        \
+                           0, 0, _waitInfo, VMCI_INVALID_HANDLE)
+#define VSOCK_SEND_WAITING_READ(_sk, _waitInfo)                         \
+   VSockVmciSendControlPkt(_sk, VSOCK_PACKET_TYPE_WAITING_READ,         \
+                           0, 0, _waitInfo, VMCI_INVALID_HANDLE)
+
+
+#ifdef VMX86_LOG
+# define LOG_PACKET(_pkt)  VSockVmciLogPkt(__FUNCTION__, __LINE__, _pkt)
+#else
+# define LOG_PACKET(_pkt)
+#endif
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VSockVmci_GetAFValue --
+ *
+ *      Returns the address family value being used.
+ *
+ * Results:
+ *      The address family on success, a negative error on failure.
+ *
+ * Side effects:
+ *      None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+int
+VSockVmci_GetAFValue(void)
+{
+   int afvalue;
+
+   down(&registrationMutex);
+
+   afvalue = vsockVmciFamilyOps.family;
+   if (!VSOCK_AF_IS_REGISTERED(afvalue)) {
+      afvalue = VSockVmciRegisterAddressFamily();
+   }
+
+   up(&registrationMutex);
+   return afvalue;
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VSockVmciTestUnregister --
+ *
+ *      Tests if it's necessary to unregister the socket family, and does so.
+ *
+ *      Note that this assumes the registration lock is held.
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+static inline void
+VSockVmciTestUnregister(void)
+{
+   if (devOpenCount <= 0 && vsockVmciSocketCount <= 0) {
+      if (VSOCK_AF_IS_REGISTERED(vsockVmciFamilyOps.family)) {
+         VSockVmciUnregisterAddressFamily();
+      }
+   }
+}
+
+
+/*
+ * Helper functions.
+ */
+
+
+#ifdef VMX86_TOOLS
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VSockVmciNotifyWaitingWrite --
+ *
+ *      Determines if the conditions have been met to notify a waiting writer.
+ *
+ * Results:
+ *      TRUE if a notification should be sent, FALSE otherwise.
+ *
+ * Side effects:
+ *      None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+static Bool
+VSockVmciNotifyWaitingWrite(VSockVmciSock *vsk)    // IN
+{
+#ifdef VSOCK_OPTIMIZATION_WAITING_NOTIFY
+   Bool retval;
+   uint64 notifyLimit;
+  
+   if (!vsk->peerWaitingWrite) {
+      return FALSE;
+   }
+
+#ifdef VSOCK_OPTIMIZATION_FLOW_CONTROL
+   /*
+    * When the sender blocks, we take that as a sign that the sender
+    * is faster than the receiver. To reduce the transmit rate of the
+    * sender, we delay the sending of the read notification by
+    * decreasing the writeNotifyWindow. The notification is delayed
+    * until the number of bytes used in the queue drops below the
+    * writeNotifyWindow.
+    */
+
+   if (!vsk->peerWaitingWriteDetected) {
+      vsk->peerWaitingWriteDetected = TRUE;
+      vsk->writeNotifyWindow -= PAGE_SIZE;
+      if (vsk->writeNotifyWindow < vsk->writeNotifyMinWindow) {
+         vsk->writeNotifyWindow = vsk->writeNotifyMinWindow;
+      }
+   }
+   notifyLimit = vsk->consumeSize - vsk->writeNotifyWindow;
+#else
+   notifyLimit = 0;
+#endif // VSOCK_OPTIMIZATION_FLOW_CONTROL
+
+   /*
+    * For now we ignore the wait information and just see if the free
+    * space exceeds the notify limit.  Note that improving this
+    * function to be more intelligent will not require a protocol
+    * change and will retain compatibility between endpoints with
+    * mixed versions of this function.
+    *
+    * The notifyLimit is used to delay notifications in the case where
+    * flow control is enabled. Below the test is expressed in terms of
+    * free space in the queue:
+    *   if freeSpace > ConsumeSize - writeNotifyWindow then notify
+    * An alternate way of expressing this is to rewrite the expression
+    * to use the data ready in the receive queue:
+    *   if writeNotifyWindow > bufferReady then notify
+    * as freeSpace == ConsumeSize - bufferReady.
+    */
+   retval = VMCIQueue_FreeSpace(vsk->consumeQ, vsk->produceQ, vsk->consumeSize) >
+            notifyLimit;
+#ifdef VSOCK_OPTIMIZATION_FLOW_CONTROL
+   if (retval) {
+      /*
+       * Once we notify the peer, we reset the detected flag so the
+       * next wait will again cause a decrease in the window size.
+       */
+
+      vsk->peerWaitingWriteDetected = FALSE;
+   }
+#endif // VSOCK_OPTIMIZATION_FLOW_CONTROL
+   return retval;
+#else
+   return TRUE;
+#endif
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VSockVmciNotifyWaitingRead --
+ *
+ *      Determines if the conditions have been met to notify a waiting reader.
+ *
+ * Results:
+ *      TRUE if a notification should be sent, FALSE otherwise.
+ *
+ * Side effects:
+ *      None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+static Bool
+VSockVmciNotifyWaitingRead(VSockVmciSock *vsk)  // IN
+{
+#ifdef VSOCK_OPTIMIZATION_WAITING_NOTIFY
+   if (!vsk->peerWaitingRead) {
+      return FALSE;
+   }
+
+   /*
+    * For now we ignore the wait information and just see if there is any data
+    * to read.  Note that improving this function to be more intelligent will
+    * not require a protocol change and will retain compatibility between
+    * endpoints with mixed versions of this function.
+    */
+   return VMCIQueue_BufReady(vsk->produceQ,
+                             vsk->consumeQ, vsk->produceSize) > 0;
+#else
+   return TRUE;
+#endif
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VSockVmciHandleWaitingWrite --
+ *
+ *      Handles an incoming waiting write message.
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      May send a notification to the peer, may update socket's wait info
+ *      structure.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+static void
+VSockVmciHandleWaitingWrite(struct sock *sk,            // IN
+                            VSockPacket *pkt,           // IN
+                            Bool bottomHalf,            // IN
+                            struct sockaddr_vm *dst,    // IN
+                            struct sockaddr_vm *src)    // IN
+{
+#ifdef VSOCK_OPTIMIZATION_WAITING_NOTIFY
+   VSockVmciSock *vsk;
+
+   vsk = vsock_sk(sk);
+
+   vsk->peerWaitingWrite = TRUE;
+   memcpy(&vsk->peerWaitingWriteInfo, &pkt->u.wait,
+          sizeof vsk->peerWaitingWriteInfo);
+
+   if (VSockVmciNotifyWaitingWrite(vsk)) {
+      Bool sent;
+
+      if (bottomHalf) {
+         sent = VSOCK_SEND_READ_BH(dst, src) > 0;
+      } else {
+         sent = VSOCK_SEND_READ(sk) > 0;
+      }
+
+      if (sent) {
+         vsk->peerWaitingWrite = FALSE;
+      }
+   }
+#endif
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VSockVmciHandleWaitingRead --
+ *
+ *      Handles an incoming waiting read message.
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      May send a notification to the peer, may update socket's wait info
+ *      structure.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+static void
+VSockVmciHandleWaitingRead(struct sock *sk,             // IN
+                           VSockPacket *pkt,            // IN
+                           Bool bottomHalf,             // IN
+                           struct sockaddr_vm *dst,     // IN
+                           struct sockaddr_vm *src)     // IN
+{
+#ifdef VSOCK_OPTIMIZATION_WAITING_NOTIFY
+   VSockVmciSock *vsk;
+
+   vsk = vsock_sk(sk);
+
+   vsk->peerWaitingRead = TRUE;
+   memcpy(&vsk->peerWaitingReadInfo, &pkt->u.wait,
+          sizeof vsk->peerWaitingReadInfo);
+
+   if (VSockVmciNotifyWaitingRead(vsk)) {
+      Bool sent;
+
+      if (bottomHalf) {
+         sent = VSOCK_SEND_WROTE_BH(dst, src) > 0;
+      } else {
+         sent = VSOCK_SEND_WROTE(sk) > 0;
+      }
+
+      if (sent) {
+         vsk->peerWaitingRead = FALSE;
+      }
+   }
+#endif
+}
+#endif
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VSockVmciRecvDgramCB --
+ *
+ *    VMCI Datagram receive callback.  This function is used specifically for
+ *    SOCK_DGRAM sockets.
+ *
+ *    This is invoked as part of a tasklet that's scheduled when the VMCI
+ *    interrupt fires.  This is run in bottom-half context and if it ever needs
+ *    to sleep it should defer that work to a work queue.
+ *
+ * Results:
+ *    Zero on success, negative error code on failure.
+ *
+ * Side effects:
+ *    An sk_buff is created and queued with this socket.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+static int
+VSockVmciRecvDgramCB(void *data,           // IN
+                     VMCIDatagram *dg)     // IN
+{
+   struct sock *sk;
+   size_t size;
+   struct sk_buff *skb;
+
+   ASSERT(dg);
+   ASSERT(dg->payloadSize <= VMCI_MAX_DG_PAYLOAD_SIZE);
+
+   sk = (struct sock *)data;
+
+   ASSERT(sk);
+   /* XXX Figure out why sk->compat_sk_socket can be NULL. */
+   ASSERT(sk->compat_sk_socket ? sk->compat_sk_socket->type == SOCK_DGRAM : 1);
+
+   size = VMCI_DG_SIZE(dg);
+
+   /*
+    * Attach the packet to the socket's receive queue as an sk_buff.
+    */
+   skb = alloc_skb(size, GFP_ATOMIC);
+   if (skb) {
+      /* compat_sk_receive_skb() will do a sock_put(), so hold here. */
+      sock_hold(sk);
+      skb_put(skb, size);
+      memcpy(skb->data, dg, size);
+      compat_sk_receive_skb(sk, skb, 0);
+   }
+
+   return 0;
+}
+
+
+#ifdef VMX86_TOOLS
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VSockVmciRecvStreamCB --
+ *
+ *    VMCI stream receive callback for control datagrams.  This function is
+ *    used specifically for SOCK_STREAM sockets.
+ *
+ *    This is invoked as part of a tasklet that's scheduled when the VMCI
+ *    interrupt fires.  This is run in bottom-half context but it defers most
+ *    of its work to the packet handling work queue.
+ *
+ * Results:
+ *    Zero on success, negative error code on failure.
+ *
+ * Side effects:
+ *    None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+static int
+VSockVmciRecvStreamCB(void *data,           // IN
+                      VMCIDatagram *dg)     // IN
+{
+   struct sock *sk;
+   struct sockaddr_vm dst;
+   struct sockaddr_vm src;
+   VSockPacket *pkt;
+   Bool processPkt;
+   int err;
+
+   ASSERT(dg);
+   ASSERT(dg->payloadSize <= VMCI_MAX_DG_PAYLOAD_SIZE);
+
+   sk = NULL;
+   err = VMCI_SUCCESS;
+   processPkt = TRUE;
+
+   /*
+    * Ignore incoming packets from contexts without sockets, or resources that
+    * aren't vsock implementations.
+    */
+   if (!VSockAddr_SocketContext(VMCI_HANDLE_TO_CONTEXT_ID(dg->src)) ||
+       VSOCK_PACKET_RID != VMCI_HANDLE_TO_RESOURCE_ID(dg->src)) {
+      return VMCI_ERROR_NO_ACCESS;
+   }
+
+   if (VMCI_DG_SIZE(dg) < sizeof *pkt) {
+      /* Drop datagrams that do not contain full VSock packets. */
+      return VMCI_ERROR_INVALID_ARGS;
+   }
+
+   pkt = (VSockPacket *)dg;
+
+   LOG_PACKET(pkt);
+
+   /*
+    * Find the socket that should handle this packet.  First we look for
+    * a connected socket and if there is none we look for a socket bound to
+    * the destintation address.
+    *
+    * Note that we don't initialize the family member of the src and dst
+    * sockaddr_vm since we don't want to call VMCISock_GetAFValue() and
+    * possibly register the address family.
+    */
+   VSockAddr_InitNoFamily(&src,
+                          VMCI_HANDLE_TO_CONTEXT_ID(pkt->dg.src),
+                          pkt->srcPort);
+
+   VSockAddr_InitNoFamily(&dst,
+                          VMCI_HANDLE_TO_CONTEXT_ID(pkt->dg.dst),
+                          pkt->dstPort);
+
+   sk = VSockVmciFindConnectedSocket(&src, &dst);
+   if (!sk) {
+      sk = VSockVmciFindBoundSocket(&dst);
+      if (!sk) {
+         /*
+          * We could not find a socket for this specified address.  If this
+          * packet is a RST, we just drop it.  If it is another packet, we send
+          * a RST.  Note that we do not send a RST reply to RSTs so that we do
+          * not continually send RSTs between two endpoints.
+          *
+          * Note that since this is a reply, dst is src and src is dst.
+          */
+         if (VSOCK_SEND_RESET_BH(&dst, &src, pkt) < 0) {
+            Log("unable to send reset.\n");
+         }
+         err = VMCI_ERROR_NOT_FOUND;
+         goto out;
+      }
+   }
+
+   /*
+    * If the received packet type is beyond all types known to this
+    * implementation, reply with an invalid message.  Hopefully this will help
+    * when implementing backwards compatibility in the future.
+    */
+   if (pkt->type >= VSOCK_PACKET_TYPE_MAX) {
+      if (VSOCK_SEND_INVALID_BH(&dst, &src) < 0) {
+         Warning("unable to send reply for invalid packet.\n");
+         err = VMCI_ERROR_INVALID_ARGS;
+         goto out;
+      }
+   }
+
+   /*
+    * We do most everything in a work queue, but let's fast path the
+    * notification of reads and writes to help data transfer performance.  We
+    * can only do this if there is no process context code executing for this
+    * socket since that may change the state.
+    */
+   bh_lock_sock(sk);
+
+   if (!compat_sock_owned_by_user(sk) && sk->compat_sk_state == SS_CONNECTED) {
+      switch (pkt->type) {
+      case VSOCK_PACKET_TYPE_WROTE:
+         sk->compat_sk_data_ready(sk, 0);
+         processPkt = FALSE;
+         break;
+      case VSOCK_PACKET_TYPE_READ:
+         sk->compat_sk_write_space(sk);
+         processPkt = FALSE;
+         break;
+      case VSOCK_PACKET_TYPE_WAITING_WRITE:
+         VSockVmciHandleWaitingWrite(sk, pkt, TRUE, &dst, &src);
+         processPkt = FALSE;
+         break;
+
+      case VSOCK_PACKET_TYPE_WAITING_READ:
+         VSockVmciHandleWaitingRead(sk, pkt, TRUE, &dst, &src);
+         processPkt = FALSE;
+         break;
+      }
+   }
+
+   bh_unlock_sock(sk);
+
+   if (processPkt) {
+      VSockRecvPktInfo *recvPktInfo;
+
+      recvPktInfo = kmalloc(sizeof *recvPktInfo, GFP_ATOMIC);
+      if (!recvPktInfo) {
+         if (VSOCK_SEND_RESET_BH(&dst, &src, pkt) < 0) {
+            Warning("unable to send reset\n");
+         }
+         err = VMCI_ERROR_NO_MEM;
+         goto out;
+      }
+
+      recvPktInfo->sk = sk;
+      memcpy(&recvPktInfo->pkt, pkt, sizeof recvPktInfo->pkt);
+      COMPAT_INIT_WORK(&recvPktInfo->work, VSockVmciRecvPktWork, recvPktInfo);
+
+      compat_schedule_work(&recvPktInfo->work);
+      /*
+       * Clear sk so that the reference count incremented by one of the Find
+       * functions above is not decremented below.  We need that reference
+       * count for the packet handler we've scheduled to run.
+       */
+      sk = NULL;
+   }
+
+out:
+   if (sk) {
+      sock_put(sk);
+   }
+   return err;
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VSockVmciPeerAttachCB --
+ *
+ *    Invoked when a peer attaches to a queue pair.
+ *
+ *    Right now this does not do anything.
+ *
+ * Results:
+ *    None.
+ *
+ * Side effects:
+ *    May modify socket state and signal socket.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+static void
+VSockVmciPeerAttachCB(VMCIId subId,             // IN
+                      VMCI_EventData *eData,    // IN
+                      void *clientData)         // IN
+{
+   struct sock *sk;
+   VMCIEventPayload_QP *ePayload;
+   VSockVmciSock *vsk;
+
+   ASSERT(eData);
+   ASSERT(clientData);
+
+   sk = (struct sock *)clientData;
+   ePayload = VMCIEventDataPayload(eData);
+
+   vsk = vsock_sk(sk);
+
+   bh_lock_sock(sk);
+
+   /*
+    * XXX This is lame, we should provide a way to lookup sockets by qpHandle.
+    */
+   if (VMCI_HANDLE_EQUAL(vsk->qpHandle, ePayload->handle)) {
+      /*
+       * XXX This doesn't do anything, but in the future we may want to set
+       * a flag here to verify the attach really did occur and we weren't just
+       * sent a datagram claiming it was.
+       */
+      goto out;
+   }
+
+out:
+   bh_unlock_sock(sk);
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VSockVmciHandleDetach --
+ *
+ *      Perform the work necessary when the peer has detached.
+ *
+ *      Note that this assumes the socket lock is held.
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      The socket's and its peer's shutdown mask will be set appropriately,
+ *      and any callers waiting on this socket will be awoken.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+static INLINE void
+VSockVmciHandleDetach(struct sock *sk) // IN
+{
+   VSockVmciSock *vsk;
+
+   ASSERT(sk);
+
+   vsk = vsock_sk(sk);
+   if (!VMCI_HANDLE_INVALID(vsk->qpHandle)) {
+      ASSERT(vsk->produceQ);
+      ASSERT(vsk->consumeQ);
+
+      /* On a detach the peer will not be sending or receiving anymore. */
+      vsk->peerShutdown = SHUTDOWN_MASK;
+
+      /*
+       * We should not be sending anymore since the peer won't be there to
+       * receive, but we can still receive if there is data left in our consume
+       * queue.
+       */
+      sk->compat_sk_shutdown |= SEND_SHUTDOWN;
+      if (VMCIQueue_BufReady(vsk->consumeQ,
+                             vsk->produceQ, vsk->consumeSize) <= 0) {
+         sk->compat_sk_shutdown |= RCV_SHUTDOWN;
+         sk->compat_sk_state = SS_UNCONNECTED;
+      }
+      sk->compat_sk_state_change(sk);
+   }
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VSockVmciPeerDetachCB --
+ *
+ *    Invoked when a peer detaches from a queue pair.
+ *
+ * Results:
+ *    None.
+ *
+ * Side effects:
+ *    May modify socket state and signal socket.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+static void
+VSockVmciPeerDetachCB(VMCIId subId,             // IN
+                      VMCI_EventData *eData,    // IN
+                      void *clientData)         // IN
+{
+   struct sock *sk;
+   VMCIEventPayload_QP *ePayload;
+   VSockVmciSock *vsk;
+
+   ASSERT(eData);
+   ASSERT(clientData);
+
+   sk = (struct sock *)clientData;
+   ePayload = VMCIEventDataPayload(eData);
+   vsk = vsock_sk(sk);
+   if (VMCI_HANDLE_INVALID(ePayload->handle)) {
+      return;
+   }
+
+   /*
+    * XXX This is lame, we should provide a way to lookup sockets by qpHandle.
+    */
+   bh_lock_sock(sk);
+
+   if (VMCI_HANDLE_EQUAL(vsk->qpHandle, ePayload->handle)) {
+      VSockVmciHandleDetach(sk);
+   }
+
+   bh_unlock_sock(sk);
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VSockVmciQPResumedCB --
+ *
+ *    Invoked when a VM is resumed.  We must mark all connected stream sockets
+ *    as detached.
+ *
+ * Results:
+ *    None.
+ *
+ * Side effects:
+ *    May modify socket state and signal socket.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+static void
+VSockVmciQPResumedCB(VMCIId subId,             // IN
+                     VMCI_EventData *eData,    // IN
+                     void *clientData)         // IN
+{
+   uint32 i;
+
+   spin_lock_bh(&vsockTableLock);
+
+   /*
+    * XXX This loop should probably be provided by util.{h,c}, but that's for
+    * another day.
+    */
+   for (i = 0; i < ARRAYSIZE(vsockConnectedTable); i++) {
+      VSockVmciSock *vsk;
+
+      list_for_each_entry(vsk, &vsockConnectedTable[i], connectedTable) {
+         struct sock *sk = sk_vsock(vsk);
+
+         /*
+          * XXX Technically this is racy but the resulting outcome from such
+          * a race is relatively harmless.  My next change will be a fix to
+          * this.
+          */
+         VSockVmciHandleDetach(sk);
+      }
+   }
+
+   spin_unlock_bh(&vsockTableLock);
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VSockVmciPendingWork --
+ *
+ *    Releases the resources for a pending socket if it has not reached the
+ *    connected state and been accepted by a user process.
+ *
+ * Results:
+ *    None.
+ *
+ * Side effects:
+ *    The socket may be removed from the connected list and all its resources
+ *    freed.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+static void
+VSockVmciPendingWork(compat_delayed_work_arg work)    // IN
+{
+   struct sock *sk;
+   struct sock *listener;
+   VSockVmciSock *vsk;
+   Bool cleanup;
+
+   vsk = COMPAT_DELAYED_WORK_GET_DATA(work, VSockVmciSock, dwork);
+   ASSERT(vsk);
+
+   sk = sk_vsock(vsk);
+   listener = vsk->listener;
+   cleanup = TRUE;
+
+   ASSERT(listener);
+
+   lock_sock(listener);
+   lock_sock(sk);
+
+   /*
+    * The socket should be on the pending list or the accept queue, but not
+    * both.  It's also possible that the socket isn't on either.
+    */
+   ASSERT(    ( VSockVmciIsPending(sk) && !VSockVmciInAcceptQueue(sk))
+           || (!VSockVmciIsPending(sk) &&  VSockVmciInAcceptQueue(sk))
+           || (!VSockVmciIsPending(sk) && !VSockVmciInAcceptQueue(sk)));
+
+   if (VSockVmciIsPending(sk)) {
+      VSockVmciRemovePending(listener, sk);
+   } else if (!vsk->rejected) {
+      /*
+       * We are not on the pending list and accept() did not reject us, so we
+       * must have been accepted by our user process.  We just need to drop our
+       * references to the sockets and be on our way.
+       */
+      cleanup = FALSE;
+      goto out;
+   }
+
+   listener->compat_sk_ack_backlog--;
+
+   /*
+    * We need to remove ourself from the global connected sockets list so
+    * incoming packets can't find this socket, and to reduce the reference
+    * count.
+    */
+   if (VSockVmciInConnectedTable(sk)) {
+      VSockVmciRemoveConnected(sk);
+   }
+
+   sk->compat_sk_state = SS_FREE;
+
+out:
+   release_sock(sk);
+   release_sock(listener);
+   if (cleanup) {
+      sock_put(sk);
+   }
+   sock_put(sk);
+   sock_put(listener);
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VSockVmciRecvPktWork --
+ *
+ *    Handles an incoming control packet for the provided socket.  This is the
+ *    state machine for our stream sockets.
+ *
+ * Results:
+ *    None.
+ *
+ * Side effects:
+ *    May set state and wakeup threads waiting for socket state to change.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+static void
+VSockVmciRecvPktWork(compat_work_arg work)  // IN
+{
+   int err;
+   VSockRecvPktInfo *recvPktInfo;
+   VSockPacket *pkt;
+   VSockVmciSock *vsk;
+   struct sock *sk;
+
+   recvPktInfo = COMPAT_WORK_GET_DATA(work, VSockRecvPktInfo);
+   ASSERT(recvPktInfo);
+
+   err = 0;
+   sk = recvPktInfo->sk;
+   pkt = &recvPktInfo->pkt;
+   vsk = vsock_sk(sk);
+
+   ASSERT(vsk);
+   ASSERT(pkt);
+   ASSERT(pkt->type < VSOCK_PACKET_TYPE_MAX);
+
+   lock_sock(sk);
+
+   switch (sk->compat_sk_state) {
+   case SS_LISTEN:
+      err = VSockVmciRecvListen(sk, pkt);
+      break;
+   case SS_UNCONNECTED:
+      Log("packet received for socket in unconnected state; dropping.\n");
+      goto out;
+   case SS_CONNECTING:
+      /*
+       * Processing of pending connections for servers goes through the
+       * listening socket, so see VSockVmciRecvListen() for that path.
+       */
+      err = VSockVmciRecvConnectingClient(sk, pkt);
+      break;
+   case SS_CONNECTED:
+      err = VSockVmciRecvConnected(sk, pkt);
+      break;
+   case SS_DISCONNECTING:
+      Log("packet receieved for socket in disconnecting state; dropping.\n");
+      goto out;
+   case SS_FREE:
+      Log("packet receieved for socket in free state; dropping.\n");
+      goto out;
+   default:
+      Log("socket is in invalid state; dropping packet.\n");
+      goto out;
+   }
+
+out:
+   release_sock(sk);
+   kfree(recvPktInfo);
+   /*
+    * Release reference obtained in the stream callback when we fetched this
+    * socket out of the bound or connected list.
+    */
+   sock_put(sk);
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VSockVmciRecvListen --
+ *
+ *    Receives packets for sockets in the listen state.
+ *
+ *    Note that this assumes the socket lock is held.
+ *
+ * Results:
+ *    Zero on success, negative error code on failure.
+ *
+ * Side effects:
+ *    A new socket may be created and a negotiate control packet is sent.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+static int
+VSockVmciRecvListen(struct sock *sk,   // IN
+                    VSockPacket *pkt)  // IN
+{
+   VSockVmciSock *vsk;
+   struct sock *pending;
+   VSockVmciSock *vpending;
+   int err;
+   uint64 qpSize;
+
+   ASSERT(sk);
+   ASSERT(pkt);
+   ASSERT(sk->compat_sk_state == SS_LISTEN);
+
+   vsk = vsock_sk(sk);
+   err = 0;
+
+   /*
+    * Because we are in the listen state, we could be receiving a packet for
+    * ourself or any previous connection requests that we received.  If it's
+    * the latter, we try to find a socket in our list of pending connections
+    * and, if we do, call the appropriate handler for the state that that
+    * socket is in.  Otherwise we try to service the connection request.
+    */
+   pending = VSockVmciGetPending(sk, pkt);
+   if (pending) {
+      lock_sock(pending);
+      switch (pending->compat_sk_state) {
+      case SS_CONNECTING:
+         err = VSockVmciRecvConnectingServer(sk, pending, pkt);
+         break;
+      default:
+         VSOCK_SEND_RESET(pending, pkt);
+         err = -EINVAL;
+      }
+
+      if (err < 0) {
+         VSockVmciRemovePending(sk, pending);
+      }
+
+      release_sock(pending);
+      VSockVmciReleasePending(pending);
+
+      return err;
+   }
+
+   /*
+    * The listen state only accepts connection requests.  Reply with a reset
+    * unless we received a reset.
+    */
+   if (pkt->type != VSOCK_PACKET_TYPE_REQUEST ||
+       pkt->u.size == 0) {
+      VSOCK_SEND_RESET(sk, pkt);
+      return -EINVAL;
+   }
+
+   /*
+    * If this socket can't accommodate this connection request, we send
+    * a reset.  Otherwise we create and initialize a child socket and reply
+    * with a connection negotiation.
+    */
+   if (sk->compat_sk_ack_backlog >= sk->compat_sk_max_ack_backlog) {
+      VSOCK_SEND_RESET(sk, pkt);
+      return -ECONNREFUSED;
+   }
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 24)
+   pending = __VSockVmciCreate(NULL, GFP_KERNEL);
+#else
+   pending = __VSockVmciCreate(compat_sock_net(sk), NULL, GFP_KERNEL);
+#endif
+   if (!pending) {
+      VSOCK_SEND_RESET(sk, pkt);
+      return -ENOMEM;
+   }
+
+   vpending = vsock_sk(pending);
+   ASSERT(vpending);
+   ASSERT(vsk->localAddr.svm_port == pkt->dstPort);
+
+   VSockAddr_Init(&vpending->localAddr,
+                  VMCI_GetContextID(),
+                  pkt->dstPort);
+   VSockAddr_Init(&vpending->remoteAddr,
+                  VMCI_HANDLE_TO_CONTEXT_ID(pkt->dg.src),
+                  pkt->srcPort);
+
+   /*
+    * If the proposed size fits within our min/max, accept
+    * it. Otherwise propose our own size.
+    */
+   if (pkt->u.size >= vsk->queuePairMinSize &&
+      pkt->u.size <= vsk->queuePairMaxSize) {
+      qpSize = pkt->u.size;
+   } else {
+      qpSize = vsk->queuePairSize;
+   }
+
+   err = VSOCK_SEND_NEGOTIATE(pending, qpSize);
+   if (err < 0) {
+      VSOCK_SEND_RESET(sk, pkt);
+      sock_put(pending);
+      err = VSockVmci_ErrorToVSockError(err);
+      goto out;
+   }
+
+   VSockVmciAddPending(sk, pending);
+   sk->compat_sk_ack_backlog++;
+
+   pending->compat_sk_state = SS_CONNECTING;
+   vpending->produceSize = vpending->consumeSize =
+                           vpending->writeNotifyWindow = pkt->u.size;
+   
+
+   /*
+    * We might never receive another message for this socket and it's not
+    * connected to any process, so we have to ensure it gets cleaned up
+    * ourself.  Our delayed work function will take care of that.  Note that we
+    * do not ever cancel this function since we have few guarantees about its
+    * state when calling cancel_delayed_work().  Instead we hold a reference on
+    * the socket for that function and make it capable of handling cases where
+    * it needs to do nothing but release that reference.
+    */
+   vpending->listener = sk;
+   sock_hold(sk);
+   sock_hold(pending);
+   COMPAT_INIT_DELAYED_WORK(&vpending->dwork, VSockVmciPendingWork, vpending);
+   compat_schedule_delayed_work(&vpending->dwork, HZ);
+
+out:
+   return err;
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VSockVmciRecvConnectingServer --
+ *
+ *    Receives packets for sockets in the connecting state on the server side.
+ *
+ *    Connecting sockets on the server side can only receive queue pair offer
+ *    packets.  All others should be treated as cause for closing the
+ *    connection.
+ *
+ *    Note that this assumes the socket lock is held for both sk and pending.
+ *
+ * Results:
+ *    Zero on success, negative error code on failure.
+ *
+ * Side effects:
+ *    A queue pair may be created, an attach control packet may be sent, the
+ *    socket may transition to the connected state, and a pending caller in
+ *    accept() may be woken up.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+static int
+VSockVmciRecvConnectingServer(struct sock *listener, // IN: the listening socket
+                              struct sock *pending,  // IN: the pending connection
+                              VSockPacket *pkt)      // IN: current packet
+{
+   VSockVmciSock *vpending;
+   VMCIHandle handle;
+   VMCIQueue *produceQ;
+   VMCIQueue *consumeQ;
+   Bool isLocal;
+   uint32 flags;
+   VMCIId detachSubId;
+   int err;
+   int skerr;
+
+   ASSERT(listener);
+   ASSERT(pkt);
+   ASSERT(listener->compat_sk_state == SS_LISTEN);
+   ASSERT(pending->compat_sk_state == SS_CONNECTING);
+
+   vpending = vsock_sk(pending);
+   detachSubId = VMCI_INVALID_ID;
+
+   switch (pkt->type) {
+   case VSOCK_PACKET_TYPE_OFFER:
+      if (VMCI_HANDLE_INVALID(pkt->u.handle)) {
+         VSOCK_SEND_RESET(pending, pkt);
+         skerr = EPROTO;
+         err = -EINVAL;
+         goto destroy;
+      }
+      break;
+   default:
+      /* Close and cleanup the connection. */
+      VSOCK_SEND_RESET(pending, pkt);
+      skerr = EPROTO;
+      err =  pkt->type == VSOCK_PACKET_TYPE_RST ?
+                0 :
+                -EINVAL;
+      goto destroy;
+   }
+
+   ASSERT(pkt->type == VSOCK_PACKET_TYPE_OFFER);
+
+   /*
+    * In order to complete the connection we need to attach to the offered
+    * queue pair and send an attach notification.  We also subscribe to the
+    * detach event so we know when our peer goes away, and we do that before
+    * attaching so we don't miss an event.  If all this succeeds, we update our
+    * state and wakeup anything waiting in accept() for a connection.
+    */
+
+   /*
+    * We don't care about attach since we ensure the other side has attached by
+    * specifying the ATTACH_ONLY flag below.
+    */
+   err = VMCIEvent_Subscribe(VMCI_EVENT_QP_PEER_DETACH,
+                             VSockVmciPeerDetachCB,
+                             pending,
+                             &detachSubId);
+   if (err < VMCI_SUCCESS) {
+      VSOCK_SEND_RESET(pending, pkt);
+      err = VSockVmci_ErrorToVSockError(err);
+      skerr = -err;
+      goto destroy;
+   }
+
+   vpending->detachSubId = detachSubId;
+
+   /* Now attach to the queue pair the client created. */
+   handle = pkt->u.handle;
+   isLocal = vpending->remoteAddr.svm_cid == vpending->localAddr.svm_cid;
+   flags = VMCI_QPFLAG_ATTACH_ONLY;
+   flags |= isLocal ? VMCI_QPFLAG_LOCAL : 0;
+
+   err = VMCIQueuePair_Alloc(&handle,
+                             &produceQ, vpending->produceSize,
+                             &consumeQ, vpending->consumeSize,
+                             VMCI_HANDLE_TO_CONTEXT_ID(pkt->dg.src),
+                             flags);
+   if (err < 0) {
+      /* We cannot complete this connection: send a reset and close. */
+      Log("Could not attach to queue pair with %d\n", err);
+      VSOCK_SEND_RESET(pending, pkt);
+      err = VSockVmci_ErrorToVSockError(err);
+      skerr = -err;
+      goto destroy;
+   }
+
+   VMCIQueue_Init(handle, produceQ);
+
+   ASSERT(VMCI_HANDLE_EQUAL(handle, pkt->u.handle));
+   vpending->qpHandle = handle;
+   vpending->produceQ = produceQ;
+   vpending->consumeQ = consumeQ;
+
+   /* Notify our peer of our attach. */
+   err = VSOCK_SEND_ATTACH(pending, handle);
+   if (err < 0) {
+      Log("Could not send attach\n");
+      VSOCK_SEND_RESET(pending, pkt);
+      err = VSockVmci_ErrorToVSockError(err);
+      skerr = -err;
+      goto destroy;
+   }
+
+   /*
+    * We have a connection.  Add our connection to the connected list so it no
+    * longer goes through the listening socket, move it from the listener's
+    * pending list to the accept queue so callers of accept() can find it.
+    * Note that enqueueing the socket increments the reference count, so even
+    * if a reset comes before the connection is accepted, the socket will be
+    * valid until it is removed from the queue.
+    */
+   pending->compat_sk_state = SS_CONNECTED;
+
+   VSockVmciInsertConnected(vsockConnectedSocketsVsk(vpending), pending);
+
+   VSockVmciRemovePending(listener, pending);
+   VSockVmciEnqueueAccept(listener, pending);
+
+   /*
+    * Callers of accept() will be be waiting on the listening socket, not the
+    * pending socket.
+    */
+   listener->compat_sk_state_change(listener);
+
+   return 0;
+
+destroy:
+   pending->compat_sk_err = skerr;
+   pending->compat_sk_state = SS_UNCONNECTED;
+   /*
+    * As long as we drop our reference, all necessary cleanup will handle when
+    * the cleanup function drops its reference and our destruct implementation
+    * is called.  Note that since the listen handler will remove pending from
+    * the pending list upon our failure, the cleanup function won't drop the
+    * additional reference, which is why we do it here.
+    */
+   sock_put(pending);
+
+   return err;
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VSockVmciRecvConnectingClient --
+ *
+ *    Receives packets for sockets in the connecting state on the client side.
+ *
+ *    Connecting sockets on the client side should only receive attach packets.
+ *    All others should be treated as cause for closing the connection.
+ *
+ *    Note that this assumes the socket lock is held for both sk and pending.
+ *
+ * Results:
+ *    Zero on success, negative error code on failure.
+ *
+ * Side effects:
+ *    The socket may transition to the connected state and wakeup the pending
+ *    caller of connect().
+ *
+ *----------------------------------------------------------------------------
+ */
+
+static int
+VSockVmciRecvConnectingClient(struct sock *sk,       // IN: socket
+                              VSockPacket *pkt)      // IN: current packet
+{
+   VSockVmciSock *vsk;
+   int err;
+   int skerr;
+
+   ASSERT(sk);
+   ASSERT(pkt);
+   ASSERT(sk->compat_sk_state == SS_CONNECTING);
+
+   vsk = vsock_sk(sk);
+
+   switch (pkt->type) {
+   case VSOCK_PACKET_TYPE_ATTACH:
+      if (VMCI_HANDLE_INVALID(pkt->u.handle) ||
+          !VMCI_HANDLE_EQUAL(pkt->u.handle, vsk->qpHandle)) {
+         skerr = EPROTO;
+         err = -EINVAL;
+         goto destroy;
+      }
+
+      /*
+       * Signify the socket is connected and wakeup the waiter in connect().
+       * Also place the socket in the connected table for accounting (it can
+       * already be found since it's in the bound table).
+       */
+      sk->compat_sk_state = SS_CONNECTED;
+      sk->compat_sk_socket->state = SS_CONNECTED;
+      VSockVmciInsertConnected(vsockConnectedSocketsVsk(vsk), sk);
+      sk->compat_sk_state_change(sk);
+      break;
+   case VSOCK_PACKET_TYPE_NEGOTIATE:
+      if (pkt->u.size == 0 ||
+          VMCI_HANDLE_TO_CONTEXT_ID(pkt->dg.src) != vsk->remoteAddr.svm_cid ||
+          pkt->srcPort != vsk->remoteAddr.svm_port ||
+          !VMCI_HANDLE_INVALID(vsk->qpHandle) ||
+          vsk->produceQ ||
+          vsk->consumeQ ||
+          vsk->produceSize != 0 ||
+          vsk->consumeSize != 0 ||
+          vsk->attachSubId != VMCI_INVALID_ID ||
+          vsk->detachSubId != VMCI_INVALID_ID) {
+         skerr = EPROTO;
+         err = -EINVAL;
+         goto destroy;
+      }
+
+      err = VSockVmciRecvConnectingClientNegotiate(sk, pkt);
+      if (err) {
+         skerr = -err;
+         goto destroy;
+      }
+
+      break;
+   case VSOCK_PACKET_TYPE_RST:
+      skerr = ECONNRESET;
+      err = 0;
+      goto destroy;
+   default:
+      /* Close and cleanup the connection. */
+      skerr = EPROTO;
+      err = -EINVAL;
+      goto destroy;
+   }
+
+   ASSERT(pkt->type == VSOCK_PACKET_TYPE_ATTACH ||
+          pkt->type == VSOCK_PACKET_TYPE_NEGOTIATE);
+
+   return 0;
+
+destroy:
+   VSOCK_SEND_RESET(sk, pkt);
+
+   sk->compat_sk_state = SS_UNCONNECTED;
+   sk->compat_sk_err = skerr;
+   sk->compat_sk_error_report(sk);
+   return err;
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VSockVmciRecvConnectingClientNegotiate --
+ *
+ *    Handles a negotiate packet for a client in the connecting state.
+ *
+ *    Note that this assumes the socket lock is held for both sk and pending.
+ *
+ * Results:
+ *    Zero on success, negative error code on failure.
+ *
+ * Side effects:
+ *    The socket may transition to the connected state and wakeup the pending
+ *    caller of connect().
+ *
+ *----------------------------------------------------------------------------
+ */
+
+static int
+VSockVmciRecvConnectingClientNegotiate(struct sock *sk,   // IN: socket
+                                       VSockPacket *pkt)  // IN: current packet
+{
+   int err;
+   VSockVmciSock *vsk;
+   VMCIHandle handle;
+   VMCIQueue *produceQ;
+   VMCIQueue *consumeQ;
+   VMCIId attachSubId;
+   VMCIId detachSubId;
+   Bool isLocal;
+
+   vsk = vsock_sk(sk);
+   handle = VMCI_INVALID_HANDLE;
+   attachSubId = VMCI_INVALID_ID;
+   detachSubId = VMCI_INVALID_ID;
+
+   ASSERT(sk);
+   ASSERT(pkt);
+   ASSERT(pkt->u.size > 0);
+   ASSERT(vsk->remoteAddr.svm_cid == VMCI_HANDLE_TO_CONTEXT_ID(pkt->dg.src));
+   ASSERT(vsk->remoteAddr.svm_port == pkt->srcPort);
+   ASSERT(VMCI_HANDLE_INVALID(vsk->qpHandle));
+   ASSERT(vsk->produceQ == NULL);
+   ASSERT(vsk->consumeQ == NULL);
+   ASSERT(vsk->produceSize == 0);
+   ASSERT(vsk->consumeSize == 0);
+   ASSERT(vsk->attachSubId == VMCI_INVALID_ID);
+   ASSERT(vsk->detachSubId == VMCI_INVALID_ID);
+
+   /* Verify that we're OK with the proposed queue pair size */
+   if (pkt->u.size < vsk->queuePairMinSize ||
+       pkt->u.size > vsk->queuePairMaxSize) {
+      err = -EINVAL;
+      goto destroy;
+   }
+
+   /*
+    * Subscribe to attach and detach events first.
+    *
+    * XXX We attach once for each queue pair created for now so it is easy
+    * to find the socket (it's provided), but later we should only subscribe
+    * once and add a way to lookup sockets by queue pair handle.
+    */
+   err = VMCIEvent_Subscribe(VMCI_EVENT_QP_PEER_ATTACH,
+                             VSockVmciPeerAttachCB,
+                             sk,
+                             &attachSubId);
+   if (err < VMCI_SUCCESS) {
+      err = VSockVmci_ErrorToVSockError(err);
+      goto destroy;
+   }
+
+   err = VMCIEvent_Subscribe(VMCI_EVENT_QP_PEER_DETACH,
+                             VSockVmciPeerDetachCB,
+                             sk,
+                             &detachSubId);
+   if (err < VMCI_SUCCESS) {
+      err = VSockVmci_ErrorToVSockError(err);
+      goto destroy;
+   }
+
+   /* Make VMCI select the handle for us. */
+   handle = VMCI_INVALID_HANDLE;
+   isLocal = vsk->remoteAddr.svm_cid == vsk->localAddr.svm_cid;
+
+   err = VMCIQueuePair_Alloc(&handle,
+                             &produceQ, pkt->u.size,
+                             &consumeQ, pkt->u.size,
+                             vsk->remoteAddr.svm_cid,
+                             isLocal ? VMCI_QPFLAG_LOCAL : 0);
+   if (err < VMCI_SUCCESS) {
+      err = VSockVmci_ErrorToVSockError(err);
+      goto destroy;
+   }
+
+   VMCIQueue_Init(handle, produceQ);
+
+   err = VSOCK_SEND_QP_OFFER(sk, handle);
+   if (err < 0) {
+      err = VSockVmci_ErrorToVSockError(err);
+      goto destroy;
+   }
+
+   vsk->qpHandle = handle;
+   vsk->produceQ = produceQ;
+   vsk->consumeQ = consumeQ;
+   vsk->produceSize = vsk->consumeSize = vsk->writeNotifyWindow = pkt->u.size;
+   vsk->attachSubId = attachSubId;
+   vsk->detachSubId = detachSubId;
+
+   return 0;
+
+destroy:
+   if (attachSubId != VMCI_INVALID_ID) {
+      VMCIEvent_Unsubscribe(attachSubId);
+      ASSERT(vsk->attachSubId == VMCI_INVALID_ID);
+   }
+
+   if (detachSubId != VMCI_INVALID_ID) {
+      VMCIEvent_Unsubscribe(detachSubId);
+      ASSERT(vsk->detachSubId == VMCI_INVALID_ID);
+   }
+
+   if (!VMCI_HANDLE_INVALID(handle)) {
+      VMCIQueuePair_Detach(handle);
+      ASSERT(VMCI_HANDLE_INVALID(vsk->qpHandle));
+   }
+
+   return err;
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VSockVmciRecvConnected --
+ *
+ *    Receives packets for sockets in the connected state.
+ *
+ *    Connected sockets should only ever receive detach, wrote, read, or reset
+ *    control messages.  Others are treated as errors that are ignored.
+ *
+ *    Wrote and read signify that the peer has produced or consumed,
+ *    respectively.
+ *
+ *    Detach messages signify that the connection is being closed cleanly and
+ *    reset messages signify that the connection is being closed in error.
+ *
+ *    Note that this assumes the socket lock is held.
+ *
+ * Results:
+ *    Zero on success, negative error code on failure.
+ *
+ * Side effects:
+ *    A queue pair may be created, an offer control packet sent, and the socket
+ *    may transition to the connecting state.
+ *
+ *
+ *----------------------------------------------------------------------------
+ */
+
+static int
+VSockVmciRecvConnected(struct sock *sk,      // IN
+                       VSockPacket *pkt)     // IN
+{
+   ASSERT(sk);
+   ASSERT(pkt);
+   ASSERT(sk->compat_sk_state == SS_CONNECTED);
+
+   /*
+    * In cases where we are closing the connection, it's sufficient to mark
+    * the state change (and maybe error) and wake up any waiting threads.
+    * Since this is a connected socket, it's owned by a user process and will
+    * be cleaned up when the failure is passed back on the current or next
+    * system call.  Our system call implementations must therefore check for
+    * error and state changes on entry and when being awoken.
+    */
+   switch (pkt->type) {
+   case VSOCK_PACKET_TYPE_SHUTDOWN:
+      if (pkt->u.mode) {
+         VSockVmciSock *vsk = vsock_sk(sk);
+
+         vsk->peerShutdown |= pkt->u.mode;
+         sk->compat_sk_state_change(sk);
+      }
+      break;
+
+   case VSOCK_PACKET_TYPE_RST:
+      sk->compat_sk_state = SS_DISCONNECTING;
+      sk->compat_sk_shutdown = SHUTDOWN_MASK;
+      sk->compat_sk_err = ECONNRESET;
+      sk->compat_sk_error_report(sk);
+      break;
+
+   case VSOCK_PACKET_TYPE_WROTE:
+      sk->compat_sk_data_ready(sk, 0);
+      break;
+
+   case VSOCK_PACKET_TYPE_READ:
+      sk->compat_sk_write_space(sk);
+      break;
+
+   case VSOCK_PACKET_TYPE_WAITING_WRITE:
+      VSockVmciHandleWaitingWrite(sk, pkt, FALSE, NULL, NULL);
+      break;
+
+   case VSOCK_PACKET_TYPE_WAITING_READ:
+      VSockVmciHandleWaitingRead(sk, pkt, FALSE, NULL, NULL);
+      break;
+
+   default:
+      return -EINVAL;
+   }
+
+   return 0;
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VSockVmciSendControlPktBH --
+ *
+ *    Sends a control packet from bottom-half context.
+ *
+ * Results:
+ *    Size of datagram sent on success, negative error code otherwise.  Note
+ *    that we return a VMCI error message since that's what callers will need
+ *    to provide.
+ *
+ * Side effects:
+ *    None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+static int
+VSockVmciSendControlPktBH(struct sockaddr_vm *src,      // IN
+                          struct sockaddr_vm *dst,      // IN
+                          VSockPacketType type,         // IN
+                          uint64 size,                  // IN
+                          uint64 mode,                  // IN
+                          VSockWaitingInfo *wait,       // IN
+                          VMCIHandle handle)            // IN
+{
+   /*
+    * Note that it is safe to use a single packet across all CPUs since two
+    * tasklets of the same type are guaranteed to not ever run simultaneously.
+    * If that ever changes, or VMCI stops using tasklets, we can use per-cpu
+    * packets.
+    */
+   static VSockPacket pkt;
+
+   VSockPacket_Init(&pkt, src, dst, type, size, mode, wait, handle);
+
+   LOG_PACKET(&pkt);
+#ifdef VSOCK_CONTROL_PACKET_COUNT
+   controlPacketCount[pkt.type]++;
+#endif
+   return VMCIDatagram_Send(&pkt.dg);
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VSockVmciSendControlPkt --
+ *
+ *      Sends a control packet.
+ *
+ * Results:
+ *      Size of datagram sent on success, negative error on failure.
+ *
+ * Side effects:
+ *      None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+static int
+VSockVmciSendControlPkt(struct sock *sk,        // IN
+                        VSockPacketType type,   // IN
+                        uint64 size,            // IN
+                        uint64 mode,            // IN
+                        VSockWaitingInfo *wait, // IN
+                        VMCIHandle handle)      // IN
+{
+   VSockPacket *pkt;
+   VSockVmciSock *vsk;
+   int err;
+
+   ASSERT(sk);
+   /*
+    * New sockets for connection establishment won't have socket structures
+    * yet; if one exists, ensure it is of the proper type.
+    */
+   ASSERT(sk->compat_sk_socket ?
+             sk->compat_sk_socket->type == SOCK_STREAM :
+             1);
+
+   vsk = vsock_sk(sk);
+
+   if (!VSockAddr_Bound(&vsk->localAddr)) {
+      return -EINVAL;
+   }
+
+   if (!VSockAddr_Bound(&vsk->remoteAddr)) {
+      return -EINVAL;
+   }
+
+   pkt = kmalloc(sizeof *pkt, GFP_KERNEL);
+   if (!pkt) {
+      return -ENOMEM;
+   }
+
+   VSockPacket_Init(pkt, &vsk->localAddr, &vsk->remoteAddr,
+                    type, size, mode, wait, handle);
+
+   LOG_PACKET(pkt);
+   err = VMCIDatagram_Send(&pkt->dg);
+   kfree(pkt);
+   if (err < 0) {
+      return VSockVmci_ErrorToVSockError(err);
+   }
+
+#ifdef VSOCK_CONTROL_PACKET_COUNT
+   controlPacketCount[pkt->type]++;
+#endif
+
+   return err;
+}
+#endif
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * __VSockVmciBind --
+ *
+ *    Common functionality needed to bind the specified address to the
+ *    VSocket.  If VMADDR_CID_ANY or VMADDR_PORT_ANY are specified, the context
+ *    ID or port are selected automatically.
+ *
+ * Results:
+ *    Zero on success, negative error code on failure.
+ *
+ * Side effects:
+ *    On success, a new datagram handle is created.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+static int
+__VSockVmciBind(struct sock *sk,          // IN/OUT
+                struct sockaddr_vm *addr) // IN
+{
+   static unsigned int port = LAST_RESERVED_PORT + 1;
+   struct sockaddr_vm newAddr;
+   VSockVmciSock *vsk;
+   VMCIId cid;
+   int err;
+
+   ASSERT(sk);
+   ASSERT(sk->compat_sk_socket);
+   ASSERT(addr);
+
+   vsk = vsock_sk(sk);
+
+   /* First ensure this socket isn't already bound. */
+   if (VSockAddr_Bound(&vsk->localAddr)) {
+      return -EINVAL;
+   }
+
+   /*
+    * Now bind to the provided address or select appropriate values if none are
+    * provided (VMADDR_CID_ANY and VMADDR_PORT_ANY).  Note that like AF_INET
+    * prevents binding to a non-local IP address (in most cases), we only allow
+    * binding to the local CID.
+    */
+   VSockAddr_Init(&newAddr, VMADDR_CID_ANY, VMADDR_PORT_ANY);
+
+   cid = VMCI_GetContextID();
+   if (addr->svm_cid != cid &&
+       addr->svm_cid != VMADDR_CID_ANY) {
+      return -EADDRNOTAVAIL;
+   }
+
+   newAddr.svm_cid = cid;
+
+   switch (sk->compat_sk_socket->type) {
+   case SOCK_STREAM:
+      spin_lock_bh(&vsockTableLock);
+
+      if (addr->svm_port == VMADDR_PORT_ANY) {
+         Bool found = FALSE;
+         unsigned int i;
+
+         for (i = 0; i < MAX_PORT_RETRIES; i++) {
+            if (port <= LAST_RESERVED_PORT) {
+               port = LAST_RESERVED_PORT + 1;
+            }
+
+            newAddr.svm_port = port++;
+
+            if (!__VSockVmciFindBoundSocket(&newAddr)) {
+               found = TRUE;
+               break;
+            }
+         }
+
+         if (!found) {
+            err = -EADDRNOTAVAIL;
+            goto out;
+         }
+      } else {
+         /* If port is in reserved range, ensure caller has necessary privileges. */
+         if (addr->svm_port <= LAST_RESERVED_PORT &&
+             !capable(CAP_NET_BIND_SERVICE)) {
+            err = -EACCES;
+            goto out;
+         }
+
+         newAddr.svm_port = addr->svm_port;
+         if (__VSockVmciFindBoundSocket(&newAddr)) {
+            err = -EADDRINUSE;
+            goto out;
+         }
+
+      }
+      break;
+   case SOCK_DGRAM:
+      /* VMCI will select a resource ID for us if we provide VMCI_INVALID_ID. */
+      newAddr.svm_port = addr->svm_port == VMADDR_PORT_ANY ?
+                            VMCI_INVALID_ID :
+                            addr->svm_port;
+
+      if (newAddr.svm_port <= LAST_RESERVED_PORT &&
+          !capable(CAP_NET_BIND_SERVICE)) {
+         err = -EACCES;
+         goto out;
+      }
+
+      err = VMCIDatagram_CreateHnd(newAddr.svm_port, 0,
+                                   VSockVmciRecvDgramCB, sk,
+                                   &vsk->dgHandle);
+      if (err != VMCI_SUCCESS ||
+          vsk->dgHandle.context == VMCI_INVALID_ID ||
+          vsk->dgHandle.resource == VMCI_INVALID_ID) {
+         err = VSockVmci_ErrorToVSockError(err);
+         goto out;
+      }
+
+      newAddr.svm_port = VMCI_HANDLE_TO_RESOURCE_ID(vsk->dgHandle);
+      break;
+   default:
+      err = -EINVAL;
+      goto out;
+   }
+
+   VSockAddr_Init(&vsk->localAddr, newAddr.svm_cid, newAddr.svm_port);
+
+   /*
+    * Remove stream sockets from the unbound list and add them to the hash
+    * table for easy lookup by its address.  The unbound list is simply an
+    * extra entry at the end of the hash table, a trick used by AF_UNIX.
+    */
+   if (sk->compat_sk_socket->type == SOCK_STREAM) {
+      __VSockVmciRemoveBound(sk);
+      __VSockVmciInsertBound(vsockBoundSockets(&vsk->localAddr), sk);
+   }
+
+   err = 0;
+
+out:
+   if (sk->compat_sk_socket->type == SOCK_STREAM) {
+      spin_unlock_bh(&vsockTableLock);
+   }
+   return err;
+}
+
+
+#ifdef VMX86_TOOLS
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VSockVmciSendWaitingWrite --
+ *
+ *      Sends a waiting write notification to this socket's peer.
+ *
+ * Results:
+ *      TRUE if the datagram is sent successfully, FALSE otherwise.
+ *
+ * Side effects:
+ *      Our peer will notify us when there is room to write in to our produce
+ *      queue.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+
+static Bool
+VSockVmciSendWaitingWrite(struct sock *sk,   // IN
+                          uint64 roomNeeded) // IN
+{
+#ifdef VSOCK_OPTIMIZATION_WAITING_NOTIFY
+   VSockVmciSock *vsk;
+   VSockWaitingInfo waitingInfo;
+   uint64 tail;
+   uint64 head;
+   uint64 roomLeft;
+
+   ASSERT(sk);
+
+   vsk = vsock_sk(sk);
+
+   VMCIQueue_GetPointers(vsk->produceQ, vsk->consumeQ, &tail, &head);
+   roomLeft = vsk->produceSize - tail;
+   if (roomNeeded + 1 >= roomLeft) {
+      /* Wraps around to current generation. */
+      waitingInfo.offset = roomNeeded + 1 - roomLeft;
+      waitingInfo.generation = vsk->produceQGeneration;
+   } else {
+      waitingInfo.offset = tail + roomNeeded + 1;
+      waitingInfo.generation = vsk->produceQGeneration - 1;
+   }
+
+   return VSOCK_SEND_WAITING_WRITE(sk, &waitingInfo) > 0;
+#else
+   return TRUE;
+#endif
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VSockVmciSendWaitingRead --
+ *
+ *      Sends a waiting read notification to this socket's peer.
+ *
+ * Results:
+ *      TRUE if the datagram is sent successfully, FALSE otherwise.
+ *
+ * Side effects:
+ *      Our peer will notify us when there is data to read from our consume
+ *      queue.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+static Bool
+VSockVmciSendWaitingRead(struct sock *sk,    // IN
+                         uint64 roomNeeded)  // IN
+{
+#ifdef VSOCK_OPTIMIZATION_WAITING_NOTIFY
+   VSockVmciSock *vsk;
+   VSockWaitingInfo waitingInfo;
+   uint64 tail;
+   uint64 head;
+   uint64 roomLeft;
+
+   ASSERT(sk);
+
+   vsk = vsock_sk(sk);
+
+   if (vsk->writeNotifyWindow < vsk->consumeSize) {
+      vsk->writeNotifyWindow = MIN(vsk->writeNotifyWindow + PAGE_SIZE,
+                                   vsk->consumeSize);
+   }
+
+   VMCIQueue_GetPointers(vsk->consumeQ, vsk->produceQ, &tail, &head);
+   roomLeft = vsk->consumeSize - head;
+   if (roomNeeded >= roomLeft) {
+      waitingInfo.offset = roomNeeded - roomLeft;
+      waitingInfo.generation = vsk->consumeQGeneration + 1;
+   } else {
+      waitingInfo.offset = head + roomNeeded;
+      waitingInfo.generation = vsk->consumeQGeneration;
+   }
+
+   return VSOCK_SEND_WAITING_READ(sk, &waitingInfo) > 0;
+#else
+   return TRUE;
+#endif
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VSockVmciSendReadNotification --
+ *
+ *      Sends a read notification to this socket's peer.
+ *
+ * Results:
+ *      >= 0 if the datagram is sent successfully, negative error value
+ *      otherwise.
+ *
+ * Side effects:
+ *      None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+static int
+VSockVmciSendReadNotification(struct sock *sk)  // IN
+{
+   VSockVmciSock *vsk;
+   Bool sentRead;
+   unsigned int retries;
+   int err;
+
+   ASSERT(sk);
+
+   vsk = vsock_sk(sk);
+   sentRead = FALSE;
+   retries = 0;
+   err = 0;
+
+   if (VSockVmciNotifyWaitingWrite(vsk)) {
+      /*
+       * Notify the peer that we have read, retrying the send on failure up to our
+       * maximum value.  XXX For now we just log the failure, but later we should
+       * schedule a work item to handle the resend until it succeeds.  That would
+       * require keeping track of work items in the vsk and cleaning them up upon
+       * socket close.
+       */
+      while (!(vsk->peerShutdown & RCV_SHUTDOWN) &&
+             !sentRead &&
+             retries < VSOCK_MAX_DGRAM_RESENDS) {
+         err = VSOCK_SEND_READ(sk);
+         if (err >= 0) {
+            sentRead = TRUE;
+         }
+
+         retries++;
+      }
+
+      if (retries >= VSOCK_MAX_DGRAM_RESENDS) {
+         Warning("unable to send read notification to peer for socket %p.\n", sk);
+      } else {
+#if defined(VSOCK_OPTIMIZATION_WAITING_NOTIFY)
+         vsk->peerWaitingWrite = FALSE;
+#endif
+      }
+   }
+   return err;
+}
+#endif // VMX86_TOOLS
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * __VSockVmciCreate --
+ *
+ *    Does the work to create the sock structure.
+ *
+ * Results:
+ *    sock structure on success, NULL on failure.
+ *
+ * Side effects:
+ *    Allocated sk is added to the unbound sockets list iff it is owned by
+ *    a struct socket.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 14)
+static struct sock *
+__VSockVmciCreate(struct socket *sock,   // IN: Owning socket, may be NULL
+                  unsigned int priority) // IN: Allocation flags
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 24)
+static struct sock *
+__VSockVmciCreate(struct socket *sock,   // IN: Owning socket, may be NULL
+                  gfp_t priority)        // IN: Allocation flags
+#else
+static struct sock *
+__VSockVmciCreate(struct net *net,       // IN: Network namespace
+                  struct socket *sock,   // IN: Owning socket, may be NULL
+                  gfp_t priority)        // IN: Allocation flags
+#endif
+{
+   struct sock *sk;
+   VSockVmciSock *vsk;
+
+   vsk = NULL;
+
+   /*
+    * Before 2.5.5, sk_alloc() always used its own cache and protocol-specific
+    * data was contained in the protinfo union.  We cannot use those other
+    * structures so we allocate our own structure and attach it to the
+    * user_data pointer that we don't otherwise need.  We must be sure to free
+    * it later in our destruct routine.
+    *
+    * From 2.5.5 until 2.6.8, sk_alloc() offerred to use a cache that the
+    * caller provided.  After this, the cache was moved into the proto
+    * structure, but you still had to specify the size and cache yourself until
+    * 2.6.12. Most recently (in 2.6.24), sk_alloc() was changed to expect the
+    * network namespace, and the option to zero the sock was dropped.
+    *
+    */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 5)
+   sk = sk_alloc(vsockVmciFamilyOps.family, priority, 1);
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 9)
+   sk = sk_alloc(vsockVmciFamilyOps.family, priority,
+                 sizeof (VSockVmciSock), vsockCachep);
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 12)
+   sk = sk_alloc(vsockVmciFamilyOps.family, priority,
+                 vsockVmciProto.slab_obj_size, vsockVmciProto.slab);
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 24)
+   sk = sk_alloc(vsockVmciFamilyOps.family, priority, &vsockVmciProto, 1);
+#else
+   sk = sk_alloc(net, vsockVmciFamilyOps.family, priority, &vsockVmciProto);
+#endif
+   if (!sk) {
+      return NULL;
+   }
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 5)
+   vsock_sk(sk) = kmalloc(sizeof *vsk, priority);
+   if (!vsock_sk(sk)) {
+      sk_free(sk);
+      return NULL;
+   }
+   sk_vsock(vsock_sk(sk)) = sk;
+#endif
+
+   /*
+    * If we go this far, we know the socket family is registered, so there's no
+    * need to register it now.
+    */
+   down(&registrationMutex);
+   vsockVmciSocketCount++;
+   up(&registrationMutex);
+
+   sock_init_data(sock, sk);
+
+   vsk = vsock_sk(sk);
+   VSockAddr_Init(&vsk->localAddr, VMADDR_CID_ANY, VMADDR_PORT_ANY);
+   VSockAddr_Init(&vsk->remoteAddr, VMADDR_CID_ANY, VMADDR_PORT_ANY);
+
+   sk->compat_sk_destruct = VSockVmciSkDestruct;
+   sk->compat_sk_backlog_rcv = VSockVmciQueueRcvSkb;
+   sk->compat_sk_state = SS_UNCONNECTED;
+
+   INIT_LIST_HEAD(&vsk->boundTable);
+   INIT_LIST_HEAD(&vsk->connectedTable);
+   vsk->dgHandle = VMCI_INVALID_HANDLE;
+#ifdef VMX86_TOOLS
+   vsk->qpHandle = VMCI_INVALID_HANDLE;
+   vsk->produceQ = vsk->consumeQ = NULL;
+   vsk->produceQGeneration = vsk->consumeQGeneration = 0;
+   vsk->produceSize = vsk->consumeSize = 0;
+   vsk->writeNotifyWindow = 0;
+   vsk->writeNotifyMinWindow = PAGE_SIZE;
+   vsk->queuePairSize = VSOCK_DEFAULT_QP_SIZE;
+   vsk->queuePairMinSize = VSOCK_DEFAULT_QP_SIZE_MIN;
+   vsk->queuePairMaxSize = VSOCK_DEFAULT_QP_SIZE_MAX;
+   vsk->peerWaitingRead = vsk->peerWaitingWrite = FALSE;
+   vsk->peerWaitingWriteDetected = FALSE;
+   memset(&vsk->peerWaitingReadInfo, 0, sizeof vsk->peerWaitingReadInfo);
+   memset(&vsk->peerWaitingWriteInfo, 0, sizeof vsk->peerWaitingWriteInfo);
+   vsk->listener = NULL;
+   INIT_LIST_HEAD(&vsk->pendingLinks);
+   INIT_LIST_HEAD(&vsk->acceptQueue);
+   vsk->rejected = FALSE;
+   vsk->attachSubId = vsk->detachSubId = VMCI_INVALID_ID;
+   vsk->peerShutdown = 0;
+#endif
+
+   if (sock) {
+      VSockVmciInsertBound(vsockUnboundSockets, sk);
+   }
+
+   return sk;
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * __VSockVmciRelease --
+ *
+ *      Releases the provided socket.
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      Any pending sockets are also released.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+static void
+__VSockVmciRelease(struct sock *sk) // IN
+{
+   if (sk) {
+      struct sk_buff *skb;
+      struct sock *pending;
+      struct VSockVmciSock *vsk;
+
+      vsk = vsock_sk(sk);
+      pending = NULL;  /* Compiler warning. */
+
+      if (VSockVmciInBoundTable(sk)) {
+         VSockVmciRemoveBound(sk);
+      }
+
+      if (VSockVmciInConnectedTable(sk)) {
+         VSockVmciRemoveConnected(sk);
+      }
+
+      if (!VMCI_HANDLE_INVALID(vsk->dgHandle)) {
+         VMCIDatagram_DestroyHnd(vsk->dgHandle);
+         vsk->dgHandle = VMCI_INVALID_HANDLE;
+      }
+
+      lock_sock(sk);
+      sock_orphan(sk);
+      sk->compat_sk_shutdown = SHUTDOWN_MASK;
+
+      while ((skb = skb_dequeue(&sk->compat_sk_receive_queue))) {
+         kfree_skb(skb);
+      }
+
+      /* Clean up any sockets that never were accepted. */
+#ifdef VMX86_TOOLS
+      while ((pending = VSockVmciDequeueAccept(sk)) != NULL) {
+         __VSockVmciRelease(pending);
+         sock_put(pending);
+      }
+#endif
+
+      release_sock(sk);
+      sock_put(sk);
+   }
+}
+
+
+/*
+ * Sock operations.
+ */
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VSockVmciSkDestruct --
+ *
+ *    Destroys the provided socket.  This is called by sk_free(), which is
+ *    invoked when the reference count of the socket drops to zero.
+ *
+ * Results:
+ *    None.
+ *
+ * Side effects:
+ *    Socket count is decremented.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+static void
+VSockVmciSkDestruct(struct sock *sk) // IN
+{
+   VSockVmciSock *vsk;
+
+   vsk = vsock_sk(sk);
+
+#ifdef VMX86_TOOLS
+   if (vsk->attachSubId != VMCI_INVALID_ID) {
+      VMCIEvent_Unsubscribe(vsk->attachSubId);
+      vsk->attachSubId = VMCI_INVALID_ID;
+   }
+
+   if (vsk->detachSubId != VMCI_INVALID_ID) {
+      VMCIEvent_Unsubscribe(vsk->detachSubId);
+      vsk->detachSubId = VMCI_INVALID_ID;
+   }
+
+   if (!VMCI_HANDLE_INVALID(vsk->qpHandle)) {
+      VMCIQueuePair_Detach(vsk->qpHandle);
+      vsk->qpHandle = VMCI_INVALID_HANDLE;
+      vsk->produceQ = vsk->consumeQ = NULL;
+      vsk->produceSize = vsk->consumeSize = 0;
+   }
+#endif
+
+   /*
+    * Each list entry holds a reference on the socket, so we should not even be
+    * here if the socket is in one of our lists.  If we are we have a stray
+    * sock_put() that needs to go away.
+    */
+   ASSERT(!VSockVmciInBoundTable(sk));
+   ASSERT(!VSockVmciInConnectedTable(sk));
+#ifdef VMX86_TOOLS
+   ASSERT(!VSockVmciIsPending(sk));
+   ASSERT(!VSockVmciInAcceptQueue(sk));
+#endif
+
+   /*
+    * When clearing these addresses, there's no need to set the family and
+    * possibly register the address family with the kernel.
+    */
+   VSockAddr_InitNoFamily(&vsk->localAddr, VMADDR_CID_ANY, VMADDR_PORT_ANY);
+   VSockAddr_InitNoFamily(&vsk->remoteAddr, VMADDR_CID_ANY, VMADDR_PORT_ANY);
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 5)
+   ASSERT(vsock_sk(sk) == vsk);
+   kfree(vsock_sk(sk));
+#endif
+
+   down(&registrationMutex);
+   vsockVmciSocketCount--;
+   VSockVmciTestUnregister();
+   up(&registrationMutex);
+
+#ifdef VSOCK_CONTROL_PACKET_COUNT
+   {
+      uint32 index;
+      for (index = 0; index < ARRAYSIZE(controlPacketCount); index++) {
+         Warning("Control packet count: Type = %u, Count = %"FMT64"u\n",
+                 index, controlPacketCount[index]);
+      }
+   }
+#endif
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VSockVmciQueueRcvSkb --
+ *
+ *    Receives skb on the socket's receive queue.
+ *
+ * Results:
+ *    Zero on success, negative error code on failure.
+ *
+ * Side effects:
+ *    None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+static int
+VSockVmciQueueRcvSkb(struct sock *sk,     // IN
+                     struct sk_buff *skb) // IN
+{
+   int err;
+
+   err = sock_queue_rcv_skb(sk, skb);
+   if (err) {
+      kfree_skb(skb);
+   }
+
+   return err;
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VSockVmciRegisterProto --
+ *
+ *      Registers the vmci sockets protocol family.
+ *
+ * Results:
+ *      Zero on success, error code on failure.
+ *
+ * Side effects:
+ *      None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+static INLINE int
+VSockVmciRegisterProto(void)
+{
+   int err;
+
+   err = 0;
+
+   /*
+    * Before 2.6.9, each address family created their own slab (by calling
+    * kmem_cache_create() directly).  From 2.6.9 until 2.6.11, these address
+    * families instead called sk_alloc_slab() and the allocated slab was
+    * assigned to the slab variable in the proto struct and was created of size
+    * slab_obj_size.  As of 2.6.12 and later, this slab allocation was moved
+    * into proto_register() and only done if you specified a non-zero value for
+    * the second argument (alloc_slab); the size of the slab element was
+    * changed to obj_size.
+    */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 5)
+   /* Simply here for clarity and so else case at end implies > rest. */
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 9)
+   vsockCachep = kmem_cache_create("vsock", sizeof (VSockVmciSock),
+                                   0, SLAB_HWCACHE_ALIGN, NULL, NULL);
+   if (!vsockCachep) {
+      err = -ENOMEM;
+   }
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 12)
+   err = sk_alloc_slab(&vsockVmciProto, "vsock");
+   if (err != 0) {
+      sk_alloc_slab_error(&vsockVmciProto);
+   }
+#else
+   /* Specify 1 as the second argument so the slab is created for us. */
+   err = proto_register(&vsockVmciProto, 1);
+#endif
+
+   return err;
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VSockVmciUnregisterProto --
+ *
+ *      Unregisters the vmci sockets protocol family.
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+static INLINE void
+VSockVmciUnregisterProto(void)
+{
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 5)
+   /* Simply here for clarity and so else case at end implies > rest. */
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 9)
+   kmem_cache_destroy(vsockCachep);
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 12)
+   sk_free_slab(&vsockVmciProto);
+#else
+   proto_unregister(&vsockVmciProto);
+#endif
+
+#ifdef VSOCK_CONTROL_PACKET_COUNT
+   {
+      uint32 index;
+      for (index = 0; index < ARRAYSIZE(controlPacketCount); index++) {
+         controlPacketCount[index] = 0;
+      }
+   }
+#endif
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VSockVmciRegisterAddressFamily --
+ *
+ *      Registers our socket address family with the kernel.
+ *
+ *      Note that this assumes the registration lock is held.
+ *
+ * Results:
+ *      The address family value on success, negative error code on failure.
+ *
+ * Side effects:
+ *      Callers of socket operations with the returned value, on success, will
+ *      be able to use our socket implementation.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+static int
+VSockVmciRegisterAddressFamily(void)
+{
+   int err = 0;
+   int i;
+
+#ifdef VMX86_TOOLS
+   /*
+    * We don't call into the vmci module or register our socket family if the
+    * vmci device isn't present.
+    */
+   vmciDevicePresent = VMCI_DeviceGet();
+   if (!vmciDevicePresent) {
+      Log("Could not register VMCI Sockets because VMCI device is not present.\n");
+      return -1;
+   }
+
+   /*
+    * Create the datagram handle that we will use to send and receive all
+    * VSocket control messages for this context.
+    */
+   err = VMCIDatagram_CreateHnd(VSOCK_PACKET_RID, 0,
+                                VSockVmciRecvStreamCB, NULL, &vmciStreamHandle);
+   if (err != VMCI_SUCCESS ||
+       vmciStreamHandle.context == VMCI_INVALID_ID ||
+       vmciStreamHandle.resource == VMCI_INVALID_ID) {
+      Warning("Unable to create datagram handle. (%d)\n", err);
+      return -ENOMEM;
+   }
+
+   err = VMCIEvent_Subscribe(VMCI_EVENT_QP_RESUMED,
+                             VSockVmciQPResumedCB,
+                             NULL,
+                             &qpResumedSubId);
+   if (err < VMCI_SUCCESS) {
+      Warning("Unable to subscribe to QP resumed event. (%d)\n", err);
+      err = -ENOMEM;
+      qpResumedSubId = VMCI_INVALID_ID;
+      goto error;
+   }
+#endif
+
+   /*
+    * Linux will not allocate an address family to code that is not part of the
+    * kernel proper, so until that time comes we need a workaround.  Here we
+    * loop through the allowed values and claim the first one that's not
+    * currently used.  Users will then make an ioctl(2) into our module to
+    * retrieve this value before calling socket(2).
+    *
+    * This is undesirable, but it's better than having users' programs break
+    * when a hard-coded, currently-available value gets assigned to someone
+    * else in the future.
+    */
+   for (i = NPROTO - 1; i >= 0; i--) {
+      vsockVmciFamilyOps.family = i;
+      err = sock_register(&vsockVmciFamilyOps);
+      if (err) {
+         Warning("Could not register address family %d.\n", i);
+         vsockVmciFamilyOps.family = VSOCK_INVALID_FAMILY;
+      } else {
+         vsockVmciDgramOps.family = i;
+#ifdef VMX86_TOOLS
+         vsockVmciStreamOps.family = i;
+#endif
+         break;
+      }
+   }
+
+   if (err) {
+      goto error;
+   }
+
+   return vsockVmciFamilyOps.family;
+
+error:
+#ifdef VMX86_TOOLS
+   if (qpResumedSubId != VMCI_INVALID_ID) {
+      VMCIEvent_Unsubscribe(qpResumedSubId);
+      qpResumedSubId = VMCI_INVALID_ID;
+   }
+   VMCIDatagram_DestroyHnd(vmciStreamHandle);
+#endif
+   return err;
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VSockVmciUnregisterAddressFamily --
+ *
+ *      Unregisters the address family with the kernel.
+ *
+ *      Note that this assumes the registration lock is held.
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      Our socket implementation is no longer accessible.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+static void
+VSockVmciUnregisterAddressFamily(void)
+{
+#ifdef VMX86_TOOLS
+   if (!vmciDevicePresent) {
+      /* Nothing was registered. */
+      return;
+   }
+
+   if (!VMCI_HANDLE_INVALID(vmciStreamHandle)) {
+      if (VMCIDatagram_DestroyHnd(vmciStreamHandle) != VMCI_SUCCESS) {
+         Warning("Could not destroy VMCI datagram handle.\n");
+      }
+   }
+
+   if (qpResumedSubId != VMCI_INVALID_ID) {
+      VMCIEvent_Unsubscribe(qpResumedSubId);
+      qpResumedSubId = VMCI_INVALID_ID;
+   }
+#endif
+
+   if (vsockVmciFamilyOps.family != VSOCK_INVALID_FAMILY) {
+      sock_unregister(vsockVmciFamilyOps.family);
+   }
+
+   vsockVmciDgramOps.family = vsockVmciFamilyOps.family = VSOCK_INVALID_FAMILY;
+#ifdef VMX86_TOOLS
+   vsockVmciStreamOps.family = vsockVmciFamilyOps.family;
+#endif
+
+}
+
+
+/*
+ * Socket operations.
+ */
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VSockVmciRelease --
+ *
+ *    Releases the provided socket by freeing the contents of its queue.  This
+ *    is called when a user process calls close(2) on the socket.
+ *
+ * Results:
+ *    Zero on success, negative error code on failure.
+ *
+ * Side effects:
+ *    None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+static int
+VSockVmciRelease(struct socket *sock) // IN
+{
+   __VSockVmciRelease(sock->sk);
+   sock->sk = NULL;
+   sock->state = SS_FREE;
+
+   return 0;
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VSockVmciBind --
+ *
+ *    Binds the provided address to the provided socket.
+ *
+ * Results:
+ *    Zero on success, negative error code on failure.
+ *
+ * Side effects:
+ *    None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+static int
+VSockVmciBind(struct socket *sock,    // IN
+              struct sockaddr *addr,  // IN
+              int addrLen)            // IN
+{
+   int err;
+   struct sock *sk;
+   struct sockaddr_vm *vmciAddr;
+
+   sk = sock->sk;
+
+   if (VSockAddr_Cast(addr, addrLen, &vmciAddr) != 0) {
+      return -EINVAL;
+   }
+
+   lock_sock(sk);
+   err = __VSockVmciBind(sk, vmciAddr);
+   release_sock(sk);
+
+   return err;
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VSockVmciDgramConnect --
+ *
+ *    Connects a datagram socket.  This can be called multiple times to change
+ *    the socket's association and can be called with a sockaddr whose family
+ *    is set to AF_UNSPEC to dissolve any existing association.
+ *
+ * Results:
+ *    Zero on success, negative error code on failure.
+ *
+ * Side effects:
+ *    None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+static int
+VSockVmciDgramConnect(struct socket *sock,   // IN
+                      struct sockaddr *addr, // IN
+                      int addrLen,           // IN
+                      int flags)             // IN
+{
+   int err;
+   struct sock *sk;
+   VSockVmciSock *vsk;
+   struct sockaddr_vm *remoteAddr;
+
+   sk = sock->sk;
+   vsk = vsock_sk(sk);
+
+   err = VSockAddr_Cast(addr, addrLen, &remoteAddr);
+   if (err == -EAFNOSUPPORT && remoteAddr->svm_family == AF_UNSPEC) {
+      lock_sock(sk);
+      VSockAddr_Init(&vsk->remoteAddr, VMADDR_CID_ANY, VMADDR_PORT_ANY);
+      sock->state = SS_UNCONNECTED;
+      release_sock(sk);
+      return 0;
+   } else if (err != 0) {
+      return -EINVAL;
+   }
+
+   lock_sock(sk);
+
+
+   if (!VSockAddr_Bound(&vsk->localAddr)) {
+      struct sockaddr_vm localAddr;
+
+      VSockAddr_Init(&localAddr, VMADDR_CID_ANY, VMADDR_PORT_ANY);
+      if ((err = __VSockVmciBind(sk, &localAddr))) {
+         goto out;
+      }
+   }
+
+   memcpy(&vsk->remoteAddr, remoteAddr, sizeof vsk->remoteAddr);
+   sock->state = SS_CONNECTED;
+
+out:
+   release_sock(sk);
+   return err;
+}
+
+
+#ifdef VMX86_TOOLS
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VSockVmciStreamConnect --
+ *
+ *    Connects a stream socket.
+ *
+ * Results:
+ *    Zero on success, negative error code on failure.
+ *
+ * Side effects:
+ *    None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+static int
+VSockVmciStreamConnect(struct socket *sock,   // IN
+                       struct sockaddr *addr, // IN
+                       int addrLen,           // IN
+                       int flags)             // IN
+{
+   int err;
+   struct sock *sk;
+   VSockVmciSock *vsk;
+   struct sockaddr_vm *remoteAddr;
+   long timeout;
+   COMPAT_DEFINE_WAIT(wait);
+
+   err = 0;
+   sk = sock->sk;
+   vsk = vsock_sk(sk);
+
+   lock_sock(sk);
+
+   /* XXX AF_UNSPEC should make us disconnect like AF_INET. */
+
+   switch (sock->state) {
+   case SS_CONNECTED:
+      err = -EISCONN;
+      goto out;
+   case SS_DISCONNECTING:
+   case SS_LISTEN:
+      err = -EINVAL;
+      goto out;
+   case SS_CONNECTING:
+      /*
+       * This continues on so we can move sock into the SS_CONNECTED state once
+       * the connection has completed (at which point err will be set to zero
+       * also).  Otherwise, we will either wait for the connection or return
+       * -EALREADY should this be a non-blocking call.
+       */
+      err = -EALREADY;
+      break;
+   default:
+      ASSERT(sk->compat_sk_state == SS_FREE ||
+             sk->compat_sk_state == SS_UNCONNECTED);
+      if (VSockAddr_Cast(addr, addrLen, &remoteAddr) != 0) {
+         err = -EINVAL;
+         goto out;
+      }
+
+      /* The hypervisor and well-known contexts do not have socket endpoints. */
+      if (!VSockAddr_SocketContext(remoteAddr->svm_cid)) {
+         err = -ENETUNREACH;
+         goto out;
+      }
+
+      /* Set the remote address that we are connecting to. */
+      memcpy(&vsk->remoteAddr, remoteAddr, sizeof vsk->remoteAddr);
+
+      /* Autobind this socket to the local address if necessary. */
+      if (!VSockAddr_Bound(&vsk->localAddr)) {
+         struct sockaddr_vm localAddr;
+
+         VSockAddr_Init(&localAddr, VMADDR_CID_ANY, VMADDR_PORT_ANY);
+         if ((err = __VSockVmciBind(sk, &localAddr))) {
+            goto out;
+         }
+      }
+
+      sk->compat_sk_state = SS_CONNECTING;
+
+      err = VSOCK_SEND_CONN_REQUEST(sk, vsk->queuePairSize);
+      if (err < 0) {
+         sk->compat_sk_state = SS_UNCONNECTED;
+         goto out;
+      }
+
+      /*
+       * Mark sock as connecting and set the error code to in progress in case
+       * this is a non-blocking connect.
+       */
+      sock->state = SS_CONNECTING;
+      err = -EINPROGRESS;
+   }
+
+   /*
+    * The receive path will handle all communication until we are able to enter
+    * the connected state.  Here we wait for the connection to be completed or
+    * a notification of an error.
+    */
+   timeout = sock_sndtimeo(sk, flags & O_NONBLOCK);
+   compat_init_prepare_to_wait(sk->compat_sk_sleep, &wait, TASK_INTERRUPTIBLE);
+
+   while (sk->compat_sk_state != SS_CONNECTED && sk->compat_sk_err == 0) {
+      if (timeout == 0) {
+         /*
+          * If we're not going to block, skip ahead to preserve error code set
+          * above.
+          */
+         goto outWait;
+      }
+
+      release_sock(sk);
+      timeout = schedule_timeout(timeout);
+      lock_sock(sk);
+
+      if (signal_pending(current)) {
+         err = sock_intr_errno(timeout);
+         goto outWaitError;
+      } else if (timeout == 0) {
+         err = -ETIMEDOUT;
+         goto outWaitError;
+      }
+
+      compat_cont_prepare_to_wait(sk->compat_sk_sleep, &wait, TASK_INTERRUPTIBLE);
+   }
+
+   if (sk->compat_sk_err) {
+      err = -sk->compat_sk_err;
+      goto outWaitError;
+   } else {
+      ASSERT(sk->compat_sk_state == SS_CONNECTED);
+      err = 0;
+   }
+
+outWait:
+   compat_finish_wait(sk->compat_sk_sleep, &wait, TASK_RUNNING);
+out:
+   release_sock(sk);
+   return err;
+
+outWaitError:
+   sk->compat_sk_state = SS_UNCONNECTED;
+   sock->state = SS_UNCONNECTED;
+   goto outWait;
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VSockVmciAccept --
+ *
+ *      Accepts next available connection request for this socket.
+ *
+ * Results:
+ *      Zero on success, negative error code on failure.
+ *
+ * Side effects:
+ *      None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+static int
+VSockVmciAccept(struct socket *sock,     // IN
+                struct socket *newsock,  // IN/OUT
+                int flags)               // IN
+{
+   struct sock *listener;
+   int err;
+   struct sock *connected;
+   VSockVmciSock *vconnected;
+   long timeout;
+   COMPAT_DEFINE_WAIT(wait);
+
+   err = 0;
+   listener = sock->sk;
+
+   lock_sock(listener);
+
+   if (sock->type != SOCK_STREAM) {
+      err = -EOPNOTSUPP;
+      goto out;
+   }
+
+   if (listener->compat_sk_state != SS_LISTEN) {
+      err = -EINVAL;
+      goto out;
+   }
+
+   /*
+    * Wait for children sockets to appear; these are the new sockets created
+    * upon connection establishment.
+    */
+   timeout = sock_sndtimeo(listener, flags & O_NONBLOCK);
+   compat_init_prepare_to_wait(listener->compat_sk_sleep, &wait, TASK_INTERRUPTIBLE);
+
+   while ((connected = VSockVmciDequeueAccept(listener)) == NULL &&
+          listener->compat_sk_err == 0) {
+      release_sock(listener);
+      timeout = schedule_timeout(timeout);
+      lock_sock(listener);
+
+      if (signal_pending(current)) {
+         err = sock_intr_errno(timeout);
+         goto outWait;
+      } else if (timeout == 0) {
+         err = -ETIMEDOUT;
+         goto outWait;
+      }
+
+      compat_cont_prepare_to_wait(listener->compat_sk_sleep, &wait, TASK_INTERRUPTIBLE);
+   }
+
+   if (listener->compat_sk_err) {
+      err = -listener->compat_sk_err;
+   }
+
+   if (connected) {
+      listener->compat_sk_ack_backlog--;
+
+      lock_sock(connected);
+      vconnected = vsock_sk(connected);
+
+      /*
+       * If the listener socket has received an error, then we should reject
+       * this socket and return.  Note that we simply mark the socket rejected,
+       * drop our reference, and let the cleanup function handle the cleanup;
+       * the fact that we found it in the listener's accept queue guarantees
+       * that the cleanup function hasn't run yet.
+       */
+      if (err) {
+         vconnected->rejected = TRUE;
+         release_sock(connected);
+         sock_put(connected);
+         goto outWait;
+      }
+
+      newsock->state = SS_CONNECTED;
+      sock_graft(connected, newsock);
+      release_sock(connected);
+      sock_put(connected);
+   }
+
+outWait:
+   compat_finish_wait(listener->compat_sk_sleep, &wait, TASK_RUNNING);
+out:
+   release_sock(listener);
+   return err;
+}
+#endif
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VSockVmciGetname --
+ *
+ *    Provides the local or remote address for the socket.
+ *
+ * Results:
+ *    Zero on success, negative error code otherwise.
+ *
+ * Side effects:
+ *    None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+static int
+VSockVmciGetname(struct socket *sock,    // IN
+                 struct sockaddr *addr,  // OUT
+                 int *addrLen,           // OUT
+                 int peer)               // IN
+{
+   int err;
+   struct sock *sk;
+   VSockVmciSock *vsk;
+   struct sockaddr_vm *vmciAddr;
+
+   sk = sock->sk;
+   vsk = vsock_sk(sk);
+   err = 0;
+
+   lock_sock(sk);
+
+   if (peer) {
+      if (sock->state != SS_CONNECTED) {
+         err = -ENOTCONN;
+         goto out;
+      }
+      vmciAddr = &vsk->remoteAddr;
+   } else {
+      vmciAddr = &vsk->localAddr;
+   }
+
+   if (!vmciAddr) {
+      err = -EINVAL;
+      goto out;
+   }
+
+   /*
+    * sys_getsockname() and sys_getpeername() pass us a MAX_SOCK_ADDR-sized
+    * buffer and don't set addrLen.  Unfortunately that macro is defined in
+    * socket.c instead of .h, so we hardcode its value here.
+    */
+   ASSERT_ON_COMPILE(sizeof *vmciAddr <= 128);
+   memcpy(addr, vmciAddr, sizeof *vmciAddr);
+   *addrLen = sizeof *vmciAddr;
+
+out:
+   release_sock(sk);
+   return err;
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VSockVmciPoll --
+ *
+ *    Waits on file for activity then provides mask indicating state of socket.
+ *
+ * Results:
+ *    Mask of flags containing socket state.
+ *
+ * Side effects:
+ *    None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+static unsigned int
+VSockVmciPoll(struct file *file,    // IN
+              struct socket *sock,  // IN
+              poll_table *wait)     // IN
+{
+   struct sock *sk;
+   unsigned int mask;
+
+   sk = sock->sk;
+
+   poll_wait(file, sk->compat_sk_sleep, wait);
+   mask = 0;
+
+   if (sk->compat_sk_err) {
+      mask |= POLLERR;
+   }
+
+   if (sk->compat_sk_shutdown == SHUTDOWN_MASK) {
+      mask |= POLLHUP;
+   }
+
+   /* POLLRDHUP wasn't added until 2.6.17. */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 17)
+   if (sk->compat_sk_shutdown & RCV_SHUTDOWN) {
+      mask |= POLLRDHUP;
+   }
+#endif
+
+   if (sock->type == SOCK_DGRAM) {
+      /*
+       * For datagram sockets we can read if there is something in the queue
+       * and write as long as the socket isn't shutdown for sending.
+       */
+      if (!skb_queue_empty(&sk->compat_sk_receive_queue) ||
+          (sk->compat_sk_shutdown & RCV_SHUTDOWN)) {
+         mask |= POLLIN | POLLRDNORM;
+      }
+
+      if (!(sk->compat_sk_shutdown & SEND_SHUTDOWN)) {
+         mask |= POLLOUT | POLLWRNORM | POLLWRBAND;
+      }
+#ifdef VMX86_TOOLS
+   } else if (sock->type == SOCK_STREAM) {
+      VSockVmciSock *vsk;
+
+      lock_sock(sk);
+
+      vsk = vsock_sk(sk);
+
+      /*
+       * Listening sockets that have connections in their accept queue and
+       * connected sockets that have consumable data can be read.  Sockets
+       * whose connections have been close, reset, or terminated should also be
+       * considered read, and we check the shutdown flag for that.
+       */
+      if ((sk->compat_sk_state == SS_LISTEN &&
+           !VSockVmciIsAcceptQueueEmpty(sk)) ||
+          (!VMCI_HANDLE_INVALID(vsk->qpHandle) &&
+           !(sk->compat_sk_shutdown & RCV_SHUTDOWN) &&
+           VMCIQueue_BufReady(vsk->consumeQ,
+                              vsk->produceQ, vsk->consumeSize)) ||
+           sk->compat_sk_shutdown) {
+          mask |= POLLIN | POLLRDNORM;
+      }
+
+      /*
+       * Connected sockets that can produce data can be written.
+       */
+      if (sk->compat_sk_state == SS_CONNECTED &&
+          !(sk->compat_sk_shutdown & SEND_SHUTDOWN) &&
+          VMCIQueue_FreeSpace(vsk->produceQ,
+                              vsk->consumeQ, vsk->produceSize) > 0) {
+         mask |= POLLOUT | POLLWRNORM | POLLWRBAND;
+      }
+
+      /*
+       * Connected sockets also need to notify their peer that they are
+       * waiting.  Optimally these calls would happen in the code that decides
+       * whether the caller will wait or not, but that's core kernel code and
+       * this is the best we can do.  If the caller doesn't sleep, the worst
+       * that happens is a few extra datagrams are sent.
+       */
+      if (sk->compat_sk_state == SS_CONNECTED) {
+         VSockVmciSendWaitingWrite(sk, 1);
+         VSockVmciSendWaitingRead(sk, 1);
+      }
+
+      release_sock(sk);
+#endif
+   }
+
+   return mask;
+}
+
+
+#ifdef VMX86_TOOLS
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VSockVmciListen --
+ *
+ *      Signify that this socket is listening for connection requests.
+ *
+ * Results:
+ *      Zero on success, negative error code on failure.
+ *
+ * Side effects:
+ *      None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+static int
+VSockVmciListen(struct socket *sock,    // IN
+                int backlog)            // IN
+{
+   int err;
+   struct sock *sk;
+   VSockVmciSock *vsk;
+
+   sk = sock->sk;
+
+   lock_sock(sk);
+
+   if (sock->type != SOCK_STREAM) {
+      err = -EOPNOTSUPP;
+      goto out;
+   }
+
+   if (sock->state != SS_UNCONNECTED) {
+      err = -EINVAL;
+      goto out;
+   }
+
+   vsk = vsock_sk(sk);
+
+   if (!VSockAddr_Bound(&vsk->localAddr)) {
+      err = -EINVAL;
+      goto out;
+   }
+
+   sk->compat_sk_max_ack_backlog = backlog;
+   sk->compat_sk_state = SS_LISTEN;
+
+   err = 0;
+
+out:
+   release_sock(sk);
+   return err;
+}
+#endif
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VSockVmciShutdown --
+ *
+ *    Shuts down the provided socket in the provided method.
+ *
+ * Results:
+ *    Zero on success, negative error code on failure.
+ *
+ * Side effects:
+ *    None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+static int
+VSockVmciShutdown(struct socket *sock,  // IN
+                  int mode)             // IN
+{
+   struct sock *sk;
+
+   /*
+    * User level uses SHUT_RD (0) and SHUT_WR (1), but the kernel uses
+    * RCV_SHUTDOWN (1) and SEND_SHUTDOWN (2), so we must increment mode here
+    * like the other address families do.  Note also that the increment makes
+    * SHUT_RDWR (2) into RCV_SHUTDOWN | SEND_SHUTDOWN (3), which is what we
+    * want.
+    */
+   mode++;
+
+   if ((mode & ~SHUTDOWN_MASK) || !mode) {
+      return -EINVAL;
+   }
+
+   if (sock->state == SS_UNCONNECTED) {
+      return -ENOTCONN;
+   }
+
+   sk = sock->sk;
+   sock->state = SS_DISCONNECTING;
+
+   /* Receive and send shutdowns are treated alike. */
+   mode = mode & (RCV_SHUTDOWN | SEND_SHUTDOWN);
+   if (mode) {
+      lock_sock(sk);
+      sk->compat_sk_shutdown |= mode;
+      sk->compat_sk_state_change(sk);
+      release_sock(sk);
+   }
+
+#ifdef VMX86_TOOLS
+   if (sk->compat_sk_type == SOCK_STREAM && mode) {
+      VSOCK_SEND_SHUTDOWN(sk, mode);
+   }
+#endif
+
+   return 0;
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VSockVmciDgramSendmsg --
+ *
+ *    Sends a datagram.
+ *
+ * Results:
+ *    Number of bytes sent on success, negative error code on failure.
+ *
+ * Side effects:
+ *    None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 43)
+static int
+VSockVmciDgramSendmsg(struct socket *sock,          // IN: socket to send on
+                      struct msghdr *msg,           // IN: message to send
+                      int len,                      // IN: length of message
+                      struct scm_cookie *scm)       // UNUSED
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 65)
+static int
+VSockVmciDgramSendmsg(struct kiocb *kiocb,          // UNUSED
+                      struct socket *sock,          // IN: socket to send on
+                      struct msghdr *msg,           // IN: message to send
+                      int len,                      // IN: length of message
+                      struct scm_cookie *scm);      // UNUSED
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 2)
+static int
+VSockVmciDgramSendmsg(struct kiocb *kiocb,          // UNUSED
+                      struct socket *sock,          // IN: socket to send on
+                      struct msghdr *msg,           // IN: message to send
+                      int len)                      // IN: length of message
+#else
+static int
+VSockVmciDgramSendmsg(struct kiocb *kiocb,          // UNUSED
+                      struct socket *sock,          // IN: socket to send on
+                      struct msghdr *msg,           // IN: message to send
+                      size_t len)                   // IN: length of message
+#endif
+{
+   int err;
+   struct sock *sk;
+   VSockVmciSock *vsk;
+   struct sockaddr_vm *remoteAddr;
+   VMCIDatagram *dg;
+
+   if (msg->msg_flags & MSG_OOB) {
+      return -EOPNOTSUPP;
+   }
+
+   if (len > VMCI_MAX_DG_PAYLOAD_SIZE) {
+      return -EMSGSIZE;
+   }
+
+   /* For now, MSG_DONTWAIT is always assumed... */
+   err = 0;
+   sk = sock->sk;
+   vsk = vsock_sk(sk);
+
+   lock_sock(sk);
+
+   if (!VSockAddr_Bound(&vsk->localAddr)) {
+      struct sockaddr_vm localAddr;
+
+      VSockAddr_Init(&localAddr, VMADDR_CID_ANY, VMADDR_PORT_ANY);
+      if ((err = __VSockVmciBind(sk, &localAddr))) {
+         goto out;
+      }
+   }
+
+   /*
+    * If the provided message contains an address, use that.  Otherwise fall
+    * back on the socket's remote handle (if it has been connected).
+    */
+   if (msg->msg_name &&
+       VSockAddr_Cast(msg->msg_name, msg->msg_namelen, &remoteAddr) == 0) {
+      /* Ensure this address is of the right type and is a valid destination. */
+      // XXXAB Temporary to handle test program
+      if (remoteAddr->svm_cid == VMADDR_CID_ANY) {
+         remoteAddr->svm_cid = VMCI_GetContextID();
+      }
+
+      if (!VSockAddr_Bound(remoteAddr)) {
+         err = -EINVAL;
+         goto out;
+      }
+   } else if (sock->state == SS_CONNECTED) {
+      remoteAddr = &vsk->remoteAddr;
+      // XXXAB Temporary to handle test program
+      if (remoteAddr->svm_cid == VMADDR_CID_ANY) {
+         remoteAddr->svm_cid = VMCI_GetContextID();
+      }
+
+      /* XXX Should connect() or this function ensure remoteAddr is bound? */
+      if (!VSockAddr_Bound(&vsk->remoteAddr)) {
+         err = -EINVAL;
+         goto out;
+      }
+   } else {
+      err = -EINVAL;
+      goto out;
+   }
+
+   /*
+    * Allocate a buffer for the user's message and our packet header.
+    */
+   dg = kmalloc(len + sizeof *dg, GFP_KERNEL);
+   if (!dg) {
+      err = -ENOMEM;
+      goto out;
+   }
+
+   memcpy_fromiovec(VMCI_DG_PAYLOAD(dg), msg->msg_iov, len);
+
+   dg->dst = VMCI_MAKE_HANDLE(remoteAddr->svm_cid, remoteAddr->svm_port);
+   dg->src = VMCI_MAKE_HANDLE(vsk->localAddr.svm_cid, vsk->localAddr.svm_port);
+   dg->payloadSize = len;
+
+   err = VMCIDatagram_Send(dg);
+   kfree(dg);
+   if (err < 0) {
+      err = VSockVmci_ErrorToVSockError(err);
+      goto out;
+   }
+
+   /*
+    * err is the number of bytes sent on success.  We need to subtract the
+    * VSock-specific header portions of what we've sent.
+    */
+   err -= sizeof *dg;
+
+out:
+   release_sock(sk);
+   return err;
+}
+
+#ifdef VMX86_TOOLS
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VSockVmciStreamSetsockopt --
+ *
+ *    Set a socket option on a stream socket
+ *
+ * Results:
+ *    0 on success, negative error code on failure.
+ *
+ * Side effects:
+ *    None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+int
+VSockVmciStreamSetsockopt(struct socket *sock,       // IN/OUT
+                          int level,                 // IN
+                          int optname,               // IN
+                          char __user *optval,       // IN
+                          int optlen)                // IN
+{
+   int err;
+   struct sock *sk;
+   VSockVmciSock *vsk;
+   uint64 val;
+
+   if (level != VSockVmci_GetAFValue()) {
+      return -ENOPROTOOPT;
+   }
+
+   if (optlen < sizeof val) {
+      return -EINVAL;
+   }
+
+   if (copy_from_user(&val, optval, sizeof val) != 0) {
+      return -EFAULT;
+   }
+
+   err = 0;
+   sk = sock->sk;
+   vsk = vsock_sk(sk);
+
+   ASSERT(vsk->queuePairMinSize <= vsk->queuePairSize &&
+          vsk->queuePairSize <= vsk->queuePairMaxSize);
+
+   lock_sock(sk);
+
+   switch (optname) {
+   case SO_VMCI_BUFFER_SIZE:
+      if (val < vsk->queuePairMinSize || val > vsk->queuePairMaxSize) {
+         err = -EINVAL;
+         goto out;
+      }
+      vsk->queuePairSize = val;
+      break;
+
+   case SO_VMCI_BUFFER_MAX_SIZE:
+      if (val < vsk->queuePairSize) {
+         err = -EINVAL;
+         goto out;
+      }
+      vsk->queuePairMaxSize = val;
+      break;
+
+   case SO_VMCI_BUFFER_MIN_SIZE:
+      if (val > vsk->queuePairSize) {
+         err = -EINVAL;
+         goto out;
+      }
+      vsk->queuePairMinSize = val;
+      break;
+
+   default:
+      err = -ENOPROTOOPT;
+      break;
+   }
+
+out:
+
+   ASSERT(vsk->queuePairMinSize <= vsk->queuePairSize &&
+          vsk->queuePairSize <= vsk->queuePairMaxSize);
+
+   release_sock(sk);
+   return err;
+}
+
+#endif
+
+#ifdef VMX86_TOOLS
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VSockVmciStreamGetsockopt --
+ *
+ *    Get a socket option for a stream socket
+ *
+ * Results:
+ *    0 on success, negative error code on failure.
+ *
+ * Side effects:
+ *    None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+int
+VSockVmciStreamGetsockopt(struct socket *sock,          // IN
+                          int level,                    // IN
+                          int optname,                  // IN
+                          char __user *optval,          // OUT
+                          int __user * optlen)          // IN/OUT
+{
+   int err;
+   int len;
+   struct sock *sk;
+   VSockVmciSock *vsk;
+   uint64 val;
+
+   if (level != VSockVmci_GetAFValue()) {
+      return -ENOPROTOOPT;
+   }
+
+   if ((err = get_user(len, optlen)) != 0) {
+      return err;
+   }
+   if (len < sizeof val) {
+      return -EINVAL;
+   }
+
+   len = sizeof val;
+
+   err = 0;
+   sk = sock->sk;
+   vsk = vsock_sk(sk);
+
+   switch (optname) {
+   case SO_VMCI_BUFFER_SIZE:
+      val = vsk->queuePairSize;
+      break;
+
+   case SO_VMCI_BUFFER_MAX_SIZE:
+      val = vsk->queuePairMaxSize;
+      break;
+
+   case SO_VMCI_BUFFER_MIN_SIZE:
+      val = vsk->queuePairMinSize;
+      break;
+
+   default:
+      return -ENOPROTOOPT;
+   }
+
+   if ((err = put_user(val, (uint64 __user *)optval)) != 0) {
+      return err;
+   }
+   if ((err = put_user(len, optlen)) != 0) {
+      return err;
+   }
+   return 0;
+}
+#endif
+
+
+#ifdef VMX86_TOOLS
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VSockVmciStreamSendmsg --
+ *
+ *    Sends a message on the socket.
+ *
+ * Results:
+ *    Number of bytes sent on success, negative error code on failure.
+ *
+ * Side effects:
+ *    None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 43)
+static int
+VSockVmciStreamSendmsg(struct socket *sock,          // IN: socket to send on
+                       struct msghdr *msg,           // IN: message to send
+                       int len,                      // IN: length of message
+                       struct scm_cookie *scm)       // UNUSED
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 65)
+static int
+VSockVmciStreamSendmsg(struct kiocb *kiocb,          // UNUSED
+                       struct socket *sock,          // IN: socket to send on
+                       struct msghdr *msg,           // IN: message to send
+                       int len,                      // IN: length of message
+                       struct scm_cookie *scm);      // UNUSED
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 2)
+static int
+VSockVmciStreamSendmsg(struct kiocb *kiocb,          // UNUSED
+                       struct socket *sock,          // IN: socket to send on
+                       struct msghdr *msg,           // IN: message to send
+                       int len)                      // IN: length of message
+#else
+static int
+VSockVmciStreamSendmsg(struct kiocb *kiocb,          // UNUSED
+                       struct socket *sock,          // IN: socket to send on
+                       struct msghdr *msg,           // IN: message to send
+                       size_t len)                   // IN: length of message
+#endif
+{
+   struct sock *sk;
+   VSockVmciSock *vsk;
+   ssize_t totalWritten;
+   long timeout;
+   int err;
+#if defined(VMX86_TOOLS) && defined(VSOCK_OPTIMIZATION_WAITING_NOTIFY)
+   uint64 produceTail;
+   uint64 consumeHead;
+#endif
+   COMPAT_DEFINE_WAIT(wait);
+
+   sk = sock->sk;
+   vsk = vsock_sk(sk);
+   totalWritten = 0;
+   err = 0;
+
+   if (msg->msg_flags & MSG_OOB) {
+      return -EOPNOTSUPP;
+   }
+
+   lock_sock(sk);
+
+   /* Callers should not provide a destination with stream sockets. */
+   if (msg->msg_namelen) {
+      err = sk->compat_sk_state == SS_CONNECTED ? -EISCONN : -EOPNOTSUPP;
+      goto out;
+   }
+
+   if (sk->compat_sk_shutdown & SEND_SHUTDOWN) {
+      err = -EPIPE;
+      goto out;
+   }
+
+   if (sk->compat_sk_state != SS_CONNECTED ||
+       !VSockAddr_Bound(&vsk->localAddr)) {
+      err = -ENOTCONN;
+      goto out;
+   }
+
+   if (!VSockAddr_Bound(&vsk->remoteAddr)) {
+      err = -EDESTADDRREQ;
+      goto out;
+   }
+
+   /*
+    * Wait for room in the produce queue to enqueue our user's data.
+    */
+   timeout = sock_sndtimeo(sk, msg->msg_flags & MSG_DONTWAIT);
+   compat_init_prepare_to_wait(sk->compat_sk_sleep, &wait, TASK_INTERRUPTIBLE);
+
+   while (totalWritten < len) {
+      Bool sentWrote;
+      unsigned int retries;
+      ssize_t written;
+
+      sentWrote = FALSE;
+      retries = 0;
+
+      while (VMCIQueue_FreeSpace(vsk->produceQ,
+                                 vsk->consumeQ, vsk->produceSize) == 0 &&
+             sk->compat_sk_err == 0 &&
+             !(sk->compat_sk_shutdown & SEND_SHUTDOWN) &&
+             !(vsk->peerShutdown & RCV_SHUTDOWN)) {
+
+         /* Don't wait for non-blocking sockets. */
+         if (timeout == 0) {
+            err = -EAGAIN;
+            goto outWait;
+         }
+
+         /* Notify our peer that we are waiting for room to write. */
+         if (!VSockVmciSendWaitingWrite(sk, 1)) {
+            err = -EHOSTUNREACH;
+            goto outWait;
+         }
+
+         release_sock(sk);
+         timeout = schedule_timeout(timeout);
+         lock_sock(sk);
+         if (signal_pending(current)) {
+            err = sock_intr_errno(timeout);
+            goto outWait;
+         } else if (timeout == 0) {
+            err = -EAGAIN;
+            goto outWait;
+         }
+
+         compat_cont_prepare_to_wait(sk->compat_sk_sleep,
+                                     &wait, TASK_INTERRUPTIBLE);
+      }
+
+      /*
+       * These checks occur both as part of and after the loop conditional
+       * since we need to check before and after sleeping.
+       */
+      if (sk->compat_sk_err) {
+         err = -sk->compat_sk_err;
+         goto outWait;
+      } else if ((sk->compat_sk_shutdown & SEND_SHUTDOWN) ||
+                 (vsk->peerShutdown & RCV_SHUTDOWN)) {
+         err = -EPIPE;
+         goto outWait;
+      }
+
+      /*
+       * Note that enqueue will only write as many bytes as are free in the
+       * produce queue, so we don't need to ensure len is smaller than the queue
+       * size.  It is the caller's responsibility to check how many bytes we were
+       * able to send.
+       */
+#if defined(VMX86_TOOLS) && defined(VSOCK_OPTIMIZATION_WAITING_NOTIFY)
+      VMCIQueue_GetPointers(vsk->produceQ, vsk->consumeQ,
+                            &produceTail, &consumeHead);
+#endif
+
+      written = VMCIQueue_EnqueueV(vsk->produceQ, vsk->consumeQ,
+                                   vsk->produceSize, msg->msg_iov,
+                                   len - totalWritten);
+      if (written < 0) {
+         err = -ENOMEM;
+         goto outWait;
+      }
+
+#if defined(VMX86_TOOLS) && defined(VSOCK_OPTIMIZATION_WAITING_NOTIFY)
+      /*
+       * Detect a wrap-around to maintain queue generation.  Note that this is
+       * safe since we hold the socket lock across the two queue pair
+       * operations.
+       */
+      if (written >= vsk->produceSize - produceTail) {
+         vsk->produceQGeneration++;
+      }
+#endif
+
+      totalWritten += written;
+
+      if (VSockVmciNotifyWaitingRead(vsk)) {
+         /*
+          * Notify the peer that we have written, retrying the send on failure up to
+          * our maximum value. See the XXX comment for the corresponding piece of
+          * code in StreamRecvmsg() for potential improvements.
+          */
+         while (!(vsk->peerShutdown & RCV_SHUTDOWN) &&
+                !sentWrote &&
+                retries < VSOCK_MAX_DGRAM_RESENDS) {
+            err = VSOCK_SEND_WROTE(sk);
+            if (err >= 0) {
+               sentWrote = TRUE;
+            }
+
+            retries++;
+         }
+
+         if (retries >= VSOCK_MAX_DGRAM_RESENDS) {
+            Warning("unable to send wrote notification to peer for socket %p.\n", sk);
+            goto outWait;
+         } else {
+#if defined(VMX86_TOOLS) && defined(VSOCK_OPTIMIZATION_WAITING_NOTIFY)
+            vsk->peerWaitingRead = FALSE;
+#endif
+         }
+      }
+   }
+
+   ASSERT(totalWritten <= INT_MAX);
+
+outWait:
+   if (totalWritten > 0) {
+      err = totalWritten;
+   }
+   compat_finish_wait(sk->compat_sk_sleep, &wait, TASK_RUNNING);
+out:
+   release_sock(sk);
+   return err;
+}
+#endif
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VSockVmciDgramRecvmsg --
+ *
+ *    Receives a datagram and places it in the caller's msg.
+ *
+ * Results:
+ *    The size of the payload on success, negative value on failure.
+ *
+ * Side effects:
+ *    None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 43)
+static int
+VSockVmciDgramRecvmsg(struct socket *sock,           // IN: socket to receive from
+                      struct msghdr *msg,            // IN/OUT: message to receive into
+                      int len,                       // IN: length of receive buffer
+                      int flags,                     // IN: receive flags
+                      struct scm_cookie *scm)        // UNUSED
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 65)
+static int
+VSockVmciDgramRecvmsg(struct kiocb *kiocb,          // UNUSED
+                      struct socket *sock,          // IN: socket to receive from
+                      struct msghdr *msg,           // IN/OUT: message to receive into
+                      int len,                      // IN: length of receive buffer
+                      int flags,                    // IN: receive flags
+                      struct scm_cookie *scm)       // UNUSED
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 2)
+static int
+VSockVmciDgramRecvmsg(struct kiocb *kiocb,          // UNUSED
+                      struct socket *sock,          // IN: socket to receive from
+                      struct msghdr *msg,           // IN/OUT: message to receive into
+                      int len,                      // IN: length of receive buffer
+                      int flags)                    // IN: receive flags
+#else
+static int
+VSockVmciDgramRecvmsg(struct kiocb *kiocb,          // UNUSED
+                      struct socket *sock,          // IN: socket to receive from
+                      struct msghdr *msg,           // IN/OUT: message to receive into
+                      size_t len,                   // IN: length of receive buffer
+                      int flags)                    // IN: receive flags
+#endif
+{
+   int err;
+   int noblock;
+   struct sock *sk;
+   VMCIDatagram *dg;
+   size_t payloadLen;
+   struct sk_buff *skb;
+   struct sockaddr_vm *vmciAddr;
+
+   err = 0;
+   sk = sock->sk;
+   payloadLen = 0;
+   noblock = flags & MSG_DONTWAIT;
+   vmciAddr = (struct sockaddr_vm *)msg->msg_name;
+
+   if (flags & MSG_OOB || flags & MSG_ERRQUEUE) {
+      return -EOPNOTSUPP;
+   }
+
+   /* Retrieve the head sk_buff from the socket's receive queue. */
+   skb = skb_recv_datagram(sk, flags, noblock, &err);
+   if (err) {
+      return err;
+   }
+
+   if (!skb) {
+      return -EAGAIN;
+   }
+
+   dg = (VMCIDatagram *)skb->data;
+   if (!dg) {
+      /* err is 0, meaning we read zero bytes. */
+      goto out;
+   }
+
+   payloadLen = dg->payloadSize;
+   /* Ensure the sk_buff matches the payload size claimed in the packet. */
+   if (payloadLen != skb->len - sizeof *dg) {
+      err = -EINVAL;
+      goto out;
+   }
+
+   if (payloadLen > len) {
+      payloadLen = len;
+      msg->msg_flags |= MSG_TRUNC;
+   }
+
+   /* Place the datagram payload in the user's iovec. */
+   err = skb_copy_datagram_iovec(skb, sizeof *dg, msg->msg_iov, payloadLen);
+   if (err) {
+      goto out;
+   }
+
+   msg->msg_namelen = 0;
+   if (vmciAddr) {
+      /* Provide the address of the sender. */
+      VSockAddr_Init(vmciAddr,
+                     VMCI_HANDLE_TO_CONTEXT_ID(dg->src),
+                     VMCI_HANDLE_TO_RESOURCE_ID(dg->src));
+      msg->msg_namelen = sizeof *vmciAddr;
+   }
+   err = payloadLen;
+
+out:
+   skb_free_datagram(sk, skb);
+   return err;
+}
+
+
+#ifdef VMX86_TOOLS
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VSockVmciStreamRecvmsg --
+ *
+ *    Receives a datagram and places it in the caller's msg.
+ *
+ * Results:
+ *    The size of the payload on success, negative value on failure.
+ *
+ * Side effects:
+ *    None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 43)
+static int
+VSockVmciStreamRecvmsg(struct socket *sock,           // IN: socket to receive from
+                       struct msghdr *msg,            // IN/OUT: message to receive into
+                       int len,                       // IN: length of receive buffer
+                       int flags,                     // IN: receive flags
+                       struct scm_cookie *scm)        // UNUSED
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 65)
+static int
+VSockVmciStreamRecvmsg(struct kiocb *kiocb,          // UNUSED
+                       struct socket *sock,          // IN: socket to receive from
+                       struct msghdr *msg,           // IN/OUT: message to receive into
+                       int len,                      // IN: length of receive buffer
+                       int flags,                    // IN: receive flags
+                       struct scm_cookie *scm)       // UNUSED
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 2)
+static int
+VSockVmciStreamRecvmsg(struct kiocb *kiocb,          // UNUSED
+                       struct socket *sock,          // IN: socket to receive from
+                       struct msghdr *msg,           // IN/OUT: message to receive into
+                       int len,                      // IN: length of receive buffer
+                       int flags)                    // IN: receive flags
+#else
+static int
+VSockVmciStreamRecvmsg(struct kiocb *kiocb,          // UNUSED
+                       struct socket *sock,          // IN: socket to receive from
+                       struct msghdr *msg,           // IN/OUT: message to receive into
+                       size_t len,                   // IN: length of receive buffer
+                       int flags)                    // IN: receive flags
+#endif
+{
+   struct sock *sk;
+   VSockVmciSock *vsk;
+   int err;
+   int target;
+   int64 ready;
+   long timeout;
+   ssize_t copied;
+   Bool sentRead;
+   unsigned int retries;
+#if defined(VMX86_TOOLS) && defined(VSOCK_OPTIMIZATION_WAITING_NOTIFY)
+   uint64 consumeHead;
+   uint64 produceTail;
+#ifdef VSOCK_OPTIMIZATION_FLOW_CONTROL
+   Bool notifyOnBlock;
+#endif
+#endif
+
+   COMPAT_DEFINE_WAIT(wait);
+
+   sk = sock->sk;
+   vsk = vsock_sk(sk);
+   err = 0;
+   retries = 0;
+   sentRead = FALSE;
+#ifdef VSOCK_OPTIMIZATION_FLOW_CONTROL
+   notifyOnBlock = FALSE;
+#endif
+
+   lock_sock(sk);
+
+   if (sk->compat_sk_state != SS_CONNECTED) {
+      err = -ENOTCONN;
+      goto out;
+   }
+
+   if (flags & MSG_OOB) {
+      err = -EOPNOTSUPP;
+      goto out;
+   }
+
+   if (sk->compat_sk_shutdown & RCV_SHUTDOWN) {
+      err = -EPIPE;
+      goto out;
+   }
+
+   /*
+    * We must not copy less than target bytes into the user's buffer before
+    * returning successfully, so we wait for the consume queue to have that
+    * much data to consume before dequeueing.  Note that this makes it
+    * impossible to handle cases where target is greater than the queue size.
+    */
+   target = sock_rcvlowat(sk, flags & MSG_WAITALL, len);
+   if (target >= vsk->consumeSize) {
+      err = -ENOMEM;
+      goto out;
+   }
+   timeout = sock_rcvtimeo(sk, flags & MSG_DONTWAIT);
+   copied = 0;
+
+#ifdef VSOCK_OPTIMIZATION_FLOW_CONTROL
+   if (vsk->writeNotifyMinWindow < target + 1) {
+      ASSERT(target < vsk->consumeSize);
+      vsk->writeNotifyMinWindow = target + 1;
+      if (vsk->writeNotifyWindow < vsk->writeNotifyMinWindow) {
+         /*
+          * If the current window is smaller than the new minimal
+          * window size, we need to reevaluate whether we need to
+          * notify the sender. If the number of ready bytes are
+          * smaller than the new window, we need to send a
+          * notification to the sender before we block.
+          */
+
+         vsk->writeNotifyWindow = vsk->writeNotifyMinWindow;
+         notifyOnBlock = TRUE;
+      }
+   }
+#endif
+
+   compat_init_prepare_to_wait(sk->compat_sk_sleep, &wait, TASK_INTERRUPTIBLE);
+
+   while ((ready = VMCIQueue_BufReady(vsk->consumeQ,
+                                      vsk->produceQ,
+                                      vsk->consumeSize)) < target &&
+          sk->compat_sk_err == 0 &&
+          !(sk->compat_sk_shutdown & RCV_SHUTDOWN) &&
+          !(vsk->peerShutdown & SEND_SHUTDOWN)) {
+
+      if (ready < 0) {
+         /* 
+          * Invalid queue pair content. XXX This should be changed to
+          * a connection reset in a later change.
+          */
+
+         err = -ENOMEM;
+         goto out;
+      }
+
+      /* Don't wait for non-blocking sockets. */
+      if (timeout == 0) {
+         err = -EAGAIN;
+         goto outWait;
+      }
+
+      /* Notify our peer that we are waiting for data to read. */
+      if (!VSockVmciSendWaitingRead(sk, target)) {
+         err = -EHOSTUNREACH;
+         goto outWait;
+      }
+
+#ifdef VSOCK_OPTIMIZATION_FLOW_CONTROL
+      if (notifyOnBlock) {
+         err = VSockVmciSendReadNotification(sk);
+         if (err < 0) {
+            goto outWait;
+         }
+         notifyOnBlock = FALSE;
+      }
+#endif
+
+      release_sock(sk);
+      timeout = schedule_timeout(timeout);
+      lock_sock(sk);
+
+      if (signal_pending(current)) {
+         err = sock_intr_errno(timeout);
+         goto outWait;
+      } else if (timeout == 0) {
+         err = -EAGAIN;
+         goto outWait;
+      }
+
+      compat_cont_prepare_to_wait(sk->compat_sk_sleep, &wait, TASK_INTERRUPTIBLE);
+   }
+
+   if (sk->compat_sk_err) {
+      err = -sk->compat_sk_err;
+      goto outWait;
+   } else if (sk->compat_sk_shutdown & RCV_SHUTDOWN) {
+      err = 0;
+      goto outWait;
+   } else if ((vsk->peerShutdown & SEND_SHUTDOWN) &&
+              VMCIQueue_BufReady(vsk->consumeQ,
+                                 vsk->produceQ, vsk->consumeSize) < target) {
+      err = -EPIPE;
+      goto outWait;
+   }
+
+   /*
+    * Now consume up to len bytes from the queue.  Note that since we have the
+    * socket locked we should copy at least ready bytes.
+    */
+#if defined(VMX86_TOOLS) && defined(VSOCK_OPTIMIZATION_WAITING_NOTIFY)
+   VMCIQueue_GetPointers(vsk->consumeQ, vsk->produceQ,
+                         &produceTail, &consumeHead);
+#endif
+
+   copied = VMCIQueue_DequeueV(vsk->produceQ, vsk->consumeQ,
+                               vsk->consumeSize, msg->msg_iov, len);
+   if (copied < 0) {
+      err = -ENOMEM;
+      goto outWait;
+   }
+
+#if defined(VMX86_TOOLS) && defined(VSOCK_OPTIMIZATION_WAITING_NOTIFY)
+   /*
+    * Detect a wrap-around to maintain queue generation.  Note that this is
+    * safe since we hold the socket lock across the two queue pair
+    * operations.
+    */
+   if (copied >= vsk->consumeSize - consumeHead) {
+      vsk->consumeQGeneration++;
+   }
+#endif
+
+   ASSERT(copied >= target);
+
+   /*
+    * If the other side has shutdown for sending and there is nothing more to
+    * read, then set our socket's RCV_SHUTDOWN flag and modify the socket
+    * state.
+    */
+   if (vsk->peerShutdown & SEND_SHUTDOWN) {
+      if (VMCIQueue_BufReady(vsk->consumeQ,
+                             vsk->produceQ, vsk->consumeSize) <= 0) {
+         sk->compat_sk_shutdown |= RCV_SHUTDOWN;
+         sk->compat_sk_state = SS_UNCONNECTED;
+         sk->compat_sk_state_change(sk);
+      }
+   }
+
+   err = VSockVmciSendReadNotification(sk);
+   if (err < 0) {
+      goto outWait;
+   }
+
+   ASSERT(copied <= INT_MAX);
+   err = copied;
+
+outWait:
+   compat_finish_wait(sk->compat_sk_sleep, &wait, TASK_RUNNING);
+out:
+   release_sock(sk);
+   return err;
+}
+#endif
+
+
+/*
+ * Protocol operation.
+ */
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VSockVmciCreate --
+ *
+ *    Creates a VSocket socket.
+ *
+ * Results:
+ *    Zero on success, negative error code on failure.
+ *
+ * Side effects:
+ *    Socket count is incremented.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 24)
+static int
+VSockVmciCreate(struct socket *sock,  // IN
+                int protocol)         // IN
+#else
+static int
+VSockVmciCreate(struct net *net,      // IN
+                struct socket *sock,  // IN
+                int protocol)         // IN
+#endif
+{
+   if (!sock) {
+      return -EINVAL;
+   }
+
+   if (protocol) {
+      return -EPROTONOSUPPORT;
+   }
+
+   switch (sock->type) {
+   case SOCK_DGRAM:
+      sock->ops = &vsockVmciDgramOps;
+      break;
+#  ifdef VMX86_TOOLS
+   /*
+    * Queue pairs are /currently/ only supported within guests, so stream
+    * sockets are only supported within guests.
+    */
+   case SOCK_STREAM:
+      sock->ops = &vsockVmciStreamOps;
+      break;
+#  endif
+   default:
+      return -ESOCKTNOSUPPORT;
+   }
+
+   sock->state = SS_UNCONNECTED;
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 24)
+   return __VSockVmciCreate(sock, GFP_KERNEL) ? 0 : -ENOMEM;
+#else
+   return __VSockVmciCreate(net, sock, GFP_KERNEL) ? 0 : -ENOMEM;
+#endif
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VSockVmciIoctl32Handler --
+ *
+ *      Handler for 32-bit ioctl(2) on 64-bit.
+ *
+ * Results:
+ *      Same as VsockVmciDevIoctl().
+ *
+ * Side effects:
+ *      None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+#ifdef VM_X86_64
+#ifndef HAVE_COMPAT_IOCTL
+static int
+VSockVmciIoctl32Handler(unsigned int fd,        // IN
+                        unsigned int iocmd,     // IN
+                        unsigned long ioarg,    // IN/OUT
+                        struct file * filp)     // IN
+{
+   int ret;
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 26) || \
+   (LINUX_VERSION_CODE >= KERNEL_VERSION(2, 5, 0) && LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 3))
+   lock_kernel();
+#endif
+   ret = -ENOTTY;
+   if (filp && filp->f_op && filp->f_op->ioctl == VSockVmciDevIoctl) {
+      ret = VSockVmciDevIoctl(filp->f_dentry->d_inode, filp, iocmd, ioarg);
+   }
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 26) || \
+   (LINUX_VERSION_CODE >= KERNEL_VERSION(2, 5, 0) && LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 3))
+   unlock_kernel();
+#endif
+   return ret;
+}
+#endif /* !HAVE_COMPAT_IOCTL */
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * register_ioctl32_handlers --
+ *
+ *      Registers the ioctl conversion handler.
+ *
+ * Results:
+ *      Zero on success, error code otherwise.
+ *
+ * Side effects:
+ *      None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+static int
+register_ioctl32_handlers(void)
+{
+#ifndef HAVE_COMPAT_IOCTL
+   {
+      int i;
+      for (i = IOCTL_VMCI_SOCKETS_FIRST; i < IOCTL_VMCI_SOCKETS_LAST; i++) {
+         int retval = register_ioctl32_conversion(i, VSockVmciIoctl32Handler);
+         if (retval) {
+            Warning("Fail to register ioctl32 conversion for cmd %d\n", i);
+            return retval;
+         }
+      }
+   }
+#endif /* !HAVE_COMPAT_IOCTL */
+   return 0;
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * unregister_ioctl32_handlers --
+ *
+ *      Unregisters the ioctl converstion handler.
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+static void
+unregister_ioctl32_handlers(void)
+{
+#ifndef HAVE_COMPAT_IOCTL
+   {
+      int i;
+      for (i = IOCTL_VMCI_SOCKETS_FIRST; i < IOCTL_VMCI_SOCKETS_LAST; i++) {
+         int retval = unregister_ioctl32_conversion(i);
+         if (retval) {
+            Warning("Fail to unregister ioctl32 conversion for cmd %d\n", i);
+         }
+      }
+   }
+#endif /* !HAVE_COMPAT_IOCTL */
+}
+#else /* VM_X86_64 */
+#define register_ioctl32_handlers() (0)
+#define unregister_ioctl32_handlers() do { } while (0)
+#endif /* VM_X86_64 */
+
+
+/*
+ * Device operations.
+ */
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VSockVmciDevOpen --
+ *
+ *      Invoked when the device is opened.  Simply maintains a count of open
+ *      instances.
+ *
+ * Results:
+ *      Zero on success, negative value otherwise.
+ *
+ * Side effects:
+ *      None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+int
+VSockVmciDevOpen(struct inode *inode,  // IN
+                 struct file *file)    // IN
+{
+   down(&registrationMutex);
+   devOpenCount++;
+   up(&registrationMutex);
+   return 0;
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VSockVmciDevRelease --
+ *
+ *      Invoked when the device is closed.  Updates the open instance count and
+ *      unregisters the socket family if this is the last user.
+ *
+ * Results:
+ *      Zero on success, negative value otherwise.
+ *
+ * Side effects:
+ *      None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+int
+VSockVmciDevRelease(struct inode *inode,  // IN
+                    struct file *file)    // IN
+{
+   down(&registrationMutex);
+   devOpenCount--;
+   VSockVmciTestUnregister();
+   up(&registrationMutex);
+   return 0;
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VSockVmciDevIoctl --
+ *
+ *      ioctl(2) handler.
+ *
+ * Results:
+ *      Zero on success, negative error code otherwise.
+ *
+ * Side effects:
+ *      None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+static int
+VSockVmciDevIoctl(struct inode *inode,     // IN
+                  struct file *filp,       // IN
+                  u_int iocmd,             // IN
+                  unsigned long ioarg)     // IN/OUT
+{
+   int retval;
+
+   retval = 0;
+
+   switch (iocmd) {
+   case IOCTL_VMCI_SOCKETS_GET_AF_VALUE: {
+      int family;
+
+      family = VSockVmci_GetAFValue();
+      if (family < 0) {
+         Warning("AF_VSOCK is not registered\n");
+      }
+      if (copy_to_user((void *)ioarg, &family, sizeof family) != 0) {
+         retval = -EFAULT;
+      }
+      break;
+   }
+
+   case IOCTL_VMCI_SOCKETS_GET_LOCAL_CID: {
+      VMCIId cid = VMCI_GetContextID();
+      if (copy_to_user((void *)ioarg, &cid, sizeof cid) != 0) {
+         retval = -EFAULT;
+      }
+      break;
+   }
+
+   default:
+      Warning("Unknown ioctl %d\n", iocmd);
+      retval = -EINVAL;
+   }
+
+   return retval;
+}
+
+
+#if defined(HAVE_COMPAT_IOCTL) || defined(HAVE_UNLOCKED_IOCTL)
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VSockVmciDevUnlockedIoctl --
+ *
+ *      Wrapper for VSockVmciDevIoctl() supporting the compat_ioctl and
+ *      unlocked_ioctl methods that have signatures different from the
+ *      old ioctl. Used as compat_ioctl method for 32bit apps running
+ *      on 64bit kernel and for unlocked_ioctl on systems supporting
+ *      those.  VSockVmciDevIoctl() may safely be called without holding
+ *      the BKL.
+ *
+ * Results:
+ *      Same as VSockVmciDevIoctl().
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static long
+VSockVmciDevUnlockedIoctl(struct file *filp,       // IN
+                          u_int iocmd,             // IN
+                          unsigned long ioarg)     // IN/OUT
+{
+   return VSockVmciDevIoctl(NULL, filp, iocmd, ioarg);
+}
+#endif
+
+/*
+ * Module operations.
+ */
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VSockVmciInit --
+ *
+ *    Initialization routine for the VSockets module.
+ *
+ * Results:
+ *    Zero on success, error code on failure.
+ *
+ * Side effects:
+ *    The VSocket protocol family and socket operations are registered.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+static int __init
+VSockVmciInit(void)
+{
+   int err;
+
+   DriverLog_Init("VSock");
+
+   request_module("vmci");
+
+   err = misc_register(&vsockVmciDevice);
+   if (err) {
+      return -ENOENT;
+   }
+
+   err = register_ioctl32_handlers();
+   if (err) {
+      misc_deregister(&vsockVmciDevice);
+      return err;
+   }
+
+   err = VSockVmciRegisterProto();
+   if (err) {
+      Warning("Cannot register vsock protocol.\n");
+      unregister_ioctl32_handlers();
+      misc_deregister(&vsockVmciDevice);
+      return err;
+   }
+
+   VSockVmciInitTables();
+   return 0;
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VSocketVmciExit --
+ *
+ *    VSockets module exit routine.
+ *
+ * Results:
+ *    None.
+ *
+ * Side effects:
+ *    Unregisters VSocket protocol family and socket operations.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+static void __exit
+VSockVmciExit(void)
+{
+   unregister_ioctl32_handlers();
+   misc_deregister(&vsockVmciDevice);
+   down(&registrationMutex);
+   VSockVmciUnregisterAddressFamily();
+   up(&registrationMutex);
+
+   VSockVmciUnregisterProto();
+}
+
+
+module_init(VSockVmciInit);
+module_exit(VSockVmciExit);
+
+MODULE_AUTHOR("VMware, Inc.");
+MODULE_DESCRIPTION("VMware Virtual Socket Family");
+MODULE_VERSION(VSOCK_DRIVER_VERSION_STRING);
+MODULE_LICENSE("GPL v2");
--- kernel/linux-2.6.26.3/drivers/misc/vsock/af_vsock.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vsock/af_vsock.h	2008-09-03 09:57:34.000000000 -0500
@@ -0,0 +1,91 @@
+/*********************************************************
+ * Copyright (C) 2007 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+
+/*
+ * af_vsock.h --
+ *
+ *      Definitions for Linux VSockets module.
+ */
+
+#ifndef __AF_VSOCK_H__
+#define __AF_VSOCK_H__
+
+#include "vsockCommon.h"
+#include "vsockPacket.h"
+#include "compat_workqueue.h"
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 5)
+# define vsock_sk(__sk)    ((VSockVmciSock *)(__sk)->user_data)
+# define sk_vsock(__vsk)   ((__vsk)->sk)
+#else
+# define vsock_sk(__sk)    ((VSockVmciSock *)__sk)
+# define sk_vsock(__vsk)   (&(__vsk)->sk)
+#endif
+
+typedef struct VSockVmciSock {
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 5)
+   struct sock *sk;
+#else
+   /* sk must be the first member. */
+   struct sock  sk;
+#endif
+   struct sockaddr_vm localAddr;
+   struct sockaddr_vm remoteAddr;
+   /* Links for the global tables of bound and connected sockets. */
+   struct list_head boundTable;
+   struct list_head connectedTable;
+   VMCIHandle dgHandle;           /* For SOCK_DGRAM only. */
+#ifdef VMX86_TOOLS
+   /* Rest are SOCK_STREAM only. */
+   VMCIHandle qpHandle;
+   VMCIQueue *produceQ;
+   VMCIQueue *consumeQ;
+   uint64 produceQGeneration;
+   uint64 consumeQGeneration;
+   uint64 produceSize;
+   uint64 consumeSize;
+   uint64 queuePairSize;
+   uint64 queuePairMinSize;
+   uint64 queuePairMaxSize;
+   Bool peerWaitingRead;
+   Bool peerWaitingWrite;
+   VSockWaitingInfo peerWaitingReadInfo;
+   VSockWaitingInfo peerWaitingWriteInfo;
+   VMCIId attachSubId;
+   VMCIId detachSubId;
+   /* Listening socket that this came from. */
+   struct sock *listener;
+   /*
+    * Used for pending list and accept queue during connection handshake.  The
+    * listening socket is the head for both lists.  Sockets created for
+    * connection requests are placed in the pending list until they are
+    * connected, at which point they are put in the accept queue list so they
+    * can be accepted in accept().  If accept() cannot accept the connection,
+    * it is marked as rejected so the cleanup function knows to clean up the
+    * socket.
+    */
+   struct list_head pendingLinks;
+   struct list_head acceptQueue;
+   Bool rejected;
+   compat_delayed_work dwork;
+   uint32 peerShutdown;
+#endif
+} VSockVmciSock;
+
+#endif /* __AF_VSOCK_H__ */
--- kernel/linux-2.6.26.3/drivers/misc/vsock/circList.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vsock/circList.h	2008-09-03 10:03:35.000000000 -0500
@@ -0,0 +1,427 @@
+/*********************************************************
+ * Copyright (C) 1998 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ *   circList.h --
+ *
+ * macros, prototypes and struct definitions for double-linked
+ * circular lists.
+ */
+
+#ifndef _CIRCLIST_H_
+#define _CIRCLIST_H_
+
+#define INCLUDE_ALLOW_USERLEVEL
+#define INCLUDE_ALLOW_VMMON
+#define INCLUDE_ALLOW_VMCORE
+#define INCLUDE_ALLOW_MODULE
+#define INCLUDE_ALLOW_VMKERNEL
+#include "vmware.h"
+
+typedef struct ListItem {
+   struct ListItem *prev;
+   struct ListItem *next;
+} ListItem;
+
+/* A list with no elements is a null pointer. */
+#define   LIST_ITEM_DEF(name)   \
+   ListItem * name = NULL
+
+#define   LIST_EMPTY(l)      ((l) == NULL)
+
+/* initialize list item */
+#define   INIT_LIST_ITEM(p)   \
+   do {   \
+      (p)->prev = (p)->next = (p);   \
+   } while (0)
+
+/* check if initialized */
+#define   IS_LIST_ITEM_INITIALIZED(li)   \
+   (((li) == (li)->prev) && ((li) == (li)->next))
+
+/* return first element in the list */
+#define   LIST_FIRST(l)      (l)
+#define   LIST_FIRST_CHK(l)   (l)
+
+/* return last element in the list */
+#define   LIST_LAST(l)      ((l)->prev)
+#define   LIST_LAST_CHK(l)   (LIST_EMPTY(l) ? NULL : LIST_LAST(l))
+
+/*
+ * LIST_CONTAINER - get the struct for this entry (like list_entry)
+ * @ptr: the &struct ListItem pointer.
+ * @type:   the type of the struct this is embedded in.
+ * @member: the name of the list struct within the struct.
+ */
+#define LIST_CONTAINER(ptr, type, member) \
+   ((type *)((char *)(ptr) - offsetof(type, member)))
+
+/*
+ * delete item from the list
+ */
+#define   LIST_DEL            DelListItem   
+
+/*
+ * link two lists together
+ */
+#define   LIST_SPLICE         SpliceLists
+
+/*
+ * Split a list into two lists
+ */
+#define   LIST_SPLIT          SplitLists
+
+/*
+ * Add item to front of stack. List pointer points to new head.
+ */
+#define   LIST_PUSH           PushListItem
+
+/*
+ * Add item at back of queue. List pointer only changes if list was empty.
+ */
+#define   LIST_QUEUE          QueueListItem
+
+/*
+ * Get the list size.
+ */
+#define   LIST_SIZE  	      GetListSize
+
+/*
+ * LIST_SCAN_FROM scans the list from "from" up until "until".
+ * The loop variable p should not be destroyed in the process.
+ * "from" is an element in the list where to start scanning.
+ * "until" is the element where search should stop.
+ * member is the field to use for the search - either "next" or "prev".
+ */
+#define   LIST_SCAN_FROM(p, from, until, member)   \
+   for (p = (from); (p) != NULL;   \
+      (p) = (((p)->member == (until)) ? NULL : (p)->member))
+
+/* scan the entire list (non-destructively) */ 
+#define   LIST_SCAN(p, l)   \
+   LIST_SCAN_FROM(p, LIST_FIRST(l), LIST_FIRST(l), next)
+
+
+/* scan a list backward from last element to first (non-destructively) */
+#define   LIST_SCAN_BACK(p, l)   \
+   LIST_SCAN_FROM(p, LIST_LAST_CHK(l), LIST_LAST(l), prev)
+
+/* scan the entire list where loop element may be destroyed */
+#define   LIST_SCAN_SAFE(p, pn, l)   \
+   if (!LIST_EMPTY(l))  \
+      for (p = (l), (pn) = NextListItem(p, l); (p) != NULL;   \
+           (p) = (pn), (pn) = NextListItem(p, l))
+
+/* scan the entire list backwards where loop element may be destroyed */
+#define   LIST_SCAN_BACK_SAFE(p, pn, l)   \
+   if (!LIST_EMPTY(l))  \
+      for (p = LIST_LAST(l), (pn) = PrevListItem(p, l); (p) != NULL;   \
+           (p) = (pn), (pn) = PrevListItem(p, l))
+
+
+/* function definitions */
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * NextListItem --
+ *
+ *      Returns the next member of a doubly linked list, or NULL if last.
+ *      Assumes: p is member of the list headed by head.
+ *
+ * Result
+ *      If head or p is NULL, return NULL. Otherwise,
+ *      next list member (or null if last).
+ *
+ * Side effects:
+ *      None.
+ *
+ *----------------------------------------------------------------------
+ */
+
+static INLINE ListItem *
+NextListItem(ListItem *p,        // IN
+             ListItem *head)     // IN
+{
+   if (head == NULL || p == NULL) {
+      return NULL;
+   }
+   /* both p and head are non-null */
+   p = p->next;
+   return p == head ? NULL : p;
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * PrevListItem --
+ *
+ *      Returns the prev member of a doubly linked list, or NULL if first.
+ *      Assumes: p is member of the list headed by head.
+ *
+ * Result
+ *      If head or prev is NULL, return NULL. Otherwise,
+ *      prev list member (or null if first).
+ *
+ * Side effects:
+ *      None.
+ *
+ *----------------------------------------------------------------------
+ */
+
+static INLINE ListItem *
+PrevListItem(ListItem *p,        // IN
+             ListItem *head)     // IN
+{
+   if (head == NULL || p == NULL) {
+      return NULL;
+   }
+   /* both p and head are non-null */
+   return p == head ? NULL : p->prev;
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * DelListItem --
+ *
+ *      Deletes a member of a doubly linked list, possibly modifies the
+ *      list header itself.
+ *      Assumes neither p nor headp is null and p is a member of *headp.
+ *
+ * Result
+ *      None
+ *
+ * Side effects:
+ *      Modifies *headp.
+ *
+ *----------------------------------------------------------------------
+ */
+
+static INLINE void
+DelListItem(ListItem *p,         // IN
+            ListItem **headp)    // IN/OUT
+{
+   ListItem *next;
+
+   ASSERT(p);
+   ASSERT(headp);
+
+   next = p->next;
+   if (p == next) {
+      *headp = NULL;
+   } else {
+      next->prev = p->prev;
+      p->prev->next = next;
+      if (*headp == p) {
+         *headp = next;
+      }
+   }
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * QueueListItem --
+ *
+ *      Adds a new member to the back of a doubly linked list (queue)
+ *      Assumes neither p nor headp is null and p is not a member of *headp.
+ *
+ * Result
+ *      None
+ *
+ * Side effects:
+ *      Modifies *headp.
+ *
+ *----------------------------------------------------------------------
+ */
+
+static INLINE void
+QueueListItem(ListItem *p,              // IN
+              ListItem **headp)         // IN/OUT
+{
+   ListItem *head;
+
+   head = *headp;
+   if (LIST_EMPTY(head)) {
+      INIT_LIST_ITEM(p);
+      *headp = p;
+   } else {
+      p->prev = head->prev;
+      p->next = head;
+      p->prev->next = p;
+      head->prev = p;
+   }
+}
+                                                                                
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * PushListItem --
+ *
+ *      Adds a new member to the front of a doubly linked list (stack)
+ *      Assumes neither p nor headp is null and p is not a member of *headp.
+ *
+ * Result
+ *      None
+ *
+ * Side effects:
+ *      Modifies *headp.
+ *
+ *----------------------------------------------------------------------
+ */
+
+static INLINE void
+PushListItem(ListItem *p,               // IN
+             ListItem **headp)          // IN/OUT
+{
+   QueueListItem(p, headp);
+   *headp = p;
+}
+ 
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * SpliceLists --
+ *
+ *      Make a single list {l1 l2} from {l1} and {l2} and return it.
+ *      It is okay for one or both lists to be NULL.
+ *      No checking is done. It is assumed that l1 and l2 are two
+ *      distinct lists.
+ *
+ * Result
+ *      A list { l1 l2 }.
+ *
+ * Side effects:
+ *      Modifies l1 and l2 list pointers.
+ *
+ *----------------------------------------------------------------------
+ */
+
+static INLINE ListItem *
+SpliceLists(ListItem *l1,      // IN
+            ListItem *l2)      // IN
+{
+   ListItem *l1Last, *l2Last;
+
+   if (LIST_EMPTY(l1)) {
+      return l2;
+   }
+
+   if (LIST_EMPTY(l2)) {
+      return l1;
+   }
+
+   l1Last = l1->prev;   /* last elem of l1 */
+   l2Last = l2->prev;   /* last elem of l2 */
+
+   /*
+    *    l1 -> ... -> l1Last    l2 -> ... l2Last
+    */
+   l1Last->next = l2;
+   l2->prev = l1Last;
+
+   l1->prev = l2Last;
+   l2Last->next = l1;
+
+   return l1;
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * SplitLists --
+ *
+ *      Make a list l = {l1 l2} into two separate lists {l1} and {l2}, where:
+ *      l = { ... x -> p -> ... } split into:
+ *      l1 = { ... -> x }
+ *      l2 = { p -> ... } 
+ *      Assumes neither p nor l is null and p is a member of l.
+ *      If p is the first element of l, then l1 will be NULL.
+ *
+ * Result
+ *      None.
+ *
+ * Side effects:
+ *      Sets *l1p and *l2p to the resulting two lists.
+ *      Modifies l's pointers.
+ *
+ *----------------------------------------------------------------------
+ */
+
+static INLINE void
+SplitLists(ListItem *p,         // IN
+           ListItem *l,         // IN
+           ListItem **l1p,      // OUT
+           ListItem **l2p)      // OUT
+{
+   ListItem *last;
+
+   if (p == LIST_FIRST(l)) {   /* first element */
+      *l1p = NULL;
+      *l2p = l;
+      return;
+   }
+
+   last = l->prev;
+
+   *l1p = l;
+   p->prev->next = l;
+   l->prev = p->prev;
+
+   *l2p = p;
+   p->prev = last;
+   last->next = p;
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * GetListSize --
+ *
+ *	Return the number of items in the list.
+ *
+ * Result:
+ *	The number of items in the list.
+ *
+ * Side effects:
+ *	None.
+ *
+ *----------------------------------------------------------------------
+ */
+
+static INLINE int
+GetListSize(ListItem *head) 	// IN
+{
+   ListItem *li;
+   int ret = 0;
+
+   LIST_SCAN(li, head) {
+      ret++;
+   }
+   return ret;
+}
+
+#endif /* _CIRCLIST_H_ */
--- kernel/linux-2.6.26.3/drivers/misc/vsock/compat_completion.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vsock/compat_completion.h	2008-09-03 10:02:58.000000000 -0500
@@ -0,0 +1,175 @@
+/*********************************************************
+ * Copyright (C) 2004 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_COMPLETION_H__
+#   define __COMPAT_COMPLETION_H__
+
+/*
+ * The kernel's completion objects were made available for module use in 2.4.9.
+ * 
+ * Between 2.4.0 and 2.4.9, we implement completions on our own using 
+ * waitqueues and counters. This was done so that we could safely support
+ * functions like complete_all(), which cannot be implemented using semaphores.
+ *
+ * Prior to that, the waitqueue API is substantially different, and since none 
+ * of our modules that are built against older kernels need complete_all(), 
+ * we fallback on a simple semaphore-based implementation. 
+ */
+
+/* 
+ * Native completions.
+ */ 
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 4, 9)
+
+#include <linux/completion.h>
+#define compat_completion struct completion
+#define compat_init_completion(comp) init_completion(comp)
+#define COMPAT_DECLARE_COMPLETION DECLARE_COMPLETION
+#define compat_wait_for_completion(comp) wait_for_completion(comp)
+#define compat_complete(comp) complete(comp)
+
+/* complete_all() was exported in 2.6.6. */
+# if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 6)
+#  include "compat_wait.h"
+#  include "compat_list.h"
+#  include "compat_spinlock.h"
+#  include "compat_sched.h"
+#  define compat_complete_all(x)         \
+      ({                                 \
+          struct list_head *currLinks;   \
+          spin_lock(&(x)->wait.lock);    \
+          (x)->done += UINT_MAX/2;       \
+                                         \
+          list_for_each(currLinks, &(x)->wait.task_list) { \
+             wait_queue_t *currQueue = list_entry(currLinks, wait_queue_t, task_list); \
+             wake_up_process(currQueue->task); \
+          }                              \
+          spin_unlock(&(x)->wait.lock);  \
+      })
+# else
+#  define compat_complete_all complete_all
+# endif
+
+/* 
+ * Completions via waitqueues.
+ */
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(2, 4, 0)
+
+/*
+ * Kernel completions in 2.4.9 and beyond use a counter and a waitqueue, and 
+ * our implementation is quite similar. Because __wake_up_common() is not 
+ * exported, our implementations of compat_complete() and compat_complete_all()
+ * are somewhat racy: the counter is incremented outside of the waitqueue's 
+ * lock. 
+ *
+ * As a result, our completion cannot guarantee in-order wake ups. For example,
+ * suppose thread A is entering compat_complete(), thread B is sleeping inside
+ * compat_wait_for_completion(), and thread C is just now entering
+ * compat_wait_for_completion(). If Thread A is scheduled first and increments 
+ * the counter, then gets swapped out, thread C may get scheduled and will 
+ * quickly go through compat_wait_for_completion() (since done != 0) while 
+ * thread B continues to sleep, even though thread B should have been the one 
+ * to wake up.
+ */
+
+#include <asm/current.h>
+#include "compat_sched.h"
+#include "compat_list.h"
+#include <linux/smp_lock.h> // for lock_kernel()/unlock_kernel()
+#include "compat_wait.h"
+
+typedef struct compat_completion {
+   unsigned int done;
+   wait_queue_head_t wq;
+} compat_completion;
+
+#define compat_init_completion(comp) do { \
+   (comp)->done = 0; \
+   init_waitqueue_head(&(comp)->wq); \
+} while (0)
+#define COMPAT_DECLARE_COMPLETION(comp) \
+   compat_completion comp = { \
+     .done = 0, \
+     .wq = __WAIT_QUEUE_HEAD_INITIALIZER((comp).wq), \
+   }
+
+/*
+ * Locking and unlocking the kernel lock here ensures that the thread
+ * is no longer running in module code: compat_complete_and_exit
+ * performs the sequence { lock_kernel(); up(comp); compat_exit(); }, with
+ * the final unlock_kernel performed implicitly by the resident kernel
+ * in do_exit.
+ */
+#define compat_wait_for_completion(comp) do { \
+   spin_lock_irq(&(comp)->wq.lock); \
+   if (!(comp)->done) { \
+      DECLARE_WAITQUEUE(wait, current); \
+      wait.flags |= WQ_FLAG_EXCLUSIVE; \
+      __add_wait_queue_tail(&(comp)->wq, &wait); \
+      do { \
+         __set_current_state(TASK_UNINTERRUPTIBLE); \
+         spin_unlock_irq(&(comp)->wq.lock); \
+         schedule(); \
+         spin_lock_irq(&(comp)->wq.lock); \
+      } while (!(comp)->done); \
+      __remove_wait_queue(&(comp)->wq, &wait); \
+   } \
+   (comp)->done--; \
+   spin_unlock_irq(&(comp)->wq.lock); \
+   lock_kernel(); \
+   unlock_kernel(); \
+} while (0)
+
+/* XXX: I don't think I need to touch the BKL. */
+#define compat_complete(comp) do { \
+   unsigned long flags; \
+   spin_lock_irqsave(&(comp)->wq.lock, flags); \
+   (comp)->done++; \
+   spin_unlock_irqrestore(&(comp)->wq.lock, flags); \
+   wake_up(&(comp)->wq); \
+} while (0)
+
+#define compat_complete_all(comp) do { \
+   unsigned long flags; \
+   spin_lock_irqsave(&(comp)->wq.lock, flags); \
+   (comp)->done += UINT_MAX / 2; \
+   spin_unlock_irqrestore(&(comp)->wq.lock, flags); \
+   wake_up_all(&(comp)->wq); \
+} while (0)
+
+/*
+ * Completions via semaphores.
+ */ 
+#else
+
+#include "compat_semaphore.h"
+#define compat_completion struct semaphore 
+#define compat_init_completion(comp) init_MUTEX_LOCKED(comp)
+#define COMPAT_DECLARE_COMPLETION(comp) DECLARE_MUTEX_LOCKED(comp) 
+
+#define compat_wait_for_completion(comp) do { \
+   down(comp); \
+   lock_kernel(); \
+   unlock_kernel(); \
+} while (0)
+
+#define compat_complete(comp) up(comp)
+
+#endif
+
+#endif /* __COMPAT_COMPLETION_H__ */
--- kernel/linux-2.6.26.3/drivers/misc/vsock/compat_file.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vsock/compat_file.h	2008-09-03 10:02:58.000000000 -0500
@@ -0,0 +1,56 @@
+/*********************************************************
+ * Copyright (C) 2002 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_FILE_H__
+#   define __COMPAT_FILE_H__
+
+
+/* The fput() API is modified in 2.2.0 --hpreg */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 2, 0)
+#   define compat_fput(_file) fput(_file)
+#else
+#   define compat_fput(_file) fput(_file, (_file)->f_inode)
+#endif
+
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 4, 0)
+#   define compat_get_file(_file) get_file(_file)
+#   define compat_file_count(_file) file_count(_file)
+#else
+#   define compat_get_file(_file) (_file)->f_count++
+#   define compat_file_count(_file) (_file)->f_count
+#endif
+
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 2, 4)
+#   define compat_filp_close(_file, _files) filp_close(_file, _files)
+#else
+static inline void compat_filp_close(struct file* filp, fl_owner_t files) {
+   if (filp->f_op && filp->f_op->flush) {
+      filp->f_op->flush(filp);
+   }
+   /*
+    * Hopefully there are no locks to release on this filp. 
+    * locks_remove_posix is not exported so we cannot use it...
+    */
+   fput(filp);
+}
+#endif
+
+
+#endif /* __COMPAT_FILE_H__ */
--- kernel/linux-2.6.26.3/drivers/misc/vsock/compat_fs.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vsock/compat_fs.h	2008-09-03 10:02:58.000000000 -0500
@@ -0,0 +1,247 @@
+/*********************************************************
+ * Copyright (C) 2006 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_FS_H__
+#   define __COMPAT_FS_H__
+
+#include <linux/fs.h>
+
+/*
+ * 2.6.5+ kernels define FS_BINARY_MOUNTDATA. Since it didn't exist and
+ * wasn't used prior, it's safe to define it to zero.
+ */
+
+#ifndef FS_BINARY_MOUNTDATA
+#define FS_BINARY_MOUNTDATA 0
+#endif
+
+/*
+ * MAX_LFS_FILESIZE wasn't defined until 2.5.4.
+ */
+#ifndef MAX_LFS_FILESIZE
+#   include <linux/pagemap.h>
+#   if BITS_PER_LONG == 32
+#      define MAX_LFS_FILESIZE       (((u64)PAGE_CACHE_SIZE << (BITS_PER_LONG - 1)) - 1)
+#   elif BITS_PER_LONG == 64
+#      define MAX_LFS_FILESIZE       0x7fffffffffffffffUL
+#   endif
+#endif
+
+
+/*
+ * sendfile as a VFS op was born in 2.5.30. Unfortunately, it also changed
+ * signatures, first in 2.5.47, then again in 2.5.70, then again in 2.6.8.
+ * Luckily, the 2.6.8+ signature is the same as the 2.5.47 signature.  And
+ * as of 2.6.23-rc1 sendfile is gone, replaced by splice_read...
+ *
+ * Let's not support sendfile from 2.5.30 to 2.5.47, because the 2.5.30
+ * signature is much different and file_send_actor isn't externed.
+ */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 23)
+#define VMW_SENDFILE_NONE
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 8)
+#define VMW_SENDFILE_NEW
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(2, 5, 70)
+#define VMW_SENDFILE_OLD
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(2, 5, 47)
+#define VMW_SENDFILE_NEW
+#else
+#define VMW_SENDFILE_NONE
+#endif
+
+/*
+ * splice_read is there since 2.6.17, but let's avoid 2.6.17-rcX kernels...
+ * After all nobody is using splice system call until 2.6.23 using it to
+ * implement sendfile.
+ */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 18)
+#define VMW_SPLICE_READ 1
+#endif
+
+/*
+ * Filesystems wishing to use generic page cache read/write routines are
+ * supposed to implement aio_read and aio_write (calling into
+ * generic_file_aio_read() and generic_file_aio_write() if necessary).
+ *
+ * The VFS exports do_sync_read() and do_sync_write() as the "new"
+ * generic_file_read() and generic_file_write(), but filesystems need not
+ * actually implement read and write- the VFS will automatically call
+ * do_sync_write() and do_sync_read() when applications invoke the standard
+ * read() and write() system calls.
+ *
+ * In 2.6.19, generic_file_read() and generic_file_write() were removed,
+ * necessitating this change. AIO dates as far back as 2.5.42, but the API has
+ * changed over time, so for simplicity, we'll only enable it from 2.6.19 and
+ * on.
+ */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 19)
+# define VMW_USE_AIO
+#endif
+
+
+/*
+ * The alloc_inode and destroy_inode VFS ops didn't exist prior to 2.4.21.
+ * Without these functions, file systems can't embed inodes.
+ */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 4, 21)
+# define VMW_EMBED_INODE
+#endif
+
+
+/*
+ * iget() was removed from the VFS as of 2.6.25-rc1. The replacement for iget()
+ * is iget_locked() which was added in 2.5.17.
+ */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 5, 17)
+# define VMW_USE_IGET_LOCKED
+#endif
+
+/*
+ * parent_ino was born in 2.5.5. For older kernels, let's use 2.5.5
+ * implementation. It uses the dcache lock which is OK because per-dentry
+ * locking appeared after 2.5.5.
+ */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 5, 5)
+#define compat_parent_ino(dentry) parent_ino(dentry)
+#else
+#define compat_parent_ino(dentry)                                             \
+({                                                                            \
+   ino_t res;                                                                 \
+   spin_lock(&dcache_lock);                                                   \
+   res = dentry->d_parent->d_inode->i_ino;                                    \
+   spin_unlock(&dcache_lock);                                                 \
+   res;                                                                       \
+})
+#endif
+
+
+/*
+ * putname changed to __putname in 2.6.6.
+ */
+#define compat___getname() __getname()
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 6)
+#define compat___putname(name) putname(name)
+#else
+#define compat___putname(name) __putname(name)
+#endif
+
+
+/*
+ * inc_nlink, drop_nlink, and clear_nlink were added in 2.6.19.
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 19)
+#define compat_inc_nlink(inode) ((inode)->i_nlink++)
+#define compat_drop_nlink(inode) ((inode)->i_nlink--)
+#define compat_clear_nlink(inode) ((inode)->i_nlink = 0)
+#else
+#define compat_inc_nlink(inode) inc_nlink(inode)
+#define compat_drop_nlink(inode) drop_nlink(inode)
+#define compat_clear_nlink(inode) clear_nlink(inode)
+#endif
+
+
+/*
+ * i_size_write and i_size_read were introduced in 2.6.0-test1 
+ * (though we'll look for them as of 2.6.1). They employ slightly different
+ * locking in order to guarantee atomicity, depending on the length of a long,
+ * whether the kernel is SMP, or whether the kernel is preemptible. Prior to
+ * i_size_write and i_size_read, there was no such locking, so that's the
+ * behavior we'll emulate.
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 1)
+#define compat_i_size_read(inode) ((inode)->i_size)
+#define compat_i_size_write(inode, size) ((inode)->i_size = size)
+#else
+#define compat_i_size_read(inode) i_size_read(inode)
+#define compat_i_size_write(inode, size) i_size_write(inode, size)
+#endif
+
+
+/*
+ * filemap_fdatawrite was introduced in 2.5.12. Prior to that, modules used
+ * filemap_fdatasync instead. In 2.4.18, both filemap_fdatawrite and 
+ * filemap_fdatawait began returning status codes. Prior to that, they were 
+ * void functions, so we'll just have them return 0.
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 18)
+#define compat_filemap_fdatawrite(mapping)                                    \
+({                                                                            \
+   int result = 0;                                                            \
+   filemap_fdatasync(mapping);                                                \
+   result;                                                                    \
+})
+#define compat_filemap_fdatawait(mapping)                                     \
+({                                                                            \
+   int result = 0;                                                            \
+   filemap_fdatawait(mapping);                                                \
+   result;                                                                    \
+})
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 12)
+#define compat_filemap_fdatawrite(mapping) filemap_fdatasync(mapping)
+#define compat_filemap_fdatawait(mapping) filemap_fdatawait(mapping)
+#else
+#define compat_filemap_fdatawrite(mapping) filemap_fdatawrite(mapping)
+#define compat_filemap_fdatawait(mapping) filemap_fdatawait(mapping)
+#endif
+
+
+/*
+ * filemap_write_and_wait was introduced in 2.6.6 and exported for module use
+ * in 2.6.16. It's really just a simple wrapper around filemap_fdatawrite and 
+ * and filemap_fdatawait, which initiates a flush of all dirty pages, then 
+ * waits for the pages to flush. The implementation here is a simplified form 
+ * of the one found in 2.6.20-rc3.
+ *
+ * Unfortunately, it just isn't possible to implement this prior to 2.4.5, when
+ * neither filemap_fdatawait nor filemap_fdatasync were exported for module
+ * use. So we'll define it out and hope for the best.
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 5)
+#define compat_filemap_write_and_wait(mapping)
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 16)
+#define compat_filemap_write_and_wait(mapping)                                \
+({                                                                            \
+   int result = 0;                                                            \
+   if (mapping->nrpages) {                                                    \
+      result = compat_filemap_fdatawrite(mapping);                            \
+      if (result != -EIO) {                                                   \
+         int result2 = compat_filemap_fdatawait(mapping);                     \
+         if (!result) {                                                       \
+            result = result2;                                                 \
+         }                                                                    \
+      }                                                                       \
+   }                                                                          \
+   result;                                                                    \
+})
+#else
+#define compat_filemap_write_and_wait(mapping) filemap_write_and_wait(mapping)
+#endif
+
+
+/*
+ * invalidate_remote_inode was introduced in 2.6.0-test5. Prior to that, 
+ * filesystems wishing to invalidate pages belonging to an inode called 
+ * invalidate_inode_pages.
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 0)
+#define compat_invalidate_remote_inode(inode) invalidate_inode_pages(inode)
+#else
+#define compat_invalidate_remote_inode(inode) invalidate_remote_inode(inode)
+#endif
+
+#endif /* __COMPAT_FS_H__ */
--- kernel/linux-2.6.26.3/drivers/misc/vsock/compat_init.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vsock/compat_init.h	2008-09-03 10:02:58.000000000 -0500
@@ -0,0 +1,38 @@
+/*********************************************************
+ * Copyright (C) 1999 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * compat_init.h: Initialization compatibility wrappers.
+ */
+
+#ifndef __COMPAT_INIT_H__
+#define __COMPAT_INIT_H__
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 2, 0)
+#include <linux/init.h>
+#endif
+
+#ifndef module_init
+#define module_init(x) int init_module(void)     { return x(); }
+#endif
+
+#ifndef module_exit
+#define module_exit(x) void cleanup_module(void) { x(); }
+#endif
+
+#endif /* __COMPAT_INIT_H__ */
--- kernel/linux-2.6.26.3/drivers/misc/vsock/compat_kernel.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vsock/compat_kernel.h	2008-09-03 10:02:58.000000000 -0500
@@ -0,0 +1,83 @@
+/*********************************************************
+ * Copyright (C) 2004 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_KERNEL_H__
+#   define __COMPAT_KERNEL_H__
+
+#include <asm/unistd.h>
+#include <linux/kernel.h>
+
+/*
+ * container_of was introduced in 2.5.28 but it's easier to check like this.
+ */
+#ifndef container_of
+#define container_of(ptr, type, member) ({			\
+        const typeof( ((type *)0)->member ) *__mptr = (ptr);	\
+        (type *)( (char *)__mptr - offsetof(type,member) );})
+#endif
+
+/*
+ * wait_for_completion and friends did not exist before 2.4.9.
+ */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 4, 9)
+
+#define compat_complete_and_exit(comp, status) complete_and_exit(comp, status)
+
+#else
+
+#include "compat_completion.h"
+
+/*
+ * Used by _syscallX macros. Note that this is global variable, so
+ * do not rely on its contents too much. As exit() is only function
+ * we use, and we never check return value from exit(), we have
+ * no problem...
+ */
+extern int errno;
+
+/*
+ * compat_exit() provides an access to the exit() function. It must 
+ * be named compat_exit(), as exit() (with different signature) is 
+ * provided by x86-64, arm and other (but not by i386).
+ */
+#define __NR_compat_exit __NR_exit
+static inline _syscall1(int, compat_exit, int, exit_code);
+
+/*
+ * See compat_wait_for_completion in compat_completion.h.
+ * compat_exit implicitly performs an unlock_kernel, in resident code,
+ * ensuring that the thread is no longer running in module code when the
+ * module is unloaded.
+ */
+#define compat_complete_and_exit(comp, status) do { \
+   lock_kernel(); \
+   compat_complete(comp); \
+   compat_exit(status); \
+} while (0)
+
+#endif
+
+/*
+ * vsnprintf became available in 2.4.10. For older kernels, just fall back on
+ * vsprintf.
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 10)
+#define vsnprintf(str, size, fmt, args) vsprintf(str, fmt, args)
+#endif
+
+#endif /* __COMPAT_KERNEL_H__ */
--- kernel/linux-2.6.26.3/drivers/misc/vsock/compat_list.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vsock/compat_list.h	2008-09-03 10:02:58.000000000 -0500
@@ -0,0 +1,55 @@
+/*********************************************************
+ * Copyright (C) 2006 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_LIST_H__
+#   define __COMPAT_LIST_H__
+
+#include <linux/list.h>
+
+/*
+ * list_add_tail is with us since 2.4.0, or something like that.
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 0)
+#define list_add_tail(newe, head) do {  \
+   struct list_head *__h = (head);      \
+   __list_add((newe), __h->prev, __h);  \
+} while (0)
+#endif
+
+/*
+ * list_for_each_safe() showed up in 2.4.10, but it may be backported so we
+ * just check for its existence.
+ */
+#ifndef list_for_each_safe
+# define list_for_each_safe(pos, n, head) \
+         for (pos = (head)->next, n = pos->next; pos != (head); \
+                 pos = n, n = pos->next)
+#endif
+
+/*
+ * list_for_each_entry() showed up in 2.4.20, but it may be backported so we
+ * just check for its existence.
+ */
+#ifndef list_for_each_entry
+# define list_for_each_entry(pos, head, member) \
+         for (pos = list_entry((head)->next, typeof(*pos), member); \
+              &pos->member != (head); \
+              pos = list_entry(pos->member.next, typeof(*pos), member))
+#endif
+
+#endif /* __COMPAT_LIST_H__ */
--- kernel/linux-2.6.26.3/drivers/misc/vsock/compat_mm.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vsock/compat_mm.h	2008-09-03 10:02:58.000000000 -0500
@@ -0,0 +1,134 @@
+/*********************************************************
+ * Copyright (C) 2002 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_MM_H__
+#   define __COMPAT_MM_H__
+
+
+#include <linux/mm.h>
+
+
+/* The get_page() API appeared in 2.3.7 --hpreg */
+/* Sometime during development it became function instead of macro --petr */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 0) && !defined(get_page) 
+#   define get_page(_page) atomic_inc(&(_page)->count)
+/* The __free_page() API is exported in 2.1.67 --hpreg */
+#   if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 1, 67)
+#      define put_page __free_page
+#   else
+#      include "compat_page.h"
+
+#      define page_to_phys(_page) (page_to_pfn(_page) << PAGE_SHIFT)
+#      define put_page(_page) free_page(page_to_phys(_page))
+#   endif
+#endif
+
+
+/* page_count() is 2.4.0 invention. Unfortunately unavailable in some RedHat 
+ * kernels (for example 2.4.21-4-RHEL3). */
+/* It is function since 2.6.0, and hopefully RedHat will not play silly games
+ * with mm_inline.h again... */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 0) && !defined(page_count)
+#  define page_count(page) atomic_read(&(page)->count)
+#endif
+
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 0)
+#  define compat_vm_pgoff(vma) ((vma)->vm_offset >> PAGE_SHIFT)
+
+static inline unsigned long compat_do_mmap_pgoff(struct file *file, unsigned long addr,
+   unsigned long len, unsigned long prot,
+   unsigned long flag, unsigned long pgoff)
+{
+   unsigned long ret = -EINVAL;
+
+   if (pgoff < 1 << (32 - PAGE_SHIFT)) {
+      ret = do_mmap(file, addr, len, prot, flag, pgoff << PAGE_SHIFT);
+   }
+   return ret;
+}
+
+#else
+#  define compat_vm_pgoff(vma) (vma)->vm_pgoff
+#  ifdef VMW_SKAS_MMAP
+#    define compat_do_mmap_pgoff(f, a, l, p, g, o) \
+				do_mmap_pgoff(current->mm, f, a, l, p, g, o)
+#  else
+#    define compat_do_mmap_pgoff(f, a, l, p, g, o) \
+				do_mmap_pgoff(f, a, l, p, g, o)
+#  endif
+#endif
+
+
+/* 2.2.x uses 0 instead of some define */
+#ifndef NOPAGE_SIGBUS
+#define NOPAGE_SIGBUS (0)
+#endif
+
+
+/* 2.2.x does not have HIGHMEM support */
+#ifndef GFP_HIGHUSER
+#define GFP_HIGHUSER (GFP_USER)
+#endif
+
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 0)
+
+#include "compat_page.h"
+
+static inline struct page * alloc_pages(unsigned int gfp_mask, unsigned int order)
+{
+   unsigned long addr;
+   
+   addr = __get_free_pages(gfp_mask, order);
+   if (!addr) {
+      return NULL;
+   }
+   return virt_to_page(addr);
+}
+#define alloc_page(gfp_mask) alloc_pages(gfp_mask, 0)
+
+#endif
+
+/*
+ * In 2.4.14, the logic behind the UnlockPage macro was moved to the 
+ * unlock_page() function. Later (in 2.5.12), the UnlockPage macro was removed
+ * altogether, and nowadays everyone uses unlock_page().
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 14)
+#define compat_unlock_page(page) UnlockPage(page)
+#else
+#define compat_unlock_page(page) unlock_page(page)
+#endif
+
+/*
+ * In 2.4.10, vmtruncate was changed from returning void to returning int.
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 10)
+#define compat_vmtruncate(inode, size)                                        \
+({                                                                            \
+   int result = 0;                                                            \
+   vmtruncate(inode, size);                                                   \
+   result;                                                                    \
+})
+#else
+#define compat_vmtruncate(inode, size) vmtruncate(inode, size)
+#endif
+
+
+#endif /* __COMPAT_MM_H__ */
--- kernel/linux-2.6.26.3/drivers/misc/vsock/compat_module.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vsock/compat_module.h	2008-09-03 10:02:58.000000000 -0500
@@ -0,0 +1,72 @@
+/*********************************************************
+ * Copyright (C) 2007 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * compat_module.h --
+ */
+
+#ifndef __COMPAT_MODULE_H__
+#   define __COMPAT_MODULE_H__
+
+
+#include <linux/module.h>
+
+
+/*
+ * Modules wishing to use the GPL license are required to include a
+ * MODULE_LICENSE definition in their module source as of 2.4.10.
+ */
+#ifndef MODULE_LICENSE
+#define MODULE_LICENSE(license)
+#endif
+
+/*
+ * To make use of our own home-brewed MODULE_INFO, we need macros to
+ * concatenate two expressions to "__mod_", and and to convert an
+ * expression into a string. I'm sure we've got these in our codebase,
+ * but I'd rather not introduce such a dependency in a compat header.
+ */
+#ifndef __module_cat
+#define __module_cat_1(a, b) __mod_ ## a ## b
+#define __module_cat(a, b) __module_cat_1(a, b)
+#endif
+
+#ifndef __stringify
+#define __stringify_1(x) #x
+#define __stringify(x) __stringify_1(x)
+#endif
+
+/*
+ * MODULE_INFO was born in 2.5.69.
+ */
+#ifndef MODULE_INFO
+#define MODULE_INFO(tag, info)                                                \
+static const char __module_cat(tag, __LINE__)[]                               \
+  __attribute__((section(".modinfo"), unused)) = __stringify(tag) "=" info
+#endif
+
+/*
+ * MODULE_VERSION was born in 2.6.4. The earlier form appends a long "\0xxx"
+ * string to the module's version, but that was removed in 2.6.10, so we'll
+ * ignore it in our wrapper.
+ */
+#ifndef MODULE_VERSION
+#define MODULE_VERSION(_version) MODULE_INFO(version, _version)
+#endif
+
+#endif /* __COMPAT_MODULE_H__ */
--- kernel/linux-2.6.26.3/drivers/misc/vsock/compat_namei.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vsock/compat_namei.h	2008-09-03 10:02:58.000000000 -0500
@@ -0,0 +1,57 @@
+/*********************************************************
+ * Copyright (C) 2006 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_NAMEI_H__
+#   define __COMPAT_NAMEI_H__
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 5, 18)
+#include <linux/namei.h>
+#endif
+
+/*
+ * In 2.6.25-rc2, dentry and mount objects were removed from the nameidata
+ * struct. They were both replaced with a struct path.
+ */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 25)
+#define compat_vmw_nd_to_dentry(nd) (nd).path.dentry
+#else
+#define compat_vmw_nd_to_dentry(nd) (nd).dentry
+#endif
+
+/* In 2.6.25-rc2, path_release(&nd) was replaced with path_put(&nd.path). */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 25)
+#define compat_path_release(nd) path_put(&(nd)->path)
+#else
+#define compat_path_release(nd) path_release(nd)
+#endif
+
+/* path_lookup was exported in 2.4.25 */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 4, 25)
+#define compat_path_lookup(path, flags, nd)     path_lookup(path, flags, nd)
+#else
+#define compat_path_lookup(path, flags, nd)     \
+         ({                                     \
+            int ret = 0;                        \
+            if (path_init(path, flags, nd)) {   \
+               ret = path_walk(path, nd);       \
+            }                                   \
+            ret;                                \
+         })
+#endif
+
+#endif /* __COMPAT_NAMEI_H__ */
--- kernel/linux-2.6.26.3/drivers/misc/vsock/compat_page.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vsock/compat_page.h	2008-09-03 10:02:58.000000000 -0500
@@ -0,0 +1,75 @@
+/*********************************************************
+ * Copyright (C) 2002 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_PAGE_H__
+#   define __COMPAT_PAGE_H__
+
+
+#include <linux/mm.h>
+#include <asm/page.h>
+
+
+/* The pfn_to_page() API appeared in 2.5.14 and changed to function during 2.6.x */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 0) && !defined(pfn_to_page)
+#   define pfn_to_page(_pfn) (mem_map + (_pfn))
+#   define page_to_pfn(_page) ((_page) - mem_map)
+#endif
+
+
+/* The virt_to_page() API appeared in 2.4.0 --hpreg */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 0) && !defined(virt_to_page)
+#   define virt_to_page(_kvAddr) pfn_to_page(MAP_NR(_kvAddr))
+#endif
+
+
+/*
+ * The get_order() API appeared at some point in 2.3.x, and was then backported
+ * in 2.2.17-21mdk and in the stock 2.2.18. Because we can only detect its
+ * definition through makefile tricks, we provide our own for now --hpreg
+ */
+static inline int
+compat_get_order(unsigned long size) // IN
+{
+   int order;
+
+   size = (size - 1) >> (PAGE_SHIFT - 1);
+   order = -1;
+   do {
+      size >>= 1;
+      order++;
+   } while (size);
+
+   return order;
+}
+
+/* 
+ * BUG() was added to <asm/page.h> in 2.2.18, and was moved to <asm/bug.h>
+ * in 2.5.58.
+ * 
+ * XXX: Technically, this belongs in some sort of "compat_asm_page.h" file, but
+ * since our compatibility wrappers don't distinguish between <asm/xxx.h> and
+ * <linux/xxx.h>, putting it here is reasonable.
+ */
+#ifndef BUG
+#define BUG() do {                                                            \
+   printk("kernel BUG at %s:%d!\n", __FILE__, __LINE__);                      \
+  __asm__ __volatile__(".byte 0x0f,0x0b");                                    \
+} while (0)
+#endif
+
+#endif /* __COMPAT_PAGE_H__ */
--- kernel/linux-2.6.26.3/drivers/misc/vsock/compat_sched.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vsock/compat_sched.h	2008-09-03 10:02:58.000000000 -0500
@@ -0,0 +1,291 @@
+/*********************************************************
+ * Copyright (C) 2002 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_SCHED_H__
+#   define __COMPAT_SCHED_H__
+
+
+#include <linux/sched.h>
+
+/* CLONE_KERNEL available in 2.5.35 and higher. */
+#ifndef CLONE_KERNEL
+#define CLONE_KERNEL CLONE_FILES | CLONE_FS | CLONE_SIGHAND
+#endif
+
+/* TASK_COMM_LEN become available in 2.6.11. */
+#ifndef TASK_COMM_LEN
+#define TASK_COMM_LEN 16
+#endif
+
+/* The capable() API appeared in 2.1.92 --hpreg */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 1, 92)
+#   define capable(_capability) suser()
+#endif
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 2, 0)
+#   define need_resched() need_resched
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 3)
+#   define need_resched() (current->need_resched)
+#endif
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 3)
+#   define cond_resched() (need_resched() ? schedule() : (void) 0)
+#endif
+
+/* Oh well.  We need yield...  Happy us! */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 20)
+#   ifdef __x86_64__
+#      define compat_yield() there_is_nothing_like_yield()
+#   else
+#      include <linux/unistd.h>
+#      include <linux/kernel.h>
+
+/*
+ * Used by _syscallX macros. Note that this is global variable, so
+ * do not rely on its contents too much. As exit() is only function
+ * we use, and we never check return value from exit(), we have
+ * no problem...
+ */
+extern int errno;
+
+/*
+ * compat_exit() provides an access to the exit() function. It must 
+ * be named compat_exit(), as exit() (with different signature) is 
+ * provided by x86-64, arm and other (but not by i386).
+ */
+#      define __NR_compat_yield __NR_sched_yield
+static inline _syscall0(int, compat_yield);
+#   endif
+#else
+#   define compat_yield() yield()
+#endif
+
+
+/*
+ * Since 2.5.34 there are two methods to enumerate tasks:
+ * for_each_process(p) { ... } which enumerates only tasks and
+ * do_each_thread(g,t) { ... } while_each_thread(g,t) which enumerates
+ *     also threads even if they share same pid.
+ */
+#ifndef for_each_process
+#   define for_each_process(p) for_each_task(p)
+#endif
+
+#ifndef do_each_thread
+#   define do_each_thread(g, t) for_each_task(g) { t = g; do
+#   define while_each_thread(g, t) while (0) }
+#endif
+
+
+/*
+ * Lock for signal mask is moving target...
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 40) && defined(CLONE_PID)
+/* 2.4.x without NPTL patches or early 2.5.x */
+#define compat_sigmask_lock sigmask_lock
+#define compat_dequeue_signal_current(siginfo_ptr) \
+   dequeue_signal(&current->blocked, (siginfo_ptr))
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 60) && !defined(INIT_SIGHAND)
+/* RedHat's 2.4.x with first version of NPTL support, or 2.5.40 to 2.5.59 */
+#define compat_sigmask_lock sig->siglock
+#define compat_dequeue_signal_current(siginfo_ptr) \
+   dequeue_signal(&current->blocked, (siginfo_ptr))
+#else
+/* RedHat's 2.4.x with second version of NPTL support, or 2.5.60+. */
+#define compat_sigmask_lock sighand->siglock
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 0)
+#define compat_dequeue_signal_current(siginfo_ptr) \
+   dequeue_signal(&current->blocked, (siginfo_ptr))
+#else
+#define compat_dequeue_signal_current(siginfo_ptr) \
+   dequeue_signal(current, &current->blocked, (siginfo_ptr))
+#endif
+#endif
+
+/*
+ * recalc_sigpending() had task argument in the past
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 29) && defined(CLONE_PID)
+/* 2.4.x without NPTL patches or early 2.5.x */
+#define compat_recalc_sigpending() recalc_sigpending(current)
+#else
+/* RedHat's 2.4.x with NPTL support, or 2.5.29+ */
+#define compat_recalc_sigpending() recalc_sigpending()
+#endif
+
+
+/*
+ * reparent_to_init() was introduced in 2.4.8.  In 2.5.38 (or possibly
+ * earlier, but later than 2.5.31) a call to it was added into
+ * daemonize(), so compat_daemonize no longer needs to call it.
+ *
+ * In 2.4.x kernels reparent_to_init() forgets to do correct refcounting
+ * on current->user. It is better to count one too many than one too few...
+ */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 4, 8) && LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 38)
+#define compat_reparent_to_init() do { \
+					reparent_to_init(); \
+					atomic_inc(&current->user->__count); \
+				  } while (0)
+#else
+#define compat_reparent_to_init() do {} while (0)
+#endif
+
+
+/*
+ * daemonize appeared in 2.2.18. Except 2.2.17-4-RH7.0, which has it too.
+ * Fortunately 2.2.17-4-RH7.0 uses versioned symbols, so we can check
+ * its existence with defined().
+ */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2, 2, 18)) && !defined(daemonize)
+static inline void daemonize(void) {
+   struct fs_struct *fs;
+
+   exit_mm(current);
+   current->session = 1;
+   current->pgrp = 1;
+   exit_fs(current);
+   fs = init_task.fs;
+   current->fs = fs;
+   atomic_inc(&fs->count);
+}
+#endif
+
+
+/*
+ * flush_signals acquires sighand->siglock since 2.5.61... Verify RH's kernels!
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 61)
+#define compat_flush_signals(task) do { \
+				      spin_lock_irq(&task->compat_sigmask_lock); \
+				      flush_signals(task); \
+				      spin_unlock_irq(&task->compat_sigmask_lock); \
+				   } while (0)
+#else
+#define compat_flush_signals(task) flush_signals(task)
+#endif
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 61)
+#define compat_allow_signal(signr) do { \
+                                      spin_lock_irq(&current->compat_sigmask_lock); \
+                                      sigdelset(&current->blocked, signr); \
+                                      compat_recalc_sigpending(); \
+                                      spin_unlock_irq(&current->compat_sigmask_lock); \
+                                   } while (0)
+#else
+#define compat_allow_signal(signr) allow_signal(signr)
+#endif
+
+/*
+ * daemonize can set process name since 2.5.61. Prior to 2.5.61, daemonize
+ * didn't block signals on our behalf.
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 61)
+#define compat_daemonize(x...)                                                \
+({                                                                            \
+   /* Beware! No snprintf here, so verify arguments! */                       \
+   sprintf(current->comm, x);                                                 \
+                                                                              \
+   /* Block all signals. */                                                   \
+   spin_lock_irq(&current->compat_sigmask_lock);                              \
+   sigfillset(&current->blocked);                                             \
+   compat_recalc_sigpending();                                                \
+   spin_unlock_irq(&current->compat_sigmask_lock);                            \
+   compat_flush_signals(current);                                             \
+                                                                              \
+   daemonize();                                                               \
+   compat_reparent_to_init();                                                 \
+})
+#else
+#define compat_daemonize(x...) daemonize(x)
+#endif
+
+
+/*
+ * set priority for specified thread. Exists on 2.6.x kernels and some
+ * 2.4.x vendor's kernels.
+ */
+#if defined(VMW_HAVE_SET_USER_NICE)
+#define compat_set_user_nice(task, n) set_user_nice((task), (n))
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 0)
+#define compat_set_user_nice(task, n) do { (task)->priority = 20 - (n); } while (0)
+#elif !defined(VMW_HAVE_SET_USER_NICE)
+#define compat_set_user_nice(task, n) do { (task)->nice = (n); } while (0)
+#endif
+
+/*
+ * try to freeze a process. For kernels 2.6.11 or newer, we know how to choose
+ * the interface. The problem is that the oldest interface, introduced in
+ * 2.5.18, was backported to 2.4.x kernels. So if we're older than 2.6.11,
+ * we'll decide what to do based on whether or not swsusp was configured
+ * for the kernel.  For kernels 2.6.20 and newer, we'll also need to include
+ * freezer.h since the try_to_freeze definition was pulled out of sched.h.
+ */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 20)
+#include <linux/freezer.h>
+#endif
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 13) || defined(VMW_TL10S64_WORKAROUND)
+#define compat_try_to_freeze() try_to_freeze()
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 11)
+#define compat_try_to_freeze() try_to_freeze(PF_FREEZE)
+#elif defined(CONFIG_SOFTWARE_SUSPEND) || defined(CONFIG_SOFTWARE_SUSPEND2)
+#include "compat_mm.h"
+#include <linux/errno.h>
+#include <linux/suspend.h>
+static inline int compat_try_to_freeze(void)  { 
+   if (current->flags & PF_FREEZE) {
+      refrigerator(PF_FREEZE); 
+      return 1;
+   } else {
+      return 0;
+   }
+}
+#else
+static inline int compat_try_to_freeze(void) { return 0; }
+#endif
+
+/*
+ * As of 2.6.23-rc1, kernel threads are no longer freezable by
+ * default. Instead, kernel threads that need to be frozen must opt-in
+ * by calling set_freezable() as soon as the thread is created.
+ */
+
+#if LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 22)
+#define compat_set_freezable() do { set_freezable(); } while (0)
+#else
+#define compat_set_freezable() do {} while (0)
+#endif
+
+/*
+ * Since 2.6.27-rc2 kill_proc() is gone... Replacement (GPL-only!)
+ * API is available since 2.6.19.  Use them from 2.6.27-rc1 up.
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 27)
+typedef int compat_pid;
+#define compat_find_get_pid(pid) (pid)
+#define compat_put_pid(pid) do { } while (0)
+#define compat_kill_pid(pid, sig, flag) kill_proc(pid, sig, flag)
+#else
+typedef struct pid * compat_pid;
+#define compat_find_get_pid(pid) find_get_pid(pid)
+#define compat_put_pid(pid) put_pid(pid)
+#define compat_kill_pid(pid, sig, flag) kill_pid(pid, sig, flag)
+#endif
+
+
+#endif /* __COMPAT_SCHED_H__ */
--- kernel/linux-2.6.26.3/drivers/misc/vsock/compat_semaphore.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vsock/compat_semaphore.h	2008-09-03 10:02:58.000000000 -0500
@@ -0,0 +1,49 @@
+/*********************************************************
+ * Copyright (C) 2002 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_SEMAPHORE_H__
+#   define __COMPAT_SEMAPHORE_H__
+
+
+/* <= 2.6.25 have asm only, 2.6.26 has both, and 2.6.27-rc2+ has linux only. */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 27)
+#   include <asm/semaphore.h>
+#else
+#   include <linux/semaphore.h>
+#endif
+
+
+/*
+* The init_MUTEX_LOCKED() API appeared in 2.2.18, and is also in
+* 2.2.17-21mdk --hpreg
+*/
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 2, 18)
+   #ifndef init_MUTEX_LOCKED
+      #define init_MUTEX_LOCKED(_sem) *(_sem) = MUTEX_LOCKED
+   #endif
+   #ifndef DECLARE_MUTEX
+      #define DECLARE_MUTEX(name) struct semaphore name = MUTEX
+   #endif
+   #ifndef DECLARE_MUTEX_LOCKED
+      #define DECLARE_MUTEX_LOCKED(name) struct semaphore name = MUTEX_LOCKED
+   #endif
+#endif
+
+
+#endif /* __COMPAT_SEMAPHORE_H__ */
--- kernel/linux-2.6.26.3/drivers/misc/vsock/compat_slab.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vsock/compat_slab.h	2008-09-03 10:02:58.000000000 -0500
@@ -0,0 +1,85 @@
+/*********************************************************
+ * Copyright (C) 2005 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_SLAB_H__
+#   define __COMPAT_SLAB_H__
+
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 2, 0)
+#   include <linux/slab.h>
+#else
+#   include <linux/malloc.h>
+#endif
+
+/*
+ * Before 2.6.20, kmem_cache_t was the accepted way to refer to a kmem_cache
+ * structure.  Prior to 2.6.15, this structure was called kmem_cache_s, and
+ * afterwards it was renamed to kmem_cache.  Here we keep things simple and use
+ * the accepted typedef until it became deprecated, at which point we switch
+ * over to the kmem_cache name.
+ */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 20)
+#   define compat_kmem_cache struct kmem_cache
+#else
+#   define compat_kmem_cache kmem_cache_t
+#endif
+
+/*
+ * Up to 2.6.22 kmem_cache_create has 6 arguments - name, size, alignment, flags,
+ * constructor, and destructor.  Then for some time kernel was asserting that
+ * destructor is NULL, and since 2.6.23-pre1 kmem_cache_create takes only 5
+ * arguments - destructor is gone.
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 22) || defined(VMW_KMEMCR_HAS_DTOR)
+#define compat_kmem_cache_create(name, size, align, flags, ctor) \
+		kmem_cache_create(name, size, align, flags, ctor, NULL)
+#else
+#define compat_kmem_cache_create(name, size, align, flags, ctor) \
+		kmem_cache_create(name, size, align, flags, ctor)
+#endif
+
+/*
+ * Up to 2.6.23 kmem_cache constructor has three arguments - pointer to block to
+ * prepare (aka "this"), from which cache it came, and some unused flags.  After
+ * 2.6.23 flags were removed, and order of "this" and cache parameters was swapped...
+ * Since 2.6.27-rc2 everything is different again, and ctor has only one argument.
+ *
+ * HAS_3_ARGS has precedence over HAS_2_ARGS if both are defined.
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 23) && !defined(VMW_KMEMCR_CTOR_HAS_3_ARGS)
+#  define VMW_KMEMCR_CTOR_HAS_3_ARGS
+#endif
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 26) && !defined(VMW_KMEMCR_CTOR_HAS_2_ARGS)
+#  define VMW_KMEMCR_CTOR_HAS_2_ARGS
+#endif
+
+#if defined(VMW_KMEMCR_CTOR_HAS_3_ARGS)
+typedef void compat_kmem_cache_ctor(void *, compat_kmem_cache *, unsigned long);
+#define COMPAT_KMEM_CACHE_CTOR_ARGS(arg) void *arg, \
+                                         compat_kmem_cache *cache, \
+                                         unsigned long flags
+#elif defined(VMW_KMEMCR_CTOR_HAS_2_ARGS)
+typedef void compat_kmem_cache_ctor(compat_kmem_cache *, void *);
+#define COMPAT_KMEM_CACHE_CTOR_ARGS(arg) compat_kmem_cache *cache, \
+                                         void *arg
+#else
+typedef void compat_kmem_cache_ctor(void *);
+#define COMPAT_KMEM_CACHE_CTOR_ARGS(arg) void *arg
+#endif
+
+#endif /* __COMPAT_SLAB_H__ */
--- kernel/linux-2.6.26.3/drivers/misc/vsock/compat_sock.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vsock/compat_sock.h	2008-09-03 10:02:58.000000000 -0500
@@ -0,0 +1,169 @@
+/*********************************************************
+ * Copyright (C) 2003 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_SOCK_H__
+#   define __COMPAT_SOCK_H__
+
+#include <linux/stddef.h> /* for NULL */
+#include <net/sock.h>
+
+
+/*
+ * Between 2.5.70 and 2.5.71 all sock members were renamed from XXX to sk_XXX.
+ *
+ * VMW_HAVE_SK_WMEM_ALLOC is defined in module Makefile if kernel's struct sock
+ * has sk_wmem_alloc member. See vmnet's Makefile.kernel for details.
+ * It also means that all modules including this file should do
+ *
+ * EXTRA_CFLAGS += $(call vm_check_build, $(SRCROOT)/socket.c,  -DVMW_HAVE_SK_WMEM_ALLOC, )
+ *
+ * in their Makefiles.
+ */
+#ifndef VMW_HAVE_SK_WMEM_ALLOC
+#   define sk_wmem_alloc wmem_alloc
+#endif
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 71)
+# define compat_sk_backlog_rcv          backlog_rcv
+# define compat_sk_destruct             destruct
+# define compat_sk_shutdown             shutdown
+# define compat_sk_receive_queue        receive_queue
+# define compat_sk_sleep                sleep
+# define compat_sk_err                  err
+# define compat_sk_state_change         state_change
+# define compat_sk_data_ready           data_ready
+# define compat_sk_write_space          write_space
+# define compat_sk_error_report         error_report
+# define compat_sk_type                 type
+# define compat_sk_refcnt               refcnt
+# define compat_sk_state                state
+# define compat_sk_error_report         error_report
+# define compat_sk_socket               socket
+# define compat_sk_ack_backlog          ack_backlog
+# define compat_sk_max_ack_backlog      max_ack_backlog
+#else
+# define compat_sk_backlog_rcv          sk_backlog_rcv
+# define compat_sk_destruct             sk_destruct
+# define compat_sk_shutdown             sk_shutdown
+# define compat_sk_receive_queue        sk_receive_queue
+# define compat_sk_sleep                sk_sleep
+# define compat_sk_err                  sk_err
+# define compat_sk_state_change         sk_state_change
+# define compat_sk_data_ready           sk_data_ready
+# define compat_sk_write_space          sk_write_space
+# define compat_sk_error_report         sk_error_report
+# define compat_sk_type                 sk_type
+# define compat_sk_refcnt               sk_refcnt
+# define compat_sk_state                sk_state
+# define compat_sk_error_report         sk_error_report
+# define compat_sk_socket               sk_socket
+# define compat_sk_ack_backlog          sk_ack_backlog
+# define compat_sk_max_ack_backlog      sk_max_ack_backlog
+#endif
+
+
+/*
+ * Prior to 2.6.24, there was no sock network namespace member. In 2.6.26, it
+ * was hidden behind accessor functions so that its behavior could vary
+ * depending on the value of CONFIG_NET_NS.
+ */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 26)
+# define compat_sock_net(sk)            sock_net(sk)
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 24)
+# define compat_sock_net(sk)            sk->sk_net
+#endif
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 42)
+# define compat_sock_owned_by_user(sk)  ((sk)->lock.users != 0)
+#else
+# define compat_sock_owned_by_user(sk)  sock_owned_by_user(sk)
+#endif
+
+/*
+ * Up until 2.4.21 for the 2.4 series and 2.5.60 for the 2.5 series,
+ * sk_filter() calls were protected with CONFIG_FILTER.  Wrapping our compat
+ * definition in a similar check allows us to build on those kernels.
+ *
+ */
+#ifdef CONFIG_FILTER
+/*
+ * Unfortunately backports for certain kernels require the use of an autoconf
+ * program to check the interface for sk_filter().
+ */
+# ifndef VMW_HAVE_NEW_SKFILTER
+#  define compat_sk_filter(sk, skb, needlock)  sk_filter(skb, (sk)->filter)
+# else
+#  define compat_sk_filter(sk, skb, needlock)  sk_filter(sk, skb, needlock)
+# endif
+#else
+# define compat_sk_filter(sk, skb, needlock)   0
+#endif
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 16)
+/* Taken from 2.6.16's sock.h and modified for macro. */
+# define compat_sk_receive_skb(sk, skb, nested)         \
+   ({                                                   \
+     int rc = NET_RX_SUCCESS;                           \
+                                                        \
+     if (compat_sk_filter(sk, skb, 0)) {                \
+        kfree_skb(skb);                                 \
+        sock_put(sk);                                   \
+     } else {                                           \
+        skb->dev = NULL;                                \
+        bh_lock_sock(sk);                               \
+        if (!compat_sock_owned_by_user(sk)) {           \
+           rc = (sk)->compat_sk_backlog_rcv(sk, skb);   \
+        } else {                                        \
+           sk_add_backlog(sk, skb);                     \
+        }                                               \
+        bh_unlock_sock(sk);                             \
+        sock_put(sk);                                   \
+     }                                                  \
+                                                        \
+     rc;                                                \
+    })
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 20)
+# define compat_sk_receive_skb(sk, skb, nested) sk_receive_skb(sk, skb)
+#else
+# define compat_sk_receive_skb(sk, skb, nested) sk_receive_skb(sk, skb, nested)
+#endif
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 72)
+/*
+ * Before 2.5.72, the helper socket functions for hlist management did not
+ * exist, so we use the sklist_ functions instead.  These are not ideal since
+ * they grab a system-wide sklist lock despite not needing it since we provide
+ * our own list.
+ */
+#define compat_sk_next next /* for when we find out it became sk_next */
+# define compat_sklist_table                    struct sock *
+/* This isn't really used in the iterator, but we need something. */
+# define compat_sklist_table_entry              struct sock
+# define compat_sk_for_each(sk, node, list)     \
+   for (sk = *(list), node = NULL; sk != NULL; sk = (sk)->compat_sk_next)
+# define compat_sk_add_node(sk, list)           sklist_insert_socket(list, sk)
+# define compat_sk_del_node_init(sk, list)      sklist_remove_socket(list, sk)
+#else
+# define compat_sklist_table                    struct hlist_head
+# define compat_sklist_table_entry              struct hlist_node
+# define compat_sk_for_each(sk, node, list)     sk_for_each(sk, node, list)
+# define compat_sk_add_node(sk, list)           sk_add_node(sk, list)
+# define compat_sk_del_node_init(sk, list)      sk_del_node_init(sk)
+#endif
+
+#endif /* __COMPAT_SOCK_H__ */
--- kernel/linux-2.6.26.3/drivers/misc/vsock/compat_spinlock.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vsock/compat_spinlock.h	2008-09-03 10:02:58.000000000 -0500
@@ -0,0 +1,68 @@
+/*********************************************************
+ * Copyright (C) 2005 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_SPINLOCK_H__
+#   define __COMPAT_SPINLOCK_H__
+
+
+/*
+ * The spin_lock() API appeared in 2.1.25 in asm/smp_lock.h
+ * It moved in 2.1.30 to asm/spinlock.h
+ * It moved again in 2.3.18 to linux/spinlock.h
+ *
+ *   --hpreg
+ */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 3, 18)
+#   include <linux/spinlock.h>
+#else
+#   if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 1, 30)
+#      include <asm/spinlock.h>
+#   else
+typedef struct {} spinlock_t;
+#      define spin_lock_init(lock)
+#      define spin_lock(lock)
+#      define spin_unlock(lock)
+#      define spin_lock_irqsave(lock, flags) do {      \
+                    save_flags(flags);                 \
+                    cli();                             \
+                    spin_lock(lock);                   \
+                 } while (0)
+#      define spin_unlock_irqrestore(lock, flags) do { \
+                    spin_unlock(lock);                 \
+                    restore_flags(flags);              \
+                 } while (0)
+#   endif
+#endif
+
+
+/*
+ * Preempt support was added during 2.5.x development cycle, and later
+ * it was backported to 2.4.x.  In 2.4.x backport these definitions
+ * live in linux/spinlock.h, that's why we put them here (in 2.6.x they
+ * are defined in linux/preempt.h which is included by linux/spinlock.h).
+ */
+#ifdef CONFIG_PREEMPT
+#define compat_preempt_disable() preempt_disable()
+#define compat_preempt_enable()  preempt_enable()
+#else
+#define compat_preempt_disable() do { } while (0)
+#define compat_preempt_enable()  do { } while (0)
+#endif
+
+
+#endif /* __COMPAT_SPINLOCK_H__ */
--- kernel/linux-2.6.26.3/drivers/misc/vsock/compat_statfs.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vsock/compat_statfs.h	2008-09-03 10:02:58.000000000 -0500
@@ -0,0 +1,32 @@
+/*********************************************************
+ * Copyright (C) 2006 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_STATFS_H__
+#   define __COMPAT_STATFS_H__
+
+/* vfs.h simply include statfs.h, but it knows what directory statfs.h is in. */
+#include <linux/vfs.h>
+
+/* 2.5.74 renamed struct statfs to kstatfs. */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 5, 74)
+#define compat_kstatfs kstatfs
+#else
+#define compat_kstatfs statfs
+#endif
+
+#endif /* __COMPAT_STATFS_H__ */
--- kernel/linux-2.6.26.3/drivers/misc/vsock/compat_string.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vsock/compat_string.h	2008-09-03 10:02:58.000000000 -0500
@@ -0,0 +1,42 @@
+/*********************************************************
+ * Copyright (C) 2007 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_STRING_H__
+#   define __COMPAT_STRING_H__
+
+#include <linux/string.h>
+
+/*
+ * kstrdup was born in 2.6.13. This implementation is almost identical to the
+ * one found there.
+ */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 13)
+#define compat_kstrdup(s, gfp) kstrdup(s, gfp)
+#else
+#define compat_kstrdup(s, gfp)                                                \
+({                                                                            \
+   size_t len;                                                                \
+   char *buf;                                                                 \
+   len = strlen(s) + 1;                                                       \
+   buf = kmalloc(len, gfp);                                                   \
+   memcpy(buf, s, len);                                                       \
+   buf;                                                                       \
+})                                                                            
+#endif
+
+#endif /* __COMPAT_STRING_H__ */
--- kernel/linux-2.6.26.3/drivers/misc/vsock/compat_uaccess.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vsock/compat_uaccess.h	2008-09-03 10:02:58.000000000 -0500
@@ -0,0 +1,79 @@
+/*********************************************************
+ * Copyright (C) 2002 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_UACCESS_H__
+#   define __COMPAT_UACCESS_H__
+
+
+/* User space access functions moved in 2.1.7 to asm/uaccess.h --hpreg */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 1, 7)
+#   include <asm/uaccess.h>
+#else
+#   include <asm/segment.h>
+#endif
+
+
+/* get_user() API modified in 2.1.4 to take 2 arguments --hpreg */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 1, 4)
+#   define compat_get_user get_user
+#else
+/*
+ * We assign 0 to the variable in case of failure to prevent "`_var' might be
+ * used uninitialized in this function" compiler warnings. I think it is OK,
+ * because the hardware-based version in newer kernels probably has the same
+ * semantics and does not guarantee that the value of _var will not be
+ * modified, should the access fail --hpreg
+ */
+#   define compat_get_user(_var, _uvAddr) ({                        \
+   int _status;                                                     \
+                                                                    \
+   _status = verify_area(VERIFY_READ, _uvAddr, sizeof(*(_uvAddr))); \
+   if (_status == 0) {                                              \
+      (_var) = get_user(_uvAddr);                                   \
+   } else {                                                         \
+      (_var) = 0;                                                   \
+   }                                                                \
+   _status;                                                         \
+})
+#endif
+
+
+/*
+ * The copy_from_user() API appeared in 2.1.4
+ *
+ * The emulation is not perfect here, but it is conservative: on failure, we
+ * always return the total size, instead of the potentially smaller faulty
+ * size --hpreg
+ *
+ * Since 2.5.55 copy_from_user() is no longer macro.
+ */
+#if !defined(copy_from_user) && LINUX_VERSION_CODE < KERNEL_VERSION(2, 2, 0)
+#   define copy_from_user(_to, _from, _size) ( \
+   verify_area(VERIFY_READ, _from, _size)      \
+       ? (_size)                               \
+       : (memcpy_fromfs(_to, _from, _size), 0) \
+)
+#   define copy_to_user(_to, _from, _size) ( \
+   verify_area(VERIFY_WRITE, _to, _size)     \
+       ? (_size)                             \
+       : (memcpy_tofs(_to, _from, _size), 0) \
+)
+#endif
+
+
+#endif /* __COMPAT_UACCESS_H__ */
--- kernel/linux-2.6.26.3/drivers/misc/vsock/compat_version.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vsock/compat_version.h	2008-09-03 10:03:46.000000000 -0500
@@ -0,0 +1,120 @@
+/*********************************************************
+ * Copyright (C) 1998 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_VERSION_H__
+#   define __COMPAT_VERSION_H__
+
+#define INCLUDE_ALLOW_VMMON
+#define INCLUDE_ALLOW_MODULE
+#define INCLUDE_ALLOW_VMCORE
+#define INCLUDE_ALLOW_VMNIXMOD
+#define INCLUDE_ALLOW_DISTRIBUTE
+
+
+#ifndef __linux__
+#   error "linux-version.h"
+#endif
+
+
+#include <linux/version.h>
+
+/* Appeared in 2.1.90 --hpreg */
+#ifndef KERNEL_VERSION
+#   define KERNEL_VERSION(a, b, c) (((a) << 16) + ((b) << 8) + (c))
+#endif
+
+
+/*
+ * Distinguish relevant classes of Linux kernels.
+ *
+ * The convention is that version X defines all
+ * the KERNEL_Y symbols where Y <= X.
+ *
+ * XXX Do not add more definitions here. This way of doing things does not
+ *     scale, and we are going to phase it out soon --hpreg
+ */
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 1, 0)
+#   define KERNEL_2_1
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 2, 0)
+#   define KERNEL_2_2
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 3, 1)
+#   define KERNEL_2_3_1
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 3, 15)
+/*   new networking */
+#   define KERNEL_2_3_15
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 3, 25)
+/*  new procfs */
+#   define KERNEL_2_3_25
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 3, 29)
+/*  even newer procfs */
+#   define KERNEL_2_3_29
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 3, 43)
+/*  softnet changes */
+#   define KERNEL_2_3_43
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 3, 47)
+/*  more softnet changes */
+#   define KERNEL_2_3_47
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 3, 99)
+/*  name in netdevice struct is array and not pointer */
+#   define KERNEL_2_3_99
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 4, 0)
+/*  New 'owner' member at the beginning of struct file_operations */
+#      define KERNEL_2_4_0
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 4, 8)
+/*  New netif_rx_ni() --hpreg */
+#   define KERNEL_2_4_8
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 4, 22)
+/*  New vmap() */
+#   define KERNEL_2_4_22
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 5, 2)
+/*  New kdev_t, major()/minor() API --hpreg */
+#   define KERNEL_2_5_2
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 5, 5)
+/*  New sk_alloc(), pte_offset_map()/pte_unmap() --hpreg */
+#   define KERNEL_2_5_5
+#endif
+
+
+#endif /* __COMPAT_VERSION_H__ */
--- kernel/linux-2.6.26.3/drivers/misc/vsock/compat_wait.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vsock/compat_wait.h	2008-09-03 10:02:58.000000000 -0500
@@ -0,0 +1,225 @@
+/*********************************************************
+ * Copyright (C) 2002 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_WAIT_H__
+#   define __COMPAT_WAIT_H__
+
+
+#include <linux/wait.h>
+#include <linux/poll.h>
+#include <linux/file.h>
+
+#include "compat_file.h"
+
+
+/*
+ * The DECLARE_WAITQUEUE() API appeared in 2.3.1
+ * It was back ported in 2.2.18
+ *
+ *  --hpreg
+ */
+
+#ifndef DECLARE_WAITQUEUE
+
+typedef struct wait_queue *wait_queue_head_t;
+#   define init_waitqueue_head(_headPtr) *(_headPtr) = NULL
+#   define DECLARE_WAITQUEUE(_var, _task) \
+   struct wait_queue _var = {_task, NULL, }
+
+typedef struct wait_queue wait_queue_t;
+#   define init_waitqueue_entry(_wait, _task) ((_wait)->task = (_task))
+
+#endif
+
+/*
+ * The 'struct poll_wqueues' appeared in 2.5.48, when global
+ * /dev/epoll interface was added.  It was backported to the
+ * 2.4.20-wolk4.0s.
+ */
+
+#ifdef VMW_HAVE_EPOLL // {
+#define compat_poll_wqueues struct poll_wqueues
+#else // } {
+#define compat_poll_wqueues poll_table
+#endif // }
+
+#ifdef VMW_HAVE_EPOLL // {
+
+/* If prototype does not match, build will abort here */
+extern void poll_initwait(compat_poll_wqueues *);
+
+#define compat_poll_initwait(wait, table) ( \
+   poll_initwait((table)), \
+   (wait) = &(table)->pt \
+)
+
+#define compat_poll_freewait(wait, table) ( \
+   poll_freewait((table)) \
+)
+
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(2, 4, 0) // {
+
+/* If prototype does not match, build will abort here */
+extern void poll_initwait(compat_poll_wqueues *);
+
+#define compat_poll_initwait(wait, table) ( \
+   (wait) = (table), \
+   poll_initwait(wait) \
+)
+
+#define compat_poll_freewait(wait, table) ( \
+   poll_freewait((table)) \
+)
+
+#else // } {
+
+#define compat_poll_initwait(wait, table) ( \
+   (wait) = (table), /* confuse compiler */ \
+   (wait) = (poll_table *) __get_free_page(GFP_KERNEL), \
+   (wait)->nr = 0, \
+   (wait)->entry = (struct poll_table_entry *)((wait) + 1), \
+   (wait)->next = NULL \
+)
+
+static inline void
+poll_freewait(poll_table *wait)
+{
+   while (wait) {
+      struct poll_table_entry * entry;
+      poll_table *old;
+
+      entry = wait->entry + wait->nr;
+      while (wait->nr > 0) {
+	 wait->nr--;
+	 entry--;
+	 remove_wait_queue(entry->wait_address, &entry->wait);
+	 compat_fput(entry->filp);
+      }
+      old = wait;
+      wait = wait->next;
+      free_page((unsigned long) old);
+   }
+}
+
+#define compat_poll_freewait(wait, table) ( \
+   poll_freewait((wait)) \
+)
+
+#endif // }
+
+/*
+ * The wait_event_interruptible_timeout() interface is not
+ * defined in pre-2.6 kernels.
+ */
+#ifndef wait_event_interruptible_timeout
+#define __wait_event_interruptible_timeout(wq, condition, ret)		\
+do {									\
+   wait_queue_t __wait;						        \
+   init_waitqueue_entry(&__wait, current);				\
+									\
+   add_wait_queue(&wq, &__wait);					\
+   for (;;) {							        \
+      set_current_state(TASK_INTERRUPTIBLE);			        \
+      if (condition)						        \
+	 break;						                \
+      if (!signal_pending(current)) {				        \
+	 ret = schedule_timeout(ret);			                \
+	 if (!ret)					                \
+	    break;					                \
+	 continue;					                \
+      }							                \
+      ret = -ERESTARTSYS;					        \
+      break;							        \
+   }								        \
+   set_current_state(TASK_RUNNING);				        \
+   remove_wait_queue(&wq, &__wait);				        \
+} while (0)
+
+#define wait_event_interruptible_timeout(wq, condition, timeout)	\
+({									\
+   long __ret = timeout;						\
+   if (!(condition))						        \
+      __wait_event_interruptible_timeout(wq, condition, __ret);         \
+   __ret;								\
+})
+#endif
+
+/*
+ * The wait_event_timeout() interface is not
+ * defined in pre-2.6 kernels.
+ */
+#ifndef wait_event_timeout
+#define __wait_event_timeout(wq, condition, ret)        		\
+do {									\
+   wait_queue_t __wait;						        \
+   init_waitqueue_entry(&__wait, current);				\
+									\
+   add_wait_queue(&wq, &__wait);					\
+   for (;;) {							        \
+      set_current_state(TASK_UNINTERRUPTIBLE);        	                \
+      if (condition)						        \
+         break;						                \
+      ret = schedule_timeout(ret);			                \
+      if (!ret)					                        \
+         break;					                        \
+   }								        \
+   set_current_state(TASK_RUNNING);				        \
+   remove_wait_queue(&wq, &__wait);				        \
+} while (0)
+
+#define wait_event_timeout(wq, condition, timeout)	                \
+({									\
+   long __ret = timeout;						\
+   if (!(condition))						        \
+      __wait_event_timeout(wq, condition, __ret);                       \
+   __ret;								\
+})
+#endif
+
+/*
+ * DEFINE_WAIT() and friends were added in 2.5.39 and backported to 2.4.28.
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 28) || \
+   (LINUX_VERSION_CODE >= KERNEL_VERSION(2, 5, 0) && \
+    LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 39))
+# define COMPAT_DEFINE_WAIT(_wait)                              \
+   DECLARE_WAITQUEUE(_wait, current)
+# define compat_init_prepare_to_wait(_sleep, _wait, _state)     \
+   do {                                                         \
+      __set_current_state(_state);                              \
+      add_wait_queue(_sleep, _wait);                            \
+   } while (0)
+# define compat_cont_prepare_to_wait(_sleep, _wait, _state)     \
+   set_current_state(_state)
+# define compat_finish_wait(_sleep, _wait, _state)              \
+   do {                                                         \
+      __set_current_state(_state);                              \
+      remove_wait_queue(_sleep, _wait);                         \
+   } while (0)
+#else
+# define COMPAT_DEFINE_WAIT(_wait)                              \
+   DEFINE_WAIT(_wait)
+# define compat_init_prepare_to_wait(_sleep, _wait, _state)     \
+   prepare_to_wait(_sleep, _wait, _state)
+# define compat_cont_prepare_to_wait(_sleep, _wait, _state)     \
+   prepare_to_wait(_sleep, _wait, _state)
+# define compat_finish_wait(_sleep, _wait, _state)              \
+   finish_wait(_sleep, _wait)
+#endif
+
+#endif /* __COMPAT_WAIT_H__ */
--- kernel/linux-2.6.26.3/drivers/misc/vsock/compat_workqueue.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vsock/compat_workqueue.h	2008-09-03 10:02:58.000000000 -0500
@@ -0,0 +1,165 @@
+/*********************************************************
+ * Copyright (C) 2007 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_WORKQUEUE_H__
+# define __COMPAT_WORKQUEUE_H__
+
+#include <linux/kernel.h>
+
+#if LINUX_VERSION_CODE > KERNEL_VERSION(2, 5, 41)
+# include <linux/workqueue.h>
+#endif
+
+/*
+ *
+ * Work queues and delayed work queues.
+ *
+ * Prior to 2.5.41, the notion of work queues did not exist.  Taskqueues are
+ * used for work queues and timers are used for delayed work queues.
+ *
+ * After 2.6.20, normal work structs ("work_struct") and delayed work
+ * ("delayed_work") structs were separated so that the work_struct could be
+ * slimmed down.  The interface was also changed such that the address of the
+ * work_struct itself is passed in as the argument to the work function.  This
+ * requires that one embed the work struct in the larger struct containing the
+ * information necessary to complete the work and use container_of() to obtain
+ * the address of the containing structure.
+ *
+ * Users of these macros should embed a compat_work or compat_delayed_work in
+ * a larger structure, then specify the larger structure as the _data argument
+ * for the initialization functions, specify the work function to take
+ * a compat_work_arg or compat_delayed_work_arg, then use the appropriate
+ * _GET_DATA macro to obtain the reference to the structure passed in as _data.
+ * An example is below.
+ *
+ *
+ *   typedef struct WorkData {
+ *      int data;
+ *      compat_work work;
+ *   } WorkData;
+ *
+ *
+ *   void
+ *   WorkFunc(compat_work_arg data)
+ *   {
+ *      WorkData *workData = COMPAT_WORK_GET_DATA(data, WorkData, work);
+ *
+ *      ...
+ *   }
+ *
+ *
+ *   {
+ *      WorkData *workData = kmalloc(sizeof *workData, GFP_EXAMPLE);
+ *      if (!workData) {
+ *         return -ENOMEM;
+ *      }
+ *
+ *      COMPAT_INIT_WORK(&workData->work, WorkFunc, workData);
+ *      compat_schedule_work(&workData->work);
+ *   }
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 41)  /* { */
+typedef struct tq_struct compat_work;
+typedef struct compat_delayed_work {
+   struct tq_struct work;
+   struct timer_list timer;
+} compat_delayed_work;
+typedef void * compat_work_arg;
+typedef void * compat_delayed_work_arg;
+
+/*
+ * Delayed work queues need to run at some point in the future in process
+ * context, but task queues don't support delaying the task one is scheduling.
+ * Timers allow us to delay the execution of our work queue until the future,
+ * but timer handlers run in bottom-half context.  As such, we use both a timer
+ * and task queue and use the timer handler below to schedule the task in
+ * process context immediately.  The timer lets us delay execution, and the
+ * task queue lets us run in process context.
+ *
+ * Note that this is similar to how delayed_work is implemented with work
+ * queues in later kernel versions.
+ */
+static inline void
+__compat_delayed_work_timer(unsigned long arg)
+{
+   compat_delayed_work *dwork = (compat_delayed_work *)arg;
+   if (dwork) {
+      schedule_task(&dwork->work);
+   }
+}
+
+# define COMPAT_INIT_WORK(_work, _func, _data)            \
+   INIT_LIST_HEAD(&(_work)->list);                        \
+   (_work)->sync = 0;                                     \
+   (_work)->routine = _func;                              \
+   (_work)->data = _data
+# define COMPAT_INIT_DELAYED_WORK(_work, _func, _data)    \
+   COMPAT_INIT_WORK(&(_work)->work, _func, _data);        \
+   init_timer(&(_work)->timer);                           \
+   (_work)->timer.expires = 0;                            \
+   (_work)->timer.function = __compat_delayed_work_timer; \
+   (_work)->timer.data = (unsigned long)_work
+# define compat_schedule_work(_work)                      \
+   schedule_task(_work)
+# define compat_schedule_delayed_work(_work, _delay)      \
+   (_work)->timer.expires = jiffies + _delay;             \
+   add_timer(&(_work)->timer)
+# define COMPAT_WORK_GET_DATA(_p, _type)                  \
+   (_type *)(_p)
+# define COMPAT_DELAYED_WORK_GET_DATA(_p, _type, _member) \
+   (_type *)(_p)
+
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 20)  /* } { */
+typedef struct work_struct compat_work;
+typedef struct work_struct compat_delayed_work;
+typedef void * compat_work_arg;
+typedef void * compat_delayed_work_arg;
+# define COMPAT_INIT_WORK(_work, _func, _data)            \
+   INIT_WORK(_work, _func, _data)
+# define COMPAT_INIT_DELAYED_WORK(_work, _func, _data)    \
+   INIT_WORK(_work, _func, _data)
+# define compat_schedule_work(_work)                      \
+   schedule_work(_work)
+# define compat_schedule_delayed_work(_work, _delay)      \
+   schedule_delayed_work(_work, _delay)
+# define COMPAT_WORK_GET_DATA(_p, _type)                  \
+   (_type *)(_p)
+# define COMPAT_DELAYED_WORK_GET_DATA(_p, _type, _member) \
+   (_type *)(_p)
+
+#else  /* } Linux >= 2.6.20 { */
+typedef struct work_struct compat_work;
+typedef struct delayed_work compat_delayed_work;
+typedef struct work_struct * compat_work_arg;
+typedef struct work_struct * compat_delayed_work_arg;
+# define COMPAT_INIT_WORK(_work, _func, _data)            \
+   INIT_WORK(_work, _func)
+# define COMPAT_INIT_DELAYED_WORK(_work, _func, _data)    \
+   INIT_DELAYED_WORK(_work, _func)
+# define compat_schedule_work(_work)                      \
+   schedule_work(_work)
+# define compat_schedule_delayed_work(_work, _delay)      \
+   schedule_delayed_work(_work, _delay)
+# define COMPAT_WORK_GET_DATA(_p, _type)                  \
+   container_of(_p, _type, work)
+# define COMPAT_DELAYED_WORK_GET_DATA(_p, _type, _member) \
+   container_of(_p, _type, _member.work)
+#endif /* } */
+
+#endif /* __COMPAT_WORKQUEUE_H__ */
+
--- kernel/linux-2.6.26.3/drivers/misc/vsock/driver-config.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vsock/driver-config.h	2008-09-03 10:03:56.000000000 -0500
@@ -0,0 +1,77 @@
+/*********************************************************
+ * Copyright (C) 1998 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * Sets the proper defines from the Linux header files
+ *
+ * This file must be included before the inclusion of any kernel header file,
+ * with the exception of linux/autoconf.h and linux/version.h --hpreg
+ */
+
+#ifndef __VMX_CONFIG_H__
+#define __VMX_CONFIG_H__
+
+#define INCLUDE_ALLOW_VMCORE
+#define INCLUDE_ALLOW_VMMON
+#define INCLUDE_ALLOW_MODULE
+#define INCLUDE_ALLOW_VMNIXMOD
+
+#include <linux/autoconf.h>
+#include "compat_version.h"
+
+/*
+ * We rely on Kernel Module support.  Check here.
+ */
+#ifndef CONFIG_MODULES
+#   error "No Module support in this kernel.  Please configure with CONFIG_MODULES"
+#endif
+
+/*
+ * 2.2 kernels still use __SMP__ (derived from CONFIG_SMP
+ * in the main Makefile), so we do it here.
+ */
+
+#ifdef CONFIG_SMP
+#   define __SMP__ 1
+#endif
+
+#if defined(CONFIG_MODVERSIONS) && defined(KERNEL_2_1)
+#   if LINUX_VERSION_CODE < KERNEL_VERSION(2,5,60)
+/*
+ * MODVERSIONS might be already defined when using kernel's Makefiles.
+ */
+#      ifndef MODVERSIONS
+#         define MODVERSIONS
+#      endif
+#      include <linux/modversions.h>
+#   endif
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 24)
+/*
+ * Force the uintptr_t definition to come from linux/types.h instead of vm_basic_types.h.
+ */
+#   include <linux/types.h>
+#   define _STDINT_H 1
+#endif
+
+#ifndef __KERNEL__
+#   define __KERNEL__
+#endif
+
+#endif
--- kernel/linux-2.6.26.3/drivers/misc/vsock/driverLog.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vsock/driverLog.c	2008-09-03 10:02:58.000000000 -0500
@@ -0,0 +1,207 @@
+/*********************************************************
+ * Copyright (C) 2007 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+
+/*
+ * driverLog.c --
+ *
+ *      Common logging functions for Linux kernel modules.
+ */
+
+#include "driver-config.h"
+#include "compat_kernel.h"
+#include "compat_sched.h"
+#include <asm/current.h>
+
+#include "driverLog.h"
+
+#define LINUXLOG_BUFFER_SIZE 1024
+
+static const char *driverLogPrefix = "";
+
+/*
+ * vsnprintf was born in 2.4.10. Fall back on vsprintf if we're
+ * an older kernel.
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 10)
+# define vsnprintf(str, size, fmt, args) vsprintf(str, fmt, args)
+#endif
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * DriverLog_Init --
+ *
+ *      Initializes the Linux logging.
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+void
+DriverLog_Init(const char *prefix) // IN
+{
+   driverLogPrefix = prefix ? prefix : "";
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * DriverLogPrint --
+ *
+ *      Log error message from a Linux module.
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      None.
+ *
+ *----------------------------------------------------------------------
+ */
+
+static void
+DriverLogPrint(const char *level,     // IN: KERN_* constant
+               const char *fmt,       // IN: error format string
+               va_list args)          // IN: arguments for format string
+{
+   static char staticBuf[LINUXLOG_BUFFER_SIZE];
+   char stackBuf[128];
+   va_list args2;
+   const char *buf;
+
+   /*
+    * By default, use a small buffer on the stack (thread safe). If it is too
+    * small, fall back to a larger static buffer (not thread safe).
+    */
+   va_copy(args2, args);
+   if (vsnprintf(stackBuf, sizeof stackBuf, fmt, args2) < sizeof stackBuf) {
+      buf = stackBuf;
+   } else {
+      vsnprintf(staticBuf, sizeof staticBuf, fmt, args);
+      buf = staticBuf;
+   }
+   va_end(args2);
+
+   printk("%s%s[%d]: %s", level, driverLogPrefix, current->pid, buf);
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * Warning --
+ *
+ *      Warning messages from kernel module: logged into kernel log
+ *      as warnings.
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      None.
+ *
+ *----------------------------------------------------------------------
+ */
+
+void
+Warning(const char *fmt, ...)  // IN: warning format string
+{
+   va_list args;
+
+   va_start(args, fmt);
+   DriverLogPrint(KERN_WARNING, fmt, args);
+   va_end(args);
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * Log --
+ *
+ *      Log messages from kernel module: logged into kernel log
+ *      as debug information.
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      None.
+ *
+ *----------------------------------------------------------------------
+ */
+
+void
+Log(const char *fmt, ...)  // IN: log format string
+{
+   va_list args;
+
+   /*
+    * Use the kernel log with at least a KERN_DEBUG level
+    * so it doesn't garbage the screen at (re)boot time on RedHat 6.0.
+    */
+
+   va_start(args, fmt);
+   DriverLogPrint(KERN_DEBUG, fmt, args);
+   va_end(args);
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * Panic --
+ *
+ *      ASSERTION failures and Panics from kernel module get here.
+ *      Message is logged to the kernel log and on console.
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      Never returns
+ *
+ *----------------------------------------------------------------------
+ */
+
+void
+Panic(const char *fmt, ...)  // IN: panic format string
+{
+   va_list args;
+
+   va_start(args, fmt);
+   DriverLogPrint(KERN_EMERG, fmt, args);
+   va_end(args);
+
+#ifdef BUG
+   BUG();
+#else
+   /* Should die with %cs unwritable, or at least with page fault. */
+   asm volatile("movb $0, %cs:(0)");
+#endif
+
+   while (1);
+}
--- kernel/linux-2.6.26.3/drivers/misc/vsock/driverLog.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vsock/driverLog.h	2008-09-03 09:57:35.000000000 -0500
@@ -0,0 +1,37 @@
+/*********************************************************
+ * Copyright (C) 2007 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+
+/*
+ * driverLog.h --
+ *
+ *      Logging functions for Linux kernel modules.
+ */
+
+#ifndef __DRIVERLOG_H__
+#define __DRIVERLOG_H__
+
+/*
+ * The definitions of Warning(), Log(), and Panic() come from vm_assert.h for
+ * consistency.
+ */
+#include "vm_assert.h"
+
+void DriverLog_Init(const char *prefix);
+
+#endif /* __DRIVERLOG_H__ */
--- kernel/linux-2.6.26.3/drivers/misc/vsock/Makefile	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vsock/Makefile	2008-09-03 09:57:35.000000000 -0500
@@ -0,0 +1,28 @@
+#############################################################
+# Copyright 1998 VMware, Inc.  All rights reserved. 
+#############################################################
+####
+#### This program is free software; you can redistribute it and/or modify it
+#### under the terms of the GNU General Public License as published by the
+#### Free Software Foundation version 2 and no later version.
+####
+#### This program is distributed in the hope that it will be useful, but
+#### WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+#### or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+#### for more details.
+####
+#### You should have received a copy of the GNU General Public License along
+#### with this program; if not, write to the Free Software Foundation, Inc.,
+#### 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+
+####
+####  VMware kernel module Makefile to be distributed externally
+####
+####
+
+obj-$(CONFIG_VSOCK) += vsock.o
+
+vsock-objs := af_vsock.o driverLog.o util.o vsockAddr.o
+
+EXTRA_CFLAGS += -DVMW_USING_KBUILD -DVMW_HAVE_EPOLL -DVMW_HAVE_SET_USER_NICE -DVMW_HAVE_NEW_SKFILTER
+EXTRA_CFLAGS += -DVMX86_TOOLS
--- kernel/linux-2.6.26.3/drivers/misc/vsock/util.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vsock/util.c	2008-09-03 10:02:58.000000000 -0500
@@ -0,0 +1,857 @@
+/*********************************************************
+ * Copyright (C) 2007 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+
+/*
+ * util.c --
+ *
+ *      Utility functions for Linux VSocket module.
+ */
+
+#include "driver-config.h"
+#include <linux/socket.h>
+#include "compat_sock.h"
+#include "compat_list.h"
+
+#include "af_vsock.h"
+#include "util.h"
+
+struct list_head vsockBindTable[VSOCK_HASH_SIZE + 1];
+struct list_head vsockConnectedTable[VSOCK_HASH_SIZE];
+
+spinlock_t vsockTableLock = SPIN_LOCK_UNLOCKED;
+
+/*
+ * snprintf() wasn't exported until 2.4.10: fall back on sprintf in those
+ * cases.  It's okay since this is only for the debug function for logging
+ * packets.
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 10)
+#define snprintf(str, size, fmt, args...) sprintf(str, fmt, ## args)
+#endif
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VSockVmciLogPkt --
+ *
+ *    Logs the provided packet.
+ *
+ * Results:
+ *    None.
+ *
+ * Side effects:
+ *    None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+void
+VSockVmciLogPkt(char const *function,   // IN
+                uint32 line,            // IN
+                VSockPacket *pkt)       // IN
+{
+   char buf[256];
+   char *cur = buf;
+   int left = sizeof buf;
+   int written = 0;
+   char *typeStrings[] = {
+      [VSOCK_PACKET_TYPE_INVALID]        = "INVALID",
+      [VSOCK_PACKET_TYPE_REQUEST]        = "REQUEST",
+      [VSOCK_PACKET_TYPE_NEGOTIATE]      = "NEGOTIATE",
+      [VSOCK_PACKET_TYPE_OFFER]          = "OFFER",
+      [VSOCK_PACKET_TYPE_ATTACH]         = "ATTACH",
+      [VSOCK_PACKET_TYPE_WROTE]          = "WROTE",
+      [VSOCK_PACKET_TYPE_READ]           = "READ",
+      [VSOCK_PACKET_TYPE_RST]            = "RST",
+      [VSOCK_PACKET_TYPE_SHUTDOWN]       = "SHUTDOWN",
+      [VSOCK_PACKET_TYPE_WAITING_WRITE]  = "WAITING_WRITE",
+      [VSOCK_PACKET_TYPE_WAITING_READ]   = "WAITING_READ",
+   };
+
+   written = snprintf(cur, left, "PKT: %u:%u -> %u:%u",
+                      VMCI_HANDLE_TO_CONTEXT_ID(pkt->dg.src),
+                      pkt->srcPort,
+                      VMCI_HANDLE_TO_CONTEXT_ID(pkt->dg.dst),
+                      pkt->dstPort);
+   if (written >= left) {
+      goto error;
+   }
+
+   left -= written;
+   cur += written;
+
+   switch (pkt->type) {
+   case VSOCK_PACKET_TYPE_REQUEST:
+   case VSOCK_PACKET_TYPE_NEGOTIATE:
+      written = snprintf(cur, left, ", %s, size = %"FMT64"u",
+                         typeStrings[pkt->type], pkt->u.size);
+      break;
+
+   case VSOCK_PACKET_TYPE_OFFER:
+   case VSOCK_PACKET_TYPE_ATTACH:
+      written = snprintf(cur, left, ", %s, handle = %u:%u",
+                         typeStrings[pkt->type],
+                         VMCI_HANDLE_TO_CONTEXT_ID(pkt->u.handle),
+                         VMCI_HANDLE_TO_RESOURCE_ID(pkt->u.handle));
+      break;
+
+   case VSOCK_PACKET_TYPE_WROTE:
+   case VSOCK_PACKET_TYPE_READ:
+   case VSOCK_PACKET_TYPE_RST:
+      written = snprintf(cur, left, ", %s", typeStrings[pkt->type]);
+      break;
+   case VSOCK_PACKET_TYPE_SHUTDOWN: {
+      Bool recv;
+      Bool send;
+
+      recv = pkt->u.mode & RCV_SHUTDOWN;
+      send = pkt->u.mode & SEND_SHUTDOWN;
+      written = snprintf(cur, left, ", %s, mode = %c%c",
+                         typeStrings[pkt->type],
+                         recv ? 'R' : ' ',
+                         send ? 'S' : ' ');
+   }
+   break;
+
+   case VSOCK_PACKET_TYPE_WAITING_WRITE:
+   case VSOCK_PACKET_TYPE_WAITING_READ:
+      written = snprintf(cur, left, ", %s, generation = %"FMT64"u, "
+                         "offset = %"FMT64"u", typeStrings[pkt->type],
+                         pkt->u.wait.generation, pkt->u.wait.offset);
+
+      break;
+
+   default:
+      written = snprintf(cur, left, ", unrecognized type");
+   }
+
+   if (written >= left) {
+      goto error;
+   }
+
+   left -= written;
+   cur += written;
+
+   written = snprintf(cur, left, "  [%s:%u]\n", function, line);
+   if (written >= left) {
+      goto error;
+   }
+
+   Log("%s", buf);
+
+   return;
+
+error:
+   Log("could not log packet\n");
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VSockVmciInitTables --
+ *
+ *    Initializes the tables used for socket lookup.
+ *
+ * Results:
+ *    None.
+ *
+ * Side effects:
+ *    None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+void
+VSockVmciInitTables(void)
+{
+   uint32 i;
+
+   for (i = 0; i < ARRAYSIZE(vsockBindTable); i++) {
+      INIT_LIST_HEAD(&vsockBindTable[i]);
+   }
+
+   for (i = 0; i < ARRAYSIZE(vsockConnectedTable); i++) {
+      INIT_LIST_HEAD(&vsockConnectedTable[i]);
+   }
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * __VSockVmciInsertBound --
+ *
+ *    Inserts socket into the bound table.
+ *
+ *    Note that this assumes any necessary locks are held.
+ *
+ * Results:
+ *    None.
+ *
+ * Side effects:
+ *    The reference count for sk is incremented.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+void
+__VSockVmciInsertBound(struct list_head *list,          // IN
+                       struct sock *sk)                 // IN
+{
+   VSockVmciSock *vsk;
+
+   ASSERT(list);
+   ASSERT(sk);
+
+   vsk = vsock_sk(sk);
+
+   sock_hold(sk);
+   list_add(&vsk->boundTable, list);
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * __VSockVmciInsertConnected --
+ *
+ *    Inserts socket into the connected table.
+ *
+ *    Note that this assumes any necessary locks are held.
+ *
+ * Results:
+ *    None.
+ *
+ * Side effects:
+ *    The reference count for sk is incremented.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+void
+__VSockVmciInsertConnected(struct list_head *list,   // IN
+                           struct sock *sk)          // IN
+{
+   VSockVmciSock *vsk;
+
+   ASSERT(list);
+   ASSERT(sk);
+
+   vsk = vsock_sk(sk);
+
+   sock_hold(sk);
+   list_add(&vsk->connectedTable, list);
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * __VSockVmciRemoveBound --
+ *
+ *    Removes socket from the bound table.
+ *
+ *    Note that this assumes any necessary locks are held.
+ *
+ * Results:
+ *    None.
+ *
+ * Side effects:
+ *    The reference count for sk is decremented.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+void
+__VSockVmciRemoveBound(struct sock *sk)  // IN
+{
+   VSockVmciSock *vsk;
+
+   ASSERT(sk);
+   ASSERT(__VSockVmciInBoundTable(sk));
+
+   vsk = vsock_sk(sk);
+
+   list_del_init(&vsk->boundTable);
+   sock_put(sk);
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * __VSockVmciRemoveConnected --
+ *
+ *    Removes socket from the connected table.
+ *
+ *    Note that this assumes any necessary locks are held.
+ *
+ * Results:
+ *    None.
+ *
+ * Side effects:
+ *    The reference count for sk is decremented.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+void
+__VSockVmciRemoveConnected(struct sock *sk)  // IN
+{
+   VSockVmciSock *vsk;
+
+   ASSERT(sk);
+   ASSERT(__VSockVmciInConnectedTable(sk));
+
+   vsk = vsock_sk(sk);
+
+   list_del_init(&vsk->connectedTable);
+   sock_put(sk);
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * __VSockVmciFindBoundSocket --
+ *
+ *    Finds the socket corresponding to the provided address in the bound
+ *    sockets hash table.
+ *
+ *    Note that this assumes any necessary locks are held.
+ *
+ * Results:
+ *    The sock structure if found, NULL if not found.
+ *
+ * Side effects:
+ *    None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+struct sock *
+__VSockVmciFindBoundSocket(struct sockaddr_vm *addr)  // IN
+{
+   VSockVmciSock *vsk;
+   struct sock *sk;
+
+   ASSERT(addr);
+
+
+   list_for_each_entry(vsk, vsockBoundSockets(addr), boundTable) {
+      if (VSockAddr_EqualsAddr(addr, &vsk->localAddr)) {
+         sk = sk_vsock(vsk);
+
+         /* We only store stream sockets in the bound table. */
+         ASSERT(sk->compat_sk_socket ?
+                   sk->compat_sk_socket->type == SOCK_STREAM :
+                   1);
+         goto found;
+      }
+   }
+
+   sk = NULL;
+found:
+   return sk;
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * __VSockVmciFindConnectedSocket --
+ *
+ *    Finds the socket corresponding to the provided addresses in the connected
+ *    sockets hash table.
+ *
+ *    Note that this assumes any necessary locks are held.
+ *
+ * Results:
+ *    The sock structure if found, NULL if not found.
+ *
+ * Side effects:
+ *    None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+struct sock *
+__VSockVmciFindConnectedSocket(struct sockaddr_vm *src,    // IN
+                               struct sockaddr_vm *dst)    // IN
+{
+   VSockVmciSock *vsk;
+   struct sock *sk;
+
+   ASSERT(src);
+   ASSERT(dst);
+
+   list_for_each_entry(vsk, vsockConnectedSockets(src, dst), connectedTable) {
+      if (VSockAddr_EqualsAddr(src, &vsk->remoteAddr) &&
+          VSockAddr_EqualsAddr(dst, &vsk->localAddr)) {
+         sk = sk_vsock(vsk);
+         goto found;
+      }
+   }
+
+   sk = NULL;
+found:
+   return sk;
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * __VSockVmciInBoundTable --
+ *
+ *    Determines whether the provided socket is in the bound table.
+ *
+ * Results:
+ *    TRUE is socket is in bound table, FALSE otherwise.
+ *
+ * Side effects:
+ *    None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+Bool
+__VSockVmciInBoundTable(struct sock *sk)     // IN
+{
+   VSockVmciSock *vsk;
+
+   ASSERT(sk);
+
+   vsk = vsock_sk(sk);
+
+   return !list_empty(&vsk->boundTable);
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * __VSockVmciInConnectedTable --
+ *
+ *    Determines whether the provided socket is in the connected table.
+ *
+ * Results:
+ *    TRUE is socket is in connected table, FALSE otherwise.
+ *
+ * Side effects:
+ *    None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+Bool
+__VSockVmciInConnectedTable(struct sock *sk)     // IN
+{
+   VSockVmciSock *vsk;
+
+   ASSERT(sk);
+
+   vsk = vsock_sk(sk);
+
+   return !list_empty(&vsk->connectedTable);
+}
+
+
+#ifdef VMX86_TOOLS
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VSockVmciGetPending --
+ *
+ *    Retrieves a pending connection that matches the addresses specified in
+ *    the provided packet.
+ *
+ *    Assumes the socket lock is held for listener.
+ *
+ * Results:
+ *    Socket of the pending connection on success, NULL if not found.
+ *
+ * Side effects:
+ *    A reference is held on the socket until the release function is called.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+struct sock *
+VSockVmciGetPending(struct sock *listener,      // IN: listening socket
+                    VSockPacket *pkt)           // IN: incoming packet
+{
+   VSockVmciSock *vlistener;
+   VSockVmciSock *vpending;
+   struct sock *pending;
+
+   ASSERT(listener);
+   ASSERT(pkt);
+
+   vlistener = vsock_sk(listener);
+
+   list_for_each_entry(vpending, &vlistener->pendingLinks, pendingLinks) {
+      struct sockaddr_vm src;
+      struct sockaddr_vm dst;
+
+      VSockAddr_Init(&src, VMCI_HANDLE_TO_CONTEXT_ID(pkt->dg.src), pkt->srcPort);
+      VSockAddr_Init(&dst, VMCI_HANDLE_TO_CONTEXT_ID(pkt->dg.dst), pkt->dstPort);
+
+      if (VSockAddr_EqualsAddr(&src, &vpending->remoteAddr) &&
+          VSockAddr_EqualsAddr(&dst, &vpending->localAddr)) {
+         pending = sk_vsock(vpending);
+         sock_hold(pending);
+         goto found;
+      }
+   }
+
+   pending = NULL;
+found:
+   return pending;
+
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VSockVmciReleasePending --
+ *
+ *    Releases the reference on a socket previously obtained by a call to
+ *    VSockVmciGetPending().
+ *
+ * Results:
+ *    None.
+ *
+ * Side effects:
+ *    The socket may be freed if this was the last reference.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+void
+VSockVmciReleasePending(struct sock *pending)   // IN: pending connection
+{
+   ASSERT(pending);
+
+   sock_put(pending);
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VSockVmciAddPending --
+ *
+ *    Adds a pending connection on listener's pending list.
+ *
+ *    Assumes the socket lock is held for listener.
+ *    Assumes the socket lock is held for pending.
+ *
+ * Results:
+ *    None.
+ *
+ * Side effects:
+ *    The reference count of the sockets is incremented.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+void
+VSockVmciAddPending(struct sock *listener,  // IN: listening socket
+                    struct sock *pending)   // IN: pending connection
+{
+   VSockVmciSock *vlistener;
+   VSockVmciSock *vpending;
+
+   ASSERT(listener);
+   ASSERT(pending);
+
+   vlistener = vsock_sk(listener);
+   vpending = vsock_sk(pending);
+
+   sock_hold(pending);
+   sock_hold(listener);
+   list_add_tail(&vpending->pendingLinks, &vlistener->pendingLinks);
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VSockVmciRemovePending --
+ *
+ *    Removes a pending connection from the listener's pending list.
+ *
+ *    Assumes the socket lock is held for listener.
+ *    Assumes the socket lock is held for pending.
+ *
+ * Results:
+ *    None.
+ *
+ * Side effects:
+ *    The reference count of the sockets is decremented.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+void
+VSockVmciRemovePending(struct sock *listener,   // IN: listening socket
+                       struct sock *pending)    // IN: pending connection
+{
+   VSockVmciSock *vlistener;
+   VSockVmciSock *vpending;
+
+   ASSERT(listener);
+   ASSERT(pending);
+
+   vlistener = vsock_sk(listener);
+   vpending = vsock_sk(pending);
+
+   list_del_init(&vpending->pendingLinks);
+   sock_put(listener);
+   sock_put(pending);
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VSockVmciEnqueueAccept --
+ *
+ *    Enqueues the connected socket on the listening socket's accepting
+ *    queue.
+ *
+ *    Assumes the socket lock is held for listener.
+ *    Assumes the socket lock is held for connected.
+ *
+ * Results:
+ *    None.
+ *
+ * Side effects:
+ *    The sockets' reference counts are incremented.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+void
+VSockVmciEnqueueAccept(struct sock *listener,    // IN: listening socket
+                       struct sock *connected)   // IN: connected socket
+{
+   VSockVmciSock *vlistener;
+   VSockVmciSock *vconnected;
+
+   ASSERT(listener);
+   ASSERT(connected);
+
+   vlistener = vsock_sk(listener);
+   vconnected = vsock_sk(connected);
+
+   sock_hold(connected);
+   sock_hold(listener);
+   list_add_tail(&vconnected->acceptQueue, &vlistener->acceptQueue);
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VSockVmciDequeueAccept --
+ *
+ *    Dequeues the next connected socket from the listening socket's accept
+ *    queue.
+ *
+ *    Assumes the socket lock is held for listener.
+ *
+ *    Note that the caller must call sock_put() on the returned socket once it
+ *    is done with the socket.
+ *
+ * Results:
+ *    The next socket from the queue, or NULL if the queue is empty.
+ *
+ * Side effects:
+ *    The reference count of the listener is decremented.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+struct sock *
+VSockVmciDequeueAccept(struct sock *listener)     // IN: listening socket
+{
+   VSockVmciSock *vlistener;
+   VSockVmciSock *vconnected;
+
+   ASSERT(listener);
+
+   vlistener = vsock_sk(listener);
+
+   if (list_empty(&vlistener->acceptQueue)) {
+      return NULL;
+   }
+
+   vconnected = list_entry(vlistener->acceptQueue.next,
+                           VSockVmciSock, acceptQueue);
+   ASSERT(vconnected);
+
+   list_del_init(&vconnected->acceptQueue);
+   sock_put(listener);
+   /*
+    * The caller will need a reference on the connected socket so we let it
+    * call sock_put().
+    */
+
+   ASSERT(sk_vsock(vconnected));
+   return sk_vsock(vconnected);
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VSockVmciRemoveAccept --
+ *
+ *    Removes a socket from the accept queue of a listening socket.
+ *
+ *    Assumes the socket lock is held for listener.
+ *    Assumes the socket lock is held for connected.
+ *
+ * Results:
+ *    None.
+ *
+ * Side effects:
+ *    The sockets' reference counts are decremented.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+void
+VSockVmciRemoveAccept(struct sock *listener,    // IN: listening socket
+                      struct sock *connected)   // IN: connected socket
+{
+   VSockVmciSock *vconnected;
+
+   ASSERT(listener);
+   ASSERT(connected);
+
+   if (!VSockVmciInAcceptQueue(connected)) {
+      return;
+   }
+
+   vconnected = vsock_sk(connected);
+   ASSERT(vconnected->listener == listener);
+
+   list_del_init(&vconnected->acceptQueue);
+   sock_put(listener);
+   sock_put(connected);
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VSockVmciInAcceptQueue --
+ *
+ *    Determines whether a socket is on an accept queue.
+ *
+ *    Assumes the socket lock is held for sk.
+ *
+ * Results:
+ *    TRUE if the socket is in an accept queue, FALSE otherwise.
+ *
+ * Side effects:
+ *    None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+Bool
+VSockVmciInAcceptQueue(struct sock *sk)   // IN: socket
+{
+   ASSERT(sk);
+
+   /*
+    * If our accept queue isn't empty, it means we're linked into some listener
+    * socket's accept queue.
+    */
+   return !VSockVmciIsAcceptQueueEmpty(sk);
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VSockVmciIsAcceptQueueEmpty --
+ *
+ *    Determines whether the provided socket's accept queue is empty.
+ *
+ *    Assumes the socket lock is held for sk.
+ *
+ * Results:
+ *    TRUE if the socket's accept queue is empty, FALSE otherwsise.
+ *
+ * Side effects:
+ *    None.
+ *
+ *
+ *----------------------------------------------------------------------------
+ */
+
+Bool
+VSockVmciIsAcceptQueueEmpty(struct sock *sk)    // IN: socket
+{
+   VSockVmciSock *vsk;
+
+   ASSERT(sk);
+
+   vsk = vsock_sk(sk);
+   return list_empty(&vsk->acceptQueue);
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VSockVmciIsPending --
+ *
+ *    Determines whether a socket is pending.
+ *
+ *    Assumes the socket lock is held for sk.
+ *
+ * Results:
+ *    TRUE if the socket is pending, FALSE otherwise.
+ *
+ * Side effects:
+ *    None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+Bool
+VSockVmciIsPending(struct sock *sk)     // IN: socket
+{
+   VSockVmciSock *vsk;
+
+   ASSERT(sk);
+
+   vsk = vsock_sk(sk);
+   return !list_empty(&vsk->pendingLinks);
+}
+#endif
--- kernel/linux-2.6.26.3/drivers/misc/vsock/util.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vsock/util.h	2008-09-03 09:57:35.000000000 -0500
@@ -0,0 +1,384 @@
+/*********************************************************
+ * Copyright (C) 2007 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+
+/*
+ * util.h --
+ *
+ *      Utility functions for Linux VSocket module.
+ */
+
+#ifndef __UTIL_H__
+#define __UTIL_H__
+
+#include "driver-config.h"
+#include "compat_sock.h"
+#include "compat_spinlock.h"
+
+#include "vsockCommon.h"
+#include "vsockPacket.h"
+
+/*
+ * Each bound VSocket is stored in the bind hash table and each connected
+ * VSocket is stored in the connected hash table.
+ *
+ * Unbound sockets are all put on the same list attached to the end of the hash
+ * table (vsockUnboundSockets).  Bound sockets are added to the hash table in
+ * the bucket that their local address hashes to (vsockBoundSockets(addr)
+ * represents the list that addr hashes to).
+ *
+ * Specifically, we initialize the vsockBindTable array to a size of
+ * VSOCK_HASH_SIZE + 1 so that vsockBindTable[0] through
+ * vsockBindTable[VSOCK_HASH_SIZE - 1] are for bound sockets and
+ * vsockBindTable[VSOCK_HASH_SIZE] is for unbound sockets.  The hash function
+ * mods with VSOCK_HASH_SIZE - 1 to ensure this.
+ */
+#define VSOCK_HASH_SIZE         251
+#define LAST_RESERVED_PORT      1023
+#define MAX_PORT_RETRIES        24
+
+extern struct list_head vsockBindTable[VSOCK_HASH_SIZE + 1];
+extern struct list_head vsockConnectedTable[VSOCK_HASH_SIZE];
+
+extern spinlock_t vsockTableLock;
+
+#define VSOCK_HASH(addr)        ((addr)->svm_port % (VSOCK_HASH_SIZE - 1))
+#define vsockBoundSockets(addr) (&vsockBindTable[VSOCK_HASH(addr)])
+#define vsockUnboundSockets     (&vsockBindTable[VSOCK_HASH_SIZE])
+
+/* XXX This can probably be implemented in a better way. */
+#define VSOCK_CONN_HASH(src, dst)       \
+   (((src)->svm_cid ^ (dst)->svm_port) % (VSOCK_HASH_SIZE - 1))
+#define vsockConnectedSockets(src, dst) \
+   (&vsockConnectedTable[VSOCK_CONN_HASH(src, dst)])
+#define vsockConnectedSocketsVsk(vsk)    \
+   vsockConnectedSockets(&(vsk)->remoteAddr, &(vsk)->localAddr)
+
+/*
+ * Prototypes.
+ */
+
+void VSockVmciLogPkt(char const *function, uint32 line, VSockPacket *pkt);
+
+void VSockVmciInitTables(void);
+void __VSockVmciInsertBound(struct list_head *list, struct sock *sk);
+void __VSockVmciInsertConnected(struct list_head *list, struct sock *sk);
+void __VSockVmciRemoveBound(struct sock *sk);
+void __VSockVmciRemoveConnected(struct sock *sk);
+struct sock *__VSockVmciFindBoundSocket(struct sockaddr_vm *addr);
+struct sock *__VSockVmciFindConnectedSocket(struct sockaddr_vm *src,
+                                            struct sockaddr_vm *dst);
+Bool __VSockVmciInBoundTable(struct sock *sk);
+Bool __VSockVmciInConnectedTable(struct sock *sk);
+
+#ifdef VMX86_TOOLS
+struct sock *VSockVmciGetPending(struct sock *listener, VSockPacket *pkt);
+void VSockVmciReleasePending(struct sock *pending);
+void VSockVmciAddPending(struct sock *listener, struct sock *pending);
+void VSockVmciRemovePending(struct sock *listener, struct sock *pending);
+void VSockVmciEnqueueAccept(struct sock *listener, struct sock *connected);
+struct sock *VSockVmciDequeueAccept(struct sock *listener);
+void VSockVmciRemoveAccept(struct sock *listener, struct sock *connected);
+Bool VSockVmciInAcceptQueue(struct sock *sk);
+Bool VSockVmciIsAcceptQueueEmpty(struct sock *sk);
+Bool VSockVmciIsPending(struct sock *sk);
+#endif
+
+static INLINE void VSockVmciInsertBound(struct list_head *list, struct sock *sk);
+static INLINE void VSockVmciInsertConnected(struct list_head *list, struct sock *sk);
+static INLINE void VSockVmciRemoveBound(struct sock *sk);
+static INLINE void VSockVmciRemoveConnected(struct sock *sk);
+static INLINE struct sock *VSockVmciFindBoundSocket(struct sockaddr_vm *addr);
+static INLINE struct sock *VSockVmciFindConnectedSocket(struct sockaddr_vm *src,
+                                                        struct sockaddr_vm *dst);
+static INLINE Bool VSockVmciInBoundTable(struct sock *sk);
+static INLINE Bool VSockVmciInConnectedTable(struct sock *sk);
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VSockVmciInsertBound --
+ *
+ *    Inserts socket into the bound table.
+ *
+ *    Note that it is important to invoke the bottom-half versions of the
+ *    spinlock functions since these may be called from tasklets.
+ *
+ * Results:
+ *    None.
+ *
+ * Side effects:
+ *    vsockTableLock is acquired and released.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+static INLINE void
+VSockVmciInsertBound(struct list_head *list,    // IN
+                     struct sock *sk)           // IN
+{
+   ASSERT(list);
+   ASSERT(sk);
+
+   spin_lock_bh(&vsockTableLock);
+   __VSockVmciInsertBound(list, sk);
+   spin_unlock_bh(&vsockTableLock);
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VSockVmciInsertConnected --
+ *
+ *    Inserts socket into the connected table.
+ *
+ *    Note that it is important to invoke the bottom-half versions of the
+ *    spinlock functions since these may be called from tasklets.
+ *
+ * Results:
+ *    None.
+ *
+ * Side effects:
+ *    vsockTableLock is acquired and released.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+static INLINE void
+VSockVmciInsertConnected(struct list_head *list,    // IN
+                         struct sock *sk)           // IN
+{
+   ASSERT(list);
+   ASSERT(sk);
+
+   spin_lock_bh(&vsockTableLock);
+   __VSockVmciInsertConnected(list, sk);
+   spin_unlock_bh(&vsockTableLock);
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VSockVmciRemoveBound --
+ *
+ *    Removes socket from the bound list.
+ *
+ *    Note that it is important to invoke the bottom-half versions of the
+ *    spinlock functions since these may be called from tasklets.
+ *
+ * Results:
+ *    None.
+ *
+ * Side effects:
+ *    vsockTableLock is acquired and released.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+static INLINE void
+VSockVmciRemoveBound(struct sock *sk)                  // IN
+{
+   ASSERT(sk);
+
+   spin_lock_bh(&vsockTableLock);
+   __VSockVmciRemoveBound(sk);
+   spin_unlock_bh(&vsockTableLock);
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VSockVmciRemoveConnected --
+ *
+ *    Removes socket from the connected list.
+ *
+ *    Note that it is important to invoke the bottom-half versions of the
+ *    spinlock functions since these may be called from tasklets.
+ *
+ * Results:
+ *    None.
+ *
+ * Side effects:
+ *    vsockTableLock is acquired and released.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+static INLINE void
+VSockVmciRemoveConnected(struct sock *sk)                  // IN
+{
+   ASSERT(sk);
+
+   spin_lock_bh(&vsockTableLock);
+   __VSockVmciRemoveConnected(sk);
+   spin_unlock_bh(&vsockTableLock);
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VSockVmciFindBoundSocket --
+ *
+ *    Finds the socket corresponding to the provided address in the bound
+ *    sockets hash table.
+ *
+ *    Note that it is important to invoke the bottom-half versions of the
+ *    spinlock functions since these are called from tasklets.
+ *
+ * Results:
+ *    The sock structure if found, NULL on failure.
+ *
+ * Side effects:
+ *    vsockTableLock is acquired and released.
+ *    The socket's reference count is increased.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+static INLINE struct sock *
+VSockVmciFindBoundSocket(struct sockaddr_vm *addr) // IN
+{
+   struct sock *sk;
+
+   ASSERT(addr);
+
+   spin_lock_bh(&vsockTableLock);
+   sk = __VSockVmciFindBoundSocket(addr);
+   if (sk) {
+      sock_hold(sk);
+   }
+   spin_unlock_bh(&vsockTableLock);
+
+   return sk;
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VSockVmciFindConnectedSocket --
+ *
+ *    Finds the socket corresponding to the provided address in the connected
+ *    sockets hash table.
+ *
+ *    Note that it is important to invoke the bottom-half versions of the
+ *    spinlock functions since these are called from tasklets.
+ *
+ * Results:
+ *    The sock structure if found, NULL on failure.
+ *
+ * Side effects:
+ *    vsockTableLock is acquired and released.
+ *    The socket's reference count is increased.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+static INLINE struct sock *
+VSockVmciFindConnectedSocket(struct sockaddr_vm *src,   // IN
+                             struct sockaddr_vm *dst)   // IN
+{
+   struct sock *sk;
+
+   ASSERT(src);
+   ASSERT(dst);
+
+   spin_lock_bh(&vsockTableLock);
+   sk = __VSockVmciFindConnectedSocket(src, dst);
+   if (sk) {
+      sock_hold(sk);
+   }
+   spin_unlock_bh(&vsockTableLock);
+
+   return sk;
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VSockVmciInBoundTable --
+ *
+ *    Determines whether the provided socket is in the bound table.
+ *
+ *    Note that it is important to invoke the bottom-half versions of the
+ *    spinlock functions since these may be called from tasklets.
+ *
+ * Results:
+ *    TRUE is socket is in bound table, FALSE otherwise.
+ *
+ * Side effects:
+ *    vsockTableLock is acquired and released.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+static INLINE Bool
+VSockVmciInBoundTable(struct sock *sk)  // IN
+{
+   Bool ret;
+
+   ASSERT(sk);
+
+   spin_lock_bh(&vsockTableLock);
+   ret = __VSockVmciInBoundTable(sk);
+   spin_unlock_bh(&vsockTableLock);
+
+   return ret;
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VSockVmciInConnectedTable --
+ *
+ *    Determines whether the provided socket is in the connected table.
+ *
+ *    Note that it is important to invoke the bottom-half versions of the
+ *    spinlock functions since these may be called from tasklets.
+ *
+ * Results:
+ *    TRUE is socket is in connected table, FALSE otherwise.
+ *
+ * Side effects:
+ *    vsockTableLock is acquired and released.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+static INLINE Bool
+VSockVmciInConnectedTable(struct sock *sk)  // IN
+{
+   Bool ret;
+
+   ASSERT(sk);
+
+   spin_lock_bh(&vsockTableLock);
+   ret = __VSockVmciInConnectedTable(sk);
+   spin_unlock_bh(&vsockTableLock);
+
+   return ret;
+}
+
+#endif /* __UTIL_H__ */
--- kernel/linux-2.6.26.3/drivers/misc/vsock/vm_assert.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vsock/vm_assert.h	2008-09-03 10:04:09.000000000 -0500
@@ -0,0 +1,316 @@
+/*********************************************************
+ * Copyright (C) 1998-2004 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * vm_assert.h --
+ *
+ *	The basic assertion facility for all VMware code.
+ *
+ *	For proper use, see
+ *	http://vmweb.vmware.com/~mts/WebSite/guide/programming/asserts.html
+ */
+
+#ifndef _VM_ASSERT_H_
+#define _VM_ASSERT_H_
+
+#define INCLUDE_ALLOW_USERLEVEL
+#define INCLUDE_ALLOW_VMMEXT
+#define INCLUDE_ALLOW_MODULE
+#define INCLUDE_ALLOW_VMMON
+#define INCLUDE_ALLOW_VMNIXMOD
+#define INCLUDE_ALLOW_VMKERNEL
+#define INCLUDE_ALLOW_VMKDRIVERS
+#define INCLUDE_ALLOW_VMK_MODULE
+#define INCLUDE_ALLOW_DISTRIBUTE
+#define INCLUDE_ALLOW_VMCORE
+#define INCLUDE_ALLOW_VMIROM
+
+// XXX not necessary except some places include vm_assert.h improperly
+#include "vm_basic_types.h"
+#include "vm_basic_defs.h"
+
+
+/*
+ * XXX old file code
+ */
+
+#ifdef FILECODEINT
+#error "Don't define FILECODEINT.  It is obsolete."
+#endif
+#ifdef FILECODE
+#error "Don't define FILECODE.  It is obsolete."
+#endif
+
+
+/*
+ * Panic and log functions
+ */
+
+EXTERN void Log(const char *fmt, ...) PRINTF_DECL(1, 2);
+EXTERN void Warning(const char *fmt, ...) PRINTF_DECL(1, 2);
+EXTERN NORETURN void Panic(const char *fmt, ...) PRINTF_DECL(1, 2);
+
+EXTERN void LogThrottled(uint32 *count, const char *fmt, ...)
+            PRINTF_DECL(2, 3);
+EXTERN void WarningThrottled(uint32 *count, const char *fmt, ...)
+            PRINTF_DECL(2, 3);
+
+/* DB family:  messages which are parsed by logfile database system */
+#define WarningDB Warning
+#define LogDB Log
+#define WarningThrottledDB WarningThrottled
+#define LogThrottledDB LogThrottled
+
+
+/*
+ * Stress testing: redefine ASSERT_IFNOT() to taste
+ */
+
+#ifndef ASSERT_IFNOT
+   #ifdef __cplusplus
+      #define ASSERT_IFNOT(cond, panic) (UNLIKELY(!(cond)) ? (panic) : (void)0)
+   #else
+      #define ASSERT_IFNOT(cond, panic) (UNLIKELY(!(cond)) ? (panic) : 0)
+   #endif
+#endif
+
+
+/*
+ * Assert, panic, and log macros
+ *
+ * Some of these are redefined below undef !VMX86_DEBUG.
+ * ASSERT() is special cased because of interaction with Windows DDK.
+ */
+
+#if defined VMX86_DEBUG || defined ASSERT_ALWAYS_AVAILABLE
+#undef ASSERT
+#define ASSERT(cond) \
+           ASSERT_IFNOT(cond, _ASSERT_PANIC(AssertAssert))
+#endif
+#define ASSERT_BUG(bug, cond) \
+           ASSERT_IFNOT(cond, _ASSERT_PANIC_BUG(bug, AssertAssert))
+#define ASSERT_BUG_DEBUGONLY(bug, cond) ASSERT_BUG(bug, cond)
+
+#define PANIC()        _ASSERT_PANIC(AssertPanic)
+#define PANIC_BUG(bug) _ASSERT_PANIC_BUG(bug, AssertPanic)
+
+#define ASSERT_NOT_IMPLEMENTED(cond) \
+           ASSERT_IFNOT(cond, NOT_IMPLEMENTED())
+#define ASSERT_NOT_IMPLEMENTED_BUG(bug, cond) \
+           ASSERT_IFNOT(cond, NOT_IMPLEMENTED_BUG(bug))
+
+#define NOT_IMPLEMENTED()        _ASSERT_PANIC(AssertNotImplemented)
+#define NOT_IMPLEMENTED_BUG(bug) _ASSERT_PANIC_BUG(bug, AssertNotImplemented)
+
+#define NOT_REACHED()            _ASSERT_PANIC(AssertNotReached)
+#define NOT_REACHED_BUG(bug)     _ASSERT_PANIC_BUG(bug, AssertNotReached)
+
+#define ASSERT_MEM_ALLOC(cond) \
+           ASSERT_IFNOT(cond, _ASSERT_PANIC(AssertMemAlloc))
+
+#ifdef VMX86_DEVEL
+   #define ASSERT_LENGTH(real, expected) \
+              ASSERT_IFNOT((real) == (expected), \
+                 Panic(AssertLengthFmt, __FILE__, __LINE__, real, expected))
+#else
+   #define ASSERT_LENGTH(real, expected) ASSERT((real) == (expected))
+#endif
+
+#ifdef VMX86_DEVEL
+   #define ASSERT_DEVEL(cond) ASSERT(cond)
+#else
+   #define ASSERT_DEVEL(cond) ((void) 0)
+#endif
+
+#define ASSERT_NO_INTERRUPTS()  ASSERT(!INTERRUPTS_ENABLED())
+#define ASSERT_HAS_INTERRUPTS() ASSERT(INTERRUPTS_ENABLED())
+
+#define ASSERT_LOG_UNEXPECTED(bug, cond) \
+           (UNLIKELY(!(cond)) ? LOG_UNEXPECTED(bug) : 0)
+#ifdef VMX86_DEVEL
+   #define LOG_UNEXPECTED(bug) \
+              Warning(AssertUnexpectedFmt, __FILE__, __LINE__, bug)
+#else
+   #define LOG_UNEXPECTED(bug) \
+              Log(AssertUnexpectedFmt, __FILE__, __LINE__, bug)
+#endif
+
+#define ASSERT_NOT_TESTED(cond) (UNLIKELY(!(cond)) ? NOT_TESTED() : 0)
+#ifdef VMX86_DEVEL
+   #define NOT_TESTED() Warning(AssertNotTestedFmt, __FILE__, __LINE__)
+#else
+   #define NOT_TESTED() Log(AssertNotTestedFmt, __FILE__, __LINE__)
+#endif
+
+#define NOT_TESTED_ONCE()                                               \
+   do {                                                                 \
+      static Bool alreadyPrinted = FALSE;                               \
+      if (UNLIKELY(!alreadyPrinted)) {                                  \
+	 alreadyPrinted = TRUE;                                         \
+	 NOT_TESTED();                                                  \
+      }                                                                 \
+   } while (0)
+
+#define NOT_TESTED_1024()                                               \
+   do {                                                                 \
+      static uint16 count = 0;                                          \
+      if (UNLIKELY(count == 0)) { NOT_TESTED(); }                       \
+      count = (count + 1) & 1023;                                       \
+   } while (0)
+
+#define LOG_ONCE(_s)                                                    \
+   do {                                                                 \
+      static Bool logged = FALSE;                                       \
+      if (!logged) {                                                    \
+	 Log _s;                                                        \
+         logged = TRUE;                                                 \
+      }                                                                 \
+   } while (0)
+
+
+/*
+ * Redefine macros that are only in debug versions
+ */
+
+#if !defined VMX86_DEBUG && !defined ASSERT_ALWAYS_AVAILABLE // {
+
+#undef  ASSERT
+#define ASSERT(cond) ((void) 0)
+
+#undef  ASSERT_BUG_DEBUGONLY
+#define ASSERT_BUG_DEBUGONLY(bug, cond) ((void) 0)
+
+#undef  ASSERT_LENGTH
+#define ASSERT_LENGTH(real, expected) ((void) 0)
+
+/*
+ * Expand NOT_REACHED() as appropriate for each situation.
+ *
+ * Mainly, we want the compiler to infer the same control-flow
+ * information as it would from Panic().  Otherwise, different
+ * compilation options will lead to different control-flow-derived
+ * errors, causing some make targets to fail while others succeed.
+ *
+ * VC++ has the __assume() built-in function which we don't trust
+ * (see bug 43485); gcc has no such construct; we just panic in
+ * userlevel code.  The monitor doesn't want to pay the size penalty
+ * (measured at 212 bytes for the release vmm for a minimal infinite
+ * loop; panic would cost even more) so it does without and lives
+ * with the inconsistency.
+ */
+
+#ifdef VMM
+#undef  NOT_REACHED
+#define NOT_REACHED() ((void) 0)
+#else
+// keep debug definition
+#endif
+
+#undef  ASSERT_LOG_UNEXPECTED
+#define ASSERT_LOG_UNEXPECTED(bug, cond) ((void) 0)
+
+#undef LOG_UNEXPECTED
+#define LOG_UNEXPECTED(bug) ((void) 0)
+
+#undef  ASSERT_NOT_TESTED
+#define ASSERT_NOT_TESTED(cond) ((void) 0)
+#undef  NOT_TESTED
+#define NOT_TESTED() ((void) 0)
+#undef  NOT_TESTED_ONCE
+#define NOT_TESTED_ONCE() ((void) 0)
+#undef  NOT_TESTED_1024
+#define NOT_TESTED_1024() ((void) 0)
+
+#endif // !VMX86_DEBUG }
+
+
+/*
+ * Compile-time assertions.
+ *
+ * ASSERT_ON_COMPILE does not use the common
+ * switch (0) { case 0: case (e): ; } trick because some compilers (e.g. MSVC)
+ * generate code for it.
+ *
+ * The implementation uses both enum and typedef because the typedef alone is
+ * insufficient; gcc allows arrays to be declared with non-constant expressions
+ * (even in typedefs, where it makes no sense).
+ */
+
+#define ASSERT_ON_COMPILE(e) \
+   do { \
+      enum { AssertOnCompileMisused = ((e) ? 1 : -1) }; \
+      typedef char AssertOnCompileFailed[AssertOnCompileMisused]; \
+   } while (0)
+
+
+/*
+ * To put an ASSERT_ON_COMPILE() outside a function, wrap it
+ * in MY_ASSERTS().  The first parameter must be unique in
+ * each .c file where it appears.  For example,
+ *
+ * MY_ASSERTS(FS3_INT,
+ *    ASSERT_ON_COMPILE(sizeof(FS3_DiskLock) == 128);
+ *    ASSERT_ON_COMPILE(sizeof(FS3_DiskLockReserved) == DISK_BLOCK_SIZE);
+ *    ASSERT_ON_COMPILE(sizeof(FS3_DiskBlock) == DISK_BLOCK_SIZE);
+ *    ASSERT_ON_COMPILE(sizeof(Hardware_DMIUUID) == 16);
+ * )
+ *
+ * Caution: ASSERT() within MY_ASSERTS() is silently ignored.
+ * The same goes for anything else not evaluated at compile time.
+ */
+
+#define MY_ASSERTS(name, assertions) \
+   static INLINE void name(void) { \
+      assertions \
+   }
+
+
+/*
+ * Internal macros, functions, and strings
+ *
+ * The monitor wants to save space at call sites, so it has specialized
+ * functions for each situation.  User level wants to save on implementation
+ * so it uses generic functions.
+ */
+
+#if !defined VMM || defined MONITOR_APP // {
+
+#define _ASSERT_PANIC(name) \
+           Panic(_##name##Fmt "\n", __FILE__, __LINE__)
+#define _ASSERT_PANIC_BUG(bug, name) \
+           Panic(_##name##Fmt " bugNr=%d\n", __FILE__, __LINE__, bug)
+
+#define AssertLengthFmt     _AssertLengthFmt
+#define AssertUnexpectedFmt _AssertUnexpectedFmt
+#define AssertNotTestedFmt  _AssertNotTestedFmt
+
+#endif // }
+
+// these don't have newline so a bug can be tacked on
+#define _AssertPanicFmt            "PANIC %s:%d"
+#define _AssertAssertFmt           "ASSERT %s:%d"
+#define _AssertNotImplementedFmt   "NOT_IMPLEMENTED %s:%d"
+#define _AssertNotReachedFmt       "NOT_REACHED %s:%d"
+#define _AssertMemAllocFmt         "MEM_ALLOC %s:%d"
+
+// these are complete formats with newline
+#define _AssertLengthFmt           "LENGTH %s:%d r=%#x e=%#x\n"
+#define _AssertUnexpectedFmt       "UNEXPECTED %s:%d bugNr=%d\n"
+#define _AssertNotTestedFmt        "NOT_TESTED %s:%d\n"
+
+#endif /* ifndef _VM_ASSERT_H_ */
--- kernel/linux-2.6.26.3/drivers/misc/vsock/vm_atomic.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vsock/vm_atomic.h	2008-09-03 10:05:36.000000000 -0500
@@ -0,0 +1,2048 @@
+/*********************************************************
+ * Copyright (C) 1998 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * vm_atomic.h --
+ *
+ *	Atomic power
+ */
+
+#ifndef _ATOMIC_H_
+#define _ATOMIC_H_
+
+#define INCLUDE_ALLOW_USERLEVEL
+#define INCLUDE_ALLOW_VMMEXT
+#define INCLUDE_ALLOW_MODULE
+#define INCLUDE_ALLOW_VMMON
+#define INCLUDE_ALLOW_VMNIXMOD
+#define INCLUDE_ALLOW_VMKDRIVERS
+#define INCLUDE_ALLOW_VMK_MODULE
+#define INCLUDE_ALLOW_VMKERNEL
+#define INCLUDE_ALLOW_DISTRIBUTE
+#define INCLUDE_ALLOW_VMCORE
+#define INCLUDE_ALLOW_VMIROM
+
+#include "vm_basic_types.h"
+
+
+/* Basic atomic type: 32 bits */
+typedef struct Atomic_uint32 {
+   volatile uint32 value;
+} Atomic_uint32;
+
+
+/* Basic atomic type: 64 bits */
+typedef struct  Atomic_uint64 {
+   volatile uint64 value;
+} Atomic_uint64 ALIGNED(8);
+
+
+/*
+ * Prototypes for msft atomics.  These are defined & inlined by the
+ * compiler so no function definition is needed.  The prototypes are
+ * needed for c++.  Since amd64 compiler doesn't support inline asm we
+ * have to use these.  Unfortunately, we still have to use some inline asm
+ * for the 32 bit code since the and/or/xor implementations didn't show up
+ * untill xp or 2k3.
+ * 
+ * The declarations for the intrinsic functions were taken from ntddk.h
+ * in the DDK. The declarations must match otherwise the 64-bit c++
+ * compiler will complain about second linkage of the intrinsic functions.
+ * We define the intrinsic using the basic types corresponding to the 
+ * Windows typedefs. This avoids having to include windows header files
+ * to get to the windows types.
+ */
+#if defined(_MSC_VER) && _MSC_VER >= 1310
+#ifdef __cplusplus
+extern "C" {
+#endif
+long  _InterlockedExchange(long volatile*, long);
+long  _InterlockedCompareExchange(long volatile*, long, long);
+long  _InterlockedExchangeAdd(long volatile*, long);
+long  _InterlockedDecrement(long volatile*);
+long  _InterlockedIncrement(long volatile*);
+#pragma intrinsic(_InterlockedExchange, _InterlockedCompareExchange)
+#pragma intrinsic(_InterlockedExchangeAdd, _InterlockedDecrement)
+#pragma intrinsic(_InterlockedIncrement)
+
+#if defined(VM_X86_64)
+long     _InterlockedAnd(long volatile*, long);
+__int64  _InterlockedAnd64(__int64 volatile*, __int64);
+long     _InterlockedOr(long volatile*, long);
+__int64  _InterlockedOr64(__int64 volatile*, __int64);
+long     _InterlockedXor(long volatile*, long);
+__int64  _InterlockedXor64(__int64 volatile*, __int64);
+__int64  _InterlockedExchangeAdd64(__int64 volatile*, __int64);
+__int64  _InterlockedIncrement64(__int64 volatile*);
+__int64  _InterlockedDecrement64(__int64 volatile*);
+__int64  _InterlockedExchange64(__int64 volatile*, __int64);
+__int64  _InterlockedCompareExchange64(__int64 volatile*, __int64, __int64);
+#if !defined(_WIN64)
+#pragma intrinsic(_InterlockedAnd, _InterlockedAnd64)
+#pragma intrinsic(_InterlockedOr, _InterlockedOr64)
+#pragma intrinsic(_InterlockedXor, _InterlockedXor64)
+#pragma intrinsic(_InterlockedExchangeAdd64, _InterlockedIncrement64)
+#pragma intrinsic(_InterlockedDecrement64, _InterlockedExchange64)
+#pragma intrinsic(_InterlockedCompareExchange64)
+#endif /* !_WIN64 */
+#endif /* __x86_64__ */
+
+#ifdef __cplusplus
+}
+#endif
+#endif /* _MSC_VER */
+
+
+/* Convert a volatile int to Atomic_uint32. */
+static INLINE Atomic_uint32 *
+Atomic_VolatileToAtomic(volatile uint32 *var)
+{
+   return (Atomic_uint32 *)var;
+}
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Atomic_Init, Atomic_SetFence, AtomicUseFence --
+ *
+ *      Determine whether an lfence intruction is executed after
+ *	every locked instruction.
+ *
+ *	Certain AMD processes have a bug (see bug 107024) that
+ *	requires an lfence after every locked instruction.
+ *
+ *	The global variable AtomicUseFence controls whether lfence
+ *	is used (see AtomicEpilogue).
+ *
+ *	Atomic_SetFence sets AtomicUseFence to the given value.
+ *
+ *	Atomic_Init computes and sets AtomicUseFence.
+ *	It does not take into account the number of processors.
+ *
+ *	The rationale for all this complexity is that Atomic_Init
+ *	is the easy-to-use interface.  It can be called a number
+ *	of times cheaply, and does not depend on other libraries.
+ *	However, because the number of CPUs is difficult to compute,
+ *	it does without it and always assumes there are more than one.
+ *
+ *	For programs that care or have special requirements,
+ *	Atomic_SetFence can be called directly, in addition to Atomic_Init.
+ *	It overrides the effect of Atomic_Init, and can be called
+ *	before, after, or between calls to Atomic_Init.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+// The freebsd assembler doesn't know the lfence instruction
+#if defined(__GNUC__) &&                                                \
+     __GNUC__ >= 3 &&                                                   \
+    (defined(__VMKERNEL__) || !defined(__FreeBSD__)) &&                 \
+    (!defined(MODULE) || defined(__VMKERNEL_MODULE__)) &&               \
+    !defined(__APPLE__) /* PR136775 */
+#define ATOMIC_USE_FENCE
+#endif
+
+#if defined(VMATOMIC_IMPORT_DLLDATA)
+VMX86_EXTERN_DATA Bool AtomicUseFence;
+#else
+EXTERN Bool AtomicUseFence;
+#endif
+
+EXTERN Bool atomicFenceInitialized;
+
+void AtomicInitFence(void);
+
+static INLINE void
+Atomic_Init(void)
+{
+#ifdef ATOMIC_USE_FENCE
+   if (!atomicFenceInitialized) {
+      AtomicInitFence();
+   }
+#endif
+}
+
+static INLINE void
+Atomic_SetFence(Bool fenceAfterLock) /* IN: TRUE to enable lfence */
+                                     /*     FALSE to disable. */
+{
+   AtomicUseFence = fenceAfterLock;
+#if defined(__VMKERNEL__)
+   extern void Atomic_SetFenceVMKAPI(Bool fenceAfterLock);
+   Atomic_SetFenceVMKAPI(fenceAfterLock);  
+#endif
+   atomicFenceInitialized = TRUE;
+}
+
+
+/* Conditionally execute fence after interlocked instruction. */
+static INLINE void
+AtomicEpilogue(void)
+{
+#ifdef ATOMIC_USE_FENCE
+   if (UNLIKELY(AtomicUseFence)) {
+      asm volatile ("lfence" ::: "memory");
+   }
+#endif
+}
+
+
+/*
+ * All the assembly code is tricky and written conservatively.
+ * For example, to make sure gcc won't introduce copies,
+ * we force the addressing mode like this:
+ *
+ *    "xchgl %0, (%1)"
+ *    : "=r" (val)
+ *    : "r" (&var->value),
+ *      "0" (val)
+ *    : "memory"
+ *
+ * - edward
+ *
+ * Actually - turns out that gcc never generates memory aliases (it
+ * still does generate register aliases though), so we can be a bit
+ * more agressive with the memory constraints. The code above can be
+ * modified like this:
+ *
+ *    "xchgl %0, %1"
+ *    : "=r" (val),
+ *      "=m" (var->value),
+ *    : "0" (val),
+ *      "1" (var->value)
+ *
+ * The advantages are that gcc can use whatever addressing mode it
+ * likes to access the memory value, and that we dont have to use a
+ * way-too-generic "memory" clobber as there is now an explicit
+ * declaration that var->value is modified.
+ *
+ * see also /usr/include/asm/atomic.h to convince yourself this is a
+ * valid optimization.
+ *
+ * - walken
+ */
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Atomic_Read --
+ *
+ *      Read
+ *
+ * Results:
+ *      The value of the atomic variable.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE uint32
+Atomic_Read(Atomic_uint32 const *var) // IN
+{
+   return var->value;
+}
+#define Atomic_Read32 Atomic_Read
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Atomic_Write --
+ *
+ *      Write
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE void
+Atomic_Write(Atomic_uint32 *var, // IN
+             uint32 val)         // IN
+{
+   var->value = val;
+}
+#define Atomic_Write32 Atomic_Write
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Atomic_ReadWrite --
+ *
+ *      Read followed by write
+ *
+ * Results:
+ *      The value of the atomic variable before the write.
+ *
+ * Side effects:
+ *      None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE uint32
+Atomic_ReadWrite(Atomic_uint32 *var, // IN
+                 uint32 val)         // IN
+#ifdef __GNUC__
+{
+   /* Checked against the Intel manual and GCC --walken */
+   __asm__ __volatile__(
+      "xchgl %0, %1"
+#   if VM_ASM_PLUS
+      : "=r" (val),
+	"+m" (var->value)
+      : "0" (val)
+#   else
+      : "=r" (val),
+	"=m" (var->value)
+      : "0" (val),
+	"1" (var->value)
+#   endif
+   );
+   AtomicEpilogue();
+   return val;
+}
+#elif _MSC_VER >= 1310
+{
+   return _InterlockedExchange((long *)&var->value, (long)val);
+}
+#elif _MSC_VER
+#pragma warning(push)
+#pragma warning(disable : 4035)         // disable no-return warning
+{
+   __asm mov eax, val
+   __asm mov ebx, var
+   __asm xchg [ebx]Atomic_uint32.value, eax
+   // eax is the return value, this is documented to work - edward
+}
+#pragma warning(pop)
+#else
+#error No compiler defined for Atomic_ReadWrite
+#endif
+#define Atomic_ReadWrite32 Atomic_ReadWrite
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Atomic_ReadIfEqualWrite --
+ *
+ *      Compare exchange: Read variable, if equal to oldVal, write newVal
+ *
+ * Results:
+ *      The value of the atomic variable before the write.
+ *
+ * Side effects:
+ *      The variable may be modified.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE uint32
+Atomic_ReadIfEqualWrite(Atomic_uint32 *var, // IN
+                        uint32 oldVal,      // IN
+                        uint32 newVal)      // IN
+#ifdef __GNUC__
+{
+   uint32 val;
+
+   /* Checked against the Intel manual and GCC --walken */
+   __asm__ __volatile__(
+      "lock; cmpxchgl %2, %1"
+#   if VM_ASM_PLUS
+      : "=a" (val),
+	"+m" (var->value)
+      : "r" (newVal),
+	"0" (oldVal)
+#   else
+      : "=a" (val),
+	"=m" (var->value)
+      : "r" (newVal),
+	"0" (oldVal) 
+     /* 
+      * "1" (var->value): results in inconsistent constraints on gcc 2.7.2.3
+      * when compiling enterprise-2.2.17-14-RH7.0-update.
+      * The constraint has been commented out for now. We may consider doing
+      * this systematically, but we need to be sure it is the right thing to
+      * do. However, it is also possible that the offending use of this asm
+      * function will be removed in the near future in which case we may 
+      * decide to reintroduce the constraint instead. hpreg & agesen.
+      */
+#   endif
+      : "cc"
+   );
+   AtomicEpilogue();
+   return val;
+}
+#elif _MSC_VER >= 1310
+{
+   return _InterlockedCompareExchange((long *)&var->value,
+				      (long)newVal,
+				      (long)oldVal);
+}
+#elif _MSC_VER
+#pragma warning(push)
+#pragma warning(disable : 4035)         // disable no-return warning
+{
+   __asm mov eax, oldVal
+   __asm mov ebx, var
+   __asm mov ecx, newVal
+   __asm lock cmpxchg [ebx]Atomic_uint32.value, ecx
+   // eax is the return value, this is documented to work - edward
+}
+#pragma warning(pop)
+#else
+#error No compiler defined for Atomic_ReadIfEqualWrite
+#endif
+#define Atomic_ReadIfEqualWrite32 Atomic_ReadIfEqualWrite
+
+
+#if defined(__x86_64__)
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Atomic_ReadIfEqualWrite64 --
+ *
+ *      Compare exchange: Read variable, if equal to oldVal, write newVal
+ *
+ * Results:
+ *      The value of the atomic variable before the write.
+ *
+ * Side effects:
+ *      The variable may be modified.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE uint64
+Atomic_ReadIfEqualWrite64(Atomic_uint64 *var, // IN
+                          uint64 oldVal,      // IN
+                          uint64 newVal)      // IN
+{
+#if defined(__GNUC__)
+   uint64 val;
+
+   /* Checked against the AMD manual and GCC --hpreg */
+   __asm__ __volatile__(
+      "lock; cmpxchgq %2, %1"
+      : "=a" (val),
+	"+m" (var->value)
+      : "r" (newVal),
+	"0" (oldVal)
+      : "cc"
+   );
+   AtomicEpilogue();
+   return val;
+#elif _MSC_VER
+   return _InterlockedCompareExchange64((__int64 *)&var->value,
+					(__int64)newVal,
+					(__int64)oldVal);
+#else
+#error No compiler defined for Atomic_ReadIfEqualWrite64
+#endif
+}
+#endif
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Atomic_And --
+ *
+ *      Atomic read, bitwise AND with a value, write.
+ *
+ * Results:
+ *      None
+ *
+ * Side effects:
+ *      None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE void
+Atomic_And(Atomic_uint32 *var, // IN
+           uint32 val)         // IN
+{
+#ifdef __GNUC__
+   /* Checked against the Intel manual and GCC --walken */
+   __asm__ __volatile__(
+      "lock; andl %1, %0"
+#   if VM_ASM_PLUS
+      : "+m" (var->value)
+      : "ri" (val)
+#   else
+      : "=m" (var->value)
+      : "ri" (val),
+        "0" (var->value)
+#   endif
+      : "cc"
+   );
+   AtomicEpilogue();
+#elif _MSC_VER
+#if defined(__x86_64__)
+   _InterlockedAnd((long *)&var->value, (long)val);
+#else
+   __asm mov eax, val
+   __asm mov ebx, var
+   __asm lock and [ebx]Atomic_uint32.value, eax
+#endif
+#else
+#error No compiler defined for Atomic_And
+#endif
+}
+#define Atomic_And32 Atomic_And
+
+
+#if defined(__x86_64__)
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Atomic_And64 --
+ *
+ *      Atomic read, bitwise AND with a value, write.
+ *
+ * Results:
+ *      None
+ *
+ * Side effects:
+ *      None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE void
+Atomic_And64(Atomic_uint64 *var, // IN
+             uint64 val)         // IN
+{
+#if defined(__GNUC__)
+   /* Checked against the AMD manual and GCC --hpreg */
+   __asm__ __volatile__(
+      "lock; andq %1, %0"
+      : "+m" (var->value)
+      : "ri" (val)
+      : "cc"
+   );
+   AtomicEpilogue();
+#elif _MSC_VER
+   _InterlockedAnd64((__int64 *)&var->value, (__int64)val);
+#else
+#error No compiler defined for Atomic_And64
+#endif
+}
+#endif
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Atomic_Or --
+ *
+ *      Atomic read, bitwise OR with a value, write.
+ *
+ * Results:
+ *      None
+ *
+ * Side effects:
+ *      None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE void
+Atomic_Or(Atomic_uint32 *var, // IN
+          uint32 val)         // IN
+{
+#ifdef __GNUC__
+   /* Checked against the Intel manual and GCC --walken */
+   __asm__ __volatile__(
+      "lock; orl %1, %0"
+#   if VM_ASM_PLUS
+      : "+m" (var->value)
+      : "ri" (val)
+#   else
+      : "=m" (var->value)
+      : "ri" (val),
+        "0" (var->value)
+#   endif
+      : "cc"
+   );
+   AtomicEpilogue();
+#elif _MSC_VER
+#if defined(__x86_64__)
+   _InterlockedOr((long *)&var->value, (long)val);
+#else
+   __asm mov eax, val
+   __asm mov ebx, var
+   __asm lock or [ebx]Atomic_uint32.value, eax
+#endif
+#else
+#error No compiler defined for Atomic_Or
+#endif
+}
+#define Atomic_Or32 Atomic_Or
+
+
+#if defined(__x86_64__)
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Atomic_Or64 --
+ *
+ *      Atomic read, bitwise OR with a value, write.
+ *
+ * Results:
+ *      None
+ *
+ * Side effects:
+ *      None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE void
+Atomic_Or64(Atomic_uint64 *var, // IN
+            uint64 val)         // IN
+{
+#if defined(__GNUC__)
+   /* Checked against the AMD manual and GCC --hpreg */
+   __asm__ __volatile__(
+      "lock; orq %1, %0"
+      : "+m" (var->value)
+      : "ri" (val)
+      : "cc"
+   );
+   AtomicEpilogue();
+#elif _MSC_VER
+   _InterlockedOr64((__int64 *)&var->value, (__int64)val);
+#else
+#error No compiler defined for Atomic_Or64
+#endif
+}
+#endif
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Atomic_Xor --
+ *
+ *      Atomic read, bitwise XOR with a value, write.
+ *
+ * Results:
+ *      None
+ *
+ * Side effects:
+ *      None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE void
+Atomic_Xor(Atomic_uint32 *var, // IN
+           uint32 val)         // IN
+{
+#ifdef __GNUC__
+   /* Checked against the Intel manual and GCC --walken */
+   __asm__ __volatile__(
+      "lock; xorl %1, %0"
+#   if VM_ASM_PLUS
+      : "+m" (var->value)
+      : "ri" (val)
+#   else
+      : "=m" (var->value)
+      : "ri" (val),
+        "0" (var->value)
+#   endif
+      : "cc"
+   );
+   AtomicEpilogue();
+#elif _MSC_VER
+#if defined(__x86_64__)
+   _InterlockedXor((long *)&var->value, (long)val);
+#else
+   __asm mov eax, val
+   __asm mov ebx, var
+   __asm lock xor [ebx]Atomic_uint32.value, eax
+#endif
+#else
+#error No compiler defined for Atomic_Xor
+#endif
+}
+#define Atomic_Xor32 Atomic_Xor
+
+
+#if defined(__x86_64__)
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Atomic_Xor64 --
+ *
+ *      Atomic read, bitwise XOR with a value, write.
+ *
+ * Results:
+ *      None
+ *
+ * Side effects:
+ *      None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE void
+Atomic_Xor64(Atomic_uint64 *var, // IN
+             uint64 val)         // IN
+{
+#if defined(__GNUC__)
+   /* Checked against the AMD manual and GCC --hpreg */
+   __asm__ __volatile__(
+      "lock; xorq %1, %0"
+      : "+m" (var->value)
+      : "ri" (val)
+      : "cc"
+   );
+   AtomicEpilogue();
+#elif _MSC_VER
+   _InterlockedXor64((__int64 *)&var->value, (__int64)val);
+#else
+#error No compiler defined for Atomic_Xor64
+#endif
+}
+#endif
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Atomic_Add --
+ *
+ *      Atomic read, add a value, write.
+ *
+ * Results:
+ *      None
+ *
+ * Side effects:
+ *      None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE void
+Atomic_Add(Atomic_uint32 *var, // IN
+           uint32 val)         // IN
+{
+#ifdef __GNUC__
+   /* Checked against the Intel manual and GCC --walken */
+   __asm__ __volatile__(
+      "lock; addl %1, %0"
+#   if VM_ASM_PLUS
+      : "+m" (var->value)
+      : "ri" (val)
+#   else
+      : "=m" (var->value)
+      : "ri" (val),
+        "0" (var->value)
+#   endif
+      : "cc"
+   );
+   AtomicEpilogue();
+#elif _MSC_VER >= 1310
+   _InterlockedExchangeAdd((long *)&var->value, (long)val);
+#elif _MSC_VER
+   __asm mov eax, val
+   __asm mov ebx, var
+   __asm lock add [ebx]Atomic_uint32.value, eax
+#else
+#error No compiler defined for Atomic_Add
+#endif
+}
+#define Atomic_Add32 Atomic_Add
+
+
+#if defined(__x86_64__)
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Atomic_Add64 --
+ *
+ *      Atomic read, add a value, write.
+ *
+ * Results:
+ *      None
+ *
+ * Side effects:
+ *      None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE void
+Atomic_Add64(Atomic_uint64 *var, // IN
+             uint64 val)         // IN
+{
+#if defined(__GNUC__)
+   /* Checked against the AMD manual and GCC --hpreg */
+   __asm__ __volatile__(
+      "lock; addq %1, %0"
+      : "+m" (var->value)
+      : "ri" (val)
+      : "cc"
+   );
+   AtomicEpilogue();
+#elif _MSC_VER
+   _InterlockedExchangeAdd64((__int64 *)&var->value, (__int64)val);
+#else
+#error No compiler defined for Atomic_Add64
+#endif
+}
+#endif
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Atomic_Sub --
+ *
+ *      Atomic read, subtract a value, write.
+ *
+ * Results:
+ *      None
+ *
+ * Side effects:
+ *      None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE void
+Atomic_Sub(Atomic_uint32 *var, // IN
+           uint32 val)         // IN
+{
+#ifdef __GNUC__
+   /* Checked against the Intel manual and GCC --walken */
+   __asm__ __volatile__(
+      "lock; subl %1, %0"
+#   if VM_ASM_PLUS
+      : "+m" (var->value)
+      : "ri" (val)
+#   else
+      : "=m" (var->value)
+      : "ri" (val),
+        "0" (var->value)
+#   endif
+      : "cc"
+   );
+   AtomicEpilogue();
+#elif _MSC_VER >= 1310
+   _InterlockedExchangeAdd((long *)&var->value, (long)-val);
+#elif _MSC_VER
+   __asm mov eax, val
+   __asm mov ebx, var
+   __asm lock sub [ebx]Atomic_uint32.value, eax
+#else
+#error No compiler defined for Atomic_Sub
+#endif
+}
+#define Atomic_Sub32 Atomic_Sub
+
+
+#if defined(__x86_64__)
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Atomic_Sub64 --
+ *
+ *      Atomic read, subtract a value, write.
+ *
+ * Results:
+ *      None
+ *
+ * Side effects:
+ *      None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE void
+Atomic_Sub64(Atomic_uint64 *var, // IN
+             uint64 val)         // IN
+{
+#ifdef __GNUC__
+   /* Checked against the AMD manual and GCC --hpreg */
+   __asm__ __volatile__(
+      "lock; subq %1, %0"
+      : "+m" (var->value)
+      : "ri" (val)
+      : "cc"
+   );
+   AtomicEpilogue();
+#elif _MSC_VER
+   _InterlockedExchangeAdd64((__int64 *)&var->value, (__int64)-val);
+#else
+#error No compiler defined for Atomic_Sub64
+#endif
+}
+#endif
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Atomic_Inc --
+ *
+ *      Atomic read, increment, write.
+ *
+ * Results:
+ *      None
+ *
+ * Side effects:
+ *      None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE void
+Atomic_Inc(Atomic_uint32 *var) // IN
+{
+#ifdef __GNUC__
+   /* Checked against the Intel manual and GCC --walken */
+   __asm__ __volatile__(
+      "lock; incl %0"
+#   if VM_ASM_PLUS
+      : "+m" (var->value)
+      :
+#   else
+      : "=m" (var->value)
+      : "0" (var->value)
+#   endif
+      : "cc"
+   );
+   AtomicEpilogue();
+#elif _MSC_VER >= 1310
+   _InterlockedIncrement((long *)&var->value);
+#elif _MSC_VER
+   __asm mov ebx, var
+   __asm lock inc [ebx]Atomic_uint32.value
+#else
+#error No compiler defined for Atomic_Inc
+#endif
+}
+#define Atomic_Inc32 Atomic_Inc
+
+
+#if defined(__x86_64__)
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Atomic_Inc64 --
+ *
+ *      Atomic read, increment, write.
+ *
+ * Results:
+ *      None
+ *
+ * Side effects:
+ *      None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE void
+Atomic_Inc64(Atomic_uint64 *var) // IN
+{
+#if defined(__GNUC__)
+   /* Checked against the AMD manual and GCC --hpreg */
+   __asm__ __volatile__(
+      "lock; incq %0"
+      : "+m" (var->value)
+      :
+      : "cc"
+   );
+   AtomicEpilogue();
+#elif _MSC_VER
+   _InterlockedIncrement64((__int64 *)&var->value);
+#else
+#error No compiler defined for Atomic_Inc64
+#endif
+}
+#endif
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Atomic_Dec --
+ *
+ *      Atomic read, decrement, write.
+ *
+ * Results:
+ *      None
+ *
+ * Side effects:
+ *      None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE void
+Atomic_Dec(Atomic_uint32 *var) // IN
+{
+#ifdef __GNUC__
+   /* Checked against the Intel manual and GCC --walken */
+   __asm__ __volatile__(
+      "lock; decl %0"
+#   if VM_ASM_PLUS
+      : "+m" (var->value)
+      :
+#   else
+      : "=m" (var->value)
+      : "0" (var->value)
+#   endif
+      : "cc"
+   );
+   AtomicEpilogue();
+#elif _MSC_VER >= 1310
+   _InterlockedDecrement((long *)&var->value);
+#elif _MSC_VER
+   __asm mov ebx, var
+   __asm lock dec [ebx]Atomic_uint32.value
+#else
+#error No compiler defined for Atomic_Dec
+#endif
+}
+#define Atomic_Dec32 Atomic_Dec
+
+
+#if defined(__x86_64__)
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Atomic_Dec64 --
+ *
+ *      Atomic read, decrement, write.
+ *
+ * Results:
+ *      None
+ *
+ * Side effects:
+ *      None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE void
+Atomic_Dec64(Atomic_uint64 *var) // IN
+{
+#if defined(__GNUC__)
+   /* Checked against the AMD manual and GCC --hpreg */
+   __asm__ __volatile__(
+      "lock; decq %0"
+      : "+m" (var->value)
+      :
+      : "cc"
+   );
+   AtomicEpilogue();
+#elif _MSC_VER
+   _InterlockedDecrement64((__int64 *)&var->value);
+#else
+#error No compiler defined for Atomic_Dec64
+#endif
+}
+#endif
+
+
+/*
+ * Note that the technique below can be used to implement ReadX(), where X is
+ * an arbitrary mathematical function.
+ */
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Atomic_FetchAndOr --
+ *
+ *      Atomic read (returned), bitwise OR with a value, write.
+ *
+ * Results:
+ *      The value of the variable before the operation.
+ *
+ * Side effects:
+ *      None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE uint32
+Atomic_FetchAndOr(Atomic_uint32 *var, // IN
+                  uint32 val)         // IN
+{
+   uint32 res;
+
+   do {
+      res = var->value;
+   } while (res != Atomic_ReadIfEqualWrite(var, res, res | val));
+
+   return res;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Atomic_FetchAndAnd --
+ *
+ *      Atomic read (returned), bitwise And with a value, write.
+ *
+ * Results:
+ *      The value of the variable before the operation.
+ *
+ * Side effects:
+ *      None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE uint32
+Atomic_FetchAndAnd(Atomic_uint32 *var, // IN
+                   uint32 val)         // IN
+{
+   uint32 res;
+
+   do {
+      res = var->value;
+   } while (res != Atomic_ReadIfEqualWrite(var, res, res & val));
+
+   return res;
+}
+#define Atomic_ReadOr32 Atomic_FetchAndOr
+
+
+#if defined(__x86_64__)
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Atomic_ReadOr64 --
+ *
+ *      Atomic read (returned), bitwise OR with a value, write.
+ *
+ * Results:
+ *      The value of the variable before the operation.
+ *
+ * Side effects:
+ *      None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE uint64
+Atomic_ReadOr64(Atomic_uint64 *var, // IN
+                uint64 val)         // IN
+{
+   uint64 res;
+
+   do {
+      res = var->value;
+   } while (res != Atomic_ReadIfEqualWrite64(var, res, res | val));
+
+   return res;
+}
+#endif
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Atomic_FetchAndAddUnfenced --
+ *
+ *      Atomic read (returned), add a value, write.
+ *
+ *      If you have to implement FetchAndAdd() on an architecture other than
+ *      x86 or x86-64, you might want to consider doing something similar to
+ *      Atomic_FetchAndOr().
+ *
+ *      The "Unfenced" version of Atomic_FetchAndInc never executes
+ *      "lfence" after the interlocked operation.
+ *
+ * Results:
+ *      The value of the variable before the operation.
+ *
+ * Side effects:
+ *      None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE uint32
+Atomic_FetchAndAddUnfenced(Atomic_uint32 *var, // IN
+                           uint32 val)         // IN
+#ifdef __GNUC__
+{
+   /* Checked against the Intel manual and GCC --walken */
+   __asm__ __volatile__(
+#   if VM_ASM_PLUS
+      "lock; xaddl %0, %1"
+      : "=r" (val),
+	"+m" (var->value)
+      : "0" (val)
+      : "cc"
+#   else
+      "lock; xaddl %0, (%1)"
+      : "=r" (val)
+      : "r" (&var->value),
+	"0" (val)
+      : "cc", "memory"
+#   endif
+   );
+   return val;
+}
+#elif _MSC_VER >= 1310
+{
+   return _InterlockedExchangeAdd((long *)&var->value, (long)val);
+}
+#elif _MSC_VER
+#pragma warning(push)
+#pragma warning(disable : 4035)         // disable no-return warning
+{
+   __asm mov eax, val
+   __asm mov ebx, var
+   __asm lock xadd [ebx]Atomic_uint32.value, eax
+}
+#pragma warning(pop)
+#else
+#error No compiler defined for Atomic_FetchAndAdd
+#endif
+#define Atomic_ReadAdd32 Atomic_FetchAndAdd
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Atomic_FetchAndAdd --
+ *
+ *      Atomic read (returned), add a value, write.
+ *
+ *      If you have to implement FetchAndAdd() on an architecture other than
+ *      x86 or x86-64, you might want to consider doing something similar to
+ *      Atomic_FetchAndOr().
+ *
+ *      Unlike "Unfenced" version, this one may execute the "lfence" after
+ *      interlocked operation.
+ *
+ * Results:
+ *      The value of the variable before the operation.
+ *
+ * Side effects:
+ *      None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE uint32
+Atomic_FetchAndAdd(Atomic_uint32 *var, // IN
+                   uint32 val)         // IN
+#ifdef __GNUC__
+{
+   val = Atomic_FetchAndAddUnfenced(var, val);
+   AtomicEpilogue();
+   return val;
+}
+#else
+{
+   return Atomic_FetchAndAddUnfenced(var, val);
+}
+#endif
+
+
+#if defined(__x86_64__)
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Atomic_ReadAdd64 --
+ *
+ *      Atomic read (returned), add a value, write.
+ *
+ * Results:
+ *      The value of the variable before the operation.
+ *
+ * Side effects:
+ *      None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE uint64
+Atomic_ReadAdd64(Atomic_uint64 *var, // IN
+                 uint64 val)         // IN
+{
+#if defined(__GNUC__)
+   /* Checked against the AMD manual and GCC --hpreg */
+   __asm__ __volatile__(
+      "lock; xaddq %0, %1"
+      : "=r" (val),
+	"+m" (var->value)
+      : "0" (val)
+      : "cc"
+   );
+   AtomicEpilogue();
+   return val;
+#elif _MSC_VER
+   return _InterlockedExchangeAdd64((__int64 *)&var->value, (__int64)val);
+#else
+#error No compiler defined for Atomic_ReadAdd64
+#endif
+}
+#endif
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Atomic_FetchAndInc --
+ *
+ *      Atomic read (returned), increment, write.
+ *
+ * Results:
+ *      The value of the variable before the operation.
+ *
+ * Side effects:
+ *      None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE uint32
+Atomic_FetchAndInc(Atomic_uint32 *var) // IN
+{
+   return Atomic_FetchAndAdd(var, 1);
+}
+#define Atomic_ReadInc32 Atomic_FetchAndInc
+
+
+#if defined(__x86_64__)
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Atomic_ReadInc64 --
+ *
+ *      Atomic read (returned), increment, write.
+ *
+ * Results:
+ *      The value of the variable before the operation.
+ *
+ * Side effects:
+ *      None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE uint64
+Atomic_ReadInc64(Atomic_uint64 *var) // IN
+{
+   return Atomic_ReadAdd64(var, 1);
+}
+#endif
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Atomic_FetchAndDec --
+ *
+ *      Atomic read (returned), decrement, write.
+ *
+ * Results:
+ *      The value of the variable before the operation.
+ *
+ * Side effects:
+ *      None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE uint32
+Atomic_FetchAndDec(Atomic_uint32 *var) // IN
+{
+   return Atomic_FetchAndAdd(var, (uint32)-1);
+}
+#define Atomic_ReadDec32 Atomic_FetchAndDec
+
+
+#if defined(__x86_64__)
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Atomic_ReadDec64 --
+ *
+ *      Atomic read (returned), decrement, write.
+ *
+ * Results:
+ *      The value of the variable before the operation.
+ *
+ * Side effects:
+ *      None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE uint64
+Atomic_ReadDec64(Atomic_uint64 *var) // IN
+{
+   return Atomic_ReadAdd64(var, CONST64U(-1));
+}
+#endif
+
+
+/*
+ * Usage of this helper struct is strictly reserved to the following
+ * function. --hpreg
+ */
+typedef struct {
+   uint32 lowValue;
+   uint32 highValue;
+} S_uint64;
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Atomic_CMPXCHG64 --
+ *
+ *      Compare exchange: Read variable, if equal to oldVal, write newVal
+ *
+ *      XXX: Ensure that if this function is to be inlined by gcc, it is 
+ *      compiled with -fno-strict-aliasing. Otherwise it will break. 
+ *      Unfortunately we know that gcc 2.95.3 (used to build the FreeBSD 3.2
+ *      Tools) does not honor -fno-strict-aliasing. As a workaround, we avoid 
+ *      inlining the function entirely for versions of gcc under 3.0.
+ *
+ * Results:
+ *      TRUE if equal, FALSE if not equal
+ *
+ * Side effects:
+ *      None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+#if defined(__GNUC__) && __GNUC__ < 3
+static Bool
+#else
+static INLINE Bool
+#endif
+Atomic_CMPXCHG64(Atomic_uint64 *var,   // IN/OUT
+                 uint64 const *oldVal, // IN
+                 uint64 const *newVal) // IN
+#ifdef __GNUC__
+{
+   Bool equal;
+
+   /* Checked against the Intel manual and GCC --walken */
+#ifdef VMM64
+   uint64 dummy;
+   __asm__ __volatile__(
+      "lock; cmpxchgq %3, %0" "\n\t"
+      "sete %1"
+      : "+m" (*var),
+	"=qm" (equal),
+	"=a" (dummy)
+      : "r" (*newVal),
+        "2" (*oldVal)
+      : "cc"
+   );
+#else /* 32-bit version */
+   int dummy1, dummy2;
+#   if defined __PIC__ && !vm_x86_64 // %ebx is reserved by the compiler.
+#      if defined __GNUC__ && __GNUC__ < 3 // Part of #188541 - for RHL 6.2 etc.
+   __asm__ __volatile__(
+      "xchg %%ebx, %6\n\t"
+      "mov (%%ebx), %%ecx\n\t"
+      "mov (%%ebx), %%ebx\n\t"
+      "lock; cmpxchg8b (%3)\n\t"
+      "xchg %%ebx, %6\n\t"
+      "sete %0"
+      : "=a" (equal), "=d" (dummy2), "=D" (dummy1)
+      : "S" (var), "0" (((S_uint64 const *)oldVal)->lowValue),
+        "1" (((S_uint64 const *)oldVal)->highValue), "D" (newVal)
+      : "ecx", "cc", "memory"
+      );
+#      else
+   __asm__ __volatile__(
+      "xchgl %%ebx, %6"      "\n\t"
+      // %3 is a register to make sure it cannot be %ebx-relative.
+      "lock; cmpxchg8b (%3)" "\n\t"
+      "xchgl %%ebx, %6"      "\n\t"
+      // Must come after restoring %ebx: %0 could be %ebx-relative.
+      "sete %0"
+      :	"=qm" (equal),
+	"=a" (dummy1),
+	"=d" (dummy2)
+      : "r" (var),
+        "1" (((S_uint64 const *)oldVal)->lowValue),
+        "2" (((S_uint64 const *)oldVal)->highValue),
+        // Cannot use "m" here: 'newVal' is read-only.
+        "r" (((S_uint64 const *)newVal)->lowValue),
+        "c" (((S_uint64 const *)newVal)->highValue)
+      : "cc", "memory"
+   );
+#      endif
+#   else
+   __asm__ __volatile__(
+      "lock; cmpxchg8b %0" "\n\t"
+      "sete %1"
+#      if VM_ASM_PLUS
+      : "+m" (*var),
+#      else
+      : "=m" (*var),
+#      endif
+	"=qm" (equal),
+	"=a" (dummy1),
+	"=d" (dummy2)
+      : "2" (((S_uint64 const *)oldVal)->lowValue),
+        "3" (((S_uint64 const *)oldVal)->highValue),
+        "b" (((S_uint64 const *)newVal)->lowValue),
+        "c" (((S_uint64 const *)newVal)->highValue)
+      : "cc"
+   );
+#   endif
+#endif
+   AtomicEpilogue();
+   return equal;
+} 
+#elif _MSC_VER
+#if defined(__x86_64__)
+{
+   return *oldVal == _InterlockedCompareExchange64((__int64 *)&var->value,
+                                                   (__int64)*newVal, 
+						   (__int64)*oldVal);
+}
+#else
+#pragma warning(push)
+#pragma warning(disable : 4035)		// disable no-return warning
+{
+   __asm mov esi, var
+   __asm mov edx, oldVal
+   __asm mov ecx, newVal
+   __asm mov eax, [edx]S_uint64.lowValue
+   __asm mov edx, [edx]S_uint64.highValue
+   __asm mov ebx, [ecx]S_uint64.lowValue
+   __asm mov ecx, [ecx]S_uint64.highValue
+   __asm lock cmpxchg8b [esi]
+   __asm sete al
+   __asm movzx eax, al
+   // eax is the return value, this is documented to work - edward
+} 
+#pragma warning(pop)
+#endif
+#else
+#error No compiler defined for Atomic_CMPXCHG64
+#endif
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Atomic_CMPXCHG32 --
+ *
+ *      Compare exchange: Read variable, if equal to oldVal, write newVal
+ *
+ * Results:
+ *      TRUE if equal, FALSE if not equal
+ *
+ * Side effects:
+ *      None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE Bool
+Atomic_CMPXCHG32(Atomic_uint32 *var,   // IN/OUT
+                 uint32 oldVal, // IN
+                 uint32 newVal) // IN
+{
+#ifdef __GNUC__
+   Bool equal;
+
+   uint32 dummy;
+   __asm__ __volatile__(
+      "lock; cmpxchgl %3, %0" "\n\t"
+      "sete %1"
+#   if VM_ASM_PLUS
+      : "+m" (*var),
+	"=qm" (equal),
+	"=a" (dummy)
+      : "r" (newVal),
+        "2" (oldVal)
+#   else
+      : "=m" (*var),
+	"=qm" (equal),
+	"=a" (dummy)
+      : /*"0" (*var), */
+        "r" (newVal),
+        "2" (oldVal)
+#   endif
+      : "cc"
+   );
+   AtomicEpilogue();
+   return equal;
+#else
+   return (Atomic_ReadIfEqualWrite(var, oldVal, newVal) == oldVal);
+#endif
+} 
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Atomic_Read64 --
+ *
+ *      Read and return.
+ *
+ * Results:
+ *      The value of the atomic variable.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE uint64
+Atomic_Read64(Atomic_uint64 const *var) // IN
+#if defined(__x86_64__)
+{
+   return var->value;
+}
+#elif defined(__GNUC__) && defined(__i386__) /* GCC on x86 */
+{
+   uint64 value;
+   /* 
+    * Since cmpxchg8b will replace the contents of EDX:EAX with the
+    * value in memory if there is no match, we need only execute the
+    * instruction once in order to atomically read 64 bits from
+    * memory.  The only constraint is that ECX:EBX must have the same
+    * value as EDX:EAX so that if the comparison succeeds.  We
+    * intentionally don't tell gcc that we are using ebx and ecx as we
+    * don't modify them and do not care what value they store.
+    */
+   __asm__ __volatile__(
+      "mov %%ebx, %%eax"   "\n\t"
+      "mov %%ecx, %%edx"   "\n\t"
+      "lock; cmpxchg8b %1"
+      : "=&A" (value)
+      : "m" (*var)
+      : "cc"
+   );
+   AtomicEpilogue();
+   return value;
+}
+#elif _MSC_VER /* MSC (assume on x86 for now) */
+#   pragma warning(push)
+#   pragma warning(disable : 4035)		// disable no-return warning
+{
+   __asm mov ecx, var
+   __asm mov edx, ecx
+   __asm mov eax, ebx
+   __asm lock cmpxchg8b [ecx]
+   // edx:eax is the return value; this is documented to work. --mann
+}
+#   pragma warning(pop)
+#else
+#   error No compiler defined for Atomic_Read64
+#endif
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * Atomic_FetchAndAdd64 --
+ *
+ *      Atomically adds a 64-bit integer to another
+ *
+ * Results:
+ *      Returns the old value just prior to the addition
+ *
+ * Side effects:
+ *      None
+ *
+ *----------------------------------------------------------------------
+ */
+
+static INLINE uint64
+Atomic_FetchAndAdd64(Atomic_uint64 *var, // IN/OUT
+		     uint64 addend)      // IN
+{
+   uint64 oldVal;
+   uint64 newVal;
+
+   do {
+      oldVal = var->value;
+      newVal = oldVal + addend;
+   } while (!Atomic_CMPXCHG64(var, &oldVal, &newVal));
+
+   return oldVal;
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * Atomic_FetchAndInc64 --
+ *
+ *      Atomically increments a 64-bit integer
+ *
+ * Results:
+ *      Returns the old value just prior to incrementing
+ *
+ * Side effects:
+ *      None
+ *
+ *----------------------------------------------------------------------
+ */
+
+static INLINE uint64
+Atomic_FetchAndInc64(Atomic_uint64 *var) // IN/OUT
+{
+   return Atomic_FetchAndAdd64(var, 1);
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * Atomic_FetchAndDec64 --
+ *
+ *      Atomically decrements a 64-bit integer
+ *
+ * Results:
+ *      Returns the old value just prior to decrementing
+ *
+ * Side effects:
+ *      None
+ *
+ *----------------------------------------------------------------------
+ */
+
+static INLINE uint64
+Atomic_FetchAndDec64(Atomic_uint64 *var) // IN/OUT
+{
+   uint64 oldVal;
+   uint64 newVal;
+
+   do {
+      oldVal = var->value;
+      newVal = oldVal - 1;
+   } while (!Atomic_CMPXCHG64(var, &oldVal, &newVal));
+
+   return oldVal;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Atomic_ReadWrite64 --
+ *
+ *      Read followed by write
+ *
+ * Results:
+ *      The value of the atomic variable before the write.
+ *
+ * Side effects:
+ *      None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE uint64
+Atomic_ReadWrite64(Atomic_uint64 *var, // IN
+                   uint64 val)         // IN
+{
+#if defined(__x86_64__)
+#if defined(__GNUC__)
+   /* Checked against the AMD manual and GCC --hpreg */
+   __asm__ __volatile__(
+      "xchgq %0, %1"
+      : "=r" (val),
+	"+m" (var->value)
+      : "0" (val)
+   );
+   AtomicEpilogue();
+   return val;
+#elif _MSC_VER
+   return _InterlockedExchange64((__int64 *)&var->value, (__int64)val);
+#else
+#error No compiler defined for Atomic_ReadWrite64
+#endif
+#else
+   uint64 oldVal;
+
+   do {
+      oldVal = var->value;
+   } while (!Atomic_CMPXCHG64(var, &oldVal, &val));
+
+   return oldVal;
+#endif
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Atomic_Write64 --
+ *
+ *      Write
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE void
+Atomic_Write64(Atomic_uint64 *var, // IN
+               uint64 val)         // IN
+{
+#if defined(__x86_64__)
+   var->value = val;
+#else
+   (void)Atomic_ReadWrite64(var, val);
+#endif
+}
+
+
+/*
+ * Template code for the Atomic_<name> type and its operators.
+ *
+ * The cast argument is an intermedia type cast to make some
+ * compilers stop complaining about casting uint32 <-> void *,
+ * even though we only do it in the 32-bit case so they are always
+ * the same size.  So for val of type uint32, instead of
+ * (void *)val, we have (void *)(uintptr_t)val.
+ * The specific problem case is the Windows ddk compiler
+ * (as used by the SVGA driver).  -- edward
+ */
+
+#define MAKE_ATOMIC_TYPE(name, size, in, out, cast)                           \
+   typedef Atomic_uint ## size Atomic_ ## name;                               \
+                                                                              \
+                                                                              \
+   static INLINE out                                                          \
+   Atomic_Read ## name(Atomic_ ## name const *var)                            \
+   {                                                                          \
+      return (out)(cast)Atomic_Read ## size(var);                             \
+   }                                                                          \
+                                                                              \
+                                                                              \
+   static INLINE void                                                         \
+   Atomic_Write ## name(Atomic_ ## name *var,                                 \
+                        in val)                                               \
+   {                                                                          \
+      Atomic_Write ## size(var, (uint ## size)(cast)val);                     \
+   }                                                                          \
+                                                                              \
+                                                                              \
+   static INLINE out                                                          \
+   Atomic_ReadWrite ## name(Atomic_ ## name *var,                             \
+                            in val)                                           \
+   {                                                                          \
+      return (out)(cast)Atomic_ReadWrite ## size(var,                         \
+		(uint ## size)(cast)val);                                     \
+   }                                                                          \
+                                                                              \
+                                                                              \
+   static INLINE out                                                          \
+   Atomic_ReadIfEqualWrite ## name(Atomic_ ## name *var,                      \
+                                   in oldVal,                                 \
+                                   in newVal)                                 \
+   {                                                                          \
+      return (out)(cast)Atomic_ReadIfEqualWrite ## size(var,                  \
+                (uint ## size)(cast)oldVal, (uint ## size)(cast)newVal);      \
+   }                                                                          \
+                                                                              \
+                                                                              \
+   static INLINE void                                                         \
+   Atomic_And ## name(Atomic_ ## name *var,                                   \
+                      in val)                                                 \
+   {                                                                          \
+      Atomic_And ## size(var, (uint ## size)(cast)val);                       \
+   }                                                                          \
+                                                                              \
+                                                                              \
+   static INLINE void                                                         \
+   Atomic_Or ## name(Atomic_ ## name *var,                                    \
+                     in val)                                                  \
+   {                                                                          \
+      Atomic_Or ## size(var, (uint ## size)(cast)val);                        \
+   }                                                                          \
+                                                                              \
+                                                                              \
+   static INLINE void                                                         \
+   Atomic_Xor ## name(Atomic_ ## name *var,                                   \
+                      in val)                                                 \
+   {                                                                          \
+      Atomic_Xor ## size(var, (uint ## size)(cast)val);                       \
+   }                                                                          \
+                                                                              \
+                                                                              \
+   static INLINE void                                                         \
+   Atomic_Add ## name(Atomic_ ## name *var,                                   \
+                      in val)                                                 \
+   {                                                                          \
+      Atomic_Add ## size(var, (uint ## size)(cast)val);                       \
+   }                                                                          \
+                                                                              \
+                                                                              \
+   static INLINE void                                                         \
+   Atomic_Sub ## name(Atomic_ ## name *var,                                   \
+                      in val)                                                 \
+   {                                                                          \
+      Atomic_Sub ## size(var, (uint ## size)(cast)val);                       \
+   }                                                                          \
+                                                                              \
+                                                                              \
+   static INLINE void                                                         \
+   Atomic_Inc ## name(Atomic_ ## name *var)                                   \
+   {                                                                          \
+      Atomic_Inc ## size(var);                                                \
+   }                                                                          \
+                                                                              \
+                                                                              \
+   static INLINE void                                                         \
+   Atomic_Dec ## name(Atomic_ ## name *var)                                   \
+   {                                                                          \
+      Atomic_Dec ## size(var);                                                \
+   }                                                                          \
+                                                                              \
+                                                                              \
+   static INLINE out                                                          \
+   Atomic_ReadOr ## name(Atomic_ ## name *var,                                \
+                         in val)                                              \
+   {                                                                          \
+      return (out)(cast)Atomic_ReadOr ## size(var, (uint ## size)(cast)val);  \
+   }                                                                          \
+                                                                              \
+                                                                              \
+   static INLINE out                                                          \
+   Atomic_ReadAdd ## name(Atomic_ ## name *var,                               \
+                          in val)                                             \
+   {                                                                          \
+      return (out)(cast)Atomic_ReadAdd ## size(var, (uint ## size)(cast)val); \
+   }                                                                          \
+                                                                              \
+                                                                              \
+   static INLINE out                                                          \
+   Atomic_ReadInc ## name(Atomic_ ## name *var)                               \
+   {                                                                          \
+      return (out)(cast)Atomic_ReadInc ## size(var);                          \
+   }                                                                          \
+                                                                              \
+                                                                              \
+   static INLINE out                                                          \
+   Atomic_ReadDec ## name(Atomic_ ## name *var)                               \
+   {                                                                          \
+      return (out)(cast)Atomic_ReadDec ## size(var);                          \
+   }
+
+
+/*
+ * Since we use a macro to generate these definitions, it is hard to look for
+ * them. So DO NOT REMOVE THIS COMMENT and keep it up-to-date. --hpreg
+ *
+ * Atomic_Ptr
+ * Atomic_ReadPtr --
+ * Atomic_WritePtr --
+ * Atomic_ReadWritePtr --
+ * Atomic_ReadIfEqualWritePtr --
+ * Atomic_AndPtr --
+ * Atomic_OrPtr --
+ * Atomic_XorPtr --
+ * Atomic_AddPtr --
+ * Atomic_SubPtr --
+ * Atomic_IncPtr --
+ * Atomic_DecPtr --
+ * Atomic_ReadOrPtr --
+ * Atomic_ReadAddPtr --
+ * Atomic_ReadIncPtr --
+ * Atomic_ReadDecPtr --
+ *
+ * Atomic_Int
+ * Atomic_ReadInt --
+ * Atomic_WriteInt --
+ * Atomic_ReadWriteInt --
+ * Atomic_ReadIfEqualWriteInt --
+ * Atomic_AndInt --
+ * Atomic_OrInt --
+ * Atomic_XorInt --
+ * Atomic_AddInt --
+ * Atomic_SubInt --
+ * Atomic_IncInt --
+ * Atomic_DecInt --
+ * Atomic_ReadOrInt --
+ * Atomic_ReadAddInt --
+ * Atomic_ReadIncInt --
+ * Atomic_ReadDecInt --
+ */
+#if defined(__x86_64__)
+MAKE_ATOMIC_TYPE(Ptr, 64, void const *, void *, uintptr_t)
+MAKE_ATOMIC_TYPE(Int, 64, int, int, int)
+#else
+MAKE_ATOMIC_TYPE(Ptr, 32, void const *, void *, uintptr_t)
+MAKE_ATOMIC_TYPE(Int, 32, int, int, int)
+#endif
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Atomic_MFence --
+ *
+ *      Implements mfence in terms of a lock xor. The reason for implementing
+ *      our own mfence is that not all of our supported cpus have an assembly
+ *      mfence (P3, Athlon). We put it here to avoid duplicating code which is
+ *      also why it is prefixed with "Atomic_".
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      Cause loads and stores prior to this to be globally
+ *      visible.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE void
+Atomic_MFence(void)
+{
+   Atomic_uint32 fence;
+   Atomic_Xor(&fence, 0x1);
+}
+
+#endif // ifndef _ATOMIC_H_
--- kernel/linux-2.6.26.3/drivers/misc/vsock/vm_basic_defs.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vsock/vm_basic_defs.h	2008-09-03 10:05:45.000000000 -0500
@@ -0,0 +1,605 @@
+/*********************************************************
+ * Copyright (C) 2003 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * vm_basic_defs.h --
+ *
+ *	Standard macros for VMware source code.
+ */
+
+#ifndef _VM_BASIC_DEFS_H_
+#define _VM_BASIC_DEFS_H_
+
+#define INCLUDE_ALLOW_USERLEVEL
+#define INCLUDE_ALLOW_VMMEXT
+#define INCLUDE_ALLOW_MODULE
+#define INCLUDE_ALLOW_VMMON
+#define INCLUDE_ALLOW_VMNIXMOD
+#define INCLUDE_ALLOW_VMKERNEL
+#define INCLUDE_ALLOW_VMKDRIVERS
+#define INCLUDE_ALLOW_VMK_MODULE
+#define INCLUDE_ALLOW_DISTRIBUTE
+#define INCLUDE_ALLOW_VMCORE
+#define INCLUDE_ALLOW_VMIROM
+#include "vm_basic_types.h" // For INLINE.
+
+/* Checks for FreeBSD, filtering out VMKERNEL. */
+#define __IS_FREEBSD__ (!defined(VMKERNEL) && defined(__FreeBSD__))
+#define __IS_FREEBSD_VER__(ver) (__IS_FREEBSD__ && __FreeBSD_version >= (ver))
+
+#if defined _WIN32 && defined USERLEVEL
+   #include <stddef.h>  /*
+                         * We re-define offsetof macro from stddef, make 
+                         * sure that its already defined before we do it
+                         */
+   #include <windows.h>	// for Sleep() and LOWORD() etc.
+#endif
+
+
+/*
+ * Simple macros
+ */
+
+#if (defined __APPLE__ || defined __FreeBSD__) && \
+    (!defined KERNEL && !defined _KERNEL && !defined VMKERNEL && !defined __KERNEL__)
+#   include <stddef.h>
+#else
+// XXX the __cplusplus one matches that of VC++, to prevent redefinition warning
+// XXX the other one matches that of gcc3.3.3/glibc2.2.4 to prevent redefinition warnings
+#ifndef offsetof
+#ifdef __cplusplus
+#define offsetof(s,m)   (size_t)&(((s *)0)->m)
+#else
+#define offsetof(TYPE, MEMBER) ((size_t) &((TYPE *)0)->MEMBER)
+#endif
+#endif
+#endif // __APPLE__
+
+#ifndef ARRAYSIZE
+#define ARRAYSIZE(a) (sizeof (a) / sizeof *(a))
+#endif
+
+#ifndef MIN
+#define MIN(_a, _b)   (((_a) < (_b)) ? (_a) : (_b))
+#endif
+
+/* The Solaris 9 cross-compiler complains about these not being used */
+#ifndef sun
+static INLINE int 
+Min(int a, int b)
+{
+   return a < b ? a : b;
+}
+#endif
+
+#ifndef MAX
+#define MAX(_a, _b)   (((_a) > (_b)) ? (_a) : (_b))
+#endif
+
+#ifndef sun
+static INLINE int 
+Max(int a, int b)
+{
+   return a > b ? a : b;
+}
+#endif
+
+#define ROUNDUP(x,y)		(((x) + (y) - 1) / (y) * (y))
+#define ROUNDDOWN(x,y)		((x) / (y) * (y))
+#define ROUNDUPBITS(x, bits)	(((uintptr_t) (x) + MASK(bits)) & ~MASK(bits))
+#define ROUNDDOWNBITS(x, bits)	((uintptr_t) (x) & ~MASK(bits))
+#define CEILING(x, y)		(((x) + (y) - 1) / (y))
+#if defined __APPLE__
+#include <machine/param.h>
+#undef MASK
+#endif
+#define MASK(n)			((1 << (n)) - 1)	/* make an n-bit mask */
+#define DWORD_ALIGN(x)          ((((x)+3) >> 2) << 2)
+#define QWORD_ALIGN(x)          ((((x)+4) >> 3) << 3)
+
+#define IMPLIES(a,b) (!(a) || (b))
+
+/*
+ * Not everybody (e.g., the monitor) has NULL
+ */
+
+#ifndef NULL
+#ifdef  __cplusplus
+#define NULL    0
+#else
+#define NULL    ((void *)0)
+#endif
+#endif
+
+
+/* 
+ * Token concatenation
+ *
+ * The C preprocessor doesn't prescan arguments when they are
+ * concatenated or stringified.  So we need extra levels of
+ * indirection to convince the preprocessor to expand its
+ * arguments.
+ */
+
+#define CONC(x, y)              x##y
+#define XCONC(x, y)             CONC(x, y)
+#define XXCONC(x, y)            XCONC(x, y)
+#define MAKESTR(x)              #x
+#define XSTR(x)                 MAKESTR(x)
+
+
+/*
+ * Page operations
+ *
+ * It has been suggested that these definitions belong elsewhere
+ * (like x86types.h).  However, I deem them common enough
+ * (since even regular user-level programs may want to do
+ * page-based memory manipulation) to be here.
+ * -- edward
+ */
+
+#ifndef PAGE_SHIFT // {
+#if defined VM_I386
+   #define PAGE_SHIFT    12
+#elif defined __APPLE__
+   #define PAGE_SHIFT    12
+#else
+   #error
+#endif
+#endif // }
+
+#ifndef PAGE_SIZE
+#define PAGE_SIZE     (1<<PAGE_SHIFT)
+#endif
+
+#ifndef PAGE_MASK
+#define PAGE_MASK     (PAGE_SIZE - 1)
+#endif
+
+#ifndef PAGE_OFFSET
+#define PAGE_OFFSET(_addr)  ((uintptr_t)(_addr)&(PAGE_SIZE-1))
+#endif
+
+#ifndef VM_PAGE_BASE
+#define VM_PAGE_BASE(_addr)  ((_addr)&~(PAGE_SIZE-1))
+#endif
+
+#ifndef VM_PAGES_SPANNED
+#define VM_PAGES_SPANNED(_addr, _size) \
+   ((((_addr) & (PAGE_SIZE - 1)) + (_size) + (PAGE_SIZE - 1)) >> PAGE_SHIFT)
+#endif
+
+#ifndef BYTES_2_PAGES
+#define BYTES_2_PAGES(_nbytes) ((_nbytes) >> PAGE_SHIFT)
+#endif
+
+#ifndef PAGES_2_BYTES
+#define PAGES_2_BYTES(_npages) (((uint64)(_npages)) << PAGE_SHIFT)
+#endif
+
+#ifndef MBYTES_2_PAGES
+#define MBYTES_2_PAGES(_nbytes) ((_nbytes) << (20 - PAGE_SHIFT))
+#endif
+
+#ifndef PAGES_2_MBYTES
+#define PAGES_2_MBYTES(_npages) ((_npages) >> (20 - PAGE_SHIFT))
+#endif
+
+#ifndef VM_PAE_LARGE_PAGE_SHIFT
+#define VM_PAE_LARGE_PAGE_SHIFT 21
+#endif 
+
+#ifndef VM_PAE_LARGE_PAGE_SIZE
+#define VM_PAE_LARGE_PAGE_SIZE (1 << VM_PAE_LARGE_PAGE_SHIFT)
+#endif
+
+#ifndef VM_PAE_LARGE_PAGE_MASK
+#define VM_PAE_LARGE_PAGE_MASK (VM_PAE_LARGE_PAGE_SIZE - 1)
+#endif
+
+#ifndef VM_PAE_LARGE_2_SMALL_PAGES
+#define VM_PAE_LARGE_2_SMALL_PAGES (BYTES_2_PAGES(VM_PAE_LARGE_PAGE_SIZE))
+#endif
+
+/*
+ * Word operations
+ */
+
+#ifndef LOWORD
+#define LOWORD(_dw)   ((_dw) & 0xffff)
+#endif
+#ifndef HIWORD
+#define HIWORD(_dw)   (((_dw) >> 16) & 0xffff)
+#endif
+
+#ifndef LOBYTE
+#define LOBYTE(_w)    ((_w) & 0xff)
+#endif
+#ifndef HIBYTE
+#define HIBYTE(_w)    (((_w) >> 8) & 0xff)
+#endif
+
+#define HIDWORD(_qw)   ((uint32)((_qw) >> 32))
+#define LODWORD(_qw)   ((uint32)(_qw))
+#define QWORD(_hi, _lo)   ((((uint64)(_hi)) << 32) | ((uint32)(_lo)))
+
+
+/*
+ * Deposit a field _src at _pos bits from the right,
+ * with a length of _len, into the integer _target.
+ */
+
+#define DEPOSIT_BITS(_src,_pos,_len,_target) { \
+	unsigned mask = ((1 << _len) - 1); \
+	unsigned shiftedmask = ((1 << _len) - 1) << _pos; \
+	_target = (_target & ~shiftedmask) | ((_src & mask) << _pos); \
+}
+
+
+/*
+ * Get return address.
+ */
+
+#ifdef _MSC_VER
+#ifdef __cplusplus
+extern "C"
+#endif 
+void *_ReturnAddress(void);
+#pragma intrinsic(_ReturnAddress)
+#define GetReturnAddress() _ReturnAddress()
+#elif __GNUC__
+#define GetReturnAddress() __builtin_return_address(0)
+#endif
+
+
+#ifdef __GNUC__
+#ifndef sun
+
+/*
+ * Get the frame pointer. We use this assembly hack instead of
+ * __builtin_frame_address() due to a bug introduced in gcc 4.1.1
+ */
+static INLINE_SINGLE_CALLER uintptr_t
+GetFrameAddr(void)
+{
+   uintptr_t bp;
+#if (__GNUC__ < 4 || (__GNUC__ == 4 && __GNUC_MINOR__ == 0))
+   bp = (uintptr_t)__builtin_frame_address(0);
+#elif (__GNUC__ == 4 && __GNUC_MINOR__ == 1 && __GNUC_PATCHLEVEL__ <= 3)
+#  if defined(VMM64) || defined(VM_X86_64)
+     __asm__ __volatile__("movq %%rbp, %0\n" : "=g" (bp));
+#  else
+     __asm__ __volatile__("movl %%ebp, %0\n" : "=g" (bp));
+#  endif
+#else
+   __asm__ __volatile__(
+#ifdef __linux__
+      ".print \"This newer version of GCC may or may not have the "
+               "__builtin_frame_address bug.  Need to update this. "
+               "See bug 147638.\"\n"
+      ".abort"
+#else /* MacOS */
+      ".abort \"This newer version of GCC may or may not have the "
+               "__builtin_frame_address bug.  Need to update this. "
+               "See bug 147638.\"\n"
+#endif
+      : "=g" (bp)
+   );
+#endif
+   return bp;
+}
+
+
+/*
+ * Returns the frame pointer of the calling function.
+ * Equivalent to __builtin_frame_address(1).
+ */
+static INLINE_SINGLE_CALLER uintptr_t
+GetCallerFrameAddr(void)
+{
+   return *(uintptr_t*)GetFrameAddr();
+}
+
+#endif // sun
+#endif // __GNUC__
+
+/*
+ * Data prefetch was added in gcc 3.1.1
+ * http://www.gnu.org/software/gcc/gcc-3.1/changes.html
+ */
+#ifdef __GNUC__
+#  if ((__GNUC__ > 3) || (__GNUC__ == 3 && __GNUC_MINOR__ > 1) || \
+       (__GNUC__ == 3 && __GNUC_MINOR__ == 1 && __GNUC_PATCHLEVEL__ >= 1))
+#     define PREFETCH_R(var) __builtin_prefetch((var), 0 /* read */, \
+                                                3 /* high temporal locality */)
+#     define PREFETCH_W(var) __builtin_prefetch((var), 1 /* write */, \
+                                                3 /* high temporal locality */)
+#  else
+#     define PREFETCH_R(var) ((void)(var))
+#     define PREFETCH_W(var) ((void)(var))
+#  endif
+#endif /* __GNUC__ */
+
+
+#ifdef USERLEVEL // {
+
+/*
+ * Note this might be a problem on NT b/c while sched_yield guarantees it
+ * moves you to the end of your priority list, Sleep(0) offers no such
+ * guarantee.  Bummer.  --Jeremy.
+ */
+
+#if defined(N_PLAT_NLM)
+/* We do not have YIELD() as we do not need it yet... */
+#elif defined(_WIN32)
+#      define YIELD()		Sleep(0)
+#else
+#      include <sched.h>        // For sched_yield.  Don't ask.  --Jeremy.
+#      define YIELD()		sched_yield()
+#endif 
+
+
+/*
+ * Standardize some Posix names on Windows.
+ */
+
+#ifdef _WIN32 // {
+
+#define  snprintf  _snprintf
+#define	vsnprintf _vsnprintf
+
+static INLINE void
+sleep(unsigned int sec)
+{
+   Sleep(sec * 1000);
+}
+
+static INLINE void
+usleep(unsigned long usec)
+{
+   Sleep(CEILING(usec, 1000));
+}
+
+typedef int pid_t;
+#define       F_OK          0
+#define       X_OK          1
+#define       W_OK          2
+#define       R_OK          4
+
+#endif // }
+
+/*
+ * Macro for username comparison.
+ */
+
+#ifdef _WIN32 // {
+#define USERCMP(x,y)  Str_Strcasecmp(x,y)
+#else
+#define USERCMP(x,y)  strcmp(x,y)
+#endif // }
+
+
+#endif // }
+
+#ifndef va_copy
+
+#ifdef _WIN32
+
+/*
+ * Windows needs va_copy. This works for both 32 and 64-bit Windows
+ * based on inspection of how varags.h from the Visual C CRTL is
+ * implemented. (Future versions of the RTL may break this).
+ */
+
+#define va_copy(dest, src) ((dest) = (src))
+
+#elif defined(__APPLE__) && defined(KERNEL)
+
+/*
+ * MacOS kernel-mode needs va_copy. Based on inspection of stdarg.h
+ * from the MacOSX10.4u.sdk kernel framework, this should work.
+ * (Future versions of the SDK may break this).
+ */
+
+#define va_copy(dest, src) ((dest) = (src))
+
+#elif defined(__GNUC__) && (__GNUC__ < 3)
+
+/*
+ * Old versions of gcc recognize __va_copy, but not va_copy.
+ */
+
+#define va_copy(dest, src) __va_copy(dest, src)
+
+#endif // _WIN32
+
+#endif // va_copy
+
+/*
+ * This one is outside USERLEVEL because it's used by
+ * files compiled into the Windows hgfs driver or the display
+ * driver.
+ */
+
+#ifdef _WIN32
+#define PATH_MAX 256
+#ifndef strcasecmp
+#define strcasecmp(_s1,_s2)   _stricmp((_s1),(_s2))
+#endif
+#ifndef strncasecmp
+#define strncasecmp(_s1,_s2,_n)   _strnicmp((_s1),(_s2),(_n))
+#endif
+#endif
+
+/* 
+ * Convenience macro for COMMUNITY_SOURCE
+ */
+#undef EXCLUDE_COMMUNITY_SOURCE
+#ifdef COMMUNITY_SOURCE
+   #define EXCLUDE_COMMUNITY_SOURCE(x) 
+#else
+   #define EXCLUDE_COMMUNITY_SOURCE(x) x
+#endif
+
+#undef COMMUNITY_SOURCE_INTEL_SECRET
+#if !defined(COMMUNITY_SOURCE) || defined(INTEL_SOURCE)
+/*
+ * It's ok to include INTEL_SECRET source code for non-commsrc,
+ * or for drops directed at Intel.
+ */
+   #define COMMUNITY_SOURCE_INTEL_SECRET
+#endif
+
+/*
+ * Convenience macros and definitions. Can often be used instead of #ifdef.
+ */
+
+#undef DEBUG_ONLY
+#undef SL_DEBUG_ONLY
+#undef VMX86_SL_DEBUG
+#ifdef VMX86_DEBUG
+#define vmx86_debug      1
+#define DEBUG_ONLY(x)    x
+/*
+ * Be very, very, very careful with SL_DEBUG. Pls ask ganesh or min before 
+ * using it.
+ */
+#define VMX86_SL_DEBUG
+#define vmx86_sl_debug   1
+#define SL_DEBUG_ONLY(x) x
+#else
+#define vmx86_debug      0
+#define DEBUG_ONLY(x)
+#define vmx86_sl_debug   0
+#define SL_DEBUG_ONLY(x)
+#endif
+
+#ifdef VMX86_STATS
+#define vmx86_stats   1
+#define STATS_ONLY(x) x
+#else
+#define vmx86_stats   0
+#define STATS_ONLY(x)
+#endif
+
+#ifdef VMX86_DEVEL
+#define vmx86_devel   1
+#define DEVEL_ONLY(x) x
+#else
+#define vmx86_devel   0
+#define DEVEL_ONLY(x)
+#endif
+
+#ifdef VMX86_LOG
+#define vmx86_log     1
+#define LOG_ONLY(x)   x
+#else
+#define vmx86_log     0
+#define LOG_ONLY(x)
+#endif
+
+#ifdef VMX86_VMM_SERIAL_LOGGING
+#define vmx86_vmm_serial_log     1
+#define VMM_SERIAL_LOG_ONLY(x)   x
+#else
+#define vmx86_vmm_serial_log     0
+#define VMM_SERIAL_LOG_ONLY(x)
+#endif
+
+#ifdef VMX86_SERVER
+#define vmx86_server 1
+#define SERVER_ONLY(x) x
+#define HOSTED_ONLY(x)
+#else
+#define vmx86_server 0
+#define SERVER_ONLY(x)
+#define HOSTED_ONLY(x) x
+#endif
+
+#ifdef VMX86_WGS
+#define vmx86_wgs 1
+#define WGS_ONLY(x) x
+#else
+#define vmx86_wgs 0
+#define WGS_ONLY(x) 
+#endif
+
+#ifdef VMKERNEL
+#define vmkernel 1
+#define VMKERNEL_ONLY(x) x
+#else
+#define vmkernel 0
+#define VMKERNEL_ONLY(x)
+#endif
+
+#ifdef _WIN32
+#define WIN32_ONLY(x) x
+#define POSIX_ONLY(x)
+#else
+#define WIN32_ONLY(x)
+#define POSIX_ONLY(x) x
+#endif
+
+#ifdef VMM
+#define VMM_ONLY(x) x
+#define USER_ONLY(x)
+#else
+#define VMM_ONLY(x)
+#define USER_ONLY(x) x
+#endif
+
+/* VMVISOR ifdef only allowed in the vmkernel */
+#ifdef VMKERNEL
+#ifdef VMVISOR
+#define vmvisor 1
+#define VMVISOR_ONLY(x) x
+#else
+#define vmvisor 0
+#define VMVISOR_ONLY(x)
+#endif
+#endif
+
+#ifdef _WIN32
+#define VMW_INVALID_HANDLE INVALID_HANDLE_VALUE
+#else
+#define VMW_INVALID_HANDLE (-1)
+#endif
+
+#ifdef _WIN32
+#define fsync(fd) _commit(fd)
+#define fileno(f) _fileno(f)
+#else
+#endif
+
+/*
+ * Debug output macros for Windows drivers (the Eng variant is for
+ * display/printer drivers only.
+ */
+#ifdef _WIN32
+#ifndef USES_OLD_WINDDK
+#if defined(VMX86_DEBUG) || defined(ASSERT_ALWAYS_AVAILABLE)
+#define WinDrvPrint(arg, ...) DbgPrint(arg, __VA_ARGS__)
+#define WinDrvEngPrint(arg, ...) EngDbgPrint(arg, __VA_ARGS__)
+#else
+#define WinDrvPrint(arg, ...)
+#define WinDrvEngPrint(arg, ...)
+#endif
+#endif
+#endif // _WIN32
+
+#endif // ifndef _VM_BASIC_DEFS_H_
--- kernel/linux-2.6.26.3/drivers/misc/vsock/vm_basic_types.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vsock/vm_basic_types.h	2008-09-03 10:05:55.000000000 -0500
@@ -0,0 +1,865 @@
+/*********************************************************
+ * Copyright (C) 1998-2008 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ *
+ * vm_basic_types.h --
+ *
+ *    basic data types.
+ */
+
+
+#ifndef _VM_BASIC_TYPES_H_
+#define _VM_BASIC_TYPES_H_
+
+#define INCLUDE_ALLOW_USERLEVEL
+#define INCLUDE_ALLOW_VMMEXT
+#define INCLUDE_ALLOW_MODULE
+#define INCLUDE_ALLOW_VMMON
+#define INCLUDE_ALLOW_VMNIXMOD
+#define INCLUDE_ALLOW_VMKERNEL
+#define INCLUDE_ALLOW_VMKDRIVERS
+#define INCLUDE_ALLOW_VMK_MODULE
+#define INCLUDE_ALLOW_DISTRIBUTE
+#define INCLUDE_ALLOW_VMCORE
+#define INCLUDE_ALLOW_VMIROM
+
+/* STRICT ANSI means the Xserver build and X defines Bool differently. */
+#if !defined(__STRICT_ANSI__) || defined(__FreeBSD__)
+typedef char           Bool;
+#endif
+
+#ifndef FALSE
+#define FALSE          0
+#endif
+
+#ifndef TRUE
+#define TRUE           1
+#endif
+
+#define IsBool(x)      (((x) & ~1) == 0)
+#define IsBool2(x, y)  ((((x) | (y)) & ~1) == 0)
+
+/*
+ * Macros __i386__ and __ia64 are intrinsically defined by GCC
+ */
+#ifdef __i386__
+#define VM_I386
+#endif
+
+#ifdef _WIN64
+#define __x86_64__
+#endif
+
+#ifdef __x86_64__
+#define VM_X86_64
+#define VM_I386
+#define vm_x86_64 (1)
+#else
+#define vm_x86_64 (0)
+#endif
+
+
+
+#ifdef _WIN32
+/* safe assumption for a while */
+#define VM_I386
+#endif
+
+#ifdef _MSC_VER
+typedef unsigned __int64 uint64;
+typedef signed __int64 int64;
+
+#pragma warning (3 :4505) // unreferenced local function
+#pragma warning (disable :4018) // signed/unsigned mismatch
+#pragma warning (disable :4761) // integral size mismatch in argument; conversion supplied
+#pragma warning (disable :4305) // truncation from 'const int' to 'short'
+#pragma warning (disable :4244) // conversion from 'unsigned short' to 'unsigned char'
+#pragma warning (disable :4267) // truncation of 'size_t'
+#pragma warning (disable :4146) // unary minus operator applied to unsigned type, result still unsigned
+#pragma warning (disable :4142) // benign redefinition of type
+
+#elif __GNUC__
+/* The Xserver source compiles with -ansi -pendantic */
+#ifndef __STRICT_ANSI__
+#if defined(VM_X86_64)
+typedef unsigned long uint64;
+typedef long int64;
+#else
+typedef unsigned long long uint64;
+typedef long long int64;
+#endif
+#elif __FreeBSD__
+typedef unsigned long long uint64;
+typedef long long int64;
+#endif
+#else
+#error - Need compiler define for int64/uint64
+#endif
+
+typedef unsigned int       uint32;
+typedef unsigned short     uint16;
+typedef unsigned char      uint8;
+
+typedef int       int32;
+typedef short     int16;
+typedef char      int8;
+
+/*
+ * FreeBSD (for the tools build) unconditionally defines these in
+ * sys/inttypes.h so don't redefine them if this file has already
+ * been included. [greg]
+ *
+ * This applies to Solaris as well.
+ */
+
+/*
+ * Before trying to do the includes based on OS defines, see if we can use
+ * feature-based defines to get as much functionality as possible
+ */
+
+#ifdef HAVE_INTTYPES_H
+#include <inttypes.h>
+#endif
+#ifdef HAVE_SYS_TYPES_H
+#include <sys/types.h>
+#endif
+#ifdef HAVE_SYS_INTTYPES_H
+#include <sys/inttypes.h>
+#endif
+#ifdef HAVE_STDINT_H
+#include <stdint.h>
+#endif
+#ifdef HAVE_STDLIB_H
+#include <stdlib.h>
+#endif
+
+#ifdef __FreeBSD__
+#include <sys/param.h> /* For __FreeBSD_version */         
+#endif
+
+#if !defined(USING_AUTOCONF)
+#   if defined(__FreeBSD__) || defined(sun)
+#      ifdef KLD_MODULE
+#         include <sys/types.h>
+#      else
+#         if !defined(VMKERNEL) && (__FreeBSD_version >= 500043)
+#            include <inttypes.h>
+#            include <sys/types.h>
+#         else
+#            include <sys/inttypes.h>
+#         endif
+#      endif
+#   elif defined __APPLE__
+#      if KERNEL
+#         include <sys/unistd.h>
+#         include <sys/types.h> /* mostly for size_t */
+#         include <stdint.h>
+#      else
+#         include <unistd.h>
+#         include <inttypes.h>
+#         include <stdlib.h>
+#         include <stdint.h>
+#      endif
+#   else
+#      if !defined(__intptr_t_defined) && !defined(intptr_t)
+#         define __intptr_t_defined
+#         define intptr_t  intptr_t
+#         ifdef VM_I386
+#            ifdef VM_X86_64
+typedef int64     intptr_t;
+#            else
+typedef int32     intptr_t;
+#            endif
+#         endif
+#      endif
+
+#      ifndef _STDINT_H
+#         ifdef VM_I386
+#            ifdef VM_X86_64
+typedef uint64    uintptr_t;
+#            else
+typedef uint32    uintptr_t;
+#            endif
+#         endif
+#      endif
+#   endif
+#endif
+
+
+/*
+ * Time
+ * XXX These should be cleaned up.  -- edward
+ */
+
+typedef int64 VmTimeType;          /* Time in microseconds */
+typedef int64 VmTimeRealClock;     /* Real clock kept in microseconds */
+typedef int64 VmTimeVirtualClock;  /* Virtual Clock kept in CPU cycles */
+
+/*
+ * Printf format specifiers for size_t and 64-bit number.
+ * Use them like this:
+ *    printf("%"FMT64"d\n", big);
+ *
+ * FMTH is for handles/fds.
+ */
+
+#ifdef _MSC_VER
+   #define FMT64      "I64"
+   #ifdef VM_X86_64
+      #define FMTSZ      "I64"
+      #define FMTPD      "I64"
+      #define FMTH       "I64"
+   #else
+      #define FMTSZ      "I"
+      #define FMTPD      "I"
+      #define FMTH       "I"
+   #endif
+#elif __GNUC__
+   #define FMTH ""
+   #if defined(N_PLAT_NLM) || defined(sun) || \
+       (defined(__FreeBSD__) && (__FreeBSD__ + 0) && ((__FreeBSD__ + 0) < 5))
+      /*
+       * Why (__FreeBSD__ + 0)?  See bug 141008.
+       * Yes, we really need to test both (__FreeBSD__ + 0) and
+       * ((__FreeBSD__ + 0) < 5).  No, we can't remove "+ 0" from
+       * ((__FreeBSD__ + 0) < 5).
+       */
+      #ifdef VM_X86_64
+         #define FMTSZ  "l"
+         #define FMTPD  "l"
+      #else
+         #define FMTSZ  ""
+         #define FMTPD  ""
+      #endif
+   #elif defined(__linux__) \
+      || (defined(_POSIX_C_SOURCE) && _POSIX_C_SOURCE >= 200112L) \
+      || (defined(_POSIX_VERSION) && _POSIX_VERSION >= 200112L) \
+      || (defined(_POSIX2_VERSION) && _POSIX2_VERSION >= 200112L)
+      /* BSD/Darwin, Linux */
+      #define FMTSZ     "z"
+
+      #ifdef VM_X86_64
+         #define FMTPD  "l"
+      #else
+         #define FMTPD  ""
+      #endif
+   #else
+      /* Systems with a pre-C99 libc */
+      #define FMTSZ     "Z"
+      #ifdef VM_X86_64
+         #define FMTPD  "l"
+      #else
+         #define FMTPD  ""
+      #endif
+   #endif
+   #ifdef VM_X86_64
+      #define FMT64     "l"
+   #elif defined(sun) || defined(__APPLE__) || defined(__FreeBSD__)
+      #define FMT64     "ll"
+   #else
+      #define FMT64     "L"
+   #endif
+#else
+   #error - Need compiler define for FMT64 and FMTSZ
+#endif
+
+/*
+ * Suffix for 64-bit constants.  Use it like this:
+ *    CONST64(0x7fffffffffffffff) for signed or
+ *    CONST64U(0x7fffffffffffffff) for unsigned.
+ *
+ * 2004.08.30(thutt):
+ *   The vmcore/asm64/gen* programs are compiled as 32-bit
+ *   applications, but must handle 64 bit constants.  If the
+ *   64-bit-constant defining macros are already defined, the
+ *   definition will not be overwritten.
+ */
+
+#if !defined(CONST64) || !defined(CONST64U)
+#ifdef _MSC_VER
+#define CONST64(c) c##I64
+#define CONST64U(c) c##uI64
+#elif __GNUC__
+#ifdef VM_X86_64
+#define CONST64(c) c##L
+#define CONST64U(c) c##uL
+#else
+#define CONST64(c) c##LL
+#define CONST64U(c) c##uLL
+#endif
+#else
+#error - Need compiler define for CONST64
+#endif
+#endif
+
+/*
+ * Use CONST3264/CONST3264U if you want a constant to be
+ * treated as a 32-bit number on 32-bit compiles and
+ * a 64-bit number on 64-bit compiles. Useful in the case
+ * of shifts, like (CONST3264U(1) << x), where x could be
+ * more than 31 on a 64-bit compile.
+ */
+
+#ifdef VM_X86_64
+    #define CONST3264(a) CONST64(a)
+    #define CONST3264U(a) CONST64U(a)
+#else
+    #define CONST3264(a) (a)
+    #define CONST3264U(a) (a)
+#endif
+
+#define MIN_INT32  ((int32)0x80000000)
+#define MAX_INT32  ((int32)0x7fffffff)
+
+#define MIN_UINT32 ((uint32)0)
+#define MAX_UINT32 ((uint32)0xffffffff)
+
+#define MIN_INT64  (CONST64(0x8000000000000000))
+#define MAX_INT64  (CONST64(0x7fffffffffffffff))
+
+#define MIN_UINT64 (CONST64U(0))
+#define MAX_UINT64 (CONST64U(0xffffffffffffffff))
+
+typedef uint8 *TCA;  /* Pointer into TC (usually). */
+
+/*
+ * Type big enough to hold an integer between 0..100
+ */
+typedef uint8 Percent;
+#define AsPercent(v)	((Percent)(v))
+#define CHOOSE_PERCENT  AsPercent(101)
+
+
+typedef uintptr_t VA;
+typedef uintptr_t VPN;
+
+typedef uint64    PA;
+typedef uint32    PPN;
+
+typedef uint64    PhysMemOff;
+typedef uint64    PhysMemSize;
+
+/* The Xserver source compiles with -ansi -pendantic */
+#ifndef __STRICT_ANSI__
+typedef uint64    BA;
+#endif
+typedef uint32    BPN;
+typedef uint32    PageNum;
+typedef unsigned  MemHandle;
+typedef int32     World_ID;
+
+#define INVALID_WORLD_ID ((World_ID)0)
+
+typedef World_ID User_CartelID;
+#define INVALID_CARTEL_ID INVALID_WORLD_ID
+
+typedef User_CartelID User_SessionID;
+#define INVALID_SESSION_ID INVALID_CARTEL_ID
+
+typedef User_CartelID User_CartelGroupID;
+#define INVALID_CARTELGROUP_ID INVALID_CARTEL_ID
+
+typedef uint32 Worldlet_ID;
+#define INVALID_WORLDLET_ID ((Worldlet_ID)0)
+
+/* world page number */
+typedef uint32    WPN;
+
+/* The Xserver source compiles with -ansi -pendantic */
+#ifndef __STRICT_ANSI__
+typedef uint64     MA;
+typedef uint32     MPN;
+#endif
+
+/*
+ * This type should be used for variables that contain sector
+ * position/quantity.
+ */
+typedef uint64 SectorType;
+
+/*
+ * Linear address
+ */
+
+typedef uintptr_t LA;
+typedef uintptr_t LPN;
+#define LA_2_LPN(_la)     ((_la) >> PAGE_SHIFT)
+#define LPN_2_LA(_lpn)    ((_lpn) << PAGE_SHIFT)
+
+#define LAST_LPN   ((((LA)  1) << (8 * sizeof(LA)   - PAGE_SHIFT)) - 1)
+#define LAST_LPN32 ((((LA32)1) << (8 * sizeof(LA32) - PAGE_SHIFT)) - 1)
+#define LAST_LPN64 ((((LA64)1) << (8 * sizeof(LA64) - PAGE_SHIFT)) - 1)
+
+/* Valid bits in a LPN. */
+#define LPN_MASK   LAST_LPN
+#define LPN_MASK32 LAST_LPN32
+#define LPN_MASK64 LAST_LPN64
+
+/*
+ * On 64 bit platform, address and page number types default
+ * to 64 bit. When we need to represent a 32 bit address, we use
+ * types defined below.
+ *
+ * On 32 bit platform, the following types are the same as the
+ * default types.
+ */
+typedef uint32 VA32;
+typedef uint32 VPN32;
+typedef uint32 LA32;
+typedef uint32 LPN32;
+typedef uint32 PA32;
+typedef uint32 PPN32;
+typedef uint32 MA32;
+typedef uint32 MPN32;
+
+/*
+ * On 64 bit platform, the following types are the same as the
+ * default types.
+ */
+typedef uint64 VA64;
+typedef uint64 VPN64;
+typedef uint64 LA64;
+typedef uint64 LPN64;
+typedef uint64 PA64;
+typedef uint64 PPN64;
+typedef uint64 MA64;
+typedef uint64 MPN64;
+
+/*
+ * VA typedefs for user world apps.
+ */
+typedef VA32 UserVA32;
+typedef VA64 UserVA64;
+typedef UserVA32 UserVAConst; /* Userspace ptr to data that we may only read. */
+typedef UserVA64 UserVA64Const; /* Used by 64-bit syscalls until conversion is finished. */
+#ifdef VMKERNEL
+typedef UserVA32 UserVA;
+#else
+typedef void * UserVA;
+#endif
+
+
+/*
+ * Maximal possible PPN value (errors too) that PhysMem can handle.
+ * Must be at least as large as MAX_PPN which is the maximum PPN
+ * for any region other than buserror.
+ */
+#define PHYSMEM_MAX_PPN ((PPN)0xffffffff)
+#define MAX_PPN         ((PPN)0x1fffffff)   /* Maximal observable PPN value. */
+#define INVALID_PPN     ((PPN)0xffffffff)
+
+#define INVALID_BPN  ((BPN) 0x1fffffff)
+
+#define INVALID_MPN  ((MPN)-1)
+#define MEMREF_MPN   ((MPN)-2)
+#define RESERVED_MPN ((MPN) 0)
+/* Support 39 bits of address space, minus one page. */
+#define MAX_MPN      ((MPN) 0x07ffffff)
+
+#define INVALID_LPN ((LPN)-1)
+#define INVALID_VPN ((VPN)-1)
+#define INVALID_LPN64 ((LPN64)-1)
+#define INVALID_PAGENUM ((PageNum)-1)
+#define INVALID_WPN ((WPN) -1)
+
+
+/*
+ * Format modifier for printing VA, LA, and VPN.
+ * Use them like this: Log("%#"FMTLA"x\n", laddr)
+ */
+
+#if defined(VMM64) || defined(FROBOS64) || vm_x86_64 || defined __APPLE__
+#   define FMTLA "l"
+#   define FMTVA "l"
+#   define FMTVPN "l"
+#else
+#   define FMTLA ""
+#   define FMTVA ""
+#   define FMTVPN ""
+#endif
+
+#ifndef EXTERN
+#define EXTERN        extern
+#endif
+#define CONST         const
+
+
+#ifndef INLINE
+#   ifdef _MSC_VER
+#      define INLINE        __inline
+#   else
+#      define INLINE        inline
+#   endif
+#endif
+
+
+/*
+ * Annotation for data that may be exported into a DLL and used by other
+ * apps that load that DLL and import the data.
+ */
+#if defined(_WIN32) && defined(VMX86_IMPORT_DLLDATA)
+#  define VMX86_EXTERN_DATA       extern __declspec(dllimport)
+#else // !_WIN32
+#  define VMX86_EXTERN_DATA       extern
+#endif
+
+#if defined(_WIN32) && !defined(VMX86_NO_THREADS)
+#define THREADSPECIFIC __declspec(thread)
+#else
+#define THREADSPECIFIC
+#endif
+
+/*
+ * Due to the wonderful "registry redirection" feature introduced in
+ * 64-bit Windows, if you access any key under HKLM\Software in 64-bit
+ * code, you need to open/create/delete that key with
+ * VMKEY_WOW64_32KEY if you want a consistent view with 32-bit code.
+ */
+
+#ifdef _WIN32
+#ifdef _WIN64
+#define VMW_KEY_WOW64_32KEY KEY_WOW64_32KEY
+#else
+#define VMW_KEY_WOW64_32KEY 0x0
+#endif
+#endif
+
+
+/*
+ * Consider the following reasons functions are inlined:
+ *
+ *  1) inlined for performance reasons
+ *  2) inlined because it's a single-use function
+ *
+ * Functions which meet only condition 2 should be marked with this
+ * inline macro; It is not critical to be inlined (but there is a
+ * code-space & runtime savings by doing so), so when other callers
+ * are added the inline-ness should be removed.
+ */
+
+#if __GNUC__ > 3 || (__GNUC__ == 3 && __GNUC_MINOR__ >= 3)
+/*
+ * Starting at version 3.3, gcc does not always inline functions marked
+ * 'inline' (it depends on their size). To force gcc to do so, one must use the
+ * extra __always_inline__ attribute.
+ */
+#   define INLINE_SINGLE_CALLER INLINE __attribute__((__always_inline__))
+#   if    defined(VMM) \
+       && (__GNUC__ > 4 || (__GNUC__ == 4 && __GNUC_MINOR__ > 1))
+#      warning Verify INLINE_SINGLE_CALLER '__always_inline__' attribute (did \
+             monitor size change?)
+#   endif
+#else
+#   define INLINE_SINGLE_CALLER INLINE
+#endif
+
+/*
+ * Used when a hard guaranteed of no inlining is needed. Very few
+ * instances need this since the absence of INLINE is a good hint
+ * that gcc will not do inlining.
+ */
+
+#if defined(__GNUC__) && defined(VMM)
+#define ABSOLUTELY_NOINLINE __attribute__((__noinline__))
+#endif
+
+/*
+ * Attributes placed on function declarations to tell the compiler
+ * that the function never returns.
+ */
+
+#ifdef _MSC_VER
+#define NORETURN __declspec(noreturn)
+#elif __GNUC__ > 2 || (__GNUC__ == 2 && __GNUC_MINOR__ >= 9)
+#define NORETURN __attribute__((__noreturn__))
+#else
+#define NORETURN
+#endif
+
+/*
+ * GCC 3.2 inline asm needs the + constraint for input/ouput memory operands.
+ * Older GCCs don't know about it --hpreg
+ */
+
+#if __GNUC__ > 3 || (__GNUC__ == 3 && __GNUC_MINOR__ >= 2)
+#   define VM_ASM_PLUS 1
+#else
+#   define VM_ASM_PLUS 0
+#endif
+
+/*
+ * Branch prediction hints:
+ *     LIKELY(exp)   - Expression exp is likely TRUE.
+ *     UNLIKELY(exp) - Expression exp is likely FALSE.
+ *   Usage example:
+ *        if (LIKELY(excCode == EXC_NONE)) {
+ *               or
+ *        if (UNLIKELY(REAL_MODE(vc))) {
+ *
+ * We know how to predict branches on gcc3 and later (hopefully),
+ * all others we don't so we do nothing.
+ */
+
+#if (__GNUC__ >= 3)
+/*
+ * gcc3 uses __builtin_expect() to inform the compiler of an expected value.
+ * We use this to inform the static branch predictor. The '!!' in LIKELY
+ * will convert any !=0 to a 1.
+ */
+#define LIKELY(_exp)     __builtin_expect(!!(_exp), 1)
+#define UNLIKELY(_exp)   __builtin_expect((_exp), 0)
+#else
+#define LIKELY(_exp)      (_exp)
+#define UNLIKELY(_exp)    (_exp)
+#endif
+
+/*
+ * GCC's argument checking for printf-like functions
+ * This is conditional until we have replaced all `"%x", void *'
+ * with `"0x%08x", (uint32) void *'. Note that %p prints different things
+ * on different platforms.  Argument checking is enabled for the
+ * vmkernel, which has already been cleansed.
+ *
+ * fmtPos is the position of the format string argument, beginning at 1
+ * varPos is the position of the variable argument, beginning at 1
+ */
+
+#if defined(__GNUC__)
+# define PRINTF_DECL(fmtPos, varPos) __attribute__((__format__(__printf__, fmtPos, varPos)))
+#else
+# define PRINTF_DECL(fmtPos, varPos)
+#endif
+
+#if defined(__GNUC__)
+# define SCANF_DECL(fmtPos, varPos) __attribute__((__format__(__scanf__, fmtPos, varPos)))
+#else
+# define SCANF_DECL(fmtPos, varPos)
+#endif
+
+/*
+ * UNUSED_PARAM should surround the parameter name and type declaration,
+ * e.g. "int MyFunction(int var1, UNUSED_PARAM(int var2))"
+ *
+ */
+
+#ifndef UNUSED_PARAM
+# if defined(__GNUC__)
+#  define UNUSED_PARAM(_parm) _parm  __attribute__((__unused__))
+# else
+#  define UNUSED_PARAM(_parm) _parm
+# endif
+#endif
+
+/*
+ * REGPARM defaults to REGPARM3, i.e., a requent that gcc
+ * puts the first three arguments in registers.  (It is fine
+ * if the function has fewer than three args.)  Gcc only.
+ * Syntactically, put REGPARM where you'd put INLINE or NORETURN.
+ */
+
+#if defined(__GNUC__)
+# define REGPARM0 __attribute__((regparm(0)))
+# define REGPARM1 __attribute__((regparm(1)))
+# define REGPARM2 __attribute__((regparm(2)))
+# define REGPARM3 __attribute__((regparm(3)))
+# define REGPARM REGPARM3
+#else
+# define REGPARM0
+# define REGPARM1
+# define REGPARM2
+# define REGPARM3
+# define REGPARM
+#endif
+
+/*
+ * ALIGNED specifies minimum alignment in "n" bytes.
+ */
+
+#ifdef __GNUC__
+#define ALIGNED(n) __attribute__((__aligned__(n)))
+#else
+#define ALIGNED(n)
+#endif
+
+/*
+ * __func__ is a stringified function name that is part of the C99 standard. The block
+ * below defines __func__ on older systems where the compiler does not support that
+ * macro.
+ */
+#if defined(__GNUC__) \
+   && ((__GNUC__ == 2 && __GNUC_MINOR < 96) \
+       || (__GNUC__ < 2))
+#   define __func__ __FUNCTION__
+#endif
+
+/*
+ * Once upon a time, this was used to silence compiler warnings that
+ * get generated when the compiler thinks that a function returns
+ * when it is marked noreturn.  Don't do it.  Use NOT_REACHED().
+ */
+
+#define INFINITE_LOOP()           do { } while (1)
+
+/*
+ * On FreeBSD (for the tools build), size_t is typedef'd if _BSD_SIZE_T_
+ * is defined. Use the same logic here so we don't define it twice. [greg]
+ */
+#ifdef __FreeBSD__
+#   ifdef _BSD_SIZE_T_
+#      undef _BSD_SIZE_T_
+#      ifdef VM_I386
+#         ifdef VM_X86_64
+             typedef uint64 size_t;
+#         else
+             typedef uint32 size_t;
+#         endif
+#      endif /* VM_I386 */
+#   endif
+
+#   ifdef _BSD_SSIZE_T_
+#      undef _BSD_SSIZE_T_
+#      define _SSIZE_T
+#      define __ssize_t_defined
+#      define _SSIZE_T_DECLARED
+#      ifdef VM_I386
+#         ifdef VM_X86_64
+             typedef int64 ssize_t;
+#         else
+             typedef int32 ssize_t;
+#         endif
+#      endif /* VM_I386 */
+#   endif
+
+#else
+#   ifndef _SIZE_T
+#      define _SIZE_T
+#      ifdef VM_I386
+#         ifdef VM_X86_64
+             typedef uint64 size_t;
+#         else
+             typedef uint32 size_t;
+#         endif
+#      endif /* VM_I386 */
+#   endif
+
+#   if !defined(FROBOS) && !defined(_SSIZE_T) && !defined(ssize_t) && \
+       !defined(__ssize_t_defined) && !defined(_SSIZE_T_DECLARED)
+#      define _SSIZE_T
+#      define __ssize_t_defined
+#      define _SSIZE_T_DECLARED
+#      ifdef VM_I386
+#         ifdef VM_X86_64
+             typedef int64 ssize_t;
+#         else
+             typedef int32 ssize_t;
+#         endif
+#      endif /* VM_I386 */
+#   endif
+
+#endif
+
+/*
+ * Format modifier for printing pid_t.  On sun the pid_t is a ulong, but on
+ * Linux it's an int.
+ * Use this like this: printf("The pid is %"FMTPID".\n", pid);
+ */
+#ifdef sun
+#   ifdef VM_X86_64
+#      define FMTPID "d"
+#   else
+#      define FMTPID "lu"
+#   endif
+#else
+# define FMTPID "d"
+#endif
+
+/*
+ * Format modifier for printing uid_t.  On sun the uid_t is a ulong, but on
+ * Linux it's an int.
+ * Use this like this: printf("The uid is %"FMTUID".\n", uid);
+ */
+#ifdef sun
+#   ifdef VM_X86_64
+#      define FMTUID "u"
+#   else
+#      define FMTUID "lu"
+#   endif
+#else
+# define FMTUID "u"
+#endif
+
+/*
+ * Format modifier for printing mode_t.  On sun the mode_t is a ulong, but on
+ * Linux it's an int.
+ * Use this like this: printf("The mode is %"FMTMODE".\n", mode);
+ */
+#ifdef sun
+#   ifdef VM_X86_64
+#      define FMTMODE "o"
+#   else
+#      define FMTMODE "lo"
+#   endif
+#else
+# define FMTMODE "o"
+#endif
+
+/*
+ * Format modifier for printing time_t. Most platforms define a time_t to be
+ * a long int, but on FreeBSD (as of 5.0, it seems), the time_t is a signed
+ * size quantity. Refer to the definition of FMTSZ to see why we need silly
+ * preprocessor arithmetic.
+ * Use this like this: printf("The mode is %"FMTTIME".\n", time);
+ */
+#if defined(__FreeBSD__) && (__FreeBSD__ + 0) && ((__FreeBSD__ + 0) >= 5)
+#   define FMTTIME FMTSZ"d"
+#else
+#   define FMTTIME "ld"
+#endif
+
+/*
+ * Define MXSemaHandle here so both vmmon and vmx see this definition.
+ */
+
+#ifdef _WIN32
+typedef uintptr_t MXSemaHandle;
+#else
+typedef int MXSemaHandle;
+#endif
+
+/*
+ * Define type for poll device handles.
+ */
+
+#ifdef _WIN32
+typedef uintptr_t PollDevHandle;
+#else
+typedef int PollDevHandle;
+#endif
+
+/*
+ * Define the utf16_t type.
+ */
+
+#if defined(_WIN32) && defined(_NATIVE_WCHAR_T_DEFINED)
+typedef wchar_t utf16_t;
+#else
+typedef uint16 utf16_t;
+#endif
+
+#endif  /* _VM_BASIC_TYPES_H_ */
--- kernel/linux-2.6.26.3/drivers/misc/vsock/vmci_call_defs.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vsock/vmci_call_defs.h	2008-09-03 10:06:09.000000000 -0500
@@ -0,0 +1,265 @@
+/*********************************************************
+ * Copyright (C) 2006-2007 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef _VMCI_CALL_DEFS_H_
+#define _VMCI_CALL_DEFS_H_
+
+#define INCLUDE_ALLOW_USERLEVEL
+#define INCLUDE_ALLOW_VMMEXT
+#define INCLUDE_ALLOW_MODULE
+#define INCLUDE_ALLOW_VMMON
+#define INCLUDE_ALLOW_VMCORE
+#define INCLUDE_ALLOW_VMKMOD
+#define INCLUDE_ALLOW_VMKERNEL
+#define INCLUDE_ALLOW_DISTRIBUTE
+
+#include "vm_basic_types.h"
+#include "vmci_defs.h"
+
+/*
+ * All structs here are an integral size of their largest member, ie. a struct 
+ * with at least one 8-byte member will have a size that is an integral of 8.
+ * A struct which has a largest member of size 4 will have a size that is an
+ * integral of 4. This is because Windows CL enforces this rule. 32 bit gcc 
+ * doesn't e.g. 32 bit gcc can misalign an 8 byte member if it is preceeded by
+ * a 4 byte member. 
+ */
+
+/*
+ * Base struct for vmci datagrams.
+ */
+
+typedef struct VMCIDatagram {
+   VMCIHandle dst;
+   VMCIHandle src;
+   uint64     payloadSize;
+} VMCIDatagram;
+
+typedef int
+(*VMCIDatagramRecvCB)(void *clientData,   // IN: client data for handler
+                      VMCIDatagram *msg); // IN: 
+
+/* Flag for creating a wellknown handle instead of a per context handle. */
+#define VMCI_FLAG_WELLKNOWN_DG_HND 0x1
+
+/* 
+ * Maximum supported size of a VMCI datagram for routable datagrams.
+ * Datagrams going to the hypervisor are allowed to be larger.
+ */
+#define VMCI_MAX_DG_SIZE (17 * 4096)
+#define VMCI_MAX_DG_PAYLOAD_SIZE (VMCI_MAX_DG_SIZE - sizeof(VMCIDatagram))
+#define VMCI_DG_PAYLOAD(_dg) (void *)((char *)(_dg) + sizeof(VMCIDatagram))
+#define VMCI_DG_HEADERSIZE sizeof(VMCIDatagram)
+#define VMCI_DG_SIZE(_dg) (VMCI_DG_HEADERSIZE + (size_t)(_dg)->payloadSize)
+#define VMCI_DG_SIZE_ALIGNED(_dg) ((VMCI_DG_SIZE(_dg) + 7) & (size_t)CONST64U(0xfffffffffffffff8))
+#define VMCI_MAX_DATAGRAM_QUEUE_SIZE  (VMCI_MAX_DG_SIZE * 2)
+
+/* 
+ * Struct for sending VMCI_DATAGRAM_REQUEST_MAP and VMCI_DATAGRAM_REMOVE_MAP
+ * datagrams. Struct size is 32 bytes. All fields in struct are aligned to
+ * their natural alignment.
+ */
+typedef struct VMCIDatagramWellKnownMapMsg {
+   VMCIDatagram hdr;
+   VMCIId       wellKnownID;
+   uint32       _pad;
+} VMCIDatagramWellKnownMapMsg;
+
+
+/*
+ * Struct used for querying, via VMCI_RESOURCES_QUERY, the availability of 
+ * hypervisor resources. 
+ * Struct size is 16 bytes. All fields in struct are aligned to their natural
+ * alignment.
+ */
+typedef struct VMCIResourcesQueuryHdr {
+   VMCIDatagram hdr;
+   uint32       numResources;
+   uint32       _padding;
+} VMCIResourcesQueryHdr;
+
+
+/*
+ * Convenience struct for negotiating vectors. Must match layout of
+ * VMCIResourceQueryHdr minus the VMCIDatagram header.
+ */
+typedef struct VMCIResourcesQueryMsg {
+   uint32        numResources;
+   uint32        _padding;
+   VMCI_Resource resources[1];
+} VMCIResourcesQueryMsg;
+
+
+/* 
+ * The maximum number of resources that can be queried using
+ * VMCI_RESOURCE_QUERY is 31, as the result is encoded in the lower 31
+ * bits of a positive return value. Negative values are reserved for
+ * errors.
+ */
+#define VMCI_RESOURCE_QUERY_MAX_NUM 31
+
+/* Maximum size for the VMCI_RESOURCE_QUERY request. */
+#define VMCI_RESOURCE_QUERY_MAX_SIZE sizeof(VMCIResourcesQueryHdr) \
+      + VMCI_RESOURCE_QUERY_MAX_NUM * sizeof(VMCI_Resource)
+
+/* 
+ * Struct used for making VMCI_SHAREDMEM_CREATE message. Struct size is 24 bytes.
+ * All fields in struct are aligned to their natural alignment.
+ */
+typedef struct VMCISharedMemCreateMsg {
+   VMCIDatagram hdr;
+   VMCIHandle   handle;
+   uint32       memSize;
+   uint32       _padding;
+   /* PPNs placed after struct. */
+} VMCISharedMemCreateMsg;
+
+
+/* 
+ * Struct used for sending VMCI_SHAREDMEM_ATTACH messages. Same as struct used 
+ * for create messages.
+ */
+typedef VMCISharedMemCreateMsg VMCISharedMemAttachMsg;
+
+
+/* 
+ * Struct used for sending VMCI_SHAREDMEM_DETACH messsages. Struct size is 16
+ * bytes. All fields in struct are aligned to their natural alignment.
+ */
+typedef struct VMCISharedMemDetachMsg {
+   VMCIDatagram hdr;
+   VMCIHandle handle;
+} VMCISharedMemDetachMsg;
+
+
+/* 
+ * Struct used for sending VMCI_SHAREDMEM_QUERY messages. Same as struct used 
+ * for detach messages.
+ */
+typedef VMCISharedMemDetachMsg VMCISharedMemQueryMsg;
+
+
+/* 
+ * This struct is used to contain data for events.  Size of this struct is a
+ * multiple of 8 bytes, and all fields are aligned to their natural alignment.
+ */
+typedef struct VMCI_EventData {
+   VMCI_Event event; /* 4 bytes. */
+   uint32     _pad;
+   /*
+    * Event payload is put here.
+    */
+} VMCI_EventData;
+
+
+/*
+ * We use the following inline function to access the payload data associated
+ * with an event data.
+ */
+
+static INLINE void *
+VMCIEventDataPayload(VMCI_EventData *evData) // IN:
+{
+   return (void *)((char *)evData + sizeof *evData);
+}
+
+/*
+ * Define the different VMCI_EVENT payload data types here.  All structs must
+ * be a multiple of 8 bytes, and fields must be aligned to their natural
+ * alignment.
+ */
+typedef struct VMCIEventPayload_Context {
+   VMCIId contextID; /* 4 bytes. */
+   uint32 _pad;
+} VMCIEventPayload_Context;
+
+typedef struct VMCIEventPayload_QP {
+   VMCIHandle handle; /* QueuePair handle. */
+   VMCIId     peerId; /* Context id of attaching/detaching VM. */
+   uint32     _pad;
+} VMCIEventPayload_QP;
+
+/*
+ * We define the following struct to get the size of the maximum event data
+ * the hypervisor may send to the guest.  If adding a new event payload type
+ * above, add it to the following struct too (inside the union).
+ */
+typedef struct VMCIEventData_Max {
+   VMCI_EventData eventData;
+   union {
+      VMCIEventPayload_Context contextPayload;
+      VMCIEventPayload_QP      qpPayload;
+   } evDataPayload;
+} VMCIEventData_Max;
+
+
+/* 
+ * Struct used for VMCI_EVENT_SUBSCRIBE/UNSUBSCRIBE and VMCI_EVENT_HANDLER 
+ * messages.  Struct size is 32 bytes.  All fields in struct are aligned to
+ * their natural alignment.
+ */
+typedef struct VMCIEventMsg {
+   VMCIDatagram   hdr;
+   VMCI_EventData eventData; /* Has event type and payload. */
+   /*
+    * Payload gets put here.
+    */
+} VMCIEventMsg;
+
+
+/*
+ * We use the following inline function to access the payload data associated
+ * with an event message.
+ */
+
+static INLINE void *
+VMCIEventMsgPayload(VMCIEventMsg *eMsg) // IN:
+{
+   return VMCIEventDataPayload(&eMsg->eventData);
+}
+
+
+/* Flags for VMCI QueuePair API. */
+#define VMCI_QPFLAG_ATTACH_ONLY 0x1 /* Fail alloc if QP not created by peer. */
+#define VMCI_QPFLAG_LOCAL       0x2 /* Only allow attaches from local context. */
+/* Update the following (bitwise OR flags) while adding new flags. */
+#define VMCI_QP_ALL_FLAGS       (VMCI_QPFLAG_ATTACH_ONLY | VMCI_QPFLAG_LOCAL)
+
+/*
+ * Structs used for QueuePair alloc and detach messages.  We align fields of
+ * these structs to 64bit boundaries.
+ */
+
+typedef struct VMCIQueuePairAllocMsg {
+   VMCIDatagram   hdr;
+   VMCIHandle     handle;
+   VMCIId         peer; /* 32bit field. */
+   uint32         flags;
+   uint64         produceSize;
+   uint64         consumeSize;
+   uint64         numPPNs;
+   /* List of PPNs placed here. */
+} VMCIQueuePairAllocMsg;
+
+
+typedef struct VMCIQueuePairDetachMsg {
+   VMCIDatagram  hdr;
+   VMCIHandle    handle;
+} VMCIQueuePairDetachMsg;
+
+#endif
--- kernel/linux-2.6.26.3/drivers/misc/vsock/vmci_defs.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vsock/vmci_defs.h	2008-09-03 10:06:21.000000000 -0500
@@ -0,0 +1,289 @@
+/*********************************************************
+ * Copyright (C) 2005-2008 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef _VMCI_DEF_H_
+#define _VMCI_DEF_H_
+
+#define INCLUDE_ALLOW_USERLEVEL
+#define INCLUDE_ALLOW_VMMEXT
+#define INCLUDE_ALLOW_MODULE
+#define INCLUDE_ALLOW_VMMON
+#define INCLUDE_ALLOW_VMCORE
+#define INCLUDE_ALLOW_VMK_MODULE
+#define INCLUDE_ALLOW_VMKERNEL
+#define INCLUDE_ALLOW_DISTRIBUTE
+
+#include "vm_basic_types.h"
+
+/* Register offsets. */
+#define VMCI_STATUS_ADDR      0x00
+#define VMCI_CONTROL_ADDR     0x04
+#define VMCI_ICR_ADDR	      0x08
+#define VMCI_IMR_ADDR         0x0c
+#define VMCI_DATA_OUT_ADDR    0x10
+#define VMCI_DATA_IN_ADDR     0x14
+#define VMCI_CAPS_ADDR        0x18
+#define VMCI_RESULT_LOW_ADDR  0x1c
+#define VMCI_RESULT_HIGH_ADDR 0x20
+
+/* Max number of devices. */
+#define VMCI_MAX_DEVICES 1
+
+/* Status register bits. */
+#define VMCI_STATUS_INT_ON     0x1
+
+/* Control register bits. */
+#define VMCI_CONTROL_RESET        0x1
+#define VMCI_CONTROL_INT_ENABLE   0x2
+#define VMCI_CONTROL_INT_DISABLE  0x4
+
+/* Capabilities register bits. */
+#define VMCI_CAPS_HYPERCALL    0x1 
+#define VMCI_CAPS_GUESTCALL    0x2
+#define VMCI_CAPS_DATAGRAM     0x4
+
+/* Interrupt Cause register bits. */
+#define VMCI_ICR_DATAGRAM     0x1
+
+/* Interrupt Mask register bits. */
+#define VMCI_IMR_DATAGRAM     0x1
+
+/* 
+ * We have a fixed set of resource IDs available in the VMX. 
+ * This allows us to have a very simple implementation since we statically 
+ * know how many will create datagram handles. If a new caller arrives and
+ * we have run out of slots we can manually increment the maximum size of
+ * available resource IDs.
+ */
+
+typedef uint32 VMCI_Resource;
+
+/* VMCI reserved hypervisor datagram resource IDs. */
+#define VMCI_RESOURCES_QUERY      0
+#define VMCI_GET_CONTEXT_ID       1
+#define VMCI_SHAREDMEM_CREATE     2
+#define VMCI_SHAREDMEM_ATTACH     3
+#define VMCI_SHAREDMEM_DETACH     4
+#define VMCI_SHAREDMEM_QUERY      5
+#define VMCI_DATAGRAM_REQUEST_MAP 6
+#define VMCI_DATAGRAM_REMOVE_MAP  7
+#define VMCI_EVENT_SUBSCRIBE      8
+#define VMCI_EVENT_UNSUBSCRIBE    9
+#define VMCI_QUEUEPAIR_ALLOC      10
+#define VMCI_QUEUEPAIR_DETACH     11
+#define VMCI_RESOURCE_MAX         12
+
+/* VMCI Ids. */
+typedef uint32 VMCIId;
+
+typedef struct VMCIHandle {
+   VMCIId context;
+   VMCIId resource;
+} VMCIHandle;
+
+static INLINE
+VMCIHandle VMCI_MAKE_HANDLE(VMCIId cid, 
+			    VMCIId rid)
+{
+   VMCIHandle h = {cid, rid};
+   return h;
+}
+
+#define VMCI_HANDLE_TO_CONTEXT_ID(_handle) ((_handle).context)
+#define VMCI_HANDLE_TO_RESOURCE_ID(_handle) ((_handle).resource)
+#define VMCI_HANDLE_EQUAL(_h1, _h2) ((_h1).context == (_h2).context && \
+				     (_h1).resource == (_h2).resource)
+
+#define VMCI_INVALID_ID 0xFFFFFFFF
+static const VMCIHandle VMCI_INVALID_HANDLE = {VMCI_INVALID_ID, 
+					       VMCI_INVALID_ID};
+
+#define VMCI_HANDLE_INVALID(_handle)   \
+   VMCI_HANDLE_EQUAL((_handle), VMCI_INVALID_HANDLE)
+
+/*
+ * The below defines can be used to send anonymous requests.
+ * This also indicates that no response is expected.
+ */
+#define VMCI_ANON_SRC_CONTEXT_ID   VMCI_INVALID_ID
+#define VMCI_ANON_SRC_RESOURCE_ID  VMCI_INVALID_ID
+#define VMCI_ANON_SRC_HANDLE       VMCI_MAKE_HANDLE(VMCI_ANON_SRC_CONTEXT_ID, \
+						    VMCI_ANON_SRC_RESOURCE_ID)
+
+/* The lowest 16 context ids are reserved for internal use. */
+#define VMCI_RESERVED_CID_LIMIT 16
+
+/*
+ * Hypervisor context id, used for calling into hypervisor
+ * supplied services from the VM. 
+ */
+#define VMCI_HYPERVISOR_CONTEXT_ID 0
+
+/* 
+ * Well-known context id, a logical context that contains 
+ * a set of well-known services.
+ */
+#define VMCI_WELL_KNOWN_CONTEXT_ID 1
+
+/* Todo: Change host context id to dynamic/random id. */
+#define VMCI_HOST_CONTEXT_ID  2
+
+/* 
+ * The VMCI_CONTEXT_RESOURCE_ID is used together with VMCI_MAKE_HANDLE to make 
+ * handles that refer to a specific context.
+ */
+#define VMCI_CONTEXT_RESOURCE_ID 0
+
+
+/* VMCI error codes. */
+#define VMCI_SUCCESS_QUEUEPAIR_ATTACH     5
+#define VMCI_SUCCESS_QUEUEPAIR_CREATE     4
+#define VMCI_SUCCESS_LAST_DETACH          3
+#define VMCI_SUCCESS_ACCESS_GRANTED       2
+#define VMCI_SUCCESS_ENTRY_DEAD           1
+#define VMCI_SUCCESS                      0
+#define VMCI_ERROR_INVALID_RESOURCE      (-1)
+#define VMCI_ERROR_INVALID_ARGS          (-2)
+#define VMCI_ERROR_NO_MEM                (-3)
+#define VMCI_ERROR_DATAGRAM_FAILED       (-4)
+#define VMCI_ERROR_MORE_DATA             (-5)
+#define VMCI_ERROR_NO_MORE_DATAGRAMS     (-6)
+#define VMCI_ERROR_NO_ACCESS             (-7)
+#define VMCI_ERROR_NO_HANDLE             (-8)
+#define VMCI_ERROR_DUPLICATE_ENTRY       (-9)
+#define VMCI_ERROR_DST_UNREACHABLE       (-10)
+#define VMCI_ERROR_PAYLOAD_TOO_LARGE     (-11)
+#define VMCI_ERROR_INVALID_PRIV          (-12)
+#define VMCI_ERROR_GENERIC               (-13)
+#define VMCI_ERROR_PAGE_ALREADY_SHARED   (-14)
+#define VMCI_ERROR_CANNOT_SHARE_PAGE     (-15)
+#define VMCI_ERROR_CANNOT_UNSHARE_PAGE   (-16)
+#define VMCI_ERROR_NO_PROCESS            (-17)
+#define VMCI_ERROR_NO_DATAGRAM           (-18)
+#define VMCI_ERROR_NO_RESOURCES          (-19)
+#define VMCI_ERROR_UNAVAILABLE           (-20)
+#define VMCI_ERROR_NOT_FOUND             (-21)
+#define VMCI_ERROR_ALREADY_EXISTS        (-22)
+#define VMCI_ERROR_NOT_PAGE_ALIGNED      (-23)
+#define VMCI_ERROR_INVALID_SIZE          (-24)
+#define VMCI_ERROR_REGION_ALREADY_SHARED (-25)
+#define VMCI_ERROR_TIMEOUT               (-26)
+#define VMCI_ERROR_DATAGRAM_INCOMPLETE   (-27)
+#define VMCI_ERROR_INCORRECT_IRQL        (-28)
+#define VMCI_ERROR_EVENT_UNKNOWN         (-29)
+#define VMCI_ERROR_OBSOLETE              (-30)
+#define VMCI_ERROR_QUEUEPAIR_MISMATCH    (-31)
+#define VMCI_ERROR_QUEUEPAIR_NOTSET      (-32)
+#define VMCI_ERROR_QUEUEPAIR_NOTOWNER    (-33)
+#define VMCI_ERROR_QUEUEPAIR_NOTATTACHED (-34)
+#define VMCI_ERROR_QUEUEPAIR_NOSPACE     (-35)
+#define VMCI_ERROR_QUEUEPAIR_NODATA      (-36)
+#define VMCI_ERROR_BUSMEM_INVALIDATION   (-37)
+ 
+/* Internal error codes. */
+#define VMCI_SHAREDMEM_ERROR_BAD_CONTEXT (-1000)
+
+#define VMCI_PATH_MAX 256
+
+/* VMCI reserved events. */
+typedef uint32 VMCI_Event;
+
+#define VMCI_EVENT_CTX_ID_UPDATE  0
+#define VMCI_EVENT_CTX_REMOVED    1
+#define VMCI_EVENT_QP_RESUMED     2
+#define VMCI_EVENT_QP_PEER_ATTACH 3
+#define VMCI_EVENT_QP_PEER_DETACH 4
+#define VMCI_EVENT_MAX            5
+
+/* Reserved guest datagram resource ids. */
+#define VMCI_EVENT_HANDLER 0
+
+/* VMCI privileges. */
+typedef enum VMCIResourcePrivilegeType {
+   VMCI_PRIV_CH_PRIV,
+   VMCI_PRIV_DESTROY_RESOURCE,
+   VMCI_PRIV_ASSIGN_CLIENT,
+   VMCI_PRIV_DG_CREATE,
+   VMCI_PRIV_DG_SEND,
+   VMCI_PRIV_SM_CREATE,
+   VMCI_PRIV_SM_ATTACH,
+   VMCI_NUM_PRIVILEGES,
+} VMCIResourcePrivilegeType;
+
+/* 
+ * VMCI coarse-grained privileges (per context or host
+ * process/endpoint. An entity with the restricted flag is only
+ * allowed to interact with the hypervisor and trusted entities.
+ */
+typedef uint32 VMCIPrivilegeFlags;
+
+#define VMCI_PRIVILEGE_FLAG_RESTRICTED     0x01
+#define VMCI_PRIVILEGE_FLAG_TRUSTED        0x02
+#define VMCI_PRIVILEGE_ALL_FLAGS           (VMCI_PRIVILEGE_FLAG_RESTRICTED | \
+				            VMCI_PRIVILEGE_FLAG_TRUSTED)
+#define VMCI_NO_PRIVILEGE_FLAGS            0x00
+#define VMCI_DEFAULT_PROC_PRIVILEGE_FLAGS  VMCI_NO_PRIVILEGE_FLAGS
+#define VMCI_LEAST_PRIVILEGE_FLAGS         VMCI_PRIVILEGE_FLAG_RESTRICTED
+#define VMCI_MAX_PRIVILEGE_FLAGS           VMCI_PRIVILEGE_FLAG_TRUSTED
+
+/* VMCI Discovery Service. */
+
+/* Well-known handle to the discovery service. */
+#define VMCI_DS_RESOURCE_ID 1 /* Reserved resource ID for discovery service. */
+#define VMCI_DS_HANDLE VMCI_MAKE_HANDLE(VMCI_WELL_KNOWN_CONTEXT_ID, \
+					VMCI_DS_RESOURCE_ID)
+#define VMCI_DS_CONTEXT VMCI_MAKE_HANDLE(VMCI_WELL_KNOWN_CONTEXT_ID, \
+					 VMCI_CONTEXT_RESOURCE_ID)
+
+/* Maximum length of a DS message. */
+#define VMCI_DS_MAX_MSG_SIZE        300
+
+/* Command actions. */
+#define VMCI_DS_ACTION_LOOKUP         0
+#define VMCI_DS_ACTION_REGISTER       1
+#define VMCI_DS_ACTION_UNREGISTER     2
+
+/* Defines wire-protocol format for a request send to the DS from a context. */
+typedef struct VMCIDsRequestHeader {
+   int32       action;
+   int32       msgid;
+   VMCIHandle  handle;
+   int32       nameLen;
+   int8        name[1];   
+} VMCIDsRequestHeader;
+
+
+/* Defines the wire-protocol format for a request send from the DS to a context. */
+typedef struct VMCIDsReplyHeader {
+   int32       msgid;
+   int32       code;
+   VMCIHandle  handle;
+   int32       msgLen;
+   int8        msg[1];
+} VMCIDsReplyHeader;
+
+#define VMCI_PUBLIC_GROUP_NAME "vmci public group"
+/* 0 through VMCI_RESERVED_RESOURCE_ID_MAX are reserved. */
+#define VMCI_RESERVED_RESOURCE_ID_MAX 1023
+
+#define VMCI_DOMAIN_NAME_MAXLEN  32
+
+#define VMCI_LGPFX "VMCI: "
+
+#endif
+
--- kernel/linux-2.6.26.3/drivers/misc/vsock/vmciGuestKernelAPI.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vsock/vmciGuestKernelAPI.h	2008-09-03 10:06:30.000000000 -0500
@@ -0,0 +1,80 @@
+/*********************************************************
+ * Copyright (C) 2007 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/* 
+ * vmciGuestKernelAPI.h --
+ *
+ *    Kernel API exported from the VMCI guest driver.
+ */
+
+#ifndef __VMCI_GUESTKERNELAPI_H__
+#define __VMCI_GUESTKERNELAPI_H__
+
+/* VMCI guest kernel API version number. */
+#define VMCI_GUEST_KERNEL_API_VERSION  1
+
+/* Macros to operate on the driver version number. */
+#define VMCI_MAJOR_VERSION(v)       (((v) >> 16) & 0xffff)
+#define VMCI_MINOT_VERSION(v)       ((v) & 0xffff)
+
+#define INCLUDE_ALLOW_MODULE
+
+#include "vmci_defs.h"
+#include "vmci_call_defs.h"
+
+#if defined(__linux__) || defined(_WIN32)
+   /* XXX TODO for other guests. */
+#  include "vmci_queue_pair.h"
+#endif
+
+/* VMCI Device Usage API. */
+Bool VMCI_DeviceGet(void);
+void VMCI_DeviceRelease(void);
+
+/* VMCI Datagram API. */
+int VMCIDatagram_CreateHnd(VMCIId resourceID, uint32 flags,
+			   VMCIDatagramRecvCB recvCB, void *clientData,
+			   VMCIHandle *outHandle);
+int VMCIDatagram_DestroyHnd(VMCIHandle handle);
+int VMCIDatagram_Send(VMCIDatagram *msg);
+
+/* VMCI Utility API. */
+VMCIId VMCI_GetContextID(void);
+uint32 VMCI_Version(void);
+
+/* VMCI Event API. */
+
+typedef void (*VMCI_EventCB)(VMCIId subID, VMCI_EventData *ed,
+			     void *clientData);
+
+int VMCIEvent_Subscribe(VMCI_Event event, VMCI_EventCB callback, 
+                        void *callbackData, VMCIId *subID);
+int VMCIEvent_Unsubscribe(VMCIId subID);
+
+/* VMCI Discovery Service API. */
+int VMCIDs_Lookup(const char *name, VMCIHandle *out);
+
+#if defined(__linux__) || defined(_WIN32)
+/* VMCI QueuePair API.  XXX TODO for other guests. */
+int VMCIQueuePair_Alloc(VMCIHandle *handle, VMCIQueue **produceQ,
+                        uint64 produceSize, VMCIQueue **consumeQ,
+                        uint64 consumeSize, VMCIId peer, uint32 flags);
+int VMCIQueuePair_Detach(VMCIHandle handle);
+#endif
+
+#endif /* !__VMCI_GUESTKERNELAPI_H__ */
--- kernel/linux-2.6.26.3/drivers/misc/vsock/vmci_infrastructure.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vsock/vmci_infrastructure.h	2008-09-03 10:06:46.000000000 -0500
@@ -0,0 +1,94 @@
+/*********************************************************
+ * Copyright (C) 2006 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * vmci_infrastructure.h -- 
+ * 
+ *      This file implements the VMCI infrastructure.
+ */ 
+ 
+#ifndef _VMCI_INFRASTRUCTURE_H_
+#define _VMCI_INFRASTRUCTURE_H_
+
+#define INCLUDE_ALLOW_USERLEVEL
+#define INCLUDE_ALLOW_VMMEXT
+#define INCLUDE_ALLOW_MODULE
+#define INCLUDE_ALLOW_VMMON
+#define INCLUDE_ALLOW_VMCORE
+#define INCLUDE_ALLOW_VMKERNEL
+#define INCLUDE_ALLOW_DISTRIBUTE
+
+#include "vmware.h"
+#include "vmci_defs.h"
+
+typedef enum {
+   VMCIOBJ_VMX_VM = 10,
+   VMCIOBJ_CONTEXT,
+   VMCIOBJ_PROCESS,
+   VMCIOBJ_DATAGRAM_PROCESS,
+   VMCIOBJ_NOT_SET,
+} VMCIObjType;
+
+/* Guestcalls currently support a maximum of 8 uint64 arguments. */
+#define VMCI_GUESTCALL_MAX_ARGS_SIZE 64
+
+/* Used to determine what checkpoint state to get and set. */
+#define VMCI_NOTIFICATION_CPT_STATE 0x1
+#define VMCI_WELLKNOWN_CPT_STATE 0x2
+#define VMCI_QP_CPT_STATE 0x3
+#define VMCI_QP_INFO_CPT_STATE 0x4
+
+/* Used to control the VMCI device in the vmkernel */
+#define VMCI_DEV_RESET            0x01
+#define VMCI_DEV_QP_RESET         0x02
+#define VMCI_DEV_QUIESCE          0x03
+#define VMCI_DEV_UNQUIESCE        0x04
+#define VMCI_DEV_QP_BREAK_SHARING 0x05
+
+/*
+ *-------------------------------------------------------------------------
+ *
+ *  VMCI_Hash --
+ *
+ *     Hash function used by the Simple Datagram API. Based on the djb2 
+ *     hash function by Dan Bernstein.
+ * 
+ *  Result:
+ *     Returns guest call size.
+ *     
+ *  Side effects:
+ *     None.
+ *
+ *-------------------------------------------------------------------------
+ */
+
+static INLINE int
+VMCI_Hash(VMCIHandle handle, // IN
+          unsigned size)     // IN
+{
+   int i;
+   int hash = 5381;
+   uint64 handleValue = (uint64)handle.resource << 32 | handle.context;
+
+   for (i = 0; i < sizeof handle; i++) {
+      hash = ((hash << 5) + hash) + (uint8)(handleValue >> (i*8));
+   }
+   return hash & (size -1);
+}
+
+#endif // _VMCI_INFRASTRUCTURE_H_
--- kernel/linux-2.6.26.3/drivers/misc/vsock/vmci_iocontrols.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vsock/vmci_iocontrols.h	2008-09-03 10:06:56.000000000 -0500
@@ -0,0 +1,394 @@
+/*********************************************************
+ * Copyright (C) 2007 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+
+/*
+ * vmci_iocontrols.h
+ *
+ *        The VMCI driver io controls.
+ */
+
+#ifndef _VMCI_IOCONTROLS_H_
+#define _VMCI_IOCONTROLS_H_
+
+#define INCLUDE_ALLOW_USERLEVEL
+#define INCLUDE_ALLOW_VMMON
+#define INCLUDE_ALLOW_VMCORE
+#define INCLUDE_ALLOW_MODULE
+#define INCLUDE_ALLOW_VMKERNEL
+
+#include "vmci_defs.h"
+
+/*
+ * Driver version.
+ *
+ * Increment major version when you make an incompatible change.
+ * Compatibility goes both ways (old driver with new executable
+ * as well as new driver with old executable).
+ */
+
+#define VMCI_VERSION_SHIFT_WIDTH   16 /* Never change this. */
+#define VMCI_MAJOR_VERSION_VALUE    8 /* Bump major version number here. */
+#define VMCI_MINOR_VERSION_VALUE    0 /* Bump minor version number here. */
+
+/* Don't modify the next three macros. */
+#define VMCI_VERSION           (VMCI_MAJOR_VERSION_VALUE << \
+                                VMCI_VERSION_SHIFT_WIDTH |  \
+                                VMCI_MINOR_VERSION_VALUE)
+#define VMCI_VERSION_MAJOR(v)  ((uint32) (v) >> VMCI_VERSION_SHIFT_WIDTH)
+#define VMCI_VERSION_MINOR(v)  ((uint16) (v))
+
+#if defined(__linux__) || defined(__APPLE__) || defined(SOLARIS) || defined(VMKERNEL)
+/*
+ * Linux defines _IO* macros, but the core kernel code ignore the encoded
+ * ioctl value. It is up to individual drivers to decode the value (for
+ * example to look at the size of a structure to determine which version
+ * of a specific command should be used) or not (which is what we
+ * currently do, so right now the ioctl value for a given command is the
+ * command itself).
+ *
+ * Hence, we just define the IOCTL_VMCI_foo values directly, with no
+ * intermediate IOCTLCMD_ representation.
+ */
+#  define IOCTLCMD(_cmd) IOCTL_VMCI_ ## _cmd
+#else // if defined(__linux__)
+/*
+ * On platforms other than Linux, IOCTLCMD_foo values are just numbers, and
+ * we build the IOCTL_VMCI_foo values around these using platform-specific
+ * format for encoding arguments and sizes.
+ */
+#  define IOCTLCMD(_cmd) IOCTLCMD_VMCI_ ## _cmd
+#endif
+
+
+enum IOCTLCmd_VMCI {
+   /*
+    * We need to bracket the range of values used for ioctls, because x86_64
+    * Linux forces us to explicitly register ioctl handlers by value for
+    * handling 32 bit ioctl syscalls.  Hence FIRST and LAST.  Pick something
+    * for FIRST that doesn't collide with vmmon (2001+).
+    */
+#if defined(__linux__)
+   IOCTLCMD(FIRST) = 1951,
+#else
+   /* Start at 0. */
+   IOCTLCMD(FIRST),
+#endif
+   IOCTLCMD(VERSION) = IOCTLCMD(FIRST),
+
+   /* BEGIN VMCI */
+   IOCTLCMD(INIT_CONTEXT),
+   IOCTLCMD(CREATE_PROCESS),
+   IOCTLCMD(CREATE_DATAGRAM_PROCESS),
+   IOCTLCMD(SHAREDMEM_CREATE),
+   IOCTLCMD(SHAREDMEM_ATTACH),
+   IOCTLCMD(SHAREDMEM_QUERY),
+   IOCTLCMD(SHAREDMEM_DETACH),
+   IOCTLCMD(VERSION2),
+   IOCTLCMD(QUEUEPAIR_ALLOC),
+   IOCTLCMD(QUEUEPAIR_SETPAGEFILE),
+   IOCTLCMD(QUEUEPAIR_DETACH),
+   IOCTLCMD(DATAGRAM_SEND),
+   IOCTLCMD(DATAGRAM_RECEIVE),
+   IOCTLCMD(DATAGRAM_REQUEST_MAP),
+   IOCTLCMD(DATAGRAM_REMOVE_MAP),
+   IOCTLCMD(CTX_ADD_NOTIFICATION),
+   IOCTLCMD(CTX_REMOVE_NOTIFICATION),
+   IOCTLCMD(CTX_GET_CPT_STATE),
+   IOCTLCMD(CTX_SET_CPT_STATE),
+   IOCTLCMD(GET_CONTEXT_ID),
+   /* END VMCI */
+
+   /*
+    * BEGIN VMCI SOCKETS
+    *
+    * We mark the end of the vmci commands and the start of the vmci sockets
+    * commands since they are used in separate modules on Linux.
+    * */
+   IOCTLCMD(LAST),
+   IOCTLCMD(SOCKETS_FIRST) = IOCTLCMD(LAST),
+   IOCTLCMD(SOCKETS_ACCEPT) = IOCTLCMD(SOCKETS_FIRST),
+   IOCTLCMD(SOCKETS_BIND),
+   IOCTLCMD(SOCKETS_CLOSE),
+   IOCTLCMD(SOCKETS_CONNECT),
+   /*
+    * The next two values are public (vmci_sockets.h) and cannot be changed.
+    * That means the number of values above these cannot be changed either
+    * unless the base index (specified below) is updated accordingly.
+    */
+   IOCTLCMD(SOCKETS_GET_AF_VALUE),
+   IOCTLCMD(SOCKETS_GET_LOCAL_CID),
+   IOCTLCMD(SOCKETS_GET_SOCK_NAME),
+   IOCTLCMD(SOCKETS_GET_SOCK_OPT),
+   IOCTLCMD(SOCKETS_GET_VM_BY_NAME),
+   IOCTLCMD(SOCKETS_LISTEN),
+   IOCTLCMD(SOCKETS_RECV),
+   IOCTLCMD(SOCKETS_RECV_FROM),
+   IOCTLCMD(SOCKETS_SELECT),
+   IOCTLCMD(SOCKETS_SEND),
+   IOCTLCMD(SOCKETS_SEND_TO),
+   IOCTLCMD(SOCKETS_SET_SOCK_OPT),
+   IOCTLCMD(SOCKETS_SHUTDOWN),
+   IOCTLCMD(SOCKETS_SOCKET),
+   /* END VMCI SOCKETS */
+
+   // Must be last.
+   IOCTLCMD(SOCKETS_LAST)
+};
+
+
+#if defined _WIN32
+/*
+ * Windows VMCI ioctl definitions.
+ */
+
+/* These values cannot be changed since some of the ioctl values are public. */
+#define FILE_DEVICE_VMCI         0x8103
+#define VMCI_IOCTL_BASE_INDEX    0x801
+#define VMCIIOCTL_BUFFERED(name) \
+      CTL_CODE(FILE_DEVICE_VMCI, \
+	       VMCI_IOCTL_BASE_INDEX + IOCTLCMD_VMCI_ ## name, \
+	       METHOD_BUFFERED, \
+	       FILE_ANY_ACCESS)
+#define VMCIIOCTL_NEITHER(name) \
+      CTL_CODE(FILE_DEVICE_VMCI, \
+	       VMCI_IOCTL_BASE_INDEX + IOCTLCMD_VMCI_ ## name, \
+	       METHOD_NEITHER, \
+	       FILE_ANY_ACCESS)
+
+#define IOCTL_VMCI_VERSION		VMCIIOCTL_BUFFERED(VERSION)
+
+/* BEGIN VMCI */
+#define IOCTL_VMCI_INIT_CONTEXT         VMCIIOCTL_BUFFERED(INIT_CONTEXT)
+#define IOCTL_VMCI_CREATE_PROCESS       VMCIIOCTL_BUFFERED(CREATE_PROCESS)
+#define IOCTL_VMCI_CREATE_DATAGRAM_PROCESS \
+               VMCIIOCTL_BUFFERED(CREATE_DATAGRAM_PROCESS)
+#define IOCTL_VMCI_HYPERCALL            VMCIIOCTL_BUFFERED(HYPERCALL)
+#define IOCTL_VMCI_SHAREDMEM_CREATE  \
+               VMCIIOCTL_BUFFERED(SHAREDMEM_CREATE)
+#define IOCTL_VMCI_SHAREDMEM_ATTACH  \
+               VMCIIOCTL_BUFFERED(SHAREDMEM_ATTACH)
+#define IOCTL_VMCI_SHAREDMEM_QUERY   \
+               VMCIIOCTL_BUFFERED(SHAREDMEM_QUERY)
+#define IOCTL_VMCI_SHAREDMEM_DETACH  \
+               VMCIIOCTL_BUFFERED(SHAREDMEM_DETACH)
+#define IOCTL_VMCI_VERSION2		VMCIIOCTL_BUFFERED(VERSION2)
+#define IOCTL_VMCI_QUEUEPAIR_ALLOC  \
+               VMCIIOCTL_BUFFERED(QUEUEPAIR_ALLOC)
+#define IOCTL_VMCI_QUEUEPAIR_SETPAGEFILE  \
+               VMCIIOCTL_BUFFERED(QUEUEPAIR_SETPAGEFILE)
+#define IOCTL_VMCI_QUEUEPAIR_DETACH  \
+               VMCIIOCTL_BUFFERED(QUEUEPAIR_DETACH)
+#define IOCTL_VMCI_DATAGRAM_SEND	VMCIIOCTL_BUFFERED(DATAGRAM_SEND)
+#define IOCTL_VMCI_DATAGRAM_RECEIVE	VMCIIOCTL_NEITHER(DATAGRAM_RECEIVE)
+#define IOCTL_VMCI_DATAGRAM_REQUEST_MAP	VMCIIOCTL_BUFFERED(DATAGRAM_REQUEST_MAP)
+#define IOCTL_VMCI_DATAGRAM_REMOVE_MAP	VMCIIOCTL_BUFFERED(DATAGRAM_REMOVE_MAP)
+#define IOCTL_VMCI_CTX_ADD_NOTIFICATION	VMCIIOCTL_BUFFERED(CTX_ADD_NOTIFICATION)
+#define IOCTL_VMCI_CTX_REMOVE_NOTIFICATION \
+               VMCIIOCTL_BUFFERED(CTX_REMOVE_NOTIFICATION)
+#define IOCTL_VMCI_CTX_GET_CPT_STATE \
+               VMCIIOCTL_BUFFERED(CTX_GET_CPT_STATE)
+#define IOCTL_VMCI_CTX_SET_CPT_STATE \
+               VMCIIOCTL_BUFFERED(CTX_SET_CPT_STATE)
+#define IOCTL_VMCI_GET_CONTEXT_ID    \
+               VMCIIOCTL_BUFFERED(GET_CONTEXT_ID)
+/* END VMCI */
+
+/* BEGIN VMCI SOCKETS */
+#define IOCTL_VMCI_SOCKETS_ACCEPT \
+               VMCIIOCTL_BUFFERED(SOCKETS_ACCEPT)
+#define IOCTL_VMCI_SOCKETS_BIND \
+               VMCIIOCTL_BUFFERED(SOCKETS_BIND)
+#define IOCTL_VMCI_SOCKETS_CLOSE \
+               VMCIIOCTL_BUFFERED(SOCKETS_CLOSE)
+#define IOCTL_VMCI_SOCKETS_CONNECT \
+               VMCIIOCTL_BUFFERED(SOCKETS_CONNECT)
+#define IOCTL_VMCI_SOCKETS_GET_AF_VALUE \
+               VMCIIOCTL_BUFFERED(SOCKETS_GET_AF_VALUE)
+#define IOCTL_VMCI_SOCKETS_GET_LOCAL_CID \
+               VMCIIOCTL_BUFFERED(SOCKETS_GET_LOCAL_CID)
+#define IOCTL_VMCI_SOCKETS_GET_SOCK_NAME \
+               VMCIIOCTL_BUFFERED(SOCKETS_GET_SOCK_NAME)
+#define IOCTL_VMCI_SOCKETS_GET_SOCK_OPT \
+               VMCIIOCTL_BUFFERED(SOCKETS_GET_SOCK_OPT)
+#define IOCTL_VMCI_SOCKETS_GET_VM_BY_NAME \
+               VMCIIOCTL_BUFFERED(SOCKETS_GET_VM_BY_NAME)
+#define IOCTL_VMCI_SOCKETS_LISTEN \
+               VMCIIOCTL_BUFFERED(SOCKETS_LISTEN)
+#define IOCTL_VMCI_SOCKETS_RECV \
+               VMCIIOCTL_BUFFERED(SOCKETS_RECV)
+#define IOCTL_VMCI_SOCKETS_RECV_FROM \
+               VMCIIOCTL_BUFFERED(SOCKETS_RECV_FROM)
+#define IOCTL_VMCI_SOCKETS_SELECT \
+               VMCIIOCTL_BUFFERED(SOCKETS_SELECT)
+#define IOCTL_VMCI_SOCKETS_SEND \
+               VMCIIOCTL_BUFFERED(SOCKETS_SEND)
+#define IOCTL_VMCI_SOCKETS_SEND_TO \
+               VMCIIOCTL_BUFFERED(SOCKETS_SEND_TO)
+#define IOCTL_VMCI_SOCKETS_SET_SOCK_OPT \
+               VMCIIOCTL_BUFFERED(SOCKETS_SET_SOCK_OPT)
+#define IOCTL_VMCI_SOCKETS_SHUTDOWN \
+               VMCIIOCTL_BUFFERED(SOCKETS_SHUTDOWN)
+#define IOCTL_VMCI_SOCKETS_SOCKET \
+               VMCIIOCTL_BUFFERED(SOCKETS_SOCKET)
+/* END VMCI SOCKETS */
+
+#endif // _WIN32
+
+
+/*
+ * VMCI driver initialization. This block can also be used to
+ * pass initial group membership etc.
+ */
+typedef struct VMCIInitBlock {
+   VMCIId             cid;
+   VMCIPrivilegeFlags flags;
+#ifdef _WIN32
+   uint64             event; /* Handle for signalling vmci calls on windows. */
+#endif // _WIN32
+} VMCIInitBlock;
+
+typedef struct VMCISharedMemInfo {
+   VMCIHandle handle;
+   uint32     size;
+   uint32     result;     
+   VA64       va; /* Currently only used in the guest. */ 
+   char       pageFileName[VMCI_PATH_MAX];
+} VMCISharedMemInfo;
+
+typedef struct VMCIQueuePairAllocInfo {
+   VMCIHandle handle;
+   VMCIId     peer;
+   uint32     flags;
+   uint64     produceSize;
+   uint64     consumeSize;
+   VA64       producePageFile; /* User VA. */
+   VA64       consumePageFile; /* User VA. */
+   uint64     producePageFileSize; /* Size of the file name array. */
+   uint64     consumePageFileSize; /* Size of the file name array. */ 
+   int32      result;
+   uint32     _pad;
+} VMCIQueuePairAllocInfo;
+
+typedef struct VMCIQueuePairPageFileInfo {
+   VMCIHandle handle;
+   VA64       producePageFile; /* User VA. */
+   VA64       consumePageFile; /* User VA. */
+   uint64     producePageFileSize; /* Size of the file name array. */
+   uint64     consumePageFileSize; /* Size of the file name array. */ 
+   int32      result;
+   uint32     _pad;
+} VMCIQueuePairPageFileInfo;
+
+typedef struct VMCIQueuePairDetachInfo {
+   VMCIHandle handle;
+   int32      result;
+   uint32     _pad;
+} VMCIQueuePairDetachInfo;
+
+typedef struct VMCIDatagramSendRecvInfo {
+   VA64   addr;
+   uint32 len;
+   int32  result;
+} VMCIDatagramSendRecvInfo;
+
+/* Used to create datagram endpoints in guest or host userlevel. */
+typedef struct VMCIDatagramCreateInfo {
+   VMCIId      resourceID;
+   uint32      flags; 
+   int         eventHnd;
+   int         result;     // result of handle create operation
+   VMCIHandle  handle;     // handle if successfull
+} VMCIDatagramCreateInfo;
+
+/* Used to add/remove well-known datagram mappings. */
+typedef struct VMCIDatagramMapInfo {
+   VMCIId      wellKnownID;
+   int         result;
+} VMCIDatagramMapInfo;
+
+
+/* Used to add/remove remote context notifications. */
+typedef struct VMCINotifyAddRemoveInfo {
+   VMCIId      remoteCID;
+   int         result;
+} VMCINotifyAddRemoveInfo;
+
+
+/* Used to set/get current context's checkpoint state. */
+typedef struct VMCICptBufInfo {
+   VA64        cptBuf;
+   uint32      cptType;
+   uint32      bufSize;
+   int32       result;
+   uint32      _pad;
+} VMCICptBufInfo;
+
+
+#ifdef __APPLE__
+/*
+ * Mac OS ioctl definitions.
+ *
+ * Mac OS defines _IO* macros, and the core kernel code uses the size encoded
+ * in the ioctl value to copy the memory back and forth (depending on the
+ * direction encoded in the ioctl value) between the user and kernel address
+ * spaces.
+ * See iocontrolsMacOS.h for details on how this is done. We use sockets only
+ * for vmci.
+ */
+
+#include <sys/ioccom.h>
+
+enum VMCrossTalkSockOpt {
+   VMCI_SO_VERSION = 0,
+   VMCI_SO_CONTEXT                  = IOCTL_VMCI_INIT_CONTEXT,
+   VMCI_SO_PROCESS                  = IOCTL_VMCI_CREATE_PROCESS,
+   VMCI_SO_DATAGRAM_PROCESS         = IOCTL_VMCI_CREATE_DATAGRAM_PROCESS,
+   VMCI_SO_SHAREDMEM_CREATE         = IOCTL_VMCI_SHAREDMEM_CREATE,
+   VMCI_SO_SHAREDMEM_ATTACH         = IOCTL_VMCI_SHAREDMEM_ATTACH,
+   VMCI_SO_SHAREDMEM_QUERY          = IOCTL_VMCI_SHAREDMEM_QUERY,
+   VMCI_SO_SHAREDMEM_DETACH         = IOCTL_VMCI_SHAREDMEM_DETACH,
+   VMCI_SO_VERSION2                 = IOCTL_VMCI_VERSION2,
+   VMCI_SO_QUEUEPAIR_ALLOC          = IOCTL_VMCI_QUEUEPAIR_ALLOC,
+   VMCI_SO_QUEUEPAIR_SETPAGEFILE    = IOCTL_VMCI_QUEUEPAIR_SETPAGEFILE,
+   VMCI_SO_QUEUEPAIR_DETACH         = IOCTL_VMCI_QUEUEPAIR_DETACH,
+   VMCI_SO_DATAGRAM_SEND            = IOCTL_VMCI_DATAGRAM_SEND,
+   VMCI_SO_DATAGRAM_RECEIVE         = IOCTL_VMCI_DATAGRAM_RECEIVE, 
+   VMCI_SO_DATAGRAM_REQUEST_MAP     = IOCTL_VMCI_DATAGRAM_REQUEST_MAP,
+   VMCI_SO_DATAGRAM_REMOVE_MAP      = IOCTL_VMCI_DATAGRAM_REMOVE_MAP, 
+   VMCI_SO_CTX_ADD_NOTIFICATION     = IOCTL_VMCI_CTX_ADD_NOTIFICATION, 
+   VMCI_SO_CTX_REMOVE_NOTIFICATION  = IOCTL_VMCI_CTX_REMOVE_NOTIFICATION, 
+   VMCI_SO_CTX_GET_CPT_STATE        = IOCTL_VMCI_CTX_GET_CPT_STATE, 
+   VMCI_SO_CTX_SET_CPT_STATE        = IOCTL_VMCI_CTX_SET_CPT_STATE, 
+   VMCI_SO_GET_CONTEXT_ID           = IOCTL_VMCI_GET_CONTEXT_ID,
+   VMCI_SO_USERFD,
+};
+
+#  define VMCI_MACOS_HOST_DEVICE_BASE    "com.vmware.kext.vmci"
+#  ifdef VMX86_DEVEL
+#     define VMCI_MACOS_HOST_DEVICE VMCI_MACOS_HOST_DEVICE_BASE ".devel"
+#  else
+#     define VMCI_MACOS_HOST_DEVICE VMCI_MACOS_HOST_DEVICE_BASE
+#  endif
+
+#endif
+
+/* Clean up helper macros */
+#undef IOCTLCMD
+
+#endif // ifndef _VMCI_IOCONTROLS_H_
--- kernel/linux-2.6.26.3/drivers/misc/vsock/vmci_kernel_if.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vsock/vmci_kernel_if.h	2008-09-03 10:02:58.000000000 -0500
@@ -0,0 +1,266 @@
+/*********************************************************
+ * Copyright (C) 2006 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * vmci_kernel_if.h -- 
+ * 
+ *      This file defines helper functions for VMCI host _and_ guest
+ *      kernel code. It must work for windows, macosx, vmkernel and
+ *      linux kernel, ie. using defines where necessary.
+ */ 
+ 
+#ifndef _VMCI_KERNEL_IF_H_
+#define _VMCI_KERNEL_IF_H_
+
+#if !defined(linux) && !defined(_WIN32) && !defined(__APPLE__) && \
+    !defined(VMKERNEL) && !defined(SOLARIS)
+#error "Platform not supported."
+#endif
+
+#if defined(_WIN32)
+#include <ntddk.h>
+#endif 
+
+#if defined(linux) && !defined(VMKERNEL)
+#  include "compat_version.h"
+#  include "compat_wait.h"
+#  include "compat_spinlock.h"
+#  include "compat_semaphore.h"
+#endif // linux
+
+#ifdef __APPLE__
+#  include <IOKit/IOLib.h>
+#include <mach/task.h>
+#include <mach/semaphore.h>
+#endif
+
+#ifdef VMKERNEL
+#include "splock.h"
+#include "semaphore_ext.h"
+#endif
+
+#ifdef SOLARIS
+#  include <sys/mutex.h>
+#  include <sys/poll.h>
+#  include <sys/semaphore.h>
+#endif
+
+#include "vm_basic_types.h"
+#include "vmci_defs.h"
+
+/* Flags for specifying memory type. */
+#define VMCI_MEMORY_NORMAL   0x0
+#define VMCI_MEMORY_ATOMIC   0x1
+#define VMCI_MEMORY_NONPAGED 0x2
+
+/* Platform specific type definitions. */
+
+#if defined(VMKERNEL)
+  typedef SP_SpinLock VMCILock;
+  typedef SP_IRQL VMCILockFlags;
+  typedef Semaphore VMCIEvent;
+  typedef Semaphore VMCIMutex;
+#elif defined(linux)
+  typedef spinlock_t VMCILock;
+  typedef unsigned long VMCILockFlags;
+  typedef wait_queue_head_t VMCIEvent;
+  typedef struct semaphore VMCIMutex;
+  typedef PPN *VMCIPpnList; /* List of PPNs in produce/consume queue. */
+#elif defined(__APPLE__)
+  typedef IOLock *VMCILock;
+  typedef unsigned long VMCILockFlags;
+  typedef semaphore_t VMCIEvent;
+  typedef IOLock *VMCIMutex;
+#elif defined(_WIN32)
+  typedef KSPIN_LOCK VMCILock;
+  typedef KIRQL VMCILockFlags;
+  typedef KEVENT VMCIEvent;
+  typedef FAST_MUTEX VMCIMutex;
+  typedef PMDL VMCIPpnList; /* MDL to map the produce/consume queue. */
+#elif defined(SOLARIS)
+  typedef kmutex_t VMCILock;
+  typedef unsigned long VMCILockFlags;
+  typedef ksema_t VMCIEvent;
+#endif // VMKERNEL
+
+/* Callback needed for correctly waiting on events. */
+typedef int (*VMCIEventReleaseCB)(void *clientData);
+
+/*
+ * The VMCI locks use a ranking scheme similar to the one used by
+ * vmkernel. While holding a lock L1 with rank R1, only locks with
+ * rank higher than R1 may be grabbed. The available ranks for VMCI 
+ * locks are (in descending order):
+ * - VMCI_LOCK_RANK_HIGH_BH : to be used for locks grabbed while executing
+ *   in a bottom half and not held while grabbing other locks.
+ * - VMCI_LOCK_RANK_MIDDLE_BH : to be for locks grabbed while executing in a
+ *   bottom half and held while grabbing locks of rank VMCI_LOCK_RANK_HIGH_BH.
+ * - VMCI_LOCK_RANK_LOW_BH : to be for locks grabbed while executing in a
+ *   bottom half and held while grabbing locks of rank
+ *   VMCI_LOCK_RANK_MIDDLE_BH.
+ * - VMCI_LOCK_RANK_HIGHEST : to be used for locks that are not held while
+ *   grabbing other locks except system locks with higher ranks and bottom
+ *   half locks.
+ * - VMCI_LOCK_RANK_HIGHER : to be used for locks that are held while
+ *   grabbing locks of rank VMCI_LOCK_RANK_HIGHEST or higher.
+ * - VMCI_LOCK_RANK_HIGH : to be used for locks that are held while
+ *   grabbing locks of rank VMCI_LOCK_RANK_HIGHER or higher. This is
+ *   the highest lock rank used by core VMCI services
+ * - VMCI_LOCK_RANK_MIDDLE : to be used for locks that are held while
+ *   grabbing locks of rank VMCI_LOCK_RANK_HIGH or higher.
+ * - VMCI_LOCK_RANK_LOW : to be used for locks that are held while
+ *   grabbing locks of rank VMCI_LOCK_RANK_MIDDLE or higher.
+ * - VMCI_LOCK_RANK_LOWEST : to be used for locks that are held while
+ *   grabbing locks of rank VMCI_LOCK_RANK_LOW or higher.
+ */
+#ifdef VMKERNEL
+  typedef SP_Rank VMCILockRank;
+
+  #define VMCI_LOCK_RANK_HIGH_BH        SP_RANK_IRQ_LEAF
+  #define VMCI_LOCK_RANK_MIDDLE_BH      (SP_RANK_IRQ_LEAF-1)
+  #define VMCI_LOCK_RANK_LOW_BH         SP_RANK_IRQ_LOWEST
+  #define VMCI_LOCK_RANK_HIGHEST        SP_RANK_SHM_MGR-1
+#else
+  typedef unsigned long VMCILockRank;
+
+  #define VMCI_LOCK_RANK_HIGH_BH        0x4000
+  #define VMCI_LOCK_RANK_MIDDLE_BH      0x2000
+  #define VMCI_LOCK_RANK_LOW_BH         0x1000
+  #define VMCI_LOCK_RANK_HIGHEST        0x0fff
+#endif // VMKERNEL
+#define VMCI_LOCK_RANK_HIGHER      (VMCI_LOCK_RANK_HIGHEST-1)
+#define VMCI_LOCK_RANK_HIGH        (VMCI_LOCK_RANK_HIGHER-1)
+#define VMCI_LOCK_RANK_MIDDLE_HIGH (VMCI_LOCK_RANK_HIGH-1)
+#define VMCI_LOCK_RANK_MIDDLE      (VMCI_LOCK_RANK_MIDDLE_HIGH-1)
+#define VMCI_LOCK_RANK_MIDDLE_LOW  (VMCI_LOCK_RANK_MIDDLE-1)
+#define VMCI_LOCK_RANK_LOW         (VMCI_LOCK_RANK_MIDDLE_LOW-1)
+#define VMCI_LOCK_RANK_LOWEST      (VMCI_LOCK_RANK_LOW-1)
+
+
+/*
+ * In vmkernel, we try to reduce the amount of memory mapped into the
+ * virtual address space by only mapping the memory of buffered
+ * datagrams when copying from and to the guest. In other OSes,
+ * regular kernel memory is used. VMCIBuffer is used to reference
+ * possibly unmapped memory.
+ */
+
+#ifdef VMKERNEL
+typedef MPN VMCIBuffer;
+#define VMCI_BUFFER_INVALID INVALID_MPN
+#else
+typedef void * VMCIBuffer;
+#define VMCI_BUFFER_INVALID NULL
+#endif
+
+/*
+ * Host specific struct used for signalling.
+ */
+
+typedef struct VMCIHost {
+#if defined(VMKERNEL)
+   World_ID vmmWorldID;
+#elif defined(linux)
+   wait_queue_head_t  waitQueue;
+#elif defined(__APPLE__)
+   struct Socket *socket; /* vmci Socket object on Mac OS. */
+#elif defined(_WIN32)
+   KEVENT *callEvent; /* Ptr to userlevel event used when signalling 
+                       * new pending guestcalls in kernel.
+                       */
+#elif defined(SOLARIS)
+   struct pollhead pollhead; /* Per datagram handle pollhead structure to
+                              * be treated as a black-box. None of its 
+                              * fields should be referenced.
+                              */
+#endif
+} VMCIHost;
+
+
+void VMCI_InitLock(VMCILock *lock, char *name, VMCILockRank rank);
+void VMCI_CleanupLock(VMCILock *lock);
+void VMCI_GrabLock(VMCILock *lock, VMCILockFlags *flags);
+void VMCI_ReleaseLock(VMCILock *lock, VMCILockFlags flags);
+void VMCI_GrabLock_BH(VMCILock *lock, VMCILockFlags *flags);
+void VMCI_ReleaseLock_BH(VMCILock *lock, VMCILockFlags flags);
+
+void VMCIHost_InitContext(VMCIHost *hostContext, uintptr_t eventHnd);
+void VMCIHost_ReleaseContext(VMCIHost *hostContext);
+void VMCIHost_SignalCall(VMCIHost *hostContext);
+void VMCIHost_ClearCall(VMCIHost *hostContext);
+Bool VMCIHost_WaitForCallLocked(VMCIHost *hostContext,
+                                VMCILock *lock,
+                                VMCILockFlags *flags,
+                                Bool useBH);
+
+void *VMCI_AllocKernelMem(size_t size, int flags);
+void VMCI_FreeKernelMem(void *ptr, size_t size);
+VMCIBuffer VMCI_AllocBuffer(size_t size, int flags);
+void *VMCI_MapBuffer(VMCIBuffer buf);
+void VMCI_ReleaseBuffer(void *ptr);
+void VMCI_FreeBuffer(VMCIBuffer buf, size_t size);
+#ifdef SOLARIS
+int VMCI_CopyToUser(void *dst, const void *src, unsigned int len, int mode);
+#else
+int VMCI_CopyToUser(void *dst, const void *src, unsigned int len);
+/*
+ * Don't need the following for guests, hence no Solaris code for this
+ * function.
+ */
+Bool VMCIWellKnownID_AllowMap(VMCIId wellKnownID,
+                              VMCIPrivilegeFlags privFlags);
+#endif
+
+void VMCI_CreateEvent(VMCIEvent *event);
+void VMCI_DestroyEvent(VMCIEvent *event);
+void VMCI_SignalEvent(VMCIEvent *event);
+void VMCI_WaitOnEvent(VMCIEvent *event, VMCIEventReleaseCB releaseCB, 
+		      void *clientData);
+
+/* XXX TODO for VMKERNEL (host) and Solaris (guest). */
+#if !defined(VMKERNEL) && (defined(__linux__) || defined(_WIN32) || \
+                           defined(__APPLE__))
+int VMCI_CopyFromUser(void *dst, const void *src, size_t len);
+#endif
+
+#if !defined(SOLARIS)
+int VMCIMutex_Init(VMCIMutex *mutex);
+void VMCIMutex_Destroy(VMCIMutex *mutex);
+void VMCIMutex_Acquire(VMCIMutex *mutex);
+void VMCIMutex_Release(VMCIMutex *mutex);
+#endif
+
+/* XXX TODO for Solaris (guest). */
+#if !defined(VMKERNEL) && (defined(__linux__) || defined(_WIN32))
+VA VMCI_AllocQueueKVA(uint64 size);
+void VMCI_FreeQueueKVA(VA va, uint64 size);
+typedef struct PPNSet {
+  uint64      numProducePages;
+  uint64      numConsumePages;
+  VMCIPpnList producePPNs;
+  VMCIPpnList consumePPNs;
+  Bool        initialized;
+} PPNSet;
+int VMCI_AllocPPNSet(VA produceVA, uint64 numProducePages, VA consumeVA,
+                     uint64 numConsumePages, PPNSet *ppnSet);
+void VMCI_FreePPNSet(PPNSet *ppnSet);
+int VMCI_PopulatePPNList(uint8 *callBuf, const PPNSet *ppnSet);
+#endif
+
+#endif // _VMCI_KERNEL_IF_H_
+
--- kernel/linux-2.6.26.3/drivers/misc/vsock/vmci_queue_pair.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vsock/vmci_queue_pair.h	2008-09-03 10:07:05.000000000 -0500
@@ -0,0 +1,667 @@
+/*********************************************************
+ * Copyright (C) 2007 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef _VMCI_QUEUE_PAIR_H_
+#define _VMCI_QUEUE_PAIR_H_
+
+/*
+ *
+ * vmci_queue_pair.h --
+ *
+ *    Defines queue layout in memory, and helper functions to enqueue and
+ *    dequeue items. XXX needs checksumming?
+ */
+
+#define INCLUDE_ALLOW_MODULE
+#define INCLUDE_ALLOW_VMX
+
+#include "vm_basic_defs.h"
+#include "vm_basic_types.h"
+#include "vm_atomic.h"
+#include "vmci_defs.h"
+#include "vm_assert.h"
+#if defined(__linux__) && defined(__KERNEL__)
+#  include "vmci_kernel_if.h"
+#endif
+
+
+#if defined(__linux__) && defined(__KERNEL__)
+struct page;
+#endif
+
+
+/*
+ * For a queue of buffer 'size' bytes, the tail and head pointers will be in
+ * the range [0, size-1].
+ */
+
+typedef struct VMCIQueueHeader {
+   /* All fields are 64bit and aligned. */
+   VMCIHandle    handle; /* Identifier. */
+   Atomic_uint64 producerTail; /* Offset in this queue. */
+   Atomic_uint64 consumerHead; /* Offset in peer queue. */
+} VMCIQueueHeader;
+
+typedef struct VMCIQueue {
+   VMCIQueueHeader queueHeader;
+   uint8 _padding[PAGE_SIZE - sizeof(VMCIQueueHeader)];
+#if defined(__linux__) && defined(__KERNEL__)
+   struct page *page[0]; /* List of pages containing queue data. */
+#else
+   uint8 buffer[0]; /* Buffer containing data. */
+#endif
+} VMCIQueue;
+
+
+typedef int VMCIMemcpyToQueueFunc(VMCIQueue *queue, uint64 queueOffset,
+                                  const void *src, size_t srcOffset,
+                                  size_t size);
+typedef int VMCIMemcpyFromQueueFunc(void *dest, size_t destOffset,
+                                    const VMCIQueue *queue, uint64 queueOffset,
+                                    size_t size);
+
+#if defined(__linux__) && defined(__KERNEL__)
+int VMCIMemcpyToQueue(VMCIQueue *queue, uint64 queueOffset, const void *src,
+                      size_t srcOffset, size_t size);
+int VMCIMemcpyFromQueue(void *dest, size_t destOffset, const VMCIQueue *queue,
+                        uint64 queueOffset, size_t size);
+int VMCIMemcpyToQueueV(VMCIQueue *queue, uint64 queueOffset, const void *src,
+                       size_t srcOffset, size_t size);
+int VMCIMemcpyFromQueueV(void *dest, size_t destOffset, const VMCIQueue *queue,
+                         uint64 queueOffset, size_t size);
+#elif defined(_WIN32) && defined(WINNT_DDK)
+int VMCIMemcpyToQueue(VMCIQueue *queue, uint64 queueOffset, const void *src,
+                      size_t srcOffset, size_t size);
+int VMCIMemcpyFromQueue(void *dest, size_t destOffset, const VMCIQueue *queue,
+                        uint64 queueOffset, size_t size);
+#else
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VMCIMemcpyToQueue --
+ *
+ *      Wrapper for memcpy --- copies from a given buffer to a VMCI Queue.
+ *      Assumes that offset + size does not wrap around in the queue.
+ *
+ * Results:
+ *      Zero on success, negative error code on failure.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE int
+VMCIMemcpyToQueue(VMCIQueue *queue,   // OUT:
+                  uint64 queueOffset, // IN:
+                  const void *src,    // IN:
+                  size_t srcOffset,   // IN:
+                  size_t size)        // IN:
+{
+   memcpy(queue->buffer + queueOffset, (uint8 *)src + srcOffset, size);
+   return 0;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VMCIMemcpyFromQueue --
+ *
+ *      Wrapper for memcpy --- copies to a given buffer from a VMCI Queue.
+ *      Assumes that offset + size does not wrap around in the queue.
+ *
+ * Results:
+ *      Zero on success, negative error code on failure.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE int
+VMCIMemcpyFromQueue(void *dest,             // OUT:
+                    size_t destOffset,      // IN:
+                    const VMCIQueue *queue, // IN:
+                    uint64 queueOffset,     // IN:
+                    size_t size)            // IN:
+{
+   memcpy((uint8 *)dest + destOffset, queue->buffer + queueOffset, size);
+   return 0;
+}
+#endif /* __linux__ && __KERNEL__ */
+
+
+/*
+ * If one client of a QueuePair is a 32bit entity, we restrict the QueuePair
+ * size to be less than 4GB, and use 32bit atomic operations on the head and
+ * tail pointers. 64bit atomic read on a 32bit entity involves cmpxchg8b which
+ * is an atomic read-modify-write. This will cause traces to fire when a 32bit
+ * consumer tries to read the producer's tail pointer, for example, because the
+ * consumer has read-only access to the producer's tail pointer.
+ *
+ * We provide the following macros to invoke 32bit or 64bit atomic operations
+ * based on the architecture the code is being compiled on.
+ */
+
+/* Architecture independent maximum queue size. */
+#define QP_MAX_QUEUE_SIZE_ARCH_ANY  CONST64U(0xffffffff)
+
+#ifdef __x86_64__
+#  define QP_MAX_QUEUE_SIZE_ARCH  CONST64U(0xffffffffffffffff)
+#  define QPAtomic_ReadOffset(x)  Atomic_Read64(x)
+#  define QPAtomic_WriteOffset(x, y) Atomic_Write64(x, y)
+#else
+#  define QP_MAX_QUEUE_SIZE_ARCH  CONST64U(0xffffffff)
+#  define QPAtomic_ReadOffset(x)  Atomic_Read32((Atomic_uint32 *)(x))
+#  define QPAtomic_WriteOffset(x, y) \
+            Atomic_Write32((Atomic_uint32 *)(x), (uint32)(y))
+#endif
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VMCIQueue_CheckAlignment --
+ *
+ *      Checks if the given queue is aligned to page boundary.
+ *
+ * Results:
+ *      TRUE or FALSE.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE Bool
+VMCIQueue_CheckAlignment(const VMCIQueue *queue) // IN:
+{
+   return ((uintptr_t)queue & (PAGE_SIZE - 1)) == 0;
+}
+
+
+static INLINE void
+VMCIQueue_GetPointers(const VMCIQueue *produceQ,
+                      const VMCIQueue *consumeQ,
+                      uint64 *producerTail,
+                      uint64 *consumerHead)
+{
+   *producerTail = QPAtomic_ReadOffset(&produceQ->queueHeader.producerTail);
+   *consumerHead = QPAtomic_ReadOffset(&consumeQ->queueHeader.consumerHead);
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VMCIQueue_ResetPointers --
+ *
+ *      Reset the tail pointer (of "this" queue) and the head pointer (of
+ *      "peer" queue).
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE void
+VMCIQueue_ResetPointers(VMCIQueue *queue) // IN:
+{
+   QPAtomic_WriteOffset(&queue->queueHeader.producerTail, CONST64U(0));
+   QPAtomic_WriteOffset(&queue->queueHeader.consumerHead, CONST64U(0));
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VMCIQueue_Init --
+ *
+ *      Initializes a queue's state (head & tail pointers).
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE void
+VMCIQueue_Init(const VMCIHandle handle, // IN:
+               VMCIQueue *queue)        // IN:
+{
+   ASSERT_NOT_IMPLEMENTED(VMCIQueue_CheckAlignment(queue));
+   queue->queueHeader.handle = handle;
+   VMCIQueue_ResetPointers(queue);
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VMCIQueueFreeSpaceInt --
+ *
+ *      Finds available free space in a produce queue to enqueue more
+ *      data or reports an error if queue pair corruption is detected.
+ *
+ * Results:
+ *      Free space size in bytes.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE int
+VMCIQueueFreeSpaceInt(const VMCIQueue *produceQueue, // IN:
+                      const VMCIQueue *consumeQueue, // IN:
+                      const uint64 produceQSize,     // IN:
+                      uint64 *freeSpace)             // OUT:
+{
+   const uint64 tail =
+      QPAtomic_ReadOffset(&produceQueue->queueHeader.producerTail);
+   const uint64 head =
+      QPAtomic_ReadOffset(&consumeQueue->queueHeader.consumerHead);
+
+   ASSERT(freeSpace);
+
+   if (tail >= produceQSize || head >= produceQSize) {
+      return VMCI_ERROR_INVALID_SIZE;
+   }
+
+   /*
+    * Deduct 1 to avoid tail becoming equal to head which causes ambiguity. If
+    * head and tail are equal it means that the queue is empty.
+    */
+   if (tail >= head) {
+      *freeSpace = produceQSize - (tail - head) - 1;
+   } else {
+      *freeSpace = head - tail - 1;
+   }
+
+   return VMCI_SUCCESS;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VMCIQueue_FreeSpace --
+ *
+ *      Finds available free space in a produce queue to enqueue more data.
+ *
+ * Results:
+ *      On success, free space size in bytes (up to MAX_INT64).
+ *      On failure, appropriate error code.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE int64
+VMCIQueue_FreeSpace(const VMCIQueue *produceQueue, // IN:
+                    const VMCIQueue *consumeQueue, // IN:
+                    const uint64 produceQSize)     // IN:
+{
+   uint64 freeSpace;
+   int retval;
+
+   retval = VMCIQueueFreeSpaceInt(produceQueue, consumeQueue, produceQSize,
+                                  &freeSpace);
+
+   if (retval != VMCI_SUCCESS) {
+      return retval;
+   }
+
+   return MIN(freeSpace, MAX_INT64);
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VMCIQueue_BufReady --
+ *
+ *      Finds available data to dequeue from a consume queue.
+ *
+ * Results:
+ *      On success, available data size in bytes (up to MAX_INT64).
+ *      On failure, appropriate error code.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE int64
+VMCIQueue_BufReady(const VMCIQueue *consumeQueue, // IN:
+                   const VMCIQueue *produceQueue, // IN:
+                   const uint64 consumeQSize)     // IN:
+{
+   int retval;
+   uint64 freeSpace;
+
+   retval = VMCIQueueFreeSpaceInt(consumeQueue, produceQueue,
+                                  consumeQSize, &freeSpace);
+   if (retval != VMCI_SUCCESS) {
+      return retval;
+   } else {
+      uint64 available = consumeQSize - freeSpace - 1;
+      return MIN(available, MAX_INT64);
+   }
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * AddPointer --
+ *
+ *      Helper to add a given offset to a head or tail pointer. Wraps the value
+ *      of the pointer around the max size of the queue.
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE void
+AddPointer(Atomic_uint64 *var, // IN:
+           size_t add,         // IN:
+           uint64 max)         // IN:
+{
+   uint64 newVal = QPAtomic_ReadOffset(var);
+
+   if (newVal >= max - add) {
+      newVal -= max;
+   }
+   newVal += add;
+
+   QPAtomic_WriteOffset(var, newVal);
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * __VMCIQueue_Enqueue --
+ *
+ *      Enqueues a given buffer to the produce queue using the provided
+ *      function. As many bytes as possible (space available in the queue)
+ *      are enqueued.
+ *
+ * Results:
+ *      VMCI_ERROR_QUEUEPAIR_NOSPACE if no space was available to enqueue data.
+ *      VMCI_ERROR_INVALID_SIZE, if any queue pointer is outside the queue 
+ *      (as defined by the queue size).
+ *      Otherwise, the number of bytes written to the queue is returned.
+ *
+ * Side effects:
+ *      Updates the tail pointer of the produce queue.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE ssize_t
+__VMCIQueue_Enqueue(VMCIQueue *produceQueue,               // IN:
+                    const VMCIQueue *consumeQueue,         // IN:
+                    const uint64 produceQSize,             // IN:
+                    const void *buf,                       // IN:
+                    size_t bufSize,                        // IN:
+                    VMCIMemcpyToQueueFunc memcpyToQueue)   // IN:
+{
+   const int64 freeSpace = VMCIQueue_FreeSpace(produceQueue, consumeQueue,
+                                               produceQSize);
+   const uint64 tail =
+      QPAtomic_ReadOffset(&produceQueue->queueHeader.producerTail);
+   size_t written;
+
+   if (!freeSpace) {
+      return VMCI_ERROR_QUEUEPAIR_NOSPACE;
+   }
+   if (freeSpace < 0) {
+      return (ssize_t)freeSpace;
+   }
+
+   written = (size_t)(freeSpace > bufSize ? bufSize : freeSpace);
+   if (LIKELY(tail + written < produceQSize)) {
+      memcpyToQueue(produceQueue, tail, buf, 0, written);
+   } else {
+      /* Tail pointer wraps around. */
+      const size_t tmp = (size_t)(produceQSize - tail);
+
+      memcpyToQueue(produceQueue, tail, buf, 0, tmp);
+      memcpyToQueue(produceQueue, 0, buf, tmp, written - tmp);
+   }
+   AddPointer(&produceQueue->queueHeader.producerTail, written, produceQSize);
+   return written;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VMCIQueue_Enqueue --
+ *
+ *      Enqueues a given buffer to the produce queue. As many bytes as possible
+ *      (space available in the queue) are enqueued. If bufSize is larger than
+ *      the maximum value of ssize_t the result is unspecified.
+ *
+ * Results:
+ *      VMCI_ERROR_QUEUEPAIR_NOSPACE if no space was available to enqueue data.
+ *      VMCI_ERROR_INVALID_SIZE, if any queue pointer is outside the queue 
+ *      (as defined by the queue size).
+ *      Otherwise, the number of bytes written to the queue is returned.
+ *
+ * Side effects:
+ *      Updates the tail pointer of the produce queue.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE ssize_t
+VMCIQueue_Enqueue(VMCIQueue *produceQueue,       // IN:
+                  const VMCIQueue *consumeQueue, // IN:
+                  const uint64 produceQSize,     // IN:
+                  const void *buf,               // IN:
+                  size_t bufSize)                // IN:
+{
+   return __VMCIQueue_Enqueue(produceQueue, consumeQueue, produceQSize,
+                              buf, bufSize, VMCIMemcpyToQueue);
+}
+
+
+#if defined(__linux__) && defined(__KERNEL__)
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VMCIQueue_EnqueueV --
+ *
+ *      Enqueues a given iovec to the produce queue. As many bytes as possible
+ *      (space available in the queue) are enqueued. If bufSize is larger than
+ *      the maximum value of ssize_t the result is unspecified.
+ *
+ * Results:
+ *      VMCI_ERROR_QUEUEPAIR_NOSPACE if no space was available to enqueue data.
+ *      VMCI_ERROR_INVALID_SIZE, if any queue pointer is outside the queue 
+ *      (as defined by the queue size).
+ *      Otherwise, the number of bytes written to the queue is returned.
+ *
+ * Side effects:
+ *      Updates the tail pointer of the produce queue.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE ssize_t
+VMCIQueue_EnqueueV(VMCIQueue *produceQueue,       // IN:
+                   const VMCIQueue *consumeQueue, // IN:
+                   const uint64 produceQSize,     // IN:
+                   struct iovec *iov,             // IN:
+                   size_t iovSize)                // IN:
+{
+   return __VMCIQueue_Enqueue(produceQueue, consumeQueue, produceQSize,
+                              (void *)iov, iovSize, VMCIMemcpyToQueueV);
+}
+#endif
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * __VMCIQueue_Dequeue --
+ *
+ *      Dequeues data (if available) from the given consume queue. Writes data
+ *      to the user provided buffer using the provided function.
+ *
+ * Results:
+ *      VMCI_ERROR_QUEUEPAIR_NODATA if no data was available to dequeue.
+ *      VMCI_ERROR_INVALID_SIZE, if any queue pointer is outside the queue 
+ *      (as defined by the queue size).
+ *      Otherwise the number of bytes dequeued is returned.
+ *
+ * Side effects:
+ *      Updates the head pointer of the consume queue.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE ssize_t
+__VMCIQueue_Dequeue(VMCIQueue *produceQueue,                    // IN:
+                    const VMCIQueue *consumeQueue,              // IN:
+                    const uint64 consumeQSize,                  // IN:
+                    void *buf,                                  // IN:
+                    size_t bufSize,                             // IN:
+                    VMCIMemcpyFromQueueFunc memcpyFromQueue)    // IN:
+{
+   const int64 bufReady = VMCIQueue_BufReady(consumeQueue, produceQueue,
+                                             consumeQSize);
+   const uint64 head =
+      QPAtomic_ReadOffset(&produceQueue->queueHeader.consumerHead);
+   size_t written;
+
+   if (!bufReady) {
+      return VMCI_ERROR_QUEUEPAIR_NODATA;
+   }
+   if (bufReady < 0) {
+      return (ssize_t)bufReady;
+   }
+
+   written = (size_t)(bufReady > bufSize ? bufSize : bufReady);
+   if (LIKELY(head + written < consumeQSize)) {
+      memcpyFromQueue(buf, 0, consumeQueue, head, written);
+   } else {
+      /* Head pointer wraps around. */
+      const size_t tmp = (size_t)(consumeQSize - head);
+
+      memcpyFromQueue(buf, 0, consumeQueue, head, tmp);
+      memcpyFromQueue(buf, tmp, consumeQueue, 0, written - tmp);
+   }
+   AddPointer(&produceQueue->queueHeader.consumerHead, written, consumeQSize);
+   return written;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VMCIQueue_Dequeue --
+ *
+ *      Dequeues data (if available) from the given consume queue. Writes data
+ *      to the user provided buffer. If bufSize is larger than the maximum
+ *      value of ssize_t the result is unspecified.
+ *
+ * Results:
+ *      VMCI_ERROR_QUEUEPAIR_NODATA if no data was available to dequeue.
+ *      VMCI_ERROR_INVALID_SIZE, if any queue pointer is outside the queue 
+ *      (as defined by the queue size).
+ *      Otherwise the number of bytes dequeued is returned.
+ *
+ * Side effects:
+ *      Updates the head pointer of the consume queue.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE ssize_t
+VMCIQueue_Dequeue(VMCIQueue *produceQueue,       // IN:
+                  const VMCIQueue *consumeQueue, // IN:
+                  const uint64 consumeQSize,     // IN:
+                  void *buf,                     // IN:
+                  size_t bufSize)                // IN:
+{
+   return __VMCIQueue_Dequeue(produceQueue, consumeQueue, consumeQSize,
+                              buf, bufSize, VMCIMemcpyFromQueue);
+}
+
+
+#if defined(__linux__) && defined(__KERNEL__)
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VMCIQueue_DequeueV --
+ *
+ *      Dequeues data (if available) from the given consume queue. Writes data
+ *      to the user provided iovec. If bufSize is larger than the maximum
+ *      value of ssize_t the result is unspecified.
+ *
+ * Results:
+ *      VMCI_ERROR_QUEUEPAIR_NODATA if no data was available to dequeue.
+ *      VMCI_ERROR_INVALID_SIZE, if any queue pointer is outside the queue 
+ *      (as defined by the queue size).
+ *      Otherwise the number of bytes dequeued is returned.
+ *
+ * Side effects:
+ *      Updates the head pointer of the consume queue.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE ssize_t
+VMCIQueue_DequeueV(VMCIQueue *produceQueue,       // IN:
+                   const VMCIQueue *consumeQueue, // IN:
+                   const uint64 consumeQSize,     // IN:
+                   struct iovec *iov,             // IN:
+                   size_t iovSize)                // IN:
+{
+   return __VMCIQueue_Dequeue(produceQueue, consumeQueue, consumeQSize,
+                              (void *)iov, iovSize, VMCIMemcpyFromQueueV);
+}
+#endif
+
+#endif /* !_VMCI_QUEUE_PAIR_H_ */
--- kernel/linux-2.6.26.3/drivers/misc/vsock/vmci_sockets.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vsock/vmci_sockets.h	2008-09-03 09:57:35.000000000 -0500
@@ -0,0 +1,242 @@
+/*********************************************************
+ * Copyright (C) 2007 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * vmci_sockets.h --
+ *
+ *    VMCI sockets public constants and types.
+ */
+
+#ifndef _VMCI_SOCKETS_H_
+#define _VMCI_SOCKETS_H_
+
+
+#if defined(_WIN32)
+#  include <winsock2.h>
+#else // _WIN32
+#if defined(linux) && !defined(VMKERNEL)
+#  if defined(__KERNEL__)
+#    include "driver-config.h"
+#    include "compat_sock.h"
+#  else
+#    include <sys/socket.h>
+#  endif // __KERNEL__
+#endif // linux && !VMKERNEL
+#endif
+
+/*
+ * We use the same value for the AF family and the socket option
+ * level. To set options, use the value of VMCISock_GetAFValue for
+ * 'level' and these constants for the optname.
+ */
+#define SO_VMCI_BUFFER_SIZE                 0
+#define SO_VMCI_BUFFER_MIN_SIZE             1
+#define SO_VMCI_BUFFER_MAX_SIZE             2
+
+/*
+ * The VMCI sockets address equivalents of INADDR_ANY.  The first works for
+ * the svm_cid (context id) field of the address structure below and indicates
+ * the current guest (or the host, if running outside a guest), while the
+ * second indicates any available port.
+ */
+#define VMADDR_CID_ANY  ((unsigned int) -1)
+#define VMADDR_PORT_ANY ((unsigned int) -1)
+
+
+#if defined(_WIN32) || defined(VMKERNEL)
+   typedef unsigned short sa_family_t;
+#endif // _WIN32
+
+#if defined(VMKERNEL)
+   struct sockaddr {
+      sa_family_t sa_family;
+      char sa_data[14];
+   };
+#endif
+
+/*
+ * Address structure for VSockets VMCI sockets. The address family should be
+ * set to AF_VMCI.
+ */
+struct sockaddr_vm {
+   sa_family_t svm_family;                          // AF_VMCI.
+   unsigned short svm_reserved1;                    // Reserved.
+   unsigned int svm_port;                           // Port.
+   unsigned int svm_cid;                            // Context id.
+   unsigned char svm_zero[sizeof(struct sockaddr) - // Same size as sockaddr.
+                          sizeof(sa_family_t) -
+                          sizeof(unsigned short) -
+                          sizeof(unsigned int) -
+                          sizeof(unsigned int)];
+};
+
+
+#if defined(_WIN32)
+#  if !defined(WINNT_DDK)
+#  include <winioctl.h>
+#  define VMCI_SOCKETS_DEVICE          TEXT("\\\\.\\VMCI")
+#  define VMCI_SOCKETS_GET_AF_VALUE    0x81032068
+#  define VMCI_SOCKETS_GET_LOCAL_CID   0x8103206c
+
+   static __inline int VMCISock_GetAFValue(void)
+   {
+      HANDLE device = CreateFile(VMCI_SOCKETS_DEVICE, GENERIC_READ, 0, NULL,
+                                 OPEN_EXISTING, FILE_FLAG_OVERLAPPED, NULL);
+      if (INVALID_HANDLE_VALUE != device) {
+         DWORD ioReturn;
+         int afvalue;
+         if (DeviceIoControl(device, VMCI_SOCKETS_GET_AF_VALUE, &afvalue,
+                             sizeof afvalue, &afvalue, sizeof afvalue,
+                             &ioReturn, NULL)) {
+            CloseHandle(device);
+            device = INVALID_HANDLE_VALUE;
+            return afvalue;
+         }
+         CloseHandle(device);
+         device = INVALID_HANDLE_VALUE;
+      }
+      return -1;
+   }
+
+   static __inline unsigned int VMCISock_GetLocalCID(void)
+   {
+      HANDLE device = CreateFile(VMCI_SOCKETS_DEVICE, GENERIC_READ, 0, NULL,
+                                 OPEN_EXISTING, FILE_FLAG_OVERLAPPED, NULL);
+      if (INVALID_HANDLE_VALUE != device) {
+         DWORD ioReturn;
+         unsigned int cid;
+         if (DeviceIoControl(device, VMCI_SOCKETS_GET_LOCAL_CID, &cid,
+                             sizeof cid, &cid, sizeof cid, &ioReturn,
+                             NULL)) {
+            CloseHandle(device);
+            device = INVALID_HANDLE_VALUE;
+            return cid;
+         }
+         CloseHandle(device);
+         device = INVALID_HANDLE_VALUE;
+      }
+      return VMADDR_CID_ANY;
+   }
+#  endif // WINNT_DDK
+#else // _WIN32
+#if defined(linux) && !defined(VMKERNEL)
+#  ifndef __KERNEL__
+#  include <sys/types.h>
+#  include <sys/stat.h>
+#  include <fcntl.h>
+#  include <sys/ioctl.h>
+#  include <unistd.h>
+
+#  include <stdio.h>
+
+#  define VMCI_SOCKETS_DEFAULT_DEVICE      "/dev/vsock"
+#  define IOCTL_VMCI_SOCKETS_GET_AF_VALUE  1976
+#  define IOCTL_VMCI_SOCKETS_GET_LOCAL_CID 1977
+
+   /*
+    *----------------------------------------------------------------------------
+    *
+    * VMCISock_GetAFValue and VMCISock_GetAFValueFd --
+    *
+    *      Returns the value to be used for the VMCI Sockets address family.
+    *      This value should be used as the domain argument to socket(2) (when
+    *      you might otherwise use AF_INET).  For VMCI Socket-specific options,
+    *      this value should also be used for the level argument to
+    *      setsockopt(2) (when you might otherwise use SOL_TCP).
+    *
+    *      This function leaves its descriptor to the vsock device open so that
+    *      the socket implementation knows that the socket family is still in
+    *      use.  We do this because we register our address family with the
+    *      kernel on-demand and need a notification to unregister the address
+    *      family.
+    *
+    *      For many programs this behavior is sufficient as is, but some may
+    *      wish to close this descriptor once they are done with VMCI Sockets.
+    *      For these programs, we provide a VMCISock_GetAFValueFd() that takes
+    *      an optional outFd argument.  This value can be provided to
+    *      VMCISock_ReleaseAFValueFd() only after the program no longer will
+    *      use VMCI Sockets.  Note that outFd is only valid in cases where
+    *      VMCISock_GetAFValueFd() returns a non-negative value.
+    *
+    * Results:
+    *      The address family value to use on success, negative error code on
+    *      failure.
+    *
+    *----------------------------------------------------------------------------
+    */
+
+   static inline int VMCISock_GetAFValueFd(int *outFd)
+   {
+      int fd;
+      int family;
+
+      fd = open(VMCI_SOCKETS_DEFAULT_DEVICE, O_RDWR);
+      if (fd < 0) {
+         return -1;
+      }
+
+      if (ioctl(fd, IOCTL_VMCI_SOCKETS_GET_AF_VALUE, &family) < 0) {
+         family = -1;
+      }
+
+      if (family < 0) {
+         close(fd);
+      } else if (outFd) {
+         *outFd = fd;
+      }
+
+      return family;
+   }
+
+   static inline int VMCISock_GetAFValue(void)
+   {
+      return VMCISock_GetAFValueFd(NULL);
+   }
+
+
+   static inline void VMCISock_ReleaseAFValueFd(int fd)
+   {
+      if (fd >= 0) {
+         close(fd);
+      }
+   }
+
+   static inline unsigned int VMCISock_GetLocalCID(void)
+   {
+      int fd;
+      unsigned int contextId;
+
+      fd = open(VMCI_SOCKETS_DEFAULT_DEVICE, O_RDWR);
+      if (fd < 0) {
+         return VMADDR_CID_ANY;
+      }
+
+      if (ioctl(fd, IOCTL_VMCI_SOCKETS_GET_LOCAL_CID, &contextId) < 0) {
+         contextId = VMADDR_CID_ANY;
+      }
+
+      close(fd);
+      return contextId;
+   }
+#  endif // __KERNEL__
+#endif // linux && !VMKERNEL
+#endif // _WIN32
+
+
+#endif // _VMCI_SOCKETS_H_
+
--- kernel/linux-2.6.26.3/drivers/misc/vsock/vmware.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vsock/vmware.h	2008-09-03 10:07:18.000000000 -0500
@@ -0,0 +1,57 @@
+/*********************************************************
+ * Copyright (C) 2003 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * vmware.h --
+ *
+ *	Standard include file for VMware source code.
+ */
+
+#ifndef _VMWARE_H_
+#define _VMWARE_H_
+
+#define INCLUDE_ALLOW_USERLEVEL
+#define INCLUDE_ALLOW_VMCORE
+#define INCLUDE_ALLOW_MODULE
+#define INCLUDE_ALLOW_VMMON
+#define INCLUDE_ALLOW_VMNIXMOD
+#define INCLUDE_ALLOW_VMKERNEL
+#define INCLUDE_ALLOW_VMK_MODULE
+#define INCLUDE_ALLOW_DISTRIBUTE
+
+#include "vm_basic_types.h"
+#include "vm_basic_defs.h"
+#include "vm_assert.h"
+
+/*
+ * Global error codes. Currently used internally, but may be exported
+ * to customers one day, like VM_E_XXX in vmcontrol_constants.h
+ */
+
+typedef enum VMwareStatus {
+   VMWARE_STATUS_SUCCESS,  /* success */
+   VMWARE_STATUS_ERROR,    /* generic error */
+   VMWARE_STATUS_NOMEM,    /* generic memory allocation error */
+   VMWARE_STATUS_INSUFFICIENT_RESOURCES, /* internal or system resource limit exceeded */
+   VMWARE_STATUS_INVALID_ARGS  /* invalid arguments */
+} VMwareStatus;
+
+#define VMWARE_SUCCESS(s) ((s) == VMWARE_STATUS_SUCCESS)
+
+
+#endif // ifndef _VMWARE_H_
--- kernel/linux-2.6.26.3/drivers/misc/vsock/vmware_pack_begin.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vsock/vmware_pack_begin.h	2008-09-03 10:02:58.000000000 -0500
@@ -0,0 +1,43 @@
+/*********************************************************
+ * Copyright (C) 2002 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * vmware_pack_begin.h --
+ *
+ *    Begin of structure packing. See vmware_pack_init.h for details.
+ *
+ *    Note that we do not use the following construct in this include file,
+ *    because we want to emit the code every time the file is included --hpreg
+ *
+ *    #ifndef foo
+ *    #   define foo
+ *    ...
+ *    #endif
+ *
+ */
+
+
+#include "vmware_pack_init.h"
+
+
+#ifdef _MSC_VER
+#   pragma pack(push, 1)
+#elif __GNUC__
+#else
+#   error Compiler packing...
+#endif
--- kernel/linux-2.6.26.3/drivers/misc/vsock/vmware_pack_end.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vsock/vmware_pack_end.h	2008-09-03 10:02:58.000000000 -0500
@@ -0,0 +1,44 @@
+/*********************************************************
+ * Copyright (C) 2002 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * vmware_pack_end.h --
+ *
+ *    End of structure packing. See vmware_pack_init.h for details.
+ *
+ *    Note that we do not use the following construct in this include file,
+ *    because we want to emit the code every time the file is included --hpreg
+ *
+ *    #ifndef foo
+ *    #   define foo
+ *    ...
+ *    #endif
+ *
+ */
+
+
+#include "vmware_pack_init.h"
+
+
+#ifdef _MSC_VER
+#   pragma pack(pop)
+#elif __GNUC__
+__attribute__((__packed__))
+#else
+#   error Compiler packing...
+#endif
--- kernel/linux-2.6.26.3/drivers/misc/vsock/vmware_pack_init.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vsock/vmware_pack_init.h	2008-09-03 10:02:58.000000000 -0500
@@ -0,0 +1,65 @@
+/*********************************************************
+ * Copyright (C) 2002 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __VMWARE_PACK_INIT_H__
+#   define __VMWARE_PACK_INIT_H__
+
+
+/*
+ * vmware_pack_init.h --
+ *
+ *    Platform-independent code to make the compiler pack (i.e. have them
+ *    occupy the smallest possible space) structure definitions. The following
+ *    constructs are known to work --hpreg
+ *
+ *    #include "vmware_pack_begin.h"
+ *    struct foo {
+ *       ...
+ *    }
+ *    #include "vmware_pack_end.h"
+ *    ;
+ *
+ *    typedef
+ *    #include "vmware_pack_begin.h"
+ *    struct foo {
+ *       ...
+ *    }
+ *    #include "vmware_pack_end.h"
+ *    foo;
+ */
+
+
+#ifdef _MSC_VER
+/*
+ * MSVC 6.0 emits warning 4103 when the pack push and pop pragma pairing is
+ * not balanced within 1 included file. That is annoying because our scheme
+ * is based on the pairing being balanced between 2 included files.
+ *
+ * So we disable this warning, but this is safe because the compiler will also
+ * emit warning 4161 when there is more pops than pushes within 1 main
+ * file --hpreg
+ */
+
+#   pragma warning(disable:4103)
+#elif __GNUC__
+#else
+#   error Compiler packing...
+#endif
+
+
+#endif /* __VMWARE_PACK_INIT_H__ */
--- kernel/linux-2.6.26.3/drivers/misc/vsock/vsockAddr.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vsock/vsockAddr.c	2008-09-03 10:02:58.000000000 -0500
@@ -0,0 +1,384 @@
+/*********************************************************
+ * Copyright (C) 2007 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * vsockAddr.c --
+ *
+ *    VSockets address implementation.
+ */
+
+/*
+ * These includes come before vsockCommon.h to ensure that VMware's ASSERT
+ * macro is used instead of Linux's irda.h definition.
+ */
+#if defined(linux) && !defined(VMKERNEL)
+#  if defined(__KERNEL__)
+#    include "driver-config.h"
+#    include <linux/socket.h>
+#    include "compat_sock.h"
+#  else
+#    include <string.h>
+#    include <errno.h>
+#  endif
+#elif defined(VMKERNEL)
+# include "vm_libc.h"
+# include "return_status.h"
+#endif
+
+#include "vsockCommon.h"
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VSockAddr_Init --
+ *
+ *      Initialize the given address with the given context id and port. This
+ *      will clear the address, set the correct family, and add the given
+ *      values.
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+void
+VSockAddr_Init(struct sockaddr_vm *addr, // OUT
+               uint32 cid,               // IN
+               uint32 port)              // IN
+{
+   ASSERT(addr);
+   memset(addr, 0, sizeof *addr);
+   VSockAddr_InitNoFamily(addr, cid, port);
+   addr->svm_family = VMCISock_GetAFValue();
+   VSOCK_ADDR_ASSERT(addr);
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VSockAddr_InitNoFamily --
+ *
+ *      Initialize the given address with the given context id and port. This
+ *      will clear the address and add the given values, but not set the
+ *      family.  Note that this is needed because in some places we don't want
+ *      to re-register the address family in the Linux kernel and all we need
+ *      is to check the context id and port.
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+void
+VSockAddr_InitNoFamily(struct sockaddr_vm *addr, // OUT
+                       uint32 cid,               // IN
+                       uint32 port)              // IN
+{
+   ASSERT(addr);
+   memset(addr, 0, sizeof *addr);
+   addr->svm_cid = cid;
+   addr->svm_port = port;
+   VSOCK_ADDR_NOFAMILY_ASSERT(addr);
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VSockAddr_Validate --
+ *
+ *      Try to validate the given address.  The address must not be null and
+ *      must have the correct address family.  Any reserved fields must be
+ *      zero.
+ *
+ * Results:
+ *      0 on success, EFAULT if the address is null, EAFNOSUPPORT if the
+ *      address is of the wrong family, and EINVAL if the reserved fields are
+ *      not zero.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+int32
+VSockAddr_Validate(const struct sockaddr_vm *addr) // IN
+{
+   int32 err;
+
+   if (NULL == addr) {
+      err = EFAULT;
+      goto exit;
+   }
+
+   if (VMCISock_GetAFValue() != addr->svm_family) {
+      err = EAFNOSUPPORT;
+      goto exit;
+   }
+
+   if (0 != addr->svm_zero[0]) {
+      err = EINVAL;
+      goto exit;
+   }
+
+   err = 0;
+
+exit:
+   return sockerr2err(err);
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VSockAddr_ValidateNoFamily --
+ *
+ *      Try to validate the given address.  The address must not be null and
+ *      any reserved fields must be zero, but the address family is not
+ *      checked.  Note that this is needed because in some places we don't want
+ *      to re-register the address family with the Linux kernel.
+ *
+ *      Also note that we duplicate the code from _Validate() since we want to
+ *      retain the ordering or the error return values.
+ *
+ * Results:
+ *      0 on success, EFAULT if the address is null and EINVAL if the reserved
+ *      fields are not zero.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+int32
+VSockAddr_ValidateNoFamily(const struct sockaddr_vm *addr) // IN
+{
+   int32 err;
+
+   if (NULL == addr) {
+      err = EFAULT;
+      goto exit;
+   }
+
+   if (0 != addr->svm_zero[0]) {
+      err = EINVAL;
+      goto exit;
+   }
+
+   err = 0;
+
+exit:
+   return sockerr2err(err);
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VSockAddr_Bound --
+ *
+ *    Determines whether the provided address is bound.
+ *
+ * Results:
+ *    TRUE if the address structure is bound, FALSE otherwise.
+ *
+ * Side effects:
+ *    None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+Bool
+VSockAddr_Bound(struct sockaddr_vm *addr) // IN: socket address to check
+{
+   ASSERT(addr);
+   return addr->svm_cid != VMADDR_CID_ANY && addr->svm_port != VMADDR_PORT_ANY;
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VSockAddr_Unbind --
+ *
+ *    Unbind the given addresss.
+ *
+ * Results:
+ *    None.
+ *
+ * Side effects:
+ *    None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+void
+VSockAddr_Unbind(struct sockaddr_vm *addr) // IN
+{
+   VSockAddr_Init(addr, VMADDR_CID_ANY, VMADDR_PORT_ANY);
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VSockAddr_EqualsAddr --
+ *
+ *    Determine if the given addresses are equal.
+ *
+ * Results:
+ *    TRUE if the addresses are equal, FALSE otherwise.
+ *
+ * Side effects:
+ *    None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+Bool
+VSockAddr_EqualsAddr(struct sockaddr_vm *addr,  // IN
+                     struct sockaddr_vm *other) // IN
+{
+   /*
+    * XXX We don't ASSERT on the family here since this is used on the receive
+    * path in Linux and we don't want to re-register the address family
+    * unnecessarily.
+    */
+   VSOCK_ADDR_NOFAMILY_ASSERT(addr);
+   VSOCK_ADDR_NOFAMILY_ASSERT(other);
+   return (addr->svm_cid == other->svm_cid &&
+           addr->svm_port == other->svm_port);
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VSockAddr_EqualsHandlePort --
+ *
+ *    Determines if the given address matches the given handle and port.
+ *
+ * Results:
+ *    TRUE if the address matches the handle and port, FALSE otherwise.
+ *
+ * Side effects:
+ *    None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+Bool
+VSockAddr_EqualsHandlePort(struct sockaddr_vm *addr, // IN
+                           VMCIHandle handle,        // IN
+                           uint32 port)              // IN
+{
+   VSOCK_ADDR_ASSERT(addr);
+   return (addr->svm_cid == VMCI_HANDLE_TO_CONTEXT_ID(handle) &&
+           addr->svm_port == port);
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VSockAddr_Cast --
+ *
+ *      Try to cast the given generic address to a VM address.  The given
+ *      length must match that of a VM address and the address must be valid.
+ *      The "outAddr" parameter contains the address if successful.
+ *
+ * Results:
+ *      0 on success, EFAULT if the length is too small.  See
+ *      VSockAddr_Validate() for other possible return codes.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+int32
+VSockAddr_Cast(const struct sockaddr *addr,  // IN
+               int32 len,                    // IN
+               struct sockaddr_vm **outAddr) // OUT
+{
+   int32 err;
+
+   ASSERT(outAddr);
+
+   if (len < sizeof **outAddr) {
+      err = EFAULT;
+      goto exit;
+   }
+
+   *outAddr = (struct sockaddr_vm *) addr;
+   err = VSockAddr_Validate(*outAddr);
+
+exit:
+   return sockerr2err(err);
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VSockAddr_SocketContext --
+ *
+ *      Determines whether the provided context id represents a context that
+ *      contains socket endpoints.
+ *
+ * Results:
+ *      TRUE if the context does have socket endpoints, FALSE otherwise.
+ *
+ * Side effects:
+ *      None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+Bool
+VSockAddr_SocketContext(uint32 cid)  // IN
+{
+   uint32 i;
+   VMCIId nonSocketContexts[] = {
+      VMCI_HYPERVISOR_CONTEXT_ID,
+      VMCI_WELL_KNOWN_CONTEXT_ID,
+   };
+
+   ASSERT_ON_COMPILE(sizeof cid == sizeof *nonSocketContexts);
+
+   for (i = 0; i < ARRAYSIZE(nonSocketContexts); i++) {
+      if (cid == nonSocketContexts[i]) {
+         return FALSE;
+      }
+   }
+
+   return TRUE;
+}
--- kernel/linux-2.6.26.3/drivers/misc/vsock/vsockAddr.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vsock/vsockAddr.h	2008-09-03 09:57:35.000000000 -0500
@@ -0,0 +1,52 @@
+/*********************************************************
+ * Copyright (C) 2007 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * vsockAddr.h --
+ *
+ *    VSockets address constants, types and functions.
+ */
+
+
+#ifndef _VSOCK_ADDR_H_
+#define _VSOCK_ADDR_H_
+
+
+/* Assert that the given address is valid. */
+#define VSOCK_ADDR_ASSERT(_a) \
+   ASSERT(0 == VSockAddr_Validate((_a)))
+#define VSOCK_ADDR_NOFAMILY_ASSERT(_a) \
+   ASSERT(0 == VSockAddr_ValidateNoFamily((_a)))
+
+
+void VSockAddr_Init(struct sockaddr_vm *addr, uint32 cid, uint32 port);
+void VSockAddr_InitNoFamily(struct sockaddr_vm *addr, uint32 cid, uint32 port);
+int32 VSockAddr_Validate(const struct sockaddr_vm *addr);
+int32 VSockAddr_ValidateNoFamily(const struct sockaddr_vm *addr);
+Bool VSockAddr_Bound(struct sockaddr_vm *addr);
+void VSockAddr_Unbind(struct sockaddr_vm *addr);
+Bool VSockAddr_EqualsAddr(struct sockaddr_vm *addr, struct sockaddr_vm *other);
+Bool VSockAddr_EqualsHandlePort(struct sockaddr_vm *addr, VMCIHandle handle,
+                                uint32 port);
+int32 VSockAddr_Cast(const struct sockaddr *addr, int32 len,
+                     struct sockaddr_vm **outAddr);
+Bool VSockAddr_SocketContext(VMCIId cid);
+
+
+#endif // _VSOCK_ADDR_H_
+
--- kernel/linux-2.6.26.3/drivers/misc/vsock/vsockCommon.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vsock/vsockCommon.h	2008-09-03 09:57:35.000000000 -0500
@@ -0,0 +1,105 @@
+/*********************************************************
+ * Copyright (C) 2007 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * vsockCommon.h --
+ *
+ *    VSockets common constants, types and functions.
+ */
+
+
+#ifndef _VSOCK_COMMON_H_
+#define _VSOCK_COMMON_H_
+
+
+#if defined(_WIN32)
+#  define VMCI_SOCKETS_AF_VALUE 28
+#  if defined(WINNT_DDK)
+#     define _WIN2K_COMPAT_SLIST_USAGE
+      /*
+       * wdm.h has to come first, otherwise NTDDI_VERSION gets all confused
+       * and we start pulling in the wrong versions of the Ke() routines.
+       */
+#     include <wdm.h>
+#     include <ntddk.h>
+#     include <windef.h>
+      /*
+       * Using ntifs.h for these functions does not play nicely with having
+       * wdm.h first.  So rather than include that header, we pull these in
+       * directly.
+       */
+      NTKERNELAPI HANDLE PsGetCurrentProcessId(VOID);
+      NTKERNELAPI NTSTATUS PsSetCreateProcessNotifyRoutine(
+         PCREATE_PROCESS_NOTIFY_ROUTINE, BOOLEAN);
+      NTSYSAPI NTSTATUS NTAPI
+         ZwWaitForSingleObject(HANDLE, BOOLEAN, PLARGE_INTEGER);
+#     define _INC_WINDOWS
+#     include "vmci_queue_pair.h"
+      /* In the kernel we can't call into the provider. */
+#     define VMCISock_GetAFValue() VMCI_SOCKETS_AF_VALUE
+#  else // WINNT_DDK
+#     include <windows.h>
+#  endif // WINNT_DDK
+#  define Uint64ToPtr(_ui) ((void *)(uint64)(_ui))
+#  define PtrToUint64(_p)  ((uint64)(_p))
+#else
+#if defined(VMKERNEL)
+#  include "uwvmkAPI.h"
+#  define VMCI_SOCKETS_AF_VALUE AF_VMCI /* Defined in uwvmkAPI.h. */
+   /* The address family is fixed in the vmkernel. */
+#  define VMCISock_GetAFValue() VMCI_SOCKETS_AF_VALUE
+#  include "vmci_queue_pair_vmk.h"
+#  define Uint64ToPtr(_ui) ((void *)(uint64)(_ui))
+#  define PtrToUint64(_p)  ((uint64)(_p))
+#else
+#if defined(linux)
+#  if defined(__KERNEL__)
+   /* Include compat_page.h now so PAGE_SIZE and friends don't get redefined. */
+#     include "driver-config.h"
+#     include "compat_page.h"
+#     if defined(VMX86_TOOLS)
+#        include "vmci_queue_pair.h"
+#     endif
+      /*
+       * In the kernel we call back into af_vsock.c to get the address family
+       * being used.  Otherwise an ioctl(2) is performed (see vmci_sockets.h).
+       */
+      extern int VSockVmci_GetAFValue(void);
+#     define VMCISock_GetAFValue() VSockVmci_GetAFValue()
+#  endif
+#endif // linux
+#endif // VMKERNEL
+#endif // _WIN32
+
+#include "vmware.h"
+#include "vmware_pack_init.h"
+#include "vmci_defs.h"
+#include "vmci_call_defs.h"
+#include "vmci_sockets.h"
+#include "vsockAddr.h"
+#include "vsockSocketWrapper.h"
+
+
+/* Memory allocation flags. */
+#define VSOCK_MEMORY_NORMAL   0
+#define VSOCK_MEMORY_ATOMIC   (1 << 0)
+#define VSOCK_MEMORY_NONPAGED (1 << 1)
+
+
+#endif // _VSOCK_COMMON_H_
+
--- kernel/linux-2.6.26.3/drivers/misc/vsock/vsockPacket.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vsock/vsockPacket.h	2008-09-03 09:57:35.000000000 -0500
@@ -0,0 +1,291 @@
+/*********************************************************
+ * Copyright (C) 2007 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * vsockPacket.h --
+ *
+ *    Packet constants, types and functions.
+ */
+
+#if defined(_WIN32) || defined(VMKERNEL)
+# include "vsockOSInt.h"
+#else
+# define VSockOS_ClearMemory(_dst, _sz)   memset(_dst, 0, _sz)
+# define VSockOS_Memcpy(_dst, _src, _sz)  memcpy(_dst, _src, _sz)
+#endif
+
+
+#ifndef _VSOCK_PACKET_H_
+#define _VSOCK_PACKET_H_
+
+
+/* If the packet format changes in a release then this should change too. */
+#define VSOCK_PACKET_VERSION 1
+
+/* The resource ID on which control packets are sent. */
+#define VSOCK_PACKET_RID 1
+
+/* Assert that the given packet is valid. */
+#define VSOCK_PACKET_ASSERT(_p)                 \
+   ASSERT((_p));                                \
+   ASSERT((_p)->type < VSOCK_PACKET_TYPE_MAX);  \
+   ASSERT(0 == (_p)->_reserved1);               \
+   ASSERT(0 == (_p)->_reserved2)
+
+
+typedef enum VSockPacketType {
+   VSOCK_PACKET_TYPE_INVALID = 0,   // Invalid type.
+   VSOCK_PACKET_TYPE_REQUEST,       // Connection request.
+   VSOCK_PACKET_TYPE_NEGOTIATE,     // Connection negotiate.
+   VSOCK_PACKET_TYPE_OFFER,         // Connection offer queue pair.
+   VSOCK_PACKET_TYPE_ATTACH,        // Connection attach.
+   VSOCK_PACKET_TYPE_WROTE,         // Wrote data to queue pair.
+   VSOCK_PACKET_TYPE_READ,          // Read data from queue pair.
+   VSOCK_PACKET_TYPE_RST,           // Reset.
+   VSOCK_PACKET_TYPE_SHUTDOWN,      // Shutdown the connection.
+   VSOCK_PACKET_TYPE_WAITING_WRITE, // Notify peer we are waiting to write.
+   VSOCK_PACKET_TYPE_WAITING_READ,  // Notify peer we are waiting to read.
+   VSOCK_PACKET_TYPE_MAX            // Last message.
+} VSockPacketType;
+
+typedef struct VSockWaitingInfo {
+   uint64 generation; // Generation of the queue.
+   uint64 offset;     // Offset within the queue.
+} VSockWaitingInfo;
+
+/*
+ * Control packet type for STREAM sockets.  DGRAMs have no control packets
+ * nor special packet header for data packets, they are just raw VMCI DGRAM
+ * messages.  For STREAMs, control packets are sent over the control channel
+ * while data is written and read directly from queue pairs with no packet
+ * format.
+ */
+typedef struct VSockPacket {
+   VMCIDatagram dg;          // Datagram header.
+   uint8 version;            // Version.
+   uint8 type;               // Type of message.
+   uint16 _reserved1;        // Reserved.
+   uint32 srcPort;           // Source port.
+   uint32 dstPort;           // Destination port.
+   uint32 _reserved2;        // Reserved.
+   union {
+      uint64 size;           // Size of queue pair for request/negotiation.
+      uint64 mode;           // Mode of shutdown for shutdown.
+      VMCIHandle handle;     // Queue pair handle once size negotiated.
+      VSockWaitingInfo wait; // Information provided for wait notifications.
+   } u;
+} VSockPacket;
+
+
+MY_ASSERTS(VSockPacketAsserts,
+   ASSERT_ON_COMPILE(sizeof (VSockPacket) == 56);
+)
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VSockPacket_Init --
+ *
+ *      Initialize the given packet.  The packet version is set and the fields
+ *      are filled out.  Reserved fields are cleared.
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE void
+VSockPacket_Init(VSockPacket *pkt,        // OUT
+                 struct sockaddr_vm *src, // IN
+                 struct sockaddr_vm *dst, // IN
+                 uint8 type,              // IN
+                 uint64 size,             // IN
+                 uint64 mode,             // IN
+                 VSockWaitingInfo *wait,  // IN
+                 VMCIHandle handle)       // IN
+{
+   ASSERT(pkt);
+   VSOCK_ADDR_NOFAMILY_ASSERT(src);
+   VSOCK_ADDR_NOFAMILY_ASSERT(dst);
+
+   pkt->dg.src = VMCI_MAKE_HANDLE(src->svm_cid, VSOCK_PACKET_RID);
+   pkt->dg.dst = VMCI_MAKE_HANDLE(dst->svm_cid, VSOCK_PACKET_RID);
+   pkt->dg.payloadSize = sizeof *pkt - sizeof pkt->dg;
+   pkt->version = VSOCK_PACKET_VERSION;
+   pkt->type = type;
+   pkt->srcPort = src->svm_port;
+   pkt->dstPort = dst->svm_port;
+   VSockOS_ClearMemory(&pkt->_reserved1, sizeof pkt->_reserved1);
+   VSockOS_ClearMemory(&pkt->_reserved2, sizeof pkt->_reserved2);
+
+   switch (pkt->type) {
+   case VSOCK_PACKET_TYPE_INVALID:
+      pkt->u.size = 0;
+      break;
+
+   case VSOCK_PACKET_TYPE_REQUEST:
+   case VSOCK_PACKET_TYPE_NEGOTIATE:
+      pkt->u.size = size;
+      break;
+
+   case VSOCK_PACKET_TYPE_OFFER:
+   case VSOCK_PACKET_TYPE_ATTACH:
+      pkt->u.handle = handle;
+      break;
+
+   case VSOCK_PACKET_TYPE_WROTE:
+   case VSOCK_PACKET_TYPE_READ:
+   case VSOCK_PACKET_TYPE_RST:
+      pkt->u.size = 0;
+      break;
+
+   case VSOCK_PACKET_TYPE_SHUTDOWN:
+      pkt->u.mode = mode;
+      break;
+
+   case VSOCK_PACKET_TYPE_WAITING_READ:
+   case VSOCK_PACKET_TYPE_WAITING_WRITE:
+      ASSERT(wait);
+      VSockOS_Memcpy(&pkt->u.wait, wait, sizeof pkt->u.wait);
+      break;
+   }
+
+   VSOCK_PACKET_ASSERT(pkt);
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VSockPacket_Validate --
+ *
+ *      Validate the given packet.
+ *
+ * Results:
+ *      0 on success, EFAULT if the address is invalid, EINVAL if the packet
+ *      fields are invalid.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE int32
+VSockPacket_Validate(VSockPacket *pkt)
+{
+   int32 err = EINVAL;
+
+   if (NULL == pkt) {
+      err = EFAULT;
+      goto exit;
+   }
+
+   if (VMCI_HANDLE_INVALID(pkt->dg.src)) {
+      goto exit;
+   }
+
+   if (VMCI_HANDLE_INVALID(pkt->dg.dst)) {
+      goto exit;
+   }
+
+   if (VMCI_INVALID_ID == pkt->dstPort || VMCI_INVALID_ID == pkt->srcPort) {
+      goto exit;
+   }
+
+   if (VSOCK_PACKET_VERSION != pkt->version) {
+      goto exit;
+   }
+
+   if (0 != pkt->_reserved1 || 0 != pkt->_reserved2) {
+      goto exit;
+   }
+
+   switch (pkt->type) {
+   case VSOCK_PACKET_TYPE_INVALID:
+      if (0 != pkt->u.size) {
+         goto exit;
+      }
+      break;
+
+   case VSOCK_PACKET_TYPE_REQUEST:
+   case VSOCK_PACKET_TYPE_NEGOTIATE:
+      if (0 == pkt->u.size) {
+         goto exit;
+      }
+      break;
+
+   case VSOCK_PACKET_TYPE_OFFER:
+   case VSOCK_PACKET_TYPE_ATTACH:
+      if (VMCI_HANDLE_INVALID(pkt->u.handle)) {
+         goto exit;
+      }
+      break;
+
+   case VSOCK_PACKET_TYPE_WROTE:
+   case VSOCK_PACKET_TYPE_READ:
+   case VSOCK_PACKET_TYPE_RST:
+      if (0 != pkt->u.size) {
+         goto exit;
+      }
+      break;
+   }
+
+   err = 0;
+   
+exit:
+   return sockerr2err(err);
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VSockPacket_GetAddresses --
+ *
+ *      Get the local and remote addresses from the given packet.
+ *
+ * Results:
+ *      None
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE void
+VSockPacket_GetAddresses(VSockPacket *pkt,           // IN
+                         struct sockaddr_vm *local,  // OUT
+                         struct sockaddr_vm *remote) // OUT
+{
+   VSOCK_PACKET_ASSERT(pkt);
+   VSockAddr_Init(local, VMCI_HANDLE_TO_CONTEXT_ID(pkt->dg.dst),
+                  pkt->dstPort);
+   VSockAddr_Init(remote, VMCI_HANDLE_TO_CONTEXT_ID(pkt->dg.src),
+                  pkt->srcPort);
+}
+
+
+#endif // _VSOCK_PACKET_H_
+
--- kernel/linux-2.6.26.3/drivers/misc/vsock/vsockSocketWrapper.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vsock/vsockSocketWrapper.h	2008-09-03 09:57:35.000000000 -0500
@@ -0,0 +1,184 @@
+/*********************************************************
+ * Copyright (C) 2007 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * vsockSocketWrapper.h --
+ *
+ *    Socket wrapper constants, types and functions.
+ */
+
+
+#ifndef _VSOCK_SOCKET_WRAPPER_H_
+#define _VSOCK_SOCKET_WRAPPER_H_
+
+
+/*
+ * Socket states and flags.  Note that MSG_WAITALL is only supported on 2K3,
+ * XP-SP2 and above.  Since we currently build for 2K to maintain backwards
+ * compatibility, it will always be 0.
+ */
+#if defined(_WIN32)
+#  define MSG_DONTWAIT        0
+#  define MSG_NOSIGNAL        0
+#  if (_WIN32_WINNT < 0x0502)
+#     define MSG_WAITALL      0
+#  endif
+#endif
+
+#if defined(_WIN32) || defined(VMKERNEL)
+#  define SS_FREE             0
+#  define SS_UNCONNECTED      1
+#  define SS_CONNECTING       2
+#  define SS_CONNECTED        3
+#  define SS_DISCONNECTING    4
+#  define RCV_SHUTDOWN        1
+#  define SEND_SHUTDOWN       2
+#  define SHUTDOWN_MASK       3
+#endif // _WIN32 || VMKERNEL
+
+
+/*
+ * Error codes.
+ */
+#if defined(_WIN32)
+# if !defined(EINTR)
+#  define EINTR               WSAEINTR
+# endif
+# if !defined(EACCES)
+#  define EACCES              WSAEACCES
+# endif
+# if !defined(EFAULT)
+#  define EFAULT              WSAEFAULT
+# endif
+# if !defined(EINVAL)
+#  define EINVAL              WSAEINVAL
+# endif
+#  define EWOULDBLOCK         WSAEWOULDBLOCK
+#  define EINPROGRESS         WSAEINPROGRESS
+#  define EALREADY            WSAEALREADY
+#  define ENOTSOCK            WSAENOTSOCK
+#  define EDESTADDRREQ        WSAEDESTADDRREQ
+#  define EMSGSIZE            WSAEMSGSIZE
+#  define EPROTOTYPE          WSAEPROTOTYPE
+#  define ENOPROTOOPT         WSAENOPROTOOPT
+#  define EPROTONOSUPPORT     WSAEPROTONOSUPPORT
+#  define ESOCKTNOSUPPORT     WSAESOCKTNOSUPPORT
+#  define EOPNOTSUPP          WSAEOPNOTSUPP
+#  define EPFNOSUPPORT        WSAEPFNOSUPPORT
+#  define EAFNOSUPPORT        WSAEAFNOSUPPORT
+#  define EADDRINUSE          WSAEADDRINUSE
+#  define EADDRNOTAVAIL       WSAEADDRNOTAVAIL
+#  define ENETDOWN            WSAENETDOWN
+#  define ENETUNREACH         WSAENETUNREACH
+#  define ENETRESET           WSAENETRESET
+#  define ECONNABORTED        WSAECONNABORTED
+#  define ECONNRESET          WSAECONNRESET
+#  define ENOBUFS             WSAENOBUFS
+#  define EISCONN             WSAEISCONN
+#  define ENOTCONN            WSAENOTCONN
+#  define ESHUTDOWN           WSAESHUTDOWN
+#  define ETIMEDOUT           WSAETIMEDOUT
+#  define ECONNREFUSED        WSAECONNREFUSED
+#  define EHOSTDOWN           WSAEHOSTDOWN
+#  define EHOSTUNREACH        WSAEHOSTUNREACH
+#else
+#if defined(VMKERNEL)
+#  define EINTR               VMK_WAIT_INTERRUPTED
+#  define EACCES              VMK_NOACCESS
+#  define EFAULT              VMK_INVALID_ADDRESS
+#  define EINVAL              VMK_FAILURE
+#  define EWOULDBLOCK         VMK_WOULD_BLOCK
+#  define EINPROGRESS         VMK_EINPROGRESS
+#  define EALREADY            VMK_EALREADY
+#  define ENOTSOCK            VMK_NOT_A_SOCKET
+#  define EDESTADDRREQ        VMK_EDESTADDRREQ
+#  define EMSGSIZE            VMK_LIMIT_EXCEEDED
+#  define EPROTOTYPE          VMK_NOT_SUPPORTED
+#  define ENOPROTOOPT         VMK_NOT_SUPPORTED
+#  define EPROTONOSUPPORT     VMK_EPROTONOSUPPORT
+#  define ESOCKTNOSUPPORT     VMK_NOT_SUPPORTED
+#  define EOPNOTSUPP          VMK_EOPNOTSUPP
+#  define EPFNOSUPPORT        VMK_ADDRFAM_UNSUPP
+#  define EAFNOSUPPORT        VMK_ADDRFAM_UNSUPP
+#  define EADDRINUSE          VMK_EADDRINUSE
+#  define EADDRNOTAVAIL       VMK_EADDRNOTAVAIL
+#  define ENETDOWN            VMK_ENETDOWN
+#  define ENETUNREACH         VMK_ENETUNREACH
+#  define ENETRESET           VMK_ENETRESET
+#  define ECONNABORTED        VMK_ECONNABORTED
+#  define ECONNRESET          VMK_ECONNRESET
+#  define ENOBUFS             VMK_NO_MEMORY
+#  define ENOMEM              VMK_NO_MEMORY
+#  define EISCONN             VMK_ALREADY_CONNECTED
+#  define ENOTCONN            VMK_ENOTCONN
+#  define ESHUTDOWN           VMK_ESHUTDOWN
+#  define ETIMEDOUT           VMK_TIMEOUT
+#  define ECONNREFUSED        VMK_ECONNREFUSED
+#  define EHOSTDOWN           VMK_EHOSTDOWN
+#  define EHOSTUNREACH        VMK_EHOSTUNREACH
+#endif // VMKERNEL
+#endif // _WIN32
+
+
+#if defined(_WIN32)
+#  define sockerr()           WSAGetLastError()
+#  define sockerr2err(_e)     (((_e) < 0) ? -(_e) : (_e))
+#  define sockcleanup()       WSACleanup()
+   typedef uint32             socklen_t;
+   typedef uint32             in_addr_t;
+#else // _WIN32
+#if defined(VMKERNEL)
+#  define SOCKET_ERROR        (-1)
+#  define INVALID_SOCKET      ((SOCKET) -1)
+#  define sockerr()           errno
+#  define sockerr2err(_e)     (_e)
+#  define sockcleanup()       do {} while (0)
+#  define closesocket(_s)     close((_s))
+   typedef int32              SOCKET;
+#else
+#if defined(linux)
+#  define SOCKET_ERROR        (-1)
+#  define INVALID_SOCKET      ((SOCKET) -1)
+#  define sockerr()           errno
+#  define sockerr2err(_e)     (((_e) > 0) ? -(_e) : (_e))
+#  define sockcleanup()       do {} while (0)
+#  define closesocket(_s)     close((_s))
+   typedef int32              SOCKET;
+#endif // linux
+#endif // VMKERNEL
+#endif // _WIN32
+
+
+/*
+ * There is no SS_XXX state equivalent to TCP_LISTEN.  Linux does have a flag
+ * __SO_ACCEPTCON which some of the socket implementations use, but it does
+ * not fit in the state field (although it is sometimes incorrectly used that
+ * way).  So we define our own listen state here for all platforms.
+ */
+#define SS_LISTEN 255
+
+
+/*
+ * Initialize sockets.  This is really for platforms that do not have
+ * on-by-default socket implementations like Windows.
+ */
+int sockinit(void);
+
+
+#endif // _VSOCK_SOCKET_WRAPPER_H_
+
--- kernel/linux-2.6.26.3/drivers/misc/vsock/vsock_version.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vsock/vsock_version.h	2008-09-03 09:57:35.000000000 -0500
@@ -0,0 +1,32 @@
+/*********************************************************
+ * Copyright (C) 2007 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * vsock_version.h --
+ *
+ * Version definitions for the Linux vsock driver.
+ */
+
+#ifndef _VSOCK_VERSION_H_
+#define _VSOCK_VERSION_H_
+
+#define VSOCK_DRIVER_VERSION          1.0.0.0
+#define VSOCK_DRIVER_VERSION_COMMAS   1,0,0,0
+#define VSOCK_DRIVER_VERSION_STRING   "1.0.0.0"
+
+#endif /* _VSOCK_VERSION_H_ */
--- kernel/linux-2.6.26.3/drivers/misc/vsock/vsockVmci.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/misc/vsock/vsockVmci.h	2008-09-03 09:57:35.000000000 -0500
@@ -0,0 +1,101 @@
+/*********************************************************
+ * Copyright (C) 2007 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * vsockVmci.h --
+ *
+ *    VSockets VMCI constants, types and functions.
+ */
+
+
+#ifndef _VSOCK_VMCI_H_
+#define _VSOCK_VMCI_H_
+
+
+extern VMCIId VMCI_GetContextID(void);
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * VSockVmci_IsLocal --
+ *
+ *      Determine if the given handle points to the local context.
+ *
+ * Results:
+ *      TRUE if the given handle is for the local context, FALSE otherwise.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE Bool
+VSockVmci_IsLocal(VMCIHandle handle) // IN
+{
+   return VMCI_GetContextID() == VMCI_HANDLE_TO_CONTEXT_ID(handle);
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VSockVmci_ErrorToVSockError --
+ *
+ *      Converts from a VMCI error code to a VSock error code.
+ *
+ * Results:
+ *      Appropriate error code.
+ *
+ * Side effects:
+ *      None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+static INLINE int32
+VSockVmci_ErrorToVSockError(int32 vmciError) // IN
+{
+   int32 err;
+   switch (vmciError) {
+   case VMCI_ERROR_NO_MEM:
+#if defined(_WIN32)
+      err = ENOBUFS;
+#else // _WIN32
+      err = ENOMEM;
+#endif // _WIN32
+      break;
+   case VMCI_ERROR_DUPLICATE_ENTRY:
+      err = EADDRINUSE;
+      break;
+   case VMCI_ERROR_NO_RESOURCES:
+      err = ENOBUFS;
+      break;
+   case VMCI_ERROR_INVALID_ARGS:
+   case VMCI_ERROR_INVALID_RESOURCE:
+   default:
+      err = EINVAL;
+   }
+
+   return sockerr2err(err);
+}
+
+
+#endif // _VSOCK_VMCI_H_
+
--- kernel/linux-2.6.26.3/drivers/net/Kconfig	2008-09-03 09:55:41.000000000 -0500
+++ linux-2.6.26.3.vmtools/drivers/net/Kconfig	2008-09-03 09:57:35.000000000 -0500
@@ -1273,6 +1273,25 @@ config PCNET32
 	  To compile this driver as a module, choose M here. The module
 	  will be called pcnet32.
 
+config VMXNET
+	tristate "VMware Fast Networking Device"
+	depends on NET_PCI && PCI
+	select CRC32
+	select MII
+	help
+	  This is a Linux kernel device driver module that drives VMware's
+	  fast networking device. As it is backed by real (virtual) hardware,
+	  it should be automatically loaded by hotplug or udev as needed. For
+	  best performance, it is recommended to enable TSO on all interfaces
+	  driven by vmxnet using ethtool.
+	  The VMware backend may present the fast networking device as an AMD
+	  vlance device instead of the actual vmxnet device. If your kernel boots
+	  using initrd, and the pcnet32 device driver is in it (pcnet32 drives AMD
+	  vlance devices), you should also add vmxnet to the initrd. Otherwise, it
+	  is possible that vmxnet will not be loaded. To have vmxnet "morph" the
+	  vlance device into the fast networking device, make the following
+	  modifications.
+
 config AMD8111_ETH
 	tristate "AMD 8111 (new PCI lance) support"
 	depends on NET_PCI && PCI
--- kernel/linux-2.6.26.3/drivers/net/Makefile	2008-09-03 09:55:41.000000000 -0500
+++ linux-2.6.26.3.vmtools/drivers/net/Makefile	2008-09-03 09:57:35.000000000 -0500
@@ -52,6 +52,7 @@ obj-$(CONFIG_VORTEX) += 3c59x.o
 obj-$(CONFIG_TYPHOON) += typhoon.o
 obj-$(CONFIG_NE2K_PCI) += ne2k-pci.o 8390.o
 obj-$(CONFIG_PCNET32) += pcnet32.o
+obj-$(CONFIG_VMXNET) += vmxnet/
 obj-$(CONFIG_EEPRO100) += eepro100.o
 obj-$(CONFIG_E100) += e100.o
 obj-$(CONFIG_TLAN) += tlan.o
--- kernel/linux-2.6.26.3/drivers/net/vmxnet/bpf_meta.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/net/vmxnet/bpf_meta.h	2008-09-03 09:57:35.000000000 -0500
@@ -0,0 +1,59 @@
+/*********************************************************
+ * Copyright (C) 2007 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef _BPF_META_H_ 
+#define _BPF_META_H_
+
+/* This file is to be shared between vmxnet and afpacket */
+
+/* The Control byte flags of bpf_meta_data */
+
+#define VMXNET_BPF_PROCESSED    0x01
+
+/* The following is the definition for dev feature bpf in linux */
+
+#ifndef NETIF_F_BPF             
+#define NETIF_F_BPF             (1<<31) /* BPF Capable Virtual Nic */
+#endif /* NETIF_F_BPF */
+
+
+/* TODO: These three definitions are picked up from vmkernel/public/net_pkt.h.
+ * Reorg the code and take this from a common place 
+ */
+
+#define MAX_BPF_FILTERS 8       /* Maximum number of Filters supported */
+typedef unsigned int BpfSnapLen;
+typedef unsigned int BpfSnapLens[MAX_BPF_FILTERS];
+
+/*
+ * skb->cb[40] maps to this structure. The bpf Trailer in vmxnet is stashed to
+ * this structure in skb.
+ *
+ */
+
+struct BPF_MetaData {
+
+    BpfSnapLens bpfSnapLens; /* 4 * 8 = 32 bytes of SnapLens as recved from VMK*/
+
+    unsigned char unused[7]; /* 7  bytes unused */
+
+    unsigned char controlByte; /* 1  used as controlbyte. For now indicates
+                                  whether VMK processed BPF or not*/ 
+};
+
+#endif
--- kernel/linux-2.6.26.3/drivers/net/vmxnet/compat_ethtool.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/net/vmxnet/compat_ethtool.h	2008-09-03 10:07:45.000000000 -0500
@@ -0,0 +1,54 @@
+/*********************************************************
+ * Copyright (C) 2007 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef _COMPAT_ETHTOOL_H
+#define _COMPAT_ETHTOOL_H
+
+/*
+ * ethtool is a userspace utility for getting and setting ethernet device
+ * settings. Kernel support for it was first published in 2.4.0-test11, but
+ * only in 2.4.15 were the ethtool_value struct and the ETHTOOL_GLINK ioctl
+ * added to ethtool.h (together, because the ETHTOOL_GLINK ioctl expects a 
+ * single value response).
+ *
+ * Likewise, ioctls for getting and setting TSO were published in 2.4.22.
+ */
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 4, 0)
+#   include <linux/ethtool.h>
+
+#   ifndef ETHTOOL_GLINK
+#      define ETHTOOL_GLINK 0x0a
+
+typedef struct {
+	__u32 cmd;
+	__u32 data;
+} compat_ethtool_value;
+
+#   else
+
+typedef struct ethtool_value compat_ethtool_value;
+#   endif
+
+#   ifndef ETHTOOL_GTSO
+#      define ETHTOOL_GTSO 0x1E
+#      define ETHTOOL_STSO 0x1F
+#   endif
+#endif
+
+#endif /* _COMPAT_ETHTOOL_H */
--- kernel/linux-2.6.26.3/drivers/net/vmxnet/compat_highmem.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/net/vmxnet/compat_highmem.h	2008-09-03 10:07:45.000000000 -0500
@@ -0,0 +1,40 @@
+/*********************************************************
+ * Copyright (C) 2002 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_HIGHMEM_H__
+#   define __COMPAT_HIGHMEM_H__
+
+
+/*
+ *  BIGMEM  (4 GB)         support appeared in 2.3.16: kmap() API added
+ *  HIGHMEM (4 GB + 64 GB) support appeared in 2.3.23: kmap() API modified
+ *  In 2.3.27, kmap() API modified again
+ *
+ *   --hpreg
+ */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 3, 27)
+#   include <linux/highmem.h>
+#else
+/* For page_address --hpreg */
+#   include <linux/pagemap.h>
+
+#   define kmap(_page) (void*)page_address(_page)
+#   define kunmap(_page)
+#endif
+
+#endif /* __COMPAT_HIGHMEM_H__ */
--- kernel/linux-2.6.26.3/drivers/net/vmxnet/compat_init.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/net/vmxnet/compat_init.h	2008-09-03 10:07:45.000000000 -0500
@@ -0,0 +1,38 @@
+/*********************************************************
+ * Copyright (C) 1999 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * compat_init.h: Initialization compatibility wrappers.
+ */
+
+#ifndef __COMPAT_INIT_H__
+#define __COMPAT_INIT_H__
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 2, 0)
+#include <linux/init.h>
+#endif
+
+#ifndef module_init
+#define module_init(x) int init_module(void)     { return x(); }
+#endif
+
+#ifndef module_exit
+#define module_exit(x) void cleanup_module(void) { x(); }
+#endif
+
+#endif /* __COMPAT_INIT_H__ */
--- kernel/linux-2.6.26.3/drivers/net/vmxnet/compat_interrupt.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/net/vmxnet/compat_interrupt.h	2008-09-03 10:07:45.000000000 -0500
@@ -0,0 +1,55 @@
+/*********************************************************
+ * Copyright (C) 2003 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_INTERRUPT_H__
+#   define __COMPAT_INTERRUPT_H__
+
+
+#include <linux/interrupt.h>
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 69)
+/*
+ * We cannot just define irqreturn_t, as some 2.4.x kernels have
+ * typedef void irqreturn_t; for "increasing" backward compatibility.
+ */
+typedef void compat_irqreturn_t;
+#define COMPAT_IRQ_NONE
+#define COMPAT_IRQ_HANDLED
+#define COMPAT_IRQ_RETVAL(x)
+#else
+typedef irqreturn_t compat_irqreturn_t;
+#define COMPAT_IRQ_NONE		IRQ_NONE
+#define COMPAT_IRQ_HANDLED	IRQ_HANDLED
+#define COMPAT_IRQ_RETVAL(x)	IRQ_RETVAL(x)
+#endif
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 18)
+#define COMPAT_IRQF_DISABLED    SA_INTERRUPT
+#define COMPAT_IRQF_SHARED      SA_SHIRQ
+#else
+#define COMPAT_IRQF_DISABLED    IRQF_DISABLED
+#define COMPAT_IRQF_SHARED      IRQF_SHARED
+#endif
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 20)
+#define COMPAT_IRQ_HANDLER_ARGS(irq, devp) (int irq, void *devp, struct pt_regs *regs)
+#else
+#define COMPAT_IRQ_HANDLER_ARGS(irq, devp) (int irq, void *devp)
+#endif
+
+#endif /* __COMPAT_INTERRUPT_H__ */
--- kernel/linux-2.6.26.3/drivers/net/vmxnet/compat_ioport.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/net/vmxnet/compat_ioport.h	2008-09-03 10:07:45.000000000 -0500
@@ -0,0 +1,63 @@
+/*********************************************************
+ * Copyright (C) 2003 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_IOPORT_H__
+#   define __COMPAT_IOPORT_H__
+
+
+#include <linux/ioport.h>
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 0)
+static inline void *
+compat_request_region(unsigned long start, unsigned long len, const char *name)
+{
+   if (check_region(start, len)) {
+      return NULL;
+   }
+   request_region(start, len, name);
+   return (void*)1;
+}
+#else
+#define compat_request_region(start, len, name) request_region(start, len, name)
+#endif
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 3, 7)
+/* mmap io support starts from 2.3.7, fail the call for kernel prior to that */
+static inline void *
+compat_request_mem_region(unsigned long start, unsigned long len, const char *name)
+{
+   return NULL;
+}
+
+static inline void
+compat_release_mem_region(unsigned long start, unsigned long len)
+{
+   return;
+}
+#else
+#define compat_request_mem_region(start, len, name) request_mem_region(start, len, name)
+#define compat_release_mem_region(start, len)       release_mem_region(start, len)
+#endif
+
+/* these two macro defs are needed by compat_pci_request_region */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 3, 15)
+#   define IORESOURCE_IO    0x00000100
+#   define IORESOURCE_MEM   0x00000200
+#endif
+
+#endif /* __COMPAT_IOPORT_H__ */
--- kernel/linux-2.6.26.3/drivers/net/vmxnet/compat_module.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/net/vmxnet/compat_module.h	2008-09-03 10:07:45.000000000 -0500
@@ -0,0 +1,72 @@
+/*********************************************************
+ * Copyright (C) 2007 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * compat_module.h --
+ */
+
+#ifndef __COMPAT_MODULE_H__
+#   define __COMPAT_MODULE_H__
+
+
+#include <linux/module.h>
+
+
+/*
+ * Modules wishing to use the GPL license are required to include a
+ * MODULE_LICENSE definition in their module source as of 2.4.10.
+ */
+#ifndef MODULE_LICENSE
+#define MODULE_LICENSE(license)
+#endif
+
+/*
+ * To make use of our own home-brewed MODULE_INFO, we need macros to
+ * concatenate two expressions to "__mod_", and and to convert an
+ * expression into a string. I'm sure we've got these in our codebase,
+ * but I'd rather not introduce such a dependency in a compat header.
+ */
+#ifndef __module_cat
+#define __module_cat_1(a, b) __mod_ ## a ## b
+#define __module_cat(a, b) __module_cat_1(a, b)
+#endif
+
+#ifndef __stringify
+#define __stringify_1(x) #x
+#define __stringify(x) __stringify_1(x)
+#endif
+
+/*
+ * MODULE_INFO was born in 2.5.69.
+ */
+#ifndef MODULE_INFO
+#define MODULE_INFO(tag, info)                                                \
+static const char __module_cat(tag, __LINE__)[]                               \
+  __attribute__((section(".modinfo"), unused)) = __stringify(tag) "=" info
+#endif
+
+/*
+ * MODULE_VERSION was born in 2.6.4. The earlier form appends a long "\0xxx"
+ * string to the module's version, but that was removed in 2.6.10, so we'll
+ * ignore it in our wrapper.
+ */
+#ifndef MODULE_VERSION
+#define MODULE_VERSION(_version) MODULE_INFO(version, _version)
+#endif
+
+#endif /* __COMPAT_MODULE_H__ */
--- kernel/linux-2.6.26.3/drivers/net/vmxnet/compat_netdevice.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/net/vmxnet/compat_netdevice.h	2008-09-03 10:07:45.000000000 -0500
@@ -0,0 +1,287 @@
+/*********************************************************
+ * Copyright (C) 2002 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_NETDEVICE_H__
+#   define __COMPAT_NETDEVICE_H__
+
+
+#include <linux/skbuff.h>
+#include <linux/rtnetlink.h>
+#include <linux/netdevice.h>
+#include <linux/etherdevice.h>
+
+/*
+ * The enet_statistics structure moved from linux/if_ether.h to
+ * linux/netdevice.h and is renamed net_device_stats in 2.1.25 --hpreg
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 1, 25)
+#   include <linux/if_ether.h>
+
+#   define net_device_stats enet_statistics
+#endif
+
+
+/* The netif_rx_ni() API appeared in 2.4.8 --hpreg */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 8)
+#   define netif_rx_ni netif_rx
+#endif
+
+
+/* The device struct was renamed net_device in 2.3.14 --hpreg */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 3, 14)
+#   define net_device device
+#endif
+
+
+/*
+ * SET_MODULE_OWNER appeared sometime during 2.3.x. It was setting
+ * dev->owner = THIS_MODULE until 2.5.70, where netdevice refcounting
+ * was completely changed.  SET_MODULE_OWNER was nop for whole
+ * 2.6.x series, and finally disappeared in 2.6.24.
+ *
+ * MOD_xxx_USE_COUNT wrappers are here, as they must be mutually
+ * exclusive with SET_MODULE_OWNER call.
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 0)
+#   define COMPAT_SET_MODULE_OWNER(dev) do {} while (0)
+#   define COMPAT_NETDEV_MOD_INC_USE_COUNT MOD_INC_USE_COUNT
+#   define COMPAT_NETDEV_MOD_DEC_USE_COUNT MOD_DEC_USE_COUNT
+#else
+#   if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 0)
+#      define COMPAT_SET_MODULE_OWNER(dev) SET_MODULE_OWNER(dev)
+#   else
+#      define COMPAT_SET_MODULE_OWNER(dev) do {} while (0)
+#   endif
+#   define COMPAT_NETDEV_MOD_INC_USE_COUNT do {} while (0)
+#   define COMPAT_NETDEV_MOD_DEC_USE_COUNT do {} while (0)
+#endif
+
+/*
+ * SET_NETDEV_DEV appeared sometime during 2.5.x, and later was
+ * crossported to various 2.4.x kernels (as dummy macro).
+ */
+#ifdef SET_NETDEV_DEV
+#   define COMPAT_SET_NETDEV_DEV(dev, pdev) SET_NETDEV_DEV(dev, pdev)
+#else
+#   define COMPAT_SET_NETDEV_DEV(dev, pdev) do {} while (0)
+#endif
+
+/*
+ * Build alloc_etherdev API on the top of init_etherdev.  For 2.0.x kernels
+ * we must provide dummy init method, otherwise register_netdev does
+ * nothing.
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 3)
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 2, 0)
+int
+vmware_dummy_init(struct net_device *dev)
+{
+   return 0;
+}
+#endif
+
+
+static inline struct net_device*
+compat_alloc_etherdev(int priv_size)
+{
+   struct net_device* dev;
+   int size = sizeof *dev + priv_size;
+
+   /*
+    * The name is dynamically allocated before 2.4.0, but 
+    * is an embedded array in later kernels.
+    */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 0)
+   size += sizeof("ethXXXXXXX");
+#endif
+   dev = kmalloc(size, GFP_KERNEL);
+   if (dev) {
+      memset(dev, 0, size);
+      if (priv_size) {
+         dev->priv = dev + 1;
+      }
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 0)
+      dev->name = (char *)(dev + 1) + priv_size;
+#endif
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 2, 0)
+      dev->init = vmware_dummy_init;
+#endif
+      if (init_etherdev(dev, 0) != dev) {
+         kfree(dev);
+         dev = NULL;
+      }
+   }
+   return dev;
+}
+#else
+#define compat_alloc_etherdev(sz)   alloc_etherdev(sz)
+#endif
+
+
+/*
+ * alloc_netdev and free_netdev are there since 2.4.23.  Their use is mandatory
+ * since 2.6.24.
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 23)
+static inline struct net_device *
+compat_alloc_netdev(int priv_size,
+                    const char *mask,
+                    void (*setup)(struct net_device *))
+{
+   struct net_device *dev;
+   int netdev_size = sizeof *dev;
+   int alloc_size;
+
+#   if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 0)
+   netdev_size += IFNAMSIZ;
+#   endif
+
+   alloc_size = netdev_size + priv_size;
+   dev = kmalloc(alloc_size, GFP_KERNEL);
+   if (dev) {
+      memset(dev, 0, alloc_size);
+      dev->priv = (char*)dev + netdev_size;
+      setup(dev);
+#   if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 0)
+      dev->name = (char*)(dev + 1);
+#   endif
+      strcpy(dev->name, mask);   
+   }
+   return dev;
+}
+#   define compat_free_netdev(dev)     kfree(dev)
+#else
+#   define compat_alloc_netdev(size, mask, setup) alloc_netdev(size, mask, setup)
+#   define compat_free_netdev(dev)                free_netdev(dev)
+#endif
+
+/* netdev_priv() appeared in 2.6.3 */
+#if  LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 3)
+#   define compat_netdev_priv(netdev)   (netdev)->priv
+#else
+#   define compat_netdev_priv(netdev)   netdev_priv(netdev)
+#endif
+
+#if defined(NETDEV_TX_OK)
+#   define COMPAT_NETDEV_TX_OK    NETDEV_TX_OK
+#   define COMPAT_NETDEV_TX_BUSY  NETDEV_TX_BUSY
+#else
+#   define COMPAT_NETDEV_TX_OK    0
+#   define COMPAT_NETDEV_TX_BUSY  1
+#endif
+
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,3,43))
+static inline void
+compat_netif_start_queue(struct device *dev)
+{
+   clear_bit(0, &dev->tbusy);
+}
+
+static inline void
+compat_netif_stop_queue(struct device *dev)
+{
+   set_bit(0, &dev->tbusy);
+}
+
+static inline int
+compat_netif_queue_stopped(struct device *dev)
+{
+   return test_bit(0, &dev->tbusy);
+}
+
+static inline void
+compat_netif_wake_queue(struct device *dev)
+{
+   clear_bit(0, &dev->tbusy);
+   mark_bh(NET_BH);
+}
+
+static inline int
+compat_netif_running(struct device *dev)
+{
+   return dev->start == 0;
+}
+
+static inline int
+compat_netif_carrier_ok(struct device *dev)
+{
+   return 1;
+}
+
+static inline void
+compat_netif_carrier_on(struct device *dev)
+{
+}
+
+static inline void
+compat_netif_carrier_off(struct device *dev)
+{
+}
+
+#else
+#define compat_netif_start_queue(dev)   netif_start_queue(dev)
+#define compat_netif_stop_queue(dev)    netif_stop_queue(dev)
+#define compat_netif_queue_stopped(dev) netif_queue_stopped(dev)
+#define compat_netif_wake_queue(dev)    netif_wake_queue(dev)
+#define compat_netif_running(dev)       netif_running(dev)
+#define compat_netif_carrier_ok(dev)    netif_carrier_ok(dev)
+#define compat_netif_carrier_on(dev)    netif_carrier_on(dev)
+#define compat_netif_carrier_off(dev)   netif_carrier_off(dev)
+#endif
+
+/* unregister_netdevice_notifier was not safe prior to 2.6.17 */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 17) && \
+    !defined(ATOMIC_NOTIFIER_INIT)
+/* pre 2.6.17 and not patched */
+static inline int compat_unregister_netdevice_notifier(struct notifier_block *nb) {
+   int err;
+
+   rtnl_lock();
+   err = unregister_netdevice_notifier(nb);
+   rtnl_unlock();
+   return err;
+}
+#else
+/* post 2.6.17 or patched */
+#define compat_unregister_netdevice_notifier(_nb) \
+        unregister_netdevice_notifier(_nb);
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 24)
+#define compat_netif_napi_add(dev, napi, poll, quota) \
+   netif_napi_add(dev, napi, poll, quota)
+#define compat_netif_rx_schedule(dev, napi) netif_rx_schedule(dev, napi)
+#define compat_napi_enable(dev, napi)       napi_enable(napi)
+#define compat_napi_disable(dev, napi)      napi_disable(napi)
+#else
+struct napi_struct {
+   int dummy;
+};
+
+#define compat_netif_napi_add(dev, napi, pollcb, quota) \
+   do {                        \
+      (dev)->poll = (pollcb);    \
+      (dev)->weight = (quota);\
+   } while (0)
+#define compat_netif_rx_schedule(dev, napi) netif_rx_schedule(dev)
+#define compat_napi_enable(dev, napi)       netif_poll_enable(dev)
+#define compat_napi_disable(dev, napi)      netif_poll_disable(dev)
+#endif
+
+#endif /* __COMPAT_NETDEVICE_H__ */
--- kernel/linux-2.6.26.3/drivers/net/vmxnet/compat_pci.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/net/vmxnet/compat_pci.h	2008-09-03 10:07:45.000000000 -0500
@@ -0,0 +1,590 @@
+/*********************************************************
+ * Copyright (C) 1999 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * compat_pci.h: PCI compatibility wrappers.
+ */
+
+#ifndef __COMPAT_PCI_H__
+#define __COMPAT_PCI_H__
+
+#include "compat_ioport.h"
+#include <linux/pci.h>
+#ifndef KERNEL_2_1
+#   include <linux/bios32.h>
+#endif
+
+
+/* 2.0.x has useless struct pci_dev; remap it to our own */
+#ifndef KERNEL_2_1
+#define pci_dev    vmw_pci_driver_instance
+#endif
+
+
+/* 2.0/2.2 does not have pci driver API */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 0)
+struct vmw_pci_driver_instance {
+   struct vmw_pci_driver_instance *next;
+   void                   *driver_data;
+   struct pci_driver      *pcidrv;
+#ifdef KERNEL_2_1
+   struct pci_dev         *pcidev;
+#else
+   unsigned char           bus;
+   unsigned char           devfn;
+   unsigned int            irq;
+#endif
+};
+#endif
+
+
+/* 2.0 has pcibios_* calls only...  We have to provide pci_* compatible wrappers. */
+#ifndef KERNEL_2_1
+static inline int
+pci_read_config_byte(struct pci_dev *pdev,  // IN: PCI slot
+                     unsigned char   where, // IN: Byte to read
+                     u8             *value) // OUT: Value read
+{
+   return pcibios_read_config_byte(pdev->bus, pdev->devfn, where, value);
+}
+
+static inline int
+pci_read_config_dword(struct pci_dev *pdev,  // IN: PCI slot
+                      unsigned char   where, // IN: Dword to read
+                      u32            *value) // OUT: Value read
+{
+   return pcibios_read_config_dword(pdev->bus, pdev->devfn, where, value);
+}
+
+static inline int
+pci_write_config_dword(struct pci_dev *pdev,  // IN: PCI slot
+                       unsigned char   where, // IN: Dword to write
+                       u32             value) // IN: Value to write
+{
+   return pcibios_write_config_dword(pdev->bus, pdev->devfn, where, value);
+}
+#endif
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * compat_pci_name --
+ *
+ *      Return human readable PCI slot name.  Note that some implementations
+ *      return a pointer to the static storage, so returned value may be
+ *      overwritten by subsequent calls to this function.
+ *
+ * Results:
+ *      Returns pointer to the string with slot name.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 4, 22)
+#define compat_pci_name(pdev) pci_name(pdev)
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(2, 4, 0)
+#define compat_pci_name(pdev) (pdev)->slot_name
+#elif defined(KERNEL_2_1)
+static inline const char*
+compat_pci_name(struct pci_dev* pdev)
+{
+   static char slot_name[12];
+   sprintf(slot_name, "%02X:%02X.%X", pdev->bus->number,
+           PCI_SLOT(pdev->devfn), PCI_FUNC(pdev->devfn));
+   return slot_name;
+}
+#else
+static inline const char*
+compat_pci_name(struct pci_dev* pdev)
+{
+   static char slot_name[12];
+   sprintf(slot_name, "%02X:%02X.%X", pdev->bus,
+           PCI_SLOT(pdev->devfn), PCI_FUNC(pdev->devfn));
+   return slot_name;
+}
+#endif
+
+
+/* pci_resource_start comes in 4 flavors - 2.0, 2.2, early 2.3, 2.4+ */
+#ifndef KERNEL_2_1
+static inline unsigned long
+compat_pci_resource_start(struct pci_dev *pdev,
+                          unsigned int    index)
+{
+   u32 addr;
+
+   if (pci_read_config_dword(pdev, PCI_BASE_ADDRESS_0 + index * 4, &addr)) {
+      printk(KERN_ERR "Unable to read base address %u from PCI slot %s!\n",
+             index, compat_pci_name(pdev));
+      return ~0UL;
+   }
+   if (addr & PCI_BASE_ADDRESS_SPACE) {
+      return addr & PCI_BASE_ADDRESS_IO_MASK;
+   } else {
+      return addr & PCI_BASE_ADDRESS_MEM_MASK;
+   }
+}
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(2, 3, 1)
+#   define compat_pci_resource_start(dev, index) \
+       (((dev)->base_address[index] & PCI_BASE_ADDRESS_SPACE) \
+          ? ((dev)->base_address[index] & PCI_BASE_ADDRESS_IO_MASK) \
+          : ((dev)->base_address[index] & PCI_BASE_ADDRESS_MEM_MASK))
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(2, 3, 43)
+#   define compat_pci_resource_start(dev, index) \
+       ((dev)->resource[index].start)
+#else
+#   define compat_pci_resource_start(dev, index) \
+       pci_resource_start(dev, index)
+#endif
+
+/* since 2.3.15, a new set of s/w res flags IORESOURCE_ is introduced,
+ * we fake them by returning either IORESOURCE_{IO, MEM} prior to 2.3.15 since
+ * this is what compat_pci_request_region uses
+ */
+#ifndef KERNEL_2_1
+static inline unsigned long
+compat_pci_resource_flags(struct pci_dev *pdev,
+                          unsigned int    index)
+{
+   u32 addr;
+
+   if (pci_read_config_dword(pdev, PCI_BASE_ADDRESS_0 + index * 4, &addr)) {
+      printk(KERN_ERR "Unable to read base address %u from PCI slot %s!\n",
+             index, compat_pci_name(pdev));
+      return ~0UL;
+   }
+   if (addr & PCI_BASE_ADDRESS_SPACE) {
+      return IORESOURCE_IO;
+   } else {
+      return IORESOURCE_MEM;
+   }
+}
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(2, 3, 1)
+#   define compat_pci_resource_flags(dev, index) \
+       (((dev)->base_address[index] & PCI_BASE_ADDRESS_SPACE) \
+          ? IORESOURCE_IO: IORESOURCE_MEM)
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(2, 3, 15)
+    /* IORESOURCE_xxx appeared in 2.3.15 and is set in resource[].flags */
+#   define compat_pci_resource_flags(dev, index) ((dev)->resource[index].flags)
+#else
+#   define compat_pci_resource_flags(dev, index) pci_resource_flags(dev, index)
+#endif
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 2, 18)
+static inline unsigned long
+compat_pci_resource_len(struct pci_dev *pdev,  // IN
+                        unsigned int    index) // IN
+{
+   u32 addr, mask;
+   unsigned char reg = PCI_BASE_ADDRESS_0 + index * 4;
+
+   if (pci_read_config_dword(pdev, reg, &addr) || addr == 0xFFFFFFFF) {
+      return 0;
+   }
+
+   pci_write_config_dword(pdev, reg, 0xFFFFFFFF);
+   pci_read_config_dword(pdev, reg, &mask);
+   pci_write_config_dword(pdev, reg, addr);
+
+   if (mask == 0 || mask == 0xFFFFFFFF) {
+      return 0;
+   }
+   if (addr & PCI_BASE_ADDRESS_SPACE) {
+      return 65536 - (mask & PCI_BASE_ADDRESS_IO_MASK & 0xFFFF);
+   } else {
+      return -(mask & PCI_BASE_ADDRESS_MEM_MASK);
+   }
+}
+#else
+#define compat_pci_resource_len(dev, index) pci_resource_len(dev, index)
+#endif
+
+/* pci_request_region appears in 2.4.20 */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 20)
+static inline int
+compat_pci_request_region(struct pci_dev *pdev, int bar, char *name)
+{
+   if (compat_pci_resource_len(pdev, bar) == 0) {
+      return 0;
+   }
+
+   if (compat_pci_resource_flags(pdev, bar) & IORESOURCE_IO) {
+      if (!compat_request_region(compat_pci_resource_start(pdev, bar),
+                                 compat_pci_resource_len(pdev, bar),
+                                 name)) {
+         return -EBUSY;
+      }
+   } else if (compat_pci_resource_flags(pdev, bar) & IORESOURCE_MEM) {
+      if (!compat_request_mem_region(compat_pci_resource_start(pdev, bar),
+                                     compat_pci_resource_len(pdev, bar),
+                                     name)) {
+         return -EBUSY;
+      }
+   }
+
+   return 0;
+}
+
+static inline void
+compat_pci_release_region(struct pci_dev *pdev, int bar)
+{
+   if (compat_pci_resource_len(pdev, bar) != 0) {
+      if (compat_pci_resource_flags(pdev, bar) & IORESOURCE_IO) {
+         release_region(compat_pci_resource_start(pdev, bar),
+                        compat_pci_resource_len(pdev, bar));
+      } else if (compat_pci_resource_flags(pdev, bar) & IORESOURCE_MEM) {
+         compat_release_mem_region(compat_pci_resource_start(pdev, bar),
+                                   compat_pci_resource_len(pdev, bar));
+      }
+   }
+}
+#else
+#define compat_pci_request_region(pdev, bar, name)  pci_request_region(pdev, bar, name)
+#define compat_pci_release_region(pdev, bar)        pci_release_region(pdev, bar)
+#endif
+
+/* pci_request_regions appeears in 2.4.3 */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 3)
+static inline int
+compat_pci_request_regions(struct pci_dev *pdev, char *name)
+{
+   int i;
+   
+   for (i = 0; i < 6; i++) {
+      if (compat_pci_request_region(pdev, i, name)) {
+         goto release;
+      }
+   }
+   return 0;
+
+release:
+   while (--i >= 0) {
+      compat_pci_release_region(pdev, i);
+   }
+   return -EBUSY;
+}
+static inline void
+compat_pci_release_regions(struct pci_dev *pdev)
+{
+   int i;
+   
+   for (i = 0; i < 6; i++) {
+      compat_pci_release_region(pdev, i);
+   }
+}
+#else
+#define compat_pci_request_regions(pdev, name) pci_request_regions(pdev, name)
+#define compat_pci_release_regions(pdev)       pci_release_regions(pdev)
+#endif
+
+/* pci_enable_device is available since 2.4.0 */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 0)
+#define compat_pci_enable_device(pdev) (0)
+#else
+#define compat_pci_enable_device(pdev) pci_enable_device(pdev)
+#endif
+
+
+/* pci_set_master is available since 2.2.0 */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 2, 0)
+#define compat_pci_set_master(pdev) (0)
+#else
+#define compat_pci_set_master(pdev) pci_set_master(pdev)
+#endif
+
+
+/* pci_disable_device is available since 2.4.4 */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 4)
+#define compat_pci_disable_device(pdev) do {} while (0)
+#else
+#define compat_pci_disable_device(pdev) pci_disable_device(pdev)
+#endif
+
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 0)
+/*
+ * Devices supported by particular pci driver.  While 2.4+ kernels
+ * can do match on subsystem and class too, we support match on
+ * vendor/device IDs only.
+ */
+struct pci_device_id {
+   unsigned int vendor, device;
+   unsigned long driver_data;
+};
+#define PCI_DEVICE(vend, dev)   .vendor = (vend), .device = (dev)
+
+/* PCI driver */
+struct pci_driver {
+   const char *name;
+   const struct pci_device_id *id_table;
+   int   (*probe)(struct pci_dev* dev, const struct pci_device_id* id);
+   void  (*remove)(struct pci_dev* dev);
+};
+
+
+/*
+ * Note that this is static variable.  Maybe everything below should be in
+ * separate compat_pci.c file, but currently only user of this file is vmxnet,
+ * and vmxnet has only one file, so it is fine.  Also with vmxnet all
+ * functions below are called just once, so difference between 'inline' and
+ * separate compat_pci.c should be very small.
+ */
+
+static struct vmw_pci_driver_instance *pci_driver_instances = NULL;
+
+#ifdef KERNEL_2_1
+#define vmw_pci_device(instance) (instance)->pcidev
+#else
+#define vmw_pci_device(instance) (instance)
+#endif
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * pci_register_driver --
+ *
+ *      Create driver instances for all matching PCI devices in the box.
+ *
+ * Results:
+ *      Returns 0 for success, negative error value for failure.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static inline int
+pci_register_driver(struct pci_driver *drv)
+{
+   const struct pci_device_id *chipID;
+
+   for (chipID = drv->id_table; chipID->vendor; chipID++) {
+#ifdef KERNEL_2_1
+      struct pci_dev *pdev;
+
+      for (pdev = NULL;
+           (pdev = pci_find_device(chipID->vendor, chipID->device, pdev)) != NULL; ) {
+#else
+      int adapter;
+      unsigned char bus, devfn, irq;
+
+      for (adapter = 0;
+           pcibios_find_device(chipID->vendor, chipID->device, adapter,
+                               &bus, &devfn) == 0;
+           adapter++) {
+#endif
+         struct vmw_pci_driver_instance *pdi;
+         int err;
+
+         pdi = kmalloc(sizeof *pdi, GFP_KERNEL);
+         if (!pdi) {
+            printk(KERN_ERR "Not enough memory.\n");
+            break;
+         }
+         pdi->pcidrv = drv;
+#ifdef KERNEL_2_1
+         pdi->pcidev = pdev;
+#else
+         pdi->bus = bus;
+         pdi->devfn = devfn;
+         if (pci_read_config_byte(pdi, PCI_INTERRUPT_LINE, &irq)) {
+            pdi->irq = -1;
+         } else {
+            pdi->irq = irq;
+         }
+#endif
+         pdi->driver_data = NULL;
+         pdi->next = pci_driver_instances;
+         pci_driver_instances = pdi;
+         err = drv->probe(vmw_pci_device(pdi), chipID);
+         if (err) {
+            pci_driver_instances = pdi->next;
+            kfree(pdi);
+         }
+      }
+   }
+   return 0;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * compat_pci_unregister_driver --
+ *
+ *      Shut down PCI driver - unbind all device instances from driver.
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static inline void
+pci_unregister_driver(struct pci_driver *drv)
+{
+   struct vmw_pci_driver_instance **ppdi;
+
+   ppdi = &pci_driver_instances;
+   while (1) {
+      struct vmw_pci_driver_instance *pdi = *ppdi;
+
+      if (!pdi) {
+         break;
+      }
+      if (pdi->pcidrv == drv) {
+         drv->remove(vmw_pci_device(pdi));
+         *ppdi = pdi->next;
+         kfree(pdi);
+      } else {
+         ppdi = &pdi->next;
+      }
+   }
+}
+#else
+/* provide PCI_DEVICE for early 2.4.x kernels */
+#ifndef PCI_DEVICE
+#define PCI_DEVICE(vend, dev)   .vendor = (vend), .device = (dev), \
+                                .subvendor = PCI_ANY_ID, .subdevice = PCI_ANY_ID
+#endif
+#endif
+
+
+/* provide dummy MODULE_DEVICE_TABLE for 2.0/2.2 */
+#ifndef MODULE_DEVICE_TABLE
+#define MODULE_DEVICE_TABLE(bus, devices)
+#endif
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * pci_set_drvdata --
+ *
+ *      Set per-device driver's private data.
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * pci_get_drvdata --
+ *
+ *      Retrieve per-device driver's private data.
+ *
+ * Results:
+ *      per-device driver's data previously set by pci_set_drvdata,
+ *      or NULL on failure.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+#ifndef KERNEL_2_1
+/* 2.0.x is simple, we have driver_data directly in pci_dev */
+#define pci_set_drvdata(pdev, data) do { (pdev)->driver_data = (data); } while (0)
+#define pci_get_drvdata(pdev)       (pdev)->driver_data
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 0)
+/* 2.2.x is trickier, we have to find driver instance first */
+static inline void
+pci_set_drvdata(struct pci_dev *pdev, void* data)
+{
+   struct vmw_pci_driver_instance *pdi;
+
+   for (pdi = pci_driver_instances; pdi; pdi = pdi->next) {
+      if (pdi->pcidev == pdev) {
+         pdi->driver_data = data;
+         return;
+      }
+   }
+   printk(KERN_ERR "pci_set_drvdata issued for unknown device %p\n", pdev);
+}
+
+static inline void *
+pci_get_drvdata(struct pci_dev *pdev)
+{
+   struct vmw_pci_driver_instance *pdi;
+
+   for (pdi = pci_driver_instances; pdi; pdi = pdi->next) {
+      if (pdi->pcidev == pdev) {
+         return pdi->driver_data;
+      }
+   }
+   printk(KERN_ERR "pci_get_drvdata issued for unknown device %p\n", pdev);
+   return NULL;
+}
+#endif
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,3,48)
+#   define PCI_DMA_BIDIRECTIONAL        0
+#   define PCI_DMA_TODEVICE             1
+#   define PCI_DMA_FROMDEVICE           2
+#   define PCI_DMA_NONE                 3
+#endif
+
+/*
+ * Power Management related compat wrappers.
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 10)
+#   define compat_pci_save_state(pdev)      pci_save_state((pdev), NULL)
+#   define compat_pci_restore_state(pdev)   pci_restore_state((pdev), NULL)
+#else
+#   define compat_pci_save_state(pdev)      pci_save_state((pdev))
+#   define compat_pci_restore_state(pdev)   pci_restore_state((pdev))
+#endif
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 11)
+#   define pm_message_t          u32
+#   define compat_pci_choose_state(pdev, state)  (state)
+#   define PCI_D0               0
+#   define PCI_D3hot            3
+#else
+#   define compat_pci_choose_state(pdev, state)  pci_choose_state((pdev), (state))
+#endif
+
+/* 2.6.14 changed the PCI shutdown callback */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,14)
+#   define COMPAT_PCI_SHUTDOWN(func)               .driver = { .shutdown = (func), }
+#   define COMPAT_PCI_DECLARE_SHUTDOWN(func, var)  (func)(struct device *(var))
+#   define COMPAT_PCI_TO_DEV(dev)                  (to_pci_dev(dev))
+#else
+#   define COMPAT_PCI_SHUTDOWN(func)               .shutdown = (func)
+#   define COMPAT_PCI_DECLARE_SHUTDOWN(func, var)  (func)(struct pci_dev *(var))
+#   define COMPAT_PCI_TO_DEV(dev)                  (dev)
+#endif
+
+
+#endif /* __COMPAT_PCI_H__ */
--- kernel/linux-2.6.26.3/drivers/net/vmxnet/compat_skbuff.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/net/vmxnet/compat_skbuff.h	2008-09-03 10:07:45.000000000 -0500
@@ -0,0 +1,156 @@
+/*********************************************************
+ * Copyright (C) 2007 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_SKBUFF_H__
+#   define __COMPAT_SKBUFF_H__
+
+#include <linux/skbuff.h>
+
+/*
+ * When transition from mac/nh/h to skb_* accessors was made, also SKB_WITH_OVERHEAD
+ * was introduced.
+ */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 22) || \
+   (LINUX_VERSION_CODE == KERNEL_VERSION(2, 6, 21) && defined(SKB_WITH_OVERHEAD))
+#define compat_skb_mac_header(skb)         skb_mac_header(skb)
+#define compat_skb_network_header(skb)     skb_network_header(skb)
+#define compat_skb_network_offset(skb)     skb_network_offset(skb)
+#define compat_skb_transport_header(skb)   skb_transport_header(skb)
+#define compat_skb_transport_offset(skb)   skb_transport_offset(skb)
+#define compat_skb_network_header_len(skb) skb_network_header_len(skb)
+#define compat_skb_tail_pointer(skb)       skb_tail_pointer(skb)
+#define compat_skb_end_pointer(skb)        skb_end_pointer(skb)
+#define compat_skb_ip_header(skb)          ((struct iphdr *)skb_network_header(skb))
+#define compat_skb_tcp_header(skb)         ((struct tcphdr *)skb_transport_header(skb))
+#define compat_skb_reset_mac_header(skb)   skb_reset_mac_header(skb)
+#define compat_skb_set_network_header(skb, off)   skb_set_network_header(skb, off)
+#define compat_skb_set_transport_header(skb, off) skb_set_transport_header(skb, off)
+#else
+#define compat_skb_mac_header(skb)         (skb)->mac.raw
+#define compat_skb_network_header(skb)     (skb)->nh.raw
+#define compat_skb_network_offset(skb)     ((skb)->nh.raw - (skb)->data)
+#define compat_skb_transport_header(skb)   (skb)->h.raw
+#define compat_skb_transport_offset(skb)   ((skb)->h.raw - (skb)->data)
+#define compat_skb_network_header_len(skb) ((skb)->h.raw - (skb)->nh.raw)
+#define compat_skb_tail_pointer(skb)       (skb)->tail
+#define compat_skb_end_pointer(skb)        (skb)->end
+#define compat_skb_ip_header(skb)          (skb)->nh.iph
+#define compat_skb_tcp_header(skb)         (skb)->h.th
+#define compat_skb_reset_mac_header(skb)   ((skb)->mac.raw = (skb)->data)
+#define compat_skb_set_network_header(skb, off)   ((skb)->nh.raw = (skb)->data + (off))
+#define compat_skb_set_transport_header(skb, off) ((skb)->h.raw = (skb)->data + (off))
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 18) || defined(VMW_SKB_LINEARIZE_2618)
+#   define compat_skb_linearize(skb) skb_linearize((skb))
+#else
+
+#   if LINUX_VERSION_CODE == KERNEL_VERSION(2, 6, 0)
+#      define compat_skb_linearize(skb) __skb_linearize((skb), GFP_ATOMIC)
+#   elif LINUX_VERSION_CODE >= KERNEL_VERSION(2, 4, 4)
+#      define compat_skb_linearize(skb) skb_linearize((skb), GFP_ATOMIC)
+#   else
+static inline int
+compat_skb_linearize(struct sk_buff *skb)
+{
+   return 0;
+}
+#   endif
+
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 20)
+#define compat_skb_csum_offset(skb)        (skb)->csum_offset
+#else
+#define compat_skb_csum_offset(skb)        (skb)->csum
+#endif
+
+/*
+ * Note that compat_skb_csum_start() has semantic different from kernel's csum_start:
+ * kernel's skb->csum_start is offset between start of checksummed area and start of
+ * complete skb buffer, while our compat_skb_csum_start(skb) is offset from start
+ * of packet itself.
+ */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 22)
+#define compat_skb_csum_start(skb)         ((skb)->csum_start - skb_headroom(skb))
+#else
+#define compat_skb_csum_start(skb)         compat_skb_transport_offset(skb)
+#endif
+
+#if defined(NETIF_F_GSO) /* 2.6.18 and upwards */
+#define compat_skb_mss(skb) (skb_shinfo(skb)->gso_size)
+#else
+#define compat_skb_mss(skb) (skb_shinfo(skb)->tso_size)
+#endif
+
+/* used by both received pkts and outgoing ones */
+#define VM_CHECKSUM_UNNECESSARY CHECKSUM_UNNECESSARY
+
+/* csum status of received pkts */
+#if defined(CHECKSUM_COMPLETE)
+#   define VM_RX_CHECKSUM_PARTIAL     CHECKSUM_COMPLETE
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 19) && defined(CHECKSUM_HW)
+#   define VM_RX_CHECKSUM_PARTIAL     CHECKSUM_HW
+#else
+#   define VM_RX_CHECKSUM_PARTIAL     CHECKSUM_PARTIAL
+#endif
+
+/* csum status of outgoing pkts */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 19) && defined(CHECKSUM_HW)
+#   define VM_TX_CHECKSUM_PARTIAL      CHECKSUM_HW
+#else
+#   define VM_TX_CHECKSUM_PARTIAL      CHECKSUM_PARTIAL
+#endif
+
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,1,0))
+#   define compat_kfree_skb(skb, type) kfree_skb(skb, type)
+#   define compat_dev_kfree_skb(skb, type) dev_kfree_skb(skb, type)
+#   define compat_dev_kfree_skb_any(skb, type) dev_kfree_skb(skb, type)
+#   define compat_dev_kfree_skb_irq(skb, type) dev_kfree_skb(skb, type)
+#else
+#   define compat_kfree_skb(skb, type) kfree_skb(skb)
+#   define compat_dev_kfree_skb(skb, type) dev_kfree_skb(skb)
+#   if (LINUX_VERSION_CODE < KERNEL_VERSION(2,3,43))
+#      define compat_dev_kfree_skb_any(skb, type) dev_kfree_skb(skb)
+#      define compat_dev_kfree_skb_irq(skb, type) dev_kfree_skb(skb)
+#   else
+#      define compat_dev_kfree_skb_any(skb, type) dev_kfree_skb_any(skb)
+#      define compat_dev_kfree_skb_irq(skb, type) dev_kfree_skb_irq(skb)
+#   endif
+#endif
+
+#ifndef NET_IP_ALIGN
+#   define COMPAT_NET_IP_ALIGN  2
+#else
+#   define COMPAT_NET_IP_ALIGN  NET_IP_ALIGN 
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 4, 4)
+#   define compat_skb_headlen(skb)         skb_headlen(skb)
+#   define compat_pskb_may_pull(skb, len)  pskb_may_pull(skb, len)
+#else
+#   define compat_skb_headlen(skb)         (skb)->len
+#   define compat_pskb_may_pull(skb, len)  1
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 12)
+#   define compat_skb_header_cloned(skb)   skb_header_cloned(skb)
+#else
+#   define compat_skb_header_cloned(skb)   0
+#endif
+#endif /* __COMPAT_SKBUFF_H__ */
--- kernel/linux-2.6.26.3/drivers/net/vmxnet/compat_slab.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/net/vmxnet/compat_slab.h	2008-09-03 10:07:45.000000000 -0500
@@ -0,0 +1,85 @@
+/*********************************************************
+ * Copyright (C) 2005 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_SLAB_H__
+#   define __COMPAT_SLAB_H__
+
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 2, 0)
+#   include <linux/slab.h>
+#else
+#   include <linux/malloc.h>
+#endif
+
+/*
+ * Before 2.6.20, kmem_cache_t was the accepted way to refer to a kmem_cache
+ * structure.  Prior to 2.6.15, this structure was called kmem_cache_s, and
+ * afterwards it was renamed to kmem_cache.  Here we keep things simple and use
+ * the accepted typedef until it became deprecated, at which point we switch
+ * over to the kmem_cache name.
+ */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 20)
+#   define compat_kmem_cache struct kmem_cache
+#else
+#   define compat_kmem_cache kmem_cache_t
+#endif
+
+/*
+ * Up to 2.6.22 kmem_cache_create has 6 arguments - name, size, alignment, flags,
+ * constructor, and destructor.  Then for some time kernel was asserting that
+ * destructor is NULL, and since 2.6.23-pre1 kmem_cache_create takes only 5
+ * arguments - destructor is gone.
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 22) || defined(VMW_KMEMCR_HAS_DTOR)
+#define compat_kmem_cache_create(name, size, align, flags, ctor) \
+		kmem_cache_create(name, size, align, flags, ctor, NULL)
+#else
+#define compat_kmem_cache_create(name, size, align, flags, ctor) \
+		kmem_cache_create(name, size, align, flags, ctor)
+#endif
+
+/*
+ * Up to 2.6.23 kmem_cache constructor has three arguments - pointer to block to
+ * prepare (aka "this"), from which cache it came, and some unused flags.  After
+ * 2.6.23 flags were removed, and order of "this" and cache parameters was swapped...
+ * Since 2.6.27-rc2 everything is different again, and ctor has only one argument.
+ *
+ * HAS_3_ARGS has precedence over HAS_2_ARGS if both are defined.
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 23) && !defined(VMW_KMEMCR_CTOR_HAS_3_ARGS)
+#  define VMW_KMEMCR_CTOR_HAS_3_ARGS
+#endif
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 26) && !defined(VMW_KMEMCR_CTOR_HAS_2_ARGS)
+#  define VMW_KMEMCR_CTOR_HAS_2_ARGS
+#endif
+
+#if defined(VMW_KMEMCR_CTOR_HAS_3_ARGS)
+typedef void compat_kmem_cache_ctor(void *, compat_kmem_cache *, unsigned long);
+#define COMPAT_KMEM_CACHE_CTOR_ARGS(arg) void *arg, \
+                                         compat_kmem_cache *cache, \
+                                         unsigned long flags
+#elif defined(VMW_KMEMCR_CTOR_HAS_2_ARGS)
+typedef void compat_kmem_cache_ctor(compat_kmem_cache *, void *);
+#define COMPAT_KMEM_CACHE_CTOR_ARGS(arg) compat_kmem_cache *cache, \
+                                         void *arg
+#else
+typedef void compat_kmem_cache_ctor(void *);
+#define COMPAT_KMEM_CACHE_CTOR_ARGS(arg) void *arg
+#endif
+
+#endif /* __COMPAT_SLAB_H__ */
--- kernel/linux-2.6.26.3/drivers/net/vmxnet/compat_spinlock.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/net/vmxnet/compat_spinlock.h	2008-09-03 10:07:45.000000000 -0500
@@ -0,0 +1,68 @@
+/*********************************************************
+ * Copyright (C) 2005 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_SPINLOCK_H__
+#   define __COMPAT_SPINLOCK_H__
+
+
+/*
+ * The spin_lock() API appeared in 2.1.25 in asm/smp_lock.h
+ * It moved in 2.1.30 to asm/spinlock.h
+ * It moved again in 2.3.18 to linux/spinlock.h
+ *
+ *   --hpreg
+ */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 3, 18)
+#   include <linux/spinlock.h>
+#else
+#   if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 1, 30)
+#      include <asm/spinlock.h>
+#   else
+typedef struct {} spinlock_t;
+#      define spin_lock_init(lock)
+#      define spin_lock(lock)
+#      define spin_unlock(lock)
+#      define spin_lock_irqsave(lock, flags) do {      \
+                    save_flags(flags);                 \
+                    cli();                             \
+                    spin_lock(lock);                   \
+                 } while (0)
+#      define spin_unlock_irqrestore(lock, flags) do { \
+                    spin_unlock(lock);                 \
+                    restore_flags(flags);              \
+                 } while (0)
+#   endif
+#endif
+
+
+/*
+ * Preempt support was added during 2.5.x development cycle, and later
+ * it was backported to 2.4.x.  In 2.4.x backport these definitions
+ * live in linux/spinlock.h, that's why we put them here (in 2.6.x they
+ * are defined in linux/preempt.h which is included by linux/spinlock.h).
+ */
+#ifdef CONFIG_PREEMPT
+#define compat_preempt_disable() preempt_disable()
+#define compat_preempt_enable()  preempt_enable()
+#else
+#define compat_preempt_disable() do { } while (0)
+#define compat_preempt_enable()  do { } while (0)
+#endif
+
+
+#endif /* __COMPAT_SPINLOCK_H__ */
--- kernel/linux-2.6.26.3/drivers/net/vmxnet/compat_timer.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/net/vmxnet/compat_timer.h	2008-09-03 10:07:45.000000000 -0500
@@ -0,0 +1,103 @@
+/*********************************************************
+ * Copyright (C) 2002 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_TIMER_H__
+#   define __COMPAT_TIMER_H__
+
+
+/*
+ * The del_timer_sync() API appeared in 2.3.43
+ * It became reliable in 2.4.0-test3
+ *
+ *   --hpreg
+ */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 4, 0)
+#   define compat_del_timer_sync(timer) del_timer_sync(timer)
+#else
+#   if LINUX_VERSION_CODE < KERNEL_VERSION(2, 3, 43)
+       /* 2.3.43 removed asm/softirq.h's reference to bh_base. */
+#      include <linux/interrupt.h>
+#   endif
+#   include <asm/softirq.h>
+
+static inline int
+compat_del_timer_sync(struct timer_list *timer) // IN
+{
+   int wasPending;
+
+   start_bh_atomic();
+   wasPending = del_timer(timer);
+   end_bh_atomic();
+
+   return wasPending;
+}
+#endif
+
+
+/*
+ * The msleep_interruptible() API appeared in 2.6.9.
+ * It is based on the msleep() API, which appeared in 2.4.29.
+ */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 9)
+#   include <linux/delay.h>
+#   define compat_msleep_interruptible(msecs) msleep_interruptible(msecs)
+#   define compat_msleep(msecs) msleep(msecs)
+#else
+#   include <linux/sched.h>
+/* 
+ * msecs_to_jiffies appeared in 2.6.7.  For earlier kernels,
+ * fall back to slow-case code (we don't use this operation
+ * enough to need the performance).
+ */
+#   if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 7)
+#      define msecs_to_jiffies(msecs) (((msecs) * HZ + 999) / 1000)
+#   endif
+/*
+ * set_current_state appeared in 2.2.18.
+ */
+#   if LINUX_VERSION_CODE < KERNEL_VERSION(2, 2, 18)
+#      define set_current_state(a) do { current->state = (a); } while(0)
+#   endif
+
+static inline void
+compat_msleep_interruptible(unsigned long msecs) // IN
+{
+   set_current_state(TASK_INTERRUPTIBLE);
+   schedule_timeout(msecs_to_jiffies(msecs) + 1);
+}
+
+static inline void
+compat_msleep(unsigned long msecs) // IN
+{
+   set_current_state(TASK_UNINTERRUPTIBLE);
+   schedule_timeout(msecs_to_jiffies(msecs) + 1);
+}
+#endif
+
+
+/*
+ * There is init_timer_deferrable() since 2.6.22.
+ */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 22)
+#   define compat_init_timer_deferrable(timer) init_timer_deferrable(timer)
+#else
+#   define compat_init_timer_deferrable(timer) init_timer(timer)
+#endif
+
+
+#endif /* __COMPAT_TIMER_H__ */
--- kernel/linux-2.6.26.3/drivers/net/vmxnet/compat_version.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/net/vmxnet/compat_version.h	2008-09-03 10:07:45.000000000 -0500
@@ -0,0 +1,121 @@
+/*********************************************************
+ * Copyright (C) 1998 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_VERSION_H__
+#   define __COMPAT_VERSION_H__
+
+#define INCLUDE_ALLOW_VMMON
+#define INCLUDE_ALLOW_MODULE
+#define INCLUDE_ALLOW_VMCORE
+#define INCLUDE_ALLOW_VMNIXMOD
+#define INCLUDE_ALLOW_DISTRIBUTE
+#include "includeCheck.h"
+
+
+#ifndef __linux__
+#   error "linux-version.h"
+#endif
+
+
+#include <linux/version.h>
+
+/* Appeared in 2.1.90 --hpreg */
+#ifndef KERNEL_VERSION
+#   define KERNEL_VERSION(a, b, c) (((a) << 16) + ((b) << 8) + (c))
+#endif
+
+
+/*
+ * Distinguish relevant classes of Linux kernels.
+ *
+ * The convention is that version X defines all
+ * the KERNEL_Y symbols where Y <= X.
+ *
+ * XXX Do not add more definitions here. This way of doing things does not
+ *     scale, and we are going to phase it out soon --hpreg
+ */
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 1, 0)
+#   define KERNEL_2_1
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 2, 0)
+#   define KERNEL_2_2
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 3, 1)
+#   define KERNEL_2_3_1
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 3, 15)
+/*   new networking */
+#   define KERNEL_2_3_15
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 3, 25)
+/*  new procfs */
+#   define KERNEL_2_3_25
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 3, 29)
+/*  even newer procfs */
+#   define KERNEL_2_3_29
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 3, 43)
+/*  softnet changes */
+#   define KERNEL_2_3_43
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 3, 47)
+/*  more softnet changes */
+#   define KERNEL_2_3_47
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 3, 99)
+/*  name in netdevice struct is array and not pointer */
+#   define KERNEL_2_3_99
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 4, 0)
+/*  New 'owner' member at the beginning of struct file_operations */
+#      define KERNEL_2_4_0
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 4, 8)
+/*  New netif_rx_ni() --hpreg */
+#   define KERNEL_2_4_8
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 4, 22)
+/*  New vmap() */
+#   define KERNEL_2_4_22
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 5, 2)
+/*  New kdev_t, major()/minor() API --hpreg */
+#   define KERNEL_2_5_2
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 5, 5)
+/*  New sk_alloc(), pte_offset_map()/pte_unmap() --hpreg */
+#   define KERNEL_2_5_5
+#endif
+
+
+#endif /* __COMPAT_VERSION_H__ */
--- kernel/linux-2.6.26.3/drivers/net/vmxnet/COPYING	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/net/vmxnet/COPYING	2008-09-03 09:57:35.000000000 -0500
@@ -0,0 +1,339 @@
+		    GNU GENERAL PUBLIC LICENSE
+		       Version 2, June 1991
+
+ Copyright (C) 1989, 1991 Free Software Foundation, Inc.,
+ 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ Everyone is permitted to copy and distribute verbatim copies
+ of this license document, but changing it is not allowed.
+
+			    Preamble
+
+  The licenses for most software are designed to take away your
+freedom to share and change it.  By contrast, the GNU General Public
+License is intended to guarantee your freedom to share and change free
+software--to make sure the software is free for all its users.  This
+General Public License applies to most of the Free Software
+Foundation's software and to any other program whose authors commit to
+using it.  (Some other Free Software Foundation software is covered by
+the GNU Lesser General Public License instead.)  You can apply it to
+your programs, too.
+
+  When we speak of free software, we are referring to freedom, not
+price.  Our General Public Licenses are designed to make sure that you
+have the freedom to distribute copies of free software (and charge for
+this service if you wish), that you receive source code or can get it
+if you want it, that you can change the software or use pieces of it
+in new free programs; and that you know you can do these things.
+
+  To protect your rights, we need to make restrictions that forbid
+anyone to deny you these rights or to ask you to surrender the rights.
+These restrictions translate to certain responsibilities for you if you
+distribute copies of the software, or if you modify it.
+
+  For example, if you distribute copies of such a program, whether
+gratis or for a fee, you must give the recipients all the rights that
+you have.  You must make sure that they, too, receive or can get the
+source code.  And you must show them these terms so they know their
+rights.
+
+  We protect your rights with two steps: (1) copyright the software, and
+(2) offer you this license which gives you legal permission to copy,
+distribute and/or modify the software.
+
+  Also, for each author's protection and ours, we want to make certain
+that everyone understands that there is no warranty for this free
+software.  If the software is modified by someone else and passed on, we
+want its recipients to know that what they have is not the original, so
+that any problems introduced by others will not reflect on the original
+authors' reputations.
+
+  Finally, any free program is threatened constantly by software
+patents.  We wish to avoid the danger that redistributors of a free
+program will individually obtain patent licenses, in effect making the
+program proprietary.  To prevent this, we have made it clear that any
+patent must be licensed for everyone's free use or not licensed at all.
+
+  The precise terms and conditions for copying, distribution and
+modification follow.
+
+		    GNU GENERAL PUBLIC LICENSE
+   TERMS AND CONDITIONS FOR COPYING, DISTRIBUTION AND MODIFICATION
+
+  0. This License applies to any program or other work which contains
+a notice placed by the copyright holder saying it may be distributed
+under the terms of this General Public License.  The "Program", below,
+refers to any such program or work, and a "work based on the Program"
+means either the Program or any derivative work under copyright law:
+that is to say, a work containing the Program or a portion of it,
+either verbatim or with modifications and/or translated into another
+language.  (Hereinafter, translation is included without limitation in
+the term "modification".)  Each licensee is addressed as "you".
+
+Activities other than copying, distribution and modification are not
+covered by this License; they are outside its scope.  The act of
+running the Program is not restricted, and the output from the Program
+is covered only if its contents constitute a work based on the
+Program (independent of having been made by running the Program).
+Whether that is true depends on what the Program does.
+
+  1. You may copy and distribute verbatim copies of the Program's
+source code as you receive it, in any medium, provided that you
+conspicuously and appropriately publish on each copy an appropriate
+copyright notice and disclaimer of warranty; keep intact all the
+notices that refer to this License and to the absence of any warranty;
+and give any other recipients of the Program a copy of this License
+along with the Program.
+
+You may charge a fee for the physical act of transferring a copy, and
+you may at your option offer warranty protection in exchange for a fee.
+
+  2. You may modify your copy or copies of the Program or any portion
+of it, thus forming a work based on the Program, and copy and
+distribute such modifications or work under the terms of Section 1
+above, provided that you also meet all of these conditions:
+
+    a) You must cause the modified files to carry prominent notices
+    stating that you changed the files and the date of any change.
+
+    b) You must cause any work that you distribute or publish, that in
+    whole or in part contains or is derived from the Program or any
+    part thereof, to be licensed as a whole at no charge to all third
+    parties under the terms of this License.
+
+    c) If the modified program normally reads commands interactively
+    when run, you must cause it, when started running for such
+    interactive use in the most ordinary way, to print or display an
+    announcement including an appropriate copyright notice and a
+    notice that there is no warranty (or else, saying that you provide
+    a warranty) and that users may redistribute the program under
+    these conditions, and telling the user how to view a copy of this
+    License.  (Exception: if the Program itself is interactive but
+    does not normally print such an announcement, your work based on
+    the Program is not required to print an announcement.)
+
+These requirements apply to the modified work as a whole.  If
+identifiable sections of that work are not derived from the Program,
+and can be reasonably considered independent and separate works in
+themselves, then this License, and its terms, do not apply to those
+sections when you distribute them as separate works.  But when you
+distribute the same sections as part of a whole which is a work based
+on the Program, the distribution of the whole must be on the terms of
+this License, whose permissions for other licensees extend to the
+entire whole, and thus to each and every part regardless of who wrote it.
+
+Thus, it is not the intent of this section to claim rights or contest
+your rights to work written entirely by you; rather, the intent is to
+exercise the right to control the distribution of derivative or
+collective works based on the Program.
+
+In addition, mere aggregation of another work not based on the Program
+with the Program (or with a work based on the Program) on a volume of
+a storage or distribution medium does not bring the other work under
+the scope of this License.
+
+  3. You may copy and distribute the Program (or a work based on it,
+under Section 2) in object code or executable form under the terms of
+Sections 1 and 2 above provided that you also do one of the following:
+
+    a) Accompany it with the complete corresponding machine-readable
+    source code, which must be distributed under the terms of Sections
+    1 and 2 above on a medium customarily used for software interchange; or,
+
+    b) Accompany it with a written offer, valid for at least three
+    years, to give any third party, for a charge no more than your
+    cost of physically performing source distribution, a complete
+    machine-readable copy of the corresponding source code, to be
+    distributed under the terms of Sections 1 and 2 above on a medium
+    customarily used for software interchange; or,
+
+    c) Accompany it with the information you received as to the offer
+    to distribute corresponding source code.  (This alternative is
+    allowed only for noncommercial distribution and only if you
+    received the program in object code or executable form with such
+    an offer, in accord with Subsection b above.)
+
+The source code for a work means the preferred form of the work for
+making modifications to it.  For an executable work, complete source
+code means all the source code for all modules it contains, plus any
+associated interface definition files, plus the scripts used to
+control compilation and installation of the executable.  However, as a
+special exception, the source code distributed need not include
+anything that is normally distributed (in either source or binary
+form) with the major components (compiler, kernel, and so on) of the
+operating system on which the executable runs, unless that component
+itself accompanies the executable.
+
+If distribution of executable or object code is made by offering
+access to copy from a designated place, then offering equivalent
+access to copy the source code from the same place counts as
+distribution of the source code, even though third parties are not
+compelled to copy the source along with the object code.
+
+  4. You may not copy, modify, sublicense, or distribute the Program
+except as expressly provided under this License.  Any attempt
+otherwise to copy, modify, sublicense or distribute the Program is
+void, and will automatically terminate your rights under this License.
+However, parties who have received copies, or rights, from you under
+this License will not have their licenses terminated so long as such
+parties remain in full compliance.
+
+  5. You are not required to accept this License, since you have not
+signed it.  However, nothing else grants you permission to modify or
+distribute the Program or its derivative works.  These actions are
+prohibited by law if you do not accept this License.  Therefore, by
+modifying or distributing the Program (or any work based on the
+Program), you indicate your acceptance of this License to do so, and
+all its terms and conditions for copying, distributing or modifying
+the Program or works based on it.
+
+  6. Each time you redistribute the Program (or any work based on the
+Program), the recipient automatically receives a license from the
+original licensor to copy, distribute or modify the Program subject to
+these terms and conditions.  You may not impose any further
+restrictions on the recipients' exercise of the rights granted herein.
+You are not responsible for enforcing compliance by third parties to
+this License.
+
+  7. If, as a consequence of a court judgment or allegation of patent
+infringement or for any other reason (not limited to patent issues),
+conditions are imposed on you (whether by court order, agreement or
+otherwise) that contradict the conditions of this License, they do not
+excuse you from the conditions of this License.  If you cannot
+distribute so as to satisfy simultaneously your obligations under this
+License and any other pertinent obligations, then as a consequence you
+may not distribute the Program at all.  For example, if a patent
+license would not permit royalty-free redistribution of the Program by
+all those who receive copies directly or indirectly through you, then
+the only way you could satisfy both it and this License would be to
+refrain entirely from distribution of the Program.
+
+If any portion of this section is held invalid or unenforceable under
+any particular circumstance, the balance of the section is intended to
+apply and the section as a whole is intended to apply in other
+circumstances.
+
+It is not the purpose of this section to induce you to infringe any
+patents or other property right claims or to contest validity of any
+such claims; this section has the sole purpose of protecting the
+integrity of the free software distribution system, which is
+implemented by public license practices.  Many people have made
+generous contributions to the wide range of software distributed
+through that system in reliance on consistent application of that
+system; it is up to the author/donor to decide if he or she is willing
+to distribute software through any other system and a licensee cannot
+impose that choice.
+
+This section is intended to make thoroughly clear what is believed to
+be a consequence of the rest of this License.
+
+  8. If the distribution and/or use of the Program is restricted in
+certain countries either by patents or by copyrighted interfaces, the
+original copyright holder who places the Program under this License
+may add an explicit geographical distribution limitation excluding
+those countries, so that distribution is permitted only in or among
+countries not thus excluded.  In such case, this License incorporates
+the limitation as if written in the body of this License.
+
+  9. The Free Software Foundation may publish revised and/or new versions
+of the General Public License from time to time.  Such new versions will
+be similar in spirit to the present version, but may differ in detail to
+address new problems or concerns.
+
+Each version is given a distinguishing version number.  If the Program
+specifies a version number of this License which applies to it and "any
+later version", you have the option of following the terms and conditions
+either of that version or of any later version published by the Free
+Software Foundation.  If the Program does not specify a version number of
+this License, you may choose any version ever published by the Free Software
+Foundation.
+
+  10. If you wish to incorporate parts of the Program into other free
+programs whose distribution conditions are different, write to the author
+to ask for permission.  For software which is copyrighted by the Free
+Software Foundation, write to the Free Software Foundation; we sometimes
+make exceptions for this.  Our decision will be guided by the two goals
+of preserving the free status of all derivatives of our free software and
+of promoting the sharing and reuse of software generally.
+
+			    NO WARRANTY
+
+  11. BECAUSE THE PROGRAM IS LICENSED FREE OF CHARGE, THERE IS NO WARRANTY
+FOR THE PROGRAM, TO THE EXTENT PERMITTED BY APPLICABLE LAW.  EXCEPT WHEN
+OTHERWISE STATED IN WRITING THE COPYRIGHT HOLDERS AND/OR OTHER PARTIES
+PROVIDE THE PROGRAM "AS IS" WITHOUT WARRANTY OF ANY KIND, EITHER EXPRESSED
+OR IMPLIED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
+MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE.  THE ENTIRE RISK AS
+TO THE QUALITY AND PERFORMANCE OF THE PROGRAM IS WITH YOU.  SHOULD THE
+PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF ALL NECESSARY SERVICING,
+REPAIR OR CORRECTION.
+
+  12. IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING
+WILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MAY MODIFY AND/OR
+REDISTRIBUTE THE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES,
+INCLUDING ANY GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING
+OUT OF THE USE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED
+TO LOSS OF DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY
+YOU OR THIRD PARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER
+PROGRAMS), EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE
+POSSIBILITY OF SUCH DAMAGES.
+
+		     END OF TERMS AND CONDITIONS
+
+	    How to Apply These Terms to Your New Programs
+
+  If you develop a new program, and you want it to be of the greatest
+possible use to the public, the best way to achieve this is to make it
+free software which everyone can redistribute and change under these terms.
+
+  To do so, attach the following notices to the program.  It is safest
+to attach them to the start of each source file to most effectively
+convey the exclusion of warranty; and each file should have at least
+the "copyright" line and a pointer to where the full notice is found.
+
+    <one line to give the program's name and a brief idea of what it does.>
+    Copyright (C) <year>  <name of author>
+
+    This program is free software; you can redistribute it and/or modify
+    it under the terms of the GNU General Public License as published by
+    the Free Software Foundation; either version 2 of the License, or
+    (at your option) any later version.
+
+    This program is distributed in the hope that it will be useful,
+    but WITHOUT ANY WARRANTY; without even the implied warranty of
+    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+    GNU General Public License for more details.
+
+    You should have received a copy of the GNU General Public License along
+    with this program; if not, write to the Free Software Foundation, Inc.,
+    51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA.
+
+Also add information on how to contact you by electronic and paper mail.
+
+If the program is interactive, make it output a short notice like this
+when it starts in an interactive mode:
+
+    Gnomovision version 69, Copyright (C) year name of author
+    Gnomovision comes with ABSOLUTELY NO WARRANTY; for details type `show w'.
+    This is free software, and you are welcome to redistribute it
+    under certain conditions; type `show c' for details.
+
+The hypothetical commands `show w' and `show c' should show the appropriate
+parts of the General Public License.  Of course, the commands you use may
+be called something other than `show w' and `show c'; they could even be
+mouse-clicks or menu items--whatever suits your program.
+
+You should also get your employer (if you work as a programmer) or your
+school, if any, to sign a "copyright disclaimer" for the program, if
+necessary.  Here is a sample; alter the names:
+
+  Yoyodyne, Inc., hereby disclaims all copyright interest in the program
+  `Gnomovision' (which makes passes at compilers) written by James Hacker.
+
+  <signature of Ty Coon>, 1 April 1989
+  Ty Coon, President of Vice
+
+This General Public License does not permit incorporating your program into
+proprietary programs.  If your program is a subroutine library, you may
+consider it more useful to permit linking proprietary applications with the
+library.  If this is what you want to do, use the GNU Lesser General
+Public License instead of this License.
--- kernel/linux-2.6.26.3/drivers/net/vmxnet/driver-config.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/net/vmxnet/driver-config.h	2008-09-03 10:07:45.000000000 -0500
@@ -0,0 +1,78 @@
+/*********************************************************
+ * Copyright (C) 1998 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * Sets the proper defines from the Linux header files
+ *
+ * This file must be included before the inclusion of any kernel header file,
+ * with the exception of linux/autoconf.h and linux/version.h --hpreg
+ */
+
+#ifndef __VMX_CONFIG_H__
+#define __VMX_CONFIG_H__
+
+#define INCLUDE_ALLOW_VMCORE
+#define INCLUDE_ALLOW_VMMON
+#define INCLUDE_ALLOW_MODULE
+#define INCLUDE_ALLOW_VMNIXMOD
+#include "includeCheck.h"
+
+#include <linux/autoconf.h>
+#include "compat_version.h"
+
+/*
+ * We rely on Kernel Module support.  Check here.
+ */
+#ifndef CONFIG_MODULES
+#   error "No Module support in this kernel.  Please configure with CONFIG_MODULES"
+#endif
+
+/*
+ * 2.2 kernels still use __SMP__ (derived from CONFIG_SMP
+ * in the main Makefile), so we do it here.
+ */
+
+#ifdef CONFIG_SMP
+#   define __SMP__ 1
+#endif
+
+#if defined(CONFIG_MODVERSIONS) && defined(KERNEL_2_1)
+#   if LINUX_VERSION_CODE < KERNEL_VERSION(2,5,60)
+/*
+ * MODVERSIONS might be already defined when using kernel's Makefiles.
+ */
+#      ifndef MODVERSIONS
+#         define MODVERSIONS
+#      endif
+#      include <linux/modversions.h>
+#   endif
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 24)
+/*
+ * Force the uintptr_t definition to come from linux/types.h instead of vm_basic_types.h.
+ */
+#   include <linux/types.h>
+#   define _STDINT_H 1
+#endif
+
+#ifndef __KERNEL__
+#   define __KERNEL__
+#endif
+
+#endif
--- kernel/linux-2.6.26.3/drivers/net/vmxnet/includeCheck.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/net/vmxnet/includeCheck.h	2008-09-03 10:07:45.000000000 -0500
@@ -0,0 +1,132 @@
+/*********************************************************
+ * Copyright (C) 1998 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * includeCheck.h --
+ *
+ *	Restrict include file use.
+ *
+ * In every .h file, define one or more of these
+ *
+ *	INCLUDE_ALLOW_VMX 
+ *	INCLUDE_ALLOW_USERLEVEL 
+ *	INCLUDE_ALLOW_VMMEXT
+ *	INCLUDE_ALLOW_VMCORE
+ *	INCLUDE_ALLOW_MODULE
+ *      INCLUDE_ALLOW_VMNIXMOD 
+ *	INCLUDE_ALLOW_VMKERNEL 
+ *	INCLUDE_ALLOW_DISTRIBUTE
+ *	INCLUDE_ALLOW_VMK_MODULE
+ *      INCLUDE_ALLOW_VMKDRIVERS
+ *      INCLUDE_ALLOW_VMIROM
+ *
+ * Then include this file.
+ *
+ * Any file that has INCLUDE_ALLOW_DISTRIBUTE defined will potentially
+ * be distributed in source form along with GPLed code.  Ensure
+ * that this is acceptable.
+ */
+
+
+/*
+ * Declare a VMCORE-only variable to help classify object
+ * files.  The variable goes in the common block and does
+ * not create multiple definition link-time conflicts.
+ */
+
+#if defined VMCORE && defined VMX86_DEVEL && defined VMX86_DEBUG && \
+    defined linux && !defined MODULE && \
+    !defined COMPILED_WITH_VMCORE
+#define COMPILED_WITH_VMCORE compiled_with_vmcore
+#ifdef ASM
+        .comm   compiled_with_vmcore, 0
+#else
+        asm(".comm compiled_with_vmcore, 0");
+#endif /* ASM */
+#endif
+
+
+#if defined VMCORE && \
+    !(defined VMX86_VMX || defined VMM || \
+      defined MONITOR_APP || defined VMMON)
+#error "Makefile problem: VMCORE without VMX86_VMX or \
+        VMM or MONITOR_APP or MODULE."
+#endif
+
+#if defined VMCORE && !defined INCLUDE_ALLOW_VMCORE
+#error "The surrounding include file is not allowed in vmcore."
+#endif
+#undef INCLUDE_ALLOW_VMCORE
+
+#if defined VMX86_VMX && !defined VMCORE && \
+    !(defined INCLUDE_ALLOW_VMX || defined INCLUDE_ALLOW_USERLEVEL)
+#error "The surrounding include file is not allowed in the VMX."
+#endif
+#undef INCLUDE_ALLOW_VMX
+
+#if defined USERLEVEL && !defined VMX86_VMX && !defined VMCORE && \
+    !defined INCLUDE_ALLOW_USERLEVEL
+#error "The surrounding include file is not allowed at userlevel."
+#endif
+#undef INCLUDE_ALLOW_USERLEVEL
+
+#if defined VMM && !defined VMCORE && \
+    !defined INCLUDE_ALLOW_VMMEXT
+#error "The surrounding include file is not allowed in the monitor."
+#endif
+#undef INCLUDE_ALLOW_VMMEXT
+
+#if defined MODULE && !defined VMKERNEL_MODULE && !defined VMNIXMOD && \
+    !defined VMMON && !defined INCLUDE_ALLOW_MODULE
+#error "The surrounding include file is not allowed in driver modules."
+#endif
+#undef INCLUDE_ALLOW_MODULE
+
+#if defined VMMON && !defined INCLUDE_ALLOW_VMMON
+#error "The surrounding include file is not allowed in vmmon."
+#endif
+#undef INCLUDE_ALLOW_VMMON
+
+#if defined VMKERNEL && !defined INCLUDE_ALLOW_VMKERNEL
+#error "The surrounding include file is not allowed in the vmkernel."
+#endif
+#undef INCLUDE_ALLOW_VMKERNEL
+
+#if defined GPLED_CODE && !defined INCLUDE_ALLOW_DISTRIBUTE
+#error "The surrounding include file is not allowed in GPL code."
+#endif
+#undef INCLUDE_ALLOW_DISTRIBUTE
+
+#if defined VMKERNEL_MODULE && !defined VMKERNEL && \
+    !defined INCLUDE_ALLOW_VMK_MODULE && !defined INCLUDE_ALLOW_VMKDRIVERS
+#error "The surrounding include file is not allowed in vmkernel modules."
+#endif
+#undef INCLUDE_ALLOW_VMK_MODULE
+#undef INCLUDE_ALLOW_VMKDRIVERS
+
+#if defined VMNIXMOD && !defined INCLUDE_ALLOW_VMNIXMOD
+#ifndef VMNIXMOD_VM
+#error "The surrounding include file is not allowed in vmnixmod."
+#endif
+#endif
+#undef INCLUDE_ALLOW_VMNIXMOD
+
+#if defined VMIROM && ! defined INCLUDE_ALLOW_VMIROM
+#error "The surrounding include file is not allowed in vmirom."
+#endif
+#undef INCLUDE_ALLOW_VMIROM
--- kernel/linux-2.6.26.3/drivers/net/vmxnet/Makefile	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/net/vmxnet/Makefile	2008-09-03 09:57:35.000000000 -0500
@@ -0,0 +1,25 @@
+#############################################################
+# Copyright 1998 VMware, Inc.  All rights reserved. 
+#############################################################
+####
+#### This program is free software; you can redistribute it and/or modify it
+#### under the terms of the GNU General Public License as published by the
+#### Free Software Foundation version 2 and no later version.
+####
+#### This program is distributed in the hope that it will be useful, but
+#### WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+#### or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+#### for more details.
+####
+#### You should have received a copy of the GNU General Public License along
+#### with this program; if not, write to the Free Software Foundation, Inc.,
+#### 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+
+####
+####  VMware vmxnet Makefile to be distributed externally
+####
+####
+
+obj-m += vmxnet.o
+
+EXTRA_CFLAGS += -DVMW_USING_KBUILD -DVMW_SKB_LINEARIZE_2618
--- kernel/linux-2.6.26.3/drivers/net/vmxnet/net_dist.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/net/vmxnet/net_dist.h	2008-09-03 09:57:35.000000000 -0500
@@ -0,0 +1,102 @@
+/*********************************************************
+ * Copyright (C) 2004 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * net_dist.h --
+ *
+ *      Networking headers.
+ */
+
+#ifndef _NET_DIST_H_
+#define _NET_DIST_H_
+
+#define INCLUDE_ALLOW_MODULE
+#define INCLUDE_ALLOW_VMNIXMOD
+#define INCLUDE_ALLOW_VMKERNEL
+#define INCLUDE_ALLOW_VMK_MODULE
+#define INCLUDE_ALLOW_VMMEXT
+#define INCLUDE_ALLOW_USERLEVEL
+#define INCLUDE_ALLOW_DISTRIBUTE
+#include "includeCheck.h"
+#include "vmkapi_types.h"
+
+typedef struct PktHandle   vmk_PktHandle;
+typedef vmk_uint32         vmk_NetPortID;
+typedef vmk_uint16         vmk_VlanID;
+
+typedef vmk_NetPortID Net_PortID;
+typedef vmk_PktHandle PktHandle;
+typedef struct PktList PktList;
+
+/*
+ * Set this to anything, and that value will never be assigned as a 
+ * PortID for a valid port, but will be assigned in most error cases.
+ */
+#define NET_INVALID_PORT_ID      0
+
+/*
+ * Set this to the largest size of private implementation data expected
+ * to be embedded in a pkt by device driver wrapper modules
+ * (e.g. sizeof(esskaybee_or_whatever))
+ */
+#ifdef VM_X86_64
+
+#define NET_MAX_IMPL_PKT_OVHD   (616)
+#else
+#define NET_MAX_IMPL_PKT_OVHD   (436)
+#endif
+
+/*
+ * Set this to the largest alignment requirements made by various driver
+ * wrappers. Unfortunately linux guarantees space for 16 byte alignment
+ * from the drivers, although most drivers don't use it (none?).
+ */
+#define NET_MAX_IMPL_ALIGN_OVHD (16)
+
+/*
+ * Set this to the size of the largest object that a driver will embed in
+ * the buffer aside from the frame data, currently the e100 has a 32 byte
+ * struct that it puts there.
+ */ 
+#define NET_MAX_DRV_PKT_OVHD    (32) 
+
+/*
+ * Set this to the largest alignment overhead connsumed by the various
+ * drivers for alignment purposes.  Many of the drivers want an extra 
+ * 2 bytes for aligning iphdr, and the 3c90x wants 64 byte aligned dma.
+ */
+#define NET_MAX_DRV_ALIGN_OVHD  (64+2)
+
+/*
+ * Portset event API.  Callers who register for these events will
+ * recieve asynchronus notification whenever an event occurs.
+ */
+typedef enum {
+   PORTSET_EVENT_PORT_CONNECT     = 0x00000001,
+   PORTSET_EVENT_PORT_DISCONNECT  = 0x00000002,
+   PORTSET_EVENT_PORT_BLOCK       = 0x00000004,
+   PORTSET_EVENT_PORT_UNBLOCK     = 0x00000008,
+   PORTSET_EVENT_PORT_L2ADDR      = 0x00000010,
+   PORTSET_EVENT_PORT_ENABLE      = 0x00000020,
+   PORTSET_EVENT_PORT_DISABLE     = 0x00000040,
+   PORTSET_EVENT_MASK_ALL         = 0x0000007f
+} PortsetEventID;
+
+typedef void (*PortsetEventCB)  (Net_PortID, PortsetEventID, void *);
+
+#endif
--- kernel/linux-2.6.26.3/drivers/net/vmxnet/net.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/net/vmxnet/net.h	2008-09-03 10:07:45.000000000 -0500
@@ -0,0 +1,136 @@
+/*********************************************************
+ * Copyright (C) 1998 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/************************************************************
+ *
+ *   net.h
+ *
+ *   This file should contain all network global defines.
+ *   No vlance/vmxnet/vnet/vmknet specific stuff should be
+ *   put here only defines used/usable by all network code.
+ *   --gustav
+ *
+ ************************************************************/
+
+#ifndef VMWARE_DEVICES_NET_H
+#define VMWARE_DEVICES_NET_H
+
+#define INCLUDE_ALLOW_USERLEVEL
+#define INCLUDE_ALLOW_MODULE
+#define INCLUDE_ALLOW_VMMEXT
+#include "includeCheck.h"
+#include "vm_device_version.h"
+
+#define ETHERNET_MTU         1518
+#define ETH_MIN_FRAME_LEN      60
+
+#ifndef ETHER_ADDR_LEN
+#define ETHER_ADDR_LEN          6  /* length of MAC address */
+#endif
+#define ETH_HEADER_LEN	       14  /* length of Ethernet header */
+#define IP_ADDR_LEN	        4  /* length of IPv4 address */
+#define IP_HEADER_LEN	       20  /* minimum length of IPv4 header */
+
+#define ETHER_MAX_QUEUED_PACKET 1600
+
+
+/*
+ * State's that a NIC can be in currently we only use this
+ * in VLance but if we implement/emulate new adapters that
+ * we also want to be able to morph a new corresponding
+ * state should be added.
+ */
+
+#define LANCE_CHIP  0x2934
+#define VMXNET_CHIP 0x4392
+
+/*
+ * Size of reserved IO space needed by the LANCE adapter and
+ * the VMXNET adapter. If you add more ports to Vmxnet than
+ * there is reserved space you must bump VMXNET_CHIP_IO_RESV_SIZE.
+ * The sizes must be powers of 2.
+ */
+
+#define LANCE_CHIP_IO_RESV_SIZE  0x20
+#define VMXNET_CHIP_IO_RESV_SIZE 0x40
+
+#define MORPH_PORT_SIZE 4
+
+
+#ifdef USERLEVEL
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * Net_AddAddrToLADRF --
+ *
+ *      Given a MAC address, sets the corresponding bit in the LANCE style
+ *      Logical Address Filter 'ladrf'.
+ *      The caller should have initialized the ladrf to all 0's, as this
+ *      function only ORs on a bit in the array.
+ *      'addr' is presumed to be ETHER_ADDR_LEN in size;
+ *      'ladrf' is presumed to point to a 64-bit vector.
+ *
+ *      Derived from a long history of derivations, originally inspired by
+ *      sample code from the AMD "Network Products: Ethernet Controllers 1998
+ *      Data Book, Book 2", pages 1-53..1-55.
+ *
+ * Returns:
+ *      None.
+ *
+ * Side effects:
+ *      Updates 'ladrf'.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+static INLINE void
+Net_AddAddrToLadrf(const uint8 *addr,  // IN: pointer to MAC address
+                   uint8 *ladrf)       // IN/OUT: pointer to ladrf
+{
+#define CRC_POLYNOMIAL_BE 0x04c11db7UL	/* Ethernet CRC, big endian */
+
+   uint16 hashcode;
+   int32 crc = 0xffffffff;		/* init CRC for each address */
+   int32 j;
+   int32 bit;
+   int32 byte;
+
+   ASSERT(addr);
+   ASSERT(ladrf);
+
+   for (byte = 0; byte < ETHER_ADDR_LEN; byte++) {  /* for each address byte */
+      /* process each address bit */
+      for (bit = *addr++, j = 0;
+           j < 8;
+           j++, bit >>= 1) {
+	 crc = (crc << 1) ^ ((((crc < 0 ? 1 : 0) ^ bit) & 0x01) ?
+               CRC_POLYNOMIAL_BE : 0);
+      }
+   }
+   hashcode = (crc & 1);	       /* hashcode is 6 LSb of CRC ... */
+   for (j = 0; j < 5; j++) {	       /* ... in reverse order. */
+      hashcode = (hashcode << 1) | ((crc>>=1) & 1);
+   }
+
+   ladrf[hashcode >> 3] |= 1 << (hashcode & 0x07);
+}
+
+#endif // USERLEVEL
+
+#endif // VMWARE_DEVICES_NET_H
--- kernel/linux-2.6.26.3/drivers/net/vmxnet/net_sg.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/net/vmxnet/net_sg.h	2008-09-03 10:07:45.000000000 -0500
@@ -0,0 +1,73 @@
+/*********************************************************
+ * Copyright (C) 2000 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * net_sg.h --
+ *
+ *	Network packet scatter gather structure.
+ */
+
+
+#ifndef _NET_SG_H
+#define _NET_SG_H
+
+#define INCLUDE_ALLOW_USERLEVEL
+#define INCLUDE_ALLOW_VMMEXT
+#define INCLUDE_ALLOW_MODULE
+#define INCLUDE_ALLOW_VMNIXMOD
+#define INCLUDE_ALLOW_VMK_MODULE
+#define INCLUDE_ALLOW_VMKERNEL
+#define INCLUDE_ALLOW_DISTRIBUTE
+#include "includeCheck.h"
+
+#define NET_SG_DEFAULT_LENGTH	16
+
+/*
+ * A single scatter-gather element for a network packet.
+ * The address is split into low and high to save space.
+ * If we make it 64 bits then Windows pads things out such that
+ * we lose a lot of space for each scatter gather array.
+ * This adds up when you have embedded scatter-gather 
+ * arrays for transmit and receive ring buffers.
+ */
+typedef struct NetSG_Elem {
+   uint32 	addrLow;
+   uint16	addrHi;
+   uint16	length;
+} NetSG_Elem;
+
+typedef enum NetSG_AddrType {
+   NET_SG_MACH_ADDR,
+   NET_SG_PHYS_ADDR,
+   NET_SG_VIRT_ADDR,
+   NET_SG_VMM_STACK_OFFSET,
+} NetSG_AddrType;
+
+typedef struct NetSG_Array {
+   uint16	addrType;
+   uint16	length;
+   NetSG_Elem	sg[NET_SG_DEFAULT_LENGTH];
+} NetSG_Array;
+
+#define NET_SG_SIZE(len) (sizeof(NetSG_Array) + (len - NET_SG_DEFAULT_LENGTH) * sizeof(NetSG_Elem))
+
+#define NET_SG_MAKE_PA(elem) (((PA)elem.addrHi << 32) | (PA)elem.addrLow)
+#define NET_SG_MAKE_PTR(elem) \
+             ((char*)(uintptr_t)(((uint64)elem.addrHi << 32) | elem.addrLow))
+
+#endif
--- kernel/linux-2.6.26.3/drivers/net/vmxnet/README	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/net/vmxnet/README	2008-09-03 09:57:35.000000000 -0500
@@ -0,0 +1,11 @@
+The files in this directory are the source files for the VMware
+Virtual Ethernet Adapter driver.  In order to build, make certain the
+Makefile is correct, especially about whether or not your system is
+multi-processor or not, and then just type:
+
+	make
+
+from this directory.  A copy of the module will be left in 'vmxnet.o',
+which can then be installed in /lib/modules/<kernel-name>/net.
+
+If you have any problems or questions, send mail to support@vmware.com
--- kernel/linux-2.6.26.3/drivers/net/vmxnet/return_status.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/net/vmxnet/return_status.h	2008-09-03 09:57:35.000000000 -0500
@@ -0,0 +1,116 @@
+/*********************************************************
+ * Copyright (C) 1998 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * return_status.h --
+ *
+ *      VMkernel return status codes.
+ *
+ */
+
+#ifndef _RETURN_STATUS_H_
+#define _RETURN_STATUS_H_
+
+#define INCLUDE_ALLOW_USERLEVEL
+#define INCLUDE_ALLOW_VMMEXT
+#define INCLUDE_ALLOW_MODULE
+#define INCLUDE_ALLOW_VMNIXMOD
+#define INCLUDE_ALLOW_VMKERNEL
+#define INCLUDE_ALLOW_VMKDRIVERS
+#define INCLUDE_ALLOW_VMK_MODULE
+#define INCLUDE_ALLOW_DISTRIBUTE
+#define INCLUDE_ALLOW_VMCORE
+#include "includeCheck.h"
+
+#include "vmkapi_status.h"
+
+/*
+ * vmkernel error codes and translation to Unix error codes
+ *
+ * The table defined in vmkapi_status.h gives the name, description,
+ * and corresponding Unix error code for each VMK error code.  The
+ * Unix error code is used when a VMK error propagates up to a user
+ * world through the Linux-compatible system call interface and we
+ * need to translate it.
+ *
+ * There is also a mechanism to wrap a Linux error code opaquely
+ * inside a VMK error code.  When the COS proxy generates an error, it
+ * starts out as a Linux error code in a COS process, propagates into
+ * the vmkernel where it needs to be translated to a VMK error code,
+ * and then goes out to a user world where it needs to be a Unix error
+ * code again.  The vmkernel does not have to understand these errors
+ * other than to know that a nonzero value is an error, so we make
+ * them opaque for simplicity.  The COS proxy calls
+ * VMK_WrapLinuxError, which adds the absolute value of (nonzero)
+ * Linux error codes to VMK_GENERIC_LINUX_ERROR.  User_TranslateStatus
+ * undoes this transformation on the way out.
+ *
+ * XXX Currently there is no need to translate VMK error codes to BSD
+ * error codes, but the macros used with this table could be easily
+ * extended to do so.  We do translate BSD error codes to VMK error
+ * codes in vmkernel/networking/lib/support.c, using a case statement.
+ * See PR 35564 for comments on how this could be improved.
+ *
+ * VMK_FAILURE and VMK_GENERIC_LINUX_ERROR must be at the start and
+ * end, and must be defined with specific values using
+ * DEFINE_VMK_ERR_AT; see return_status.c.
+ *
+ * All the values should be positive because we return these directly as
+ * _vmnix call return values (at least for sysinfo).  A negative value
+ * there could get interpretted as a linux error code.
+ *
+ */
+
+#define LINUX_OK   0
+#define FREEBSD_OK 0
+
+/*
+ * operations
+ */
+
+extern const char *VMK_ReturnStatusToString(VMK_ReturnStatus status);
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * VMK_WrapLinuxError --
+ *
+ *      Wrap a Linux errno value inside a VMK_ReturnStatus value.  The
+ *      status value is opaque to the vmkernel, except that 0 (no
+ *      error) is guaranteed to translate to VMK_OK.  This routine is
+ *      for use by the COS proxy to pass errors back through the
+ *      vmkernel to a user world.
+ *
+ *      This is a macro instead of a static inline because
+ *      return_status.h gets #included both from places where "INLINE"
+ *      is not defined and from places where "inline" is wrong.  Ugh.
+ *
+ * Results:
+ *      Opaque VMK_ReturnStatus.
+ *
+ * Side effects:
+ *      None.
+ *
+ *----------------------------------------------------------------------
+ */
+#define VMK_WrapLinuxError(error) \
+   ((error) == 0 ? VMK_OK : \
+    (error) <  0 ? VMK_GENERIC_LINUX_ERROR - (error) : \
+                   VMK_GENERIC_LINUX_ERROR + (error))
+
+#endif
--- kernel/linux-2.6.26.3/drivers/net/vmxnet/vm_basic_types.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/net/vmxnet/vm_basic_types.h	2008-09-03 10:07:45.000000000 -0500
@@ -0,0 +1,866 @@
+/*********************************************************
+ * Copyright (C) 1998-2008 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ *
+ * vm_basic_types.h --
+ *
+ *    basic data types.
+ */
+
+
+#ifndef _VM_BASIC_TYPES_H_
+#define _VM_BASIC_TYPES_H_
+
+#define INCLUDE_ALLOW_USERLEVEL
+#define INCLUDE_ALLOW_VMMEXT
+#define INCLUDE_ALLOW_MODULE
+#define INCLUDE_ALLOW_VMMON
+#define INCLUDE_ALLOW_VMNIXMOD
+#define INCLUDE_ALLOW_VMKERNEL
+#define INCLUDE_ALLOW_VMKDRIVERS
+#define INCLUDE_ALLOW_VMK_MODULE
+#define INCLUDE_ALLOW_DISTRIBUTE
+#define INCLUDE_ALLOW_VMCORE
+#define INCLUDE_ALLOW_VMIROM
+#include "includeCheck.h"
+
+/* STRICT ANSI means the Xserver build and X defines Bool differently. */
+#if !defined(__STRICT_ANSI__) || defined(__FreeBSD__)
+typedef char           Bool;
+#endif
+
+#ifndef FALSE
+#define FALSE          0
+#endif
+
+#ifndef TRUE
+#define TRUE           1
+#endif
+
+#define IsBool(x)      (((x) & ~1) == 0)
+#define IsBool2(x, y)  ((((x) | (y)) & ~1) == 0)
+
+/*
+ * Macros __i386__ and __ia64 are intrinsically defined by GCC
+ */
+#ifdef __i386__
+#define VM_I386
+#endif
+
+#ifdef _WIN64
+#define __x86_64__
+#endif
+
+#ifdef __x86_64__
+#define VM_X86_64
+#define VM_I386
+#define vm_x86_64 (1)
+#else
+#define vm_x86_64 (0)
+#endif
+
+
+
+#ifdef _WIN32
+/* safe assumption for a while */
+#define VM_I386
+#endif
+
+#ifdef _MSC_VER
+typedef unsigned __int64 uint64;
+typedef signed __int64 int64;
+
+#pragma warning (3 :4505) // unreferenced local function
+#pragma warning (disable :4018) // signed/unsigned mismatch
+#pragma warning (disable :4761) // integral size mismatch in argument; conversion supplied
+#pragma warning (disable :4305) // truncation from 'const int' to 'short'
+#pragma warning (disable :4244) // conversion from 'unsigned short' to 'unsigned char'
+#pragma warning (disable :4267) // truncation of 'size_t'
+#pragma warning (disable :4146) // unary minus operator applied to unsigned type, result still unsigned
+#pragma warning (disable :4142) // benign redefinition of type
+
+#elif __GNUC__
+/* The Xserver source compiles with -ansi -pendantic */
+#ifndef __STRICT_ANSI__
+#if defined(VM_X86_64)
+typedef unsigned long uint64;
+typedef long int64;
+#else
+typedef unsigned long long uint64;
+typedef long long int64;
+#endif
+#elif __FreeBSD__
+typedef unsigned long long uint64;
+typedef long long int64;
+#endif
+#else
+#error - Need compiler define for int64/uint64
+#endif
+
+typedef unsigned int       uint32;
+typedef unsigned short     uint16;
+typedef unsigned char      uint8;
+
+typedef int       int32;
+typedef short     int16;
+typedef char      int8;
+
+/*
+ * FreeBSD (for the tools build) unconditionally defines these in
+ * sys/inttypes.h so don't redefine them if this file has already
+ * been included. [greg]
+ *
+ * This applies to Solaris as well.
+ */
+
+/*
+ * Before trying to do the includes based on OS defines, see if we can use
+ * feature-based defines to get as much functionality as possible
+ */
+
+#ifdef HAVE_INTTYPES_H
+#include <inttypes.h>
+#endif
+#ifdef HAVE_SYS_TYPES_H
+#include <sys/types.h>
+#endif
+#ifdef HAVE_SYS_INTTYPES_H
+#include <sys/inttypes.h>
+#endif
+#ifdef HAVE_STDINT_H
+#include <stdint.h>
+#endif
+#ifdef HAVE_STDLIB_H
+#include <stdlib.h>
+#endif
+
+#ifdef __FreeBSD__
+#include <sys/param.h> /* For __FreeBSD_version */         
+#endif
+
+#if !defined(USING_AUTOCONF)
+#   if defined(__FreeBSD__) || defined(sun)
+#      ifdef KLD_MODULE
+#         include <sys/types.h>
+#      else
+#         if !defined(VMKERNEL) && (__FreeBSD_version >= 500043)
+#            include <inttypes.h>
+#            include <sys/types.h>
+#         else
+#            include <sys/inttypes.h>
+#         endif
+#      endif
+#   elif defined __APPLE__
+#      if KERNEL
+#         include <sys/unistd.h>
+#         include <sys/types.h> /* mostly for size_t */
+#         include <stdint.h>
+#      else
+#         include <unistd.h>
+#         include <inttypes.h>
+#         include <stdlib.h>
+#         include <stdint.h>
+#      endif
+#   else
+#      if !defined(__intptr_t_defined) && !defined(intptr_t)
+#         define __intptr_t_defined
+#         define intptr_t  intptr_t
+#         ifdef VM_I386
+#            ifdef VM_X86_64
+typedef int64     intptr_t;
+#            else
+typedef int32     intptr_t;
+#            endif
+#         endif
+#      endif
+
+#      ifndef _STDINT_H
+#         ifdef VM_I386
+#            ifdef VM_X86_64
+typedef uint64    uintptr_t;
+#            else
+typedef uint32    uintptr_t;
+#            endif
+#         endif
+#      endif
+#   endif
+#endif
+
+
+/*
+ * Time
+ * XXX These should be cleaned up.  -- edward
+ */
+
+typedef int64 VmTimeType;          /* Time in microseconds */
+typedef int64 VmTimeRealClock;     /* Real clock kept in microseconds */
+typedef int64 VmTimeVirtualClock;  /* Virtual Clock kept in CPU cycles */
+
+/*
+ * Printf format specifiers for size_t and 64-bit number.
+ * Use them like this:
+ *    printf("%"FMT64"d\n", big);
+ *
+ * FMTH is for handles/fds.
+ */
+
+#ifdef _MSC_VER
+   #define FMT64      "I64"
+   #ifdef VM_X86_64
+      #define FMTSZ      "I64"
+      #define FMTPD      "I64"
+      #define FMTH       "I64"
+   #else
+      #define FMTSZ      "I"
+      #define FMTPD      "I"
+      #define FMTH       "I"
+   #endif
+#elif __GNUC__
+   #define FMTH ""
+   #if defined(N_PLAT_NLM) || defined(sun) || \
+       (defined(__FreeBSD__) && (__FreeBSD__ + 0) && ((__FreeBSD__ + 0) < 5))
+      /*
+       * Why (__FreeBSD__ + 0)?  See bug 141008.
+       * Yes, we really need to test both (__FreeBSD__ + 0) and
+       * ((__FreeBSD__ + 0) < 5).  No, we can't remove "+ 0" from
+       * ((__FreeBSD__ + 0) < 5).
+       */
+      #ifdef VM_X86_64
+         #define FMTSZ  "l"
+         #define FMTPD  "l"
+      #else
+         #define FMTSZ  ""
+         #define FMTPD  ""
+      #endif
+   #elif defined(__linux__) \
+      || (defined(_POSIX_C_SOURCE) && _POSIX_C_SOURCE >= 200112L) \
+      || (defined(_POSIX_VERSION) && _POSIX_VERSION >= 200112L) \
+      || (defined(_POSIX2_VERSION) && _POSIX2_VERSION >= 200112L)
+      /* BSD/Darwin, Linux */
+      #define FMTSZ     "z"
+
+      #ifdef VM_X86_64
+         #define FMTPD  "l"
+      #else
+         #define FMTPD  ""
+      #endif
+   #else
+      /* Systems with a pre-C99 libc */
+      #define FMTSZ     "Z"
+      #ifdef VM_X86_64
+         #define FMTPD  "l"
+      #else
+         #define FMTPD  ""
+      #endif
+   #endif
+   #ifdef VM_X86_64
+      #define FMT64     "l"
+   #elif defined(sun) || defined(__APPLE__) || defined(__FreeBSD__)
+      #define FMT64     "ll"
+   #else
+      #define FMT64     "L"
+   #endif
+#else
+   #error - Need compiler define for FMT64 and FMTSZ
+#endif
+
+/*
+ * Suffix for 64-bit constants.  Use it like this:
+ *    CONST64(0x7fffffffffffffff) for signed or
+ *    CONST64U(0x7fffffffffffffff) for unsigned.
+ *
+ * 2004.08.30(thutt):
+ *   The vmcore/asm64/gen* programs are compiled as 32-bit
+ *   applications, but must handle 64 bit constants.  If the
+ *   64-bit-constant defining macros are already defined, the
+ *   definition will not be overwritten.
+ */
+
+#if !defined(CONST64) || !defined(CONST64U)
+#ifdef _MSC_VER
+#define CONST64(c) c##I64
+#define CONST64U(c) c##uI64
+#elif __GNUC__
+#ifdef VM_X86_64
+#define CONST64(c) c##L
+#define CONST64U(c) c##uL
+#else
+#define CONST64(c) c##LL
+#define CONST64U(c) c##uLL
+#endif
+#else
+#error - Need compiler define for CONST64
+#endif
+#endif
+
+/*
+ * Use CONST3264/CONST3264U if you want a constant to be
+ * treated as a 32-bit number on 32-bit compiles and
+ * a 64-bit number on 64-bit compiles. Useful in the case
+ * of shifts, like (CONST3264U(1) << x), where x could be
+ * more than 31 on a 64-bit compile.
+ */
+
+#ifdef VM_X86_64
+    #define CONST3264(a) CONST64(a)
+    #define CONST3264U(a) CONST64U(a)
+#else
+    #define CONST3264(a) (a)
+    #define CONST3264U(a) (a)
+#endif
+
+#define MIN_INT32  ((int32)0x80000000)
+#define MAX_INT32  ((int32)0x7fffffff)
+
+#define MIN_UINT32 ((uint32)0)
+#define MAX_UINT32 ((uint32)0xffffffff)
+
+#define MIN_INT64  (CONST64(0x8000000000000000))
+#define MAX_INT64  (CONST64(0x7fffffffffffffff))
+
+#define MIN_UINT64 (CONST64U(0))
+#define MAX_UINT64 (CONST64U(0xffffffffffffffff))
+
+typedef uint8 *TCA;  /* Pointer into TC (usually). */
+
+/*
+ * Type big enough to hold an integer between 0..100
+ */
+typedef uint8 Percent;
+#define AsPercent(v)	((Percent)(v))
+#define CHOOSE_PERCENT  AsPercent(101)
+
+
+typedef uintptr_t VA;
+typedef uintptr_t VPN;
+
+typedef uint64    PA;
+typedef uint32    PPN;
+
+typedef uint64    PhysMemOff;
+typedef uint64    PhysMemSize;
+
+/* The Xserver source compiles with -ansi -pendantic */
+#ifndef __STRICT_ANSI__
+typedef uint64    BA;
+#endif
+typedef uint32    BPN;
+typedef uint32    PageNum;
+typedef unsigned  MemHandle;
+typedef int32     World_ID;
+
+#define INVALID_WORLD_ID ((World_ID)0)
+
+typedef World_ID User_CartelID;
+#define INVALID_CARTEL_ID INVALID_WORLD_ID
+
+typedef User_CartelID User_SessionID;
+#define INVALID_SESSION_ID INVALID_CARTEL_ID
+
+typedef User_CartelID User_CartelGroupID;
+#define INVALID_CARTELGROUP_ID INVALID_CARTEL_ID
+
+typedef uint32 Worldlet_ID;
+#define INVALID_WORLDLET_ID ((Worldlet_ID)0)
+
+/* world page number */
+typedef uint32    WPN;
+
+/* The Xserver source compiles with -ansi -pendantic */
+#ifndef __STRICT_ANSI__
+typedef uint64     MA;
+typedef uint32     MPN;
+#endif
+
+/*
+ * This type should be used for variables that contain sector
+ * position/quantity.
+ */
+typedef uint64 SectorType;
+
+/*
+ * Linear address
+ */
+
+typedef uintptr_t LA;
+typedef uintptr_t LPN;
+#define LA_2_LPN(_la)     ((_la) >> PAGE_SHIFT)
+#define LPN_2_LA(_lpn)    ((_lpn) << PAGE_SHIFT)
+
+#define LAST_LPN   ((((LA)  1) << (8 * sizeof(LA)   - PAGE_SHIFT)) - 1)
+#define LAST_LPN32 ((((LA32)1) << (8 * sizeof(LA32) - PAGE_SHIFT)) - 1)
+#define LAST_LPN64 ((((LA64)1) << (8 * sizeof(LA64) - PAGE_SHIFT)) - 1)
+
+/* Valid bits in a LPN. */
+#define LPN_MASK   LAST_LPN
+#define LPN_MASK32 LAST_LPN32
+#define LPN_MASK64 LAST_LPN64
+
+/*
+ * On 64 bit platform, address and page number types default
+ * to 64 bit. When we need to represent a 32 bit address, we use
+ * types defined below.
+ *
+ * On 32 bit platform, the following types are the same as the
+ * default types.
+ */
+typedef uint32 VA32;
+typedef uint32 VPN32;
+typedef uint32 LA32;
+typedef uint32 LPN32;
+typedef uint32 PA32;
+typedef uint32 PPN32;
+typedef uint32 MA32;
+typedef uint32 MPN32;
+
+/*
+ * On 64 bit platform, the following types are the same as the
+ * default types.
+ */
+typedef uint64 VA64;
+typedef uint64 VPN64;
+typedef uint64 LA64;
+typedef uint64 LPN64;
+typedef uint64 PA64;
+typedef uint64 PPN64;
+typedef uint64 MA64;
+typedef uint64 MPN64;
+
+/*
+ * VA typedefs for user world apps.
+ */
+typedef VA32 UserVA32;
+typedef VA64 UserVA64;
+typedef UserVA32 UserVAConst; /* Userspace ptr to data that we may only read. */
+typedef UserVA64 UserVA64Const; /* Used by 64-bit syscalls until conversion is finished. */
+#ifdef VMKERNEL
+typedef UserVA32 UserVA;
+#else
+typedef void * UserVA;
+#endif
+
+
+/*
+ * Maximal possible PPN value (errors too) that PhysMem can handle.
+ * Must be at least as large as MAX_PPN which is the maximum PPN
+ * for any region other than buserror.
+ */
+#define PHYSMEM_MAX_PPN ((PPN)0xffffffff)
+#define MAX_PPN         ((PPN)0x1fffffff)   /* Maximal observable PPN value. */
+#define INVALID_PPN     ((PPN)0xffffffff)
+
+#define INVALID_BPN  ((BPN) 0x1fffffff)
+
+#define INVALID_MPN  ((MPN)-1)
+#define MEMREF_MPN   ((MPN)-2)
+#define RESERVED_MPN ((MPN) 0)
+/* Support 39 bits of address space, minus one page. */
+#define MAX_MPN      ((MPN) 0x07ffffff)
+
+#define INVALID_LPN ((LPN)-1)
+#define INVALID_VPN ((VPN)-1)
+#define INVALID_LPN64 ((LPN64)-1)
+#define INVALID_PAGENUM ((PageNum)-1)
+#define INVALID_WPN ((WPN) -1)
+
+
+/*
+ * Format modifier for printing VA, LA, and VPN.
+ * Use them like this: Log("%#"FMTLA"x\n", laddr)
+ */
+
+#if defined(VMM64) || defined(FROBOS64) || vm_x86_64 || defined __APPLE__
+#   define FMTLA "l"
+#   define FMTVA "l"
+#   define FMTVPN "l"
+#else
+#   define FMTLA ""
+#   define FMTVA ""
+#   define FMTVPN ""
+#endif
+
+#ifndef EXTERN
+#define EXTERN        extern
+#endif
+#define CONST         const
+
+
+#ifndef INLINE
+#   ifdef _MSC_VER
+#      define INLINE        __inline
+#   else
+#      define INLINE        inline
+#   endif
+#endif
+
+
+/*
+ * Annotation for data that may be exported into a DLL and used by other
+ * apps that load that DLL and import the data.
+ */
+#if defined(_WIN32) && defined(VMX86_IMPORT_DLLDATA)
+#  define VMX86_EXTERN_DATA       extern __declspec(dllimport)
+#else // !_WIN32
+#  define VMX86_EXTERN_DATA       extern
+#endif
+
+#if defined(_WIN32) && !defined(VMX86_NO_THREADS)
+#define THREADSPECIFIC __declspec(thread)
+#else
+#define THREADSPECIFIC
+#endif
+
+/*
+ * Due to the wonderful "registry redirection" feature introduced in
+ * 64-bit Windows, if you access any key under HKLM\Software in 64-bit
+ * code, you need to open/create/delete that key with
+ * VMKEY_WOW64_32KEY if you want a consistent view with 32-bit code.
+ */
+
+#ifdef _WIN32
+#ifdef _WIN64
+#define VMW_KEY_WOW64_32KEY KEY_WOW64_32KEY
+#else
+#define VMW_KEY_WOW64_32KEY 0x0
+#endif
+#endif
+
+
+/*
+ * Consider the following reasons functions are inlined:
+ *
+ *  1) inlined for performance reasons
+ *  2) inlined because it's a single-use function
+ *
+ * Functions which meet only condition 2 should be marked with this
+ * inline macro; It is not critical to be inlined (but there is a
+ * code-space & runtime savings by doing so), so when other callers
+ * are added the inline-ness should be removed.
+ */
+
+#if __GNUC__ > 3 || (__GNUC__ == 3 && __GNUC_MINOR__ >= 3)
+/*
+ * Starting at version 3.3, gcc does not always inline functions marked
+ * 'inline' (it depends on their size). To force gcc to do so, one must use the
+ * extra __always_inline__ attribute.
+ */
+#   define INLINE_SINGLE_CALLER INLINE __attribute__((__always_inline__))
+#   if    defined(VMM) \
+       && (__GNUC__ > 4 || (__GNUC__ == 4 && __GNUC_MINOR__ > 1))
+#      warning Verify INLINE_SINGLE_CALLER '__always_inline__' attribute (did \
+             monitor size change?)
+#   endif
+#else
+#   define INLINE_SINGLE_CALLER INLINE
+#endif
+
+/*
+ * Used when a hard guaranteed of no inlining is needed. Very few
+ * instances need this since the absence of INLINE is a good hint
+ * that gcc will not do inlining.
+ */
+
+#if defined(__GNUC__) && defined(VMM)
+#define ABSOLUTELY_NOINLINE __attribute__((__noinline__))
+#endif
+
+/*
+ * Attributes placed on function declarations to tell the compiler
+ * that the function never returns.
+ */
+
+#ifdef _MSC_VER
+#define NORETURN __declspec(noreturn)
+#elif __GNUC__ > 2 || (__GNUC__ == 2 && __GNUC_MINOR__ >= 9)
+#define NORETURN __attribute__((__noreturn__))
+#else
+#define NORETURN
+#endif
+
+/*
+ * GCC 3.2 inline asm needs the + constraint for input/ouput memory operands.
+ * Older GCCs don't know about it --hpreg
+ */
+
+#if __GNUC__ > 3 || (__GNUC__ == 3 && __GNUC_MINOR__ >= 2)
+#   define VM_ASM_PLUS 1
+#else
+#   define VM_ASM_PLUS 0
+#endif
+
+/*
+ * Branch prediction hints:
+ *     LIKELY(exp)   - Expression exp is likely TRUE.
+ *     UNLIKELY(exp) - Expression exp is likely FALSE.
+ *   Usage example:
+ *        if (LIKELY(excCode == EXC_NONE)) {
+ *               or
+ *        if (UNLIKELY(REAL_MODE(vc))) {
+ *
+ * We know how to predict branches on gcc3 and later (hopefully),
+ * all others we don't so we do nothing.
+ */
+
+#if (__GNUC__ >= 3)
+/*
+ * gcc3 uses __builtin_expect() to inform the compiler of an expected value.
+ * We use this to inform the static branch predictor. The '!!' in LIKELY
+ * will convert any !=0 to a 1.
+ */
+#define LIKELY(_exp)     __builtin_expect(!!(_exp), 1)
+#define UNLIKELY(_exp)   __builtin_expect((_exp), 0)
+#else
+#define LIKELY(_exp)      (_exp)
+#define UNLIKELY(_exp)    (_exp)
+#endif
+
+/*
+ * GCC's argument checking for printf-like functions
+ * This is conditional until we have replaced all `"%x", void *'
+ * with `"0x%08x", (uint32) void *'. Note that %p prints different things
+ * on different platforms.  Argument checking is enabled for the
+ * vmkernel, which has already been cleansed.
+ *
+ * fmtPos is the position of the format string argument, beginning at 1
+ * varPos is the position of the variable argument, beginning at 1
+ */
+
+#if defined(__GNUC__)
+# define PRINTF_DECL(fmtPos, varPos) __attribute__((__format__(__printf__, fmtPos, varPos)))
+#else
+# define PRINTF_DECL(fmtPos, varPos)
+#endif
+
+#if defined(__GNUC__)
+# define SCANF_DECL(fmtPos, varPos) __attribute__((__format__(__scanf__, fmtPos, varPos)))
+#else
+# define SCANF_DECL(fmtPos, varPos)
+#endif
+
+/*
+ * UNUSED_PARAM should surround the parameter name and type declaration,
+ * e.g. "int MyFunction(int var1, UNUSED_PARAM(int var2))"
+ *
+ */
+
+#ifndef UNUSED_PARAM
+# if defined(__GNUC__)
+#  define UNUSED_PARAM(_parm) _parm  __attribute__((__unused__))
+# else
+#  define UNUSED_PARAM(_parm) _parm
+# endif
+#endif
+
+/*
+ * REGPARM defaults to REGPARM3, i.e., a requent that gcc
+ * puts the first three arguments in registers.  (It is fine
+ * if the function has fewer than three args.)  Gcc only.
+ * Syntactically, put REGPARM where you'd put INLINE or NORETURN.
+ */
+
+#if defined(__GNUC__)
+# define REGPARM0 __attribute__((regparm(0)))
+# define REGPARM1 __attribute__((regparm(1)))
+# define REGPARM2 __attribute__((regparm(2)))
+# define REGPARM3 __attribute__((regparm(3)))
+# define REGPARM REGPARM3
+#else
+# define REGPARM0
+# define REGPARM1
+# define REGPARM2
+# define REGPARM3
+# define REGPARM
+#endif
+
+/*
+ * ALIGNED specifies minimum alignment in "n" bytes.
+ */
+
+#ifdef __GNUC__
+#define ALIGNED(n) __attribute__((__aligned__(n)))
+#else
+#define ALIGNED(n)
+#endif
+
+/*
+ * __func__ is a stringified function name that is part of the C99 standard. The block
+ * below defines __func__ on older systems where the compiler does not support that
+ * macro.
+ */
+#if defined(__GNUC__) \
+   && ((__GNUC__ == 2 && __GNUC_MINOR < 96) \
+       || (__GNUC__ < 2))
+#   define __func__ __FUNCTION__
+#endif
+
+/*
+ * Once upon a time, this was used to silence compiler warnings that
+ * get generated when the compiler thinks that a function returns
+ * when it is marked noreturn.  Don't do it.  Use NOT_REACHED().
+ */
+
+#define INFINITE_LOOP()           do { } while (1)
+
+/*
+ * On FreeBSD (for the tools build), size_t is typedef'd if _BSD_SIZE_T_
+ * is defined. Use the same logic here so we don't define it twice. [greg]
+ */
+#ifdef __FreeBSD__
+#   ifdef _BSD_SIZE_T_
+#      undef _BSD_SIZE_T_
+#      ifdef VM_I386
+#         ifdef VM_X86_64
+             typedef uint64 size_t;
+#         else
+             typedef uint32 size_t;
+#         endif
+#      endif /* VM_I386 */
+#   endif
+
+#   ifdef _BSD_SSIZE_T_
+#      undef _BSD_SSIZE_T_
+#      define _SSIZE_T
+#      define __ssize_t_defined
+#      define _SSIZE_T_DECLARED
+#      ifdef VM_I386
+#         ifdef VM_X86_64
+             typedef int64 ssize_t;
+#         else
+             typedef int32 ssize_t;
+#         endif
+#      endif /* VM_I386 */
+#   endif
+
+#else
+#   ifndef _SIZE_T
+#      define _SIZE_T
+#      ifdef VM_I386
+#         ifdef VM_X86_64
+             typedef uint64 size_t;
+#         else
+             typedef uint32 size_t;
+#         endif
+#      endif /* VM_I386 */
+#   endif
+
+#   if !defined(FROBOS) && !defined(_SSIZE_T) && !defined(ssize_t) && \
+       !defined(__ssize_t_defined) && !defined(_SSIZE_T_DECLARED)
+#      define _SSIZE_T
+#      define __ssize_t_defined
+#      define _SSIZE_T_DECLARED
+#      ifdef VM_I386
+#         ifdef VM_X86_64
+             typedef int64 ssize_t;
+#         else
+             typedef int32 ssize_t;
+#         endif
+#      endif /* VM_I386 */
+#   endif
+
+#endif
+
+/*
+ * Format modifier for printing pid_t.  On sun the pid_t is a ulong, but on
+ * Linux it's an int.
+ * Use this like this: printf("The pid is %"FMTPID".\n", pid);
+ */
+#ifdef sun
+#   ifdef VM_X86_64
+#      define FMTPID "d"
+#   else
+#      define FMTPID "lu"
+#   endif
+#else
+# define FMTPID "d"
+#endif
+
+/*
+ * Format modifier for printing uid_t.  On sun the uid_t is a ulong, but on
+ * Linux it's an int.
+ * Use this like this: printf("The uid is %"FMTUID".\n", uid);
+ */
+#ifdef sun
+#   ifdef VM_X86_64
+#      define FMTUID "u"
+#   else
+#      define FMTUID "lu"
+#   endif
+#else
+# define FMTUID "u"
+#endif
+
+/*
+ * Format modifier for printing mode_t.  On sun the mode_t is a ulong, but on
+ * Linux it's an int.
+ * Use this like this: printf("The mode is %"FMTMODE".\n", mode);
+ */
+#ifdef sun
+#   ifdef VM_X86_64
+#      define FMTMODE "o"
+#   else
+#      define FMTMODE "lo"
+#   endif
+#else
+# define FMTMODE "o"
+#endif
+
+/*
+ * Format modifier for printing time_t. Most platforms define a time_t to be
+ * a long int, but on FreeBSD (as of 5.0, it seems), the time_t is a signed
+ * size quantity. Refer to the definition of FMTSZ to see why we need silly
+ * preprocessor arithmetic.
+ * Use this like this: printf("The mode is %"FMTTIME".\n", time);
+ */
+#if defined(__FreeBSD__) && (__FreeBSD__ + 0) && ((__FreeBSD__ + 0) >= 5)
+#   define FMTTIME FMTSZ"d"
+#else
+#   define FMTTIME "ld"
+#endif
+
+/*
+ * Define MXSemaHandle here so both vmmon and vmx see this definition.
+ */
+
+#ifdef _WIN32
+typedef uintptr_t MXSemaHandle;
+#else
+typedef int MXSemaHandle;
+#endif
+
+/*
+ * Define type for poll device handles.
+ */
+
+#ifdef _WIN32
+typedef uintptr_t PollDevHandle;
+#else
+typedef int PollDevHandle;
+#endif
+
+/*
+ * Define the utf16_t type.
+ */
+
+#if defined(_WIN32) && defined(_NATIVE_WCHAR_T_DEFINED)
+typedef wchar_t utf16_t;
+#else
+typedef uint16 utf16_t;
+#endif
+
+#endif  /* _VM_BASIC_TYPES_H_ */
--- kernel/linux-2.6.26.3/drivers/net/vmxnet/vm_device_version.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/net/vmxnet/vm_device_version.h	2008-09-03 10:07:45.000000000 -0500
@@ -0,0 +1,186 @@
+/*********************************************************
+ * Copyright (C) 1998 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef VM_DEVICE_VERSION_H
+#define VM_DEVICE_VERSION_H
+
+#define INCLUDE_ALLOW_USERLEVEL
+#define INCLUDE_ALLOW_VMMEXT
+#define INCLUDE_ALLOW_MODULE
+#define INCLUDE_ALLOW_VMKERNEL
+#define INCLUDE_ALLOW_VMCORE
+#include "includeCheck.h"
+
+#ifdef _WIN32
+#include "guiddef.h"
+#endif
+
+/* Our own PCI IDs
+ *    VMware SVGA II (Unified VGA)
+ *    VMware SVGA (PCI Accelerator)
+ *    VMware vmxnet (Idealized NIC)
+ *    VMware vmxscsi (Abortive idealized SCSI controller)
+ *    VMware chipset (Subsystem ID for our motherboards)
+ *    VMware e1000 (Subsystem ID)
+ *    VMware vmxnet3 (Uniform Pass Through NIC)
+ */
+#define PCI_VENDOR_ID_VMWARE            0x15AD
+#define PCI_DEVICE_ID_VMWARE_SVGA2      0x0405
+#define PCI_DEVICE_ID_VMWARE_SVGA       0x0710
+#define PCI_DEVICE_ID_VMWARE_NET        0x0720
+#define PCI_DEVICE_ID_VMWARE_SCSI       0x0730
+#define PCI_DEVICE_ID_VMWARE_VMCI       0x0740
+#define PCI_DEVICE_ID_VMWARE_CHIPSET    0x1976
+#define PCI_DEVICE_ID_VMWARE_82545EM    0x0750 /* single port */
+#define PCI_DEVICE_ID_VMWARE_82546EB    0x0760 /* dual port   */
+#define PCI_DEVICE_ID_VMWARE_EHCI       0x0770
+#define PCI_DEVICE_ID_VMWARE_1394       0x0780
+#define PCI_DEVICE_ID_VMWARE_BRIDGE     0x0790
+#define PCI_DEVICE_ID_VMWARE_ROOTPORT   0x07A0
+#define PCI_DEVICE_ID_VMWARE_VMXNET3    0x07B0
+#define PCI_DEVICE_ID_VMWARE_PVSCSI     0x07C0
+
+/* The hypervisor device might grow.  Please leave room
+ * for 7 more subfunctions.
+ */
+#define PCI_DEVICE_ID_VMWARE_HYPER      0x0800
+#define PCI_DEVICE_ID_VMWARE_VMI        0x0801
+
+#define PCI_DEVICE_VMI_CLASS            0x05
+#define PCI_DEVICE_VMI_SUBCLASS         0x80
+#define PCI_DEVICE_VMI_INTERFACE        0x00
+#define PCI_DEVICE_VMI_REVISION         0x01
+
+/* From linux/pci_ids.h:
+ *   AMD Lance Ethernet controller
+ *   BusLogic SCSI controller
+ *   Ensoniq ES1371 sound controller
+ */
+#define PCI_VENDOR_ID_AMD               0x1022
+#define PCI_DEVICE_ID_AMD_VLANCE        0x2000
+#define PCI_VENDOR_ID_BUSLOGIC			0x104B
+#define PCI_DEVICE_ID_BUSLOGIC_MULTIMASTER_NC	0x0140
+#define PCI_DEVICE_ID_BUSLOGIC_MULTIMASTER	0x1040
+#define PCI_VENDOR_ID_ENSONIQ           0x1274
+#define PCI_DEVICE_ID_ENSONIQ_ES1371    0x1371
+
+/* From linux/pci_ids.h:
+ *    Intel 82439TX (430 HX North Bridge)
+ *    Intel 82371AB (PIIX4 South Bridge)
+ *    Intel 82443BX (440 BX North Bridge and AGP Bridge)
+ *    Intel 82545EM (e1000, server adapter, single port)
+ *    Intel 82546EB (e1000, server adapter, dual port)
+ */
+#define PCI_VENDOR_ID_INTEL             0x8086
+#define PCI_DEVICE_ID_INTEL_82439TX     0x7100
+#define PCI_DEVICE_ID_INTEL_82371AB_0   0x7110
+#define PCI_DEVICE_ID_INTEL_82371AB_2   0x7112
+#define PCI_DEVICE_ID_INTEL_82371AB_3   0x7113
+#define PCI_DEVICE_ID_INTEL_82371AB     0x7111
+#define PCI_DEVICE_ID_INTEL_82443BX     0x7190
+#define PCI_DEVICE_ID_INTEL_82443BX_1   0x7191
+#define PCI_DEVICE_ID_INTEL_82443BX_2   0x7192 /* Used when no AGP support */
+#define PCI_DEVICE_ID_INTEL_82545EM     0x100f
+#define PCI_DEVICE_ID_INTEL_82546EB     0x1010
+
+
+/************* Strings for IDE Identity Fields **************************/
+#define VIDE_ID_SERIAL_STR	"00000000000000000001"	/* Must be 20 Bytes */
+#define VIDE_ID_FIRMWARE_STR	"00000001"		/* Must be 8 Bytes */
+
+/* No longer than 40 Bytes */
+#define VIDE_ATA_MODEL_STR PRODUCT_GENERIC_NAME " Virtual IDE Hard Drive"
+#define VIDE_ATAPI_MODEL_STR PRODUCT_GENERIC_NAME " Virtual IDE CDROM Drive"
+
+#define ATAPI_VENDOR_ID	"NECVMWar"		/* Must be 8 Bytes */
+#define ATAPI_PRODUCT_ID PRODUCT_GENERIC_NAME " IDE CDROM"	/* Must be 16 Bytes */
+#define ATAPI_REV_LEVEL	"1.00"			/* Must be 4 Bytes */
+
+#define IDE_NUM_INTERFACES   2	/* support for two interfaces */
+#define IDE_DRIVES_PER_IF    2
+
+/************* Strings for SCSI Identity Fields **************************/
+#define SCSI_DISK_MODEL_STR PRODUCT_GENERIC_NAME " Virtual SCSI Hard Drive"
+#define SCSI_DISK_VENDOR_NAME COMPANY_NAME
+#define SCSI_DISK_REV_LEVEL "1.0"
+#define SCSI_CDROM_MODEL_STR PRODUCT_GENERIC_NAME " Virtual SCSI CDROM Drive"
+#define SCSI_CDROM_VENDOR_NAME COMPANY_NAME
+#define SCSI_CDROM_REV_LEVEL "1.0"
+
+/************* SCSI implementation limits ********************************/
+#define SCSI_MAX_CONTROLLERS	 4	  // Need more than 1 for MSCS clustering
+#define	SCSI_MAX_DEVICES	 16	  // BT-958 emulates only 16
+#define SCSI_IDE_CHANNEL         SCSI_MAX_CONTROLLERS
+#define SCSI_IDE_HOSTED_CHANNEL  (SCSI_MAX_CONTROLLERS + 1)
+#define SCSI_MAX_CHANNELS        (SCSI_MAX_CONTROLLERS + 2)
+
+/************* Strings for the VESA BIOS Identity Fields *****************/
+#define VBE_OEM_STRING COMPANY_NAME " SVGA"
+#define VBE_VENDOR_NAME COMPANY_NAME
+#define VBE_PRODUCT_NAME PRODUCT_GENERIC_NAME
+
+/************* PCI implementation limits ********************************/
+#define PCI_MAX_BRIDGES         15
+
+/************* Ethernet implementation limits ***************************/
+#define MAX_ETHERNET_CARDS      10
+
+/************* PCI Passthrough implementation limits ********************/
+#define MAX_PCI_PASSTHRU_DEVICES 2
+
+/************* USB implementation limits ********************************/
+#define MAX_USB_DEVICES_PER_HOST_CONTROLLER 127
+
+/************* Strings for Host USB Driver *******************************/
+
+#ifdef _WIN32
+
+/*
+ * Globally unique ID for the VMware device interface. Define INITGUID before including
+ * this header file to instantiate the variable.
+ */
+DEFINE_GUID(GUID_DEVICE_INTERFACE_VMWARE_USB_DEVICES, 
+0x2da1fe75, 0xaab3, 0x4d2c, 0xac, 0xdf, 0x39, 0x8, 0x8c, 0xad, 0xa6, 0x65);
+
+/*
+ * Globally unique ID for the VMware device setup class.
+ */
+DEFINE_GUID(GUID_CLASS_VMWARE_USB_DEVICES, 
+0x3b3e62a5, 0x3556, 0x4d7e, 0xad, 0xad, 0xf5, 0xfa, 0x3a, 0x71, 0x2b, 0x56);
+
+/*
+ * This string defines the device ID string of a VMware USB device.
+ * The format is USB\Vid_XXXX&Pid_YYYY, where XXXX and YYYY are the
+ * hexadecimal representations of the vendor and product ids, respectively.
+ *
+ * The official vendor ID for VMware, Inc. is 0x0E0F.
+ * The product id for USB generic devices is 0x0001.
+ */
+#define USB_VMWARE_DEVICE_ID_WIDE L"USB\\Vid_0E0F&Pid_0001"
+#define USB_DEVICE_ID_LENGTH (sizeof(USB_VMWARE_DEVICE_ID_WIDE) / sizeof(WCHAR))
+
+#ifdef UNICODE
+#define USB_PNP_SETUP_CLASS_NAME L"VMwareUSBDevices"
+#define USB_PNP_DRIVER_NAME L"vmusb"
+#else
+#define USB_PNP_SETUP_CLASS_NAME "VMwareUSBDevices"
+#define USB_PNP_DRIVER_NAME "vmusb"
+#endif
+#endif
+
+#endif /* VM_DEVICE_VERSION_H */
--- kernel/linux-2.6.26.3/drivers/net/vmxnet/vmkapi_status.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/net/vmxnet/vmkapi_status.h	2008-09-03 09:57:35.000000000 -0500
@@ -0,0 +1,321 @@
+/*********************************************************
+ * Copyright (C) 2004 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * @VMKAPIMOD_LICENSE@
+ */
+
+/*
+ * vmkapi_status.h --
+ *
+ *	Defines the VMKernel return statuses
+ */
+
+#ifndef _VMKAPI_STATUS_H_
+#define _VMKAPI_STATUS_H_
+
+#define INCLUDE_ALLOW_USERLEVEL
+#define INCLUDE_ALLOW_VMMEXT
+#define INCLUDE_ALLOW_MODULE
+#define INCLUDE_ALLOW_VMNIXMOD
+#define INCLUDE_ALLOW_VMKERNEL
+#define INCLUDE_ALLOW_VMKDRIVERS
+#define INCLUDE_ALLOW_VMK_MODULE
+#define INCLUDE_ALLOW_DISTRIBUTE
+#define INCLUDE_ALLOW_VMCORE
+#include "includeCheck.h"
+
+/*
+ * The return statuses are part of the VMkernel public API. To avoid breaking
+ * 3rd party software built on top of this API, any change to the table must
+ * maintain backward source level as well as binary compatibility i.e. a status
+ * cannot be moved in the table or removed from the table, and new statuses must
+ * be added at the end (before VMK_GENERIC_LINUX_ERROR).
+ *
+ *                VMK error code name           Description                                   Unix name
+ *                ===================           ===========                                   =========
+ */
+#define VMK_ERROR_CODES \
+   DEFINE_VMK_ERR_AT(VMK_OK,                    "Success", 0,                                 OK          )\
+   DEFINE_VMK_ERR_AT(VMK_FAILURE,               "Failure", 0x0bad0001,                        EINVAL      )\
+   DEFINE_VMK_ERR(VMK_WOULD_BLOCK,              "Would block",                                EAGAIN      )\
+   DEFINE_VMK_ERR(VMK_NOT_FOUND,                "Not found",                                  ENOENT      )\
+   DEFINE_VMK_ERR(VMK_BUSY,                     "Busy",                                       EBUSY       )\
+   DEFINE_VMK_ERR(VMK_EXISTS,                   "Already exists",                             EEXIST      )\
+   DEFINE_VMK_ERR(VMK_LIMIT_EXCEEDED,           "Limit exceeded",                             EFBIG       )\
+   DEFINE_VMK_ERR(VMK_BAD_PARAM,                "Bad parameter",                              EINVAL      )\
+   DEFINE_VMK_ERR(VMK_METADATA_READ_ERROR,      "Metadata read error",                        EIO         )\
+   DEFINE_VMK_ERR(VMK_METADATA_WRITE_ERROR,     "Metadata write error",                       EIO         )\
+   DEFINE_VMK_ERR(VMK_IO_ERROR,                 "I/O error",                                  EIO         )\
+   DEFINE_VMK_ERR(VMK_READ_ERROR,               "Read error",                                 EIO         )\
+   DEFINE_VMK_ERR(VMK_WRITE_ERROR,              "Write error",                                EIO         )\
+   DEFINE_VMK_ERR(VMK_INVALID_NAME,             "Invalid name",                               ENAMETOOLONG)\
+   DEFINE_VMK_ERR(VMK_INVALID_HANDLE,           "Invalid handle",                             EBADF       )\
+   DEFINE_VMK_ERR(VMK_INVALID_ADAPTER,          "No such SCSI adapter",                       ENODEV      )\
+   DEFINE_VMK_ERR(VMK_INVALID_TARGET,           "No such target on adapter",                  ENODEV      )\
+   DEFINE_VMK_ERR(VMK_INVALID_PARTITION,        "No such partition on target",                ENXIO       )\
+   DEFINE_VMK_ERR(VMK_INVALID_FS,               "No filesystem on the device",                ENXIO       )\
+   DEFINE_VMK_ERR(VMK_INVALID_MEMMAP,           "Memory map mismatch",                        EFAULT      )\
+   DEFINE_VMK_ERR(VMK_NO_MEMORY,                "Out of memory",                              ENOMEM      )\
+   DEFINE_VMK_ERR(VMK_NO_MEMORY_RETRY,          "Out of memory (ok to retry)",                ENOMEM      )\
+   DEFINE_VMK_ERR(VMK_NO_RESOURCES,             "Out of resources",                           ENOMEM      )\
+   DEFINE_VMK_ERR(VMK_NO_FREE_HANDLES,          "No free handles",                            EMFILE      )\
+   DEFINE_VMK_ERR(VMK_NUM_HANDLES_EXCEEDED,     "Exceeded maximum number of allowed handles", ENFILE      )\
+   DEFINE_VMK_ERR(VMK_DEPRECATED_NO_FREE_PTR_BLOCKS,       "No free pointer blocks (deprecated)",                     ENOSPC      )\
+   DEFINE_VMK_ERR(VMK_DEPRECATED_NO_FREE_DATA_BLOCKS,      "No free data blocks (deprecated)",                        ENOSPC      )\
+   DEFINE_VMK_ERR(VMK_CORRUPT_REDOLOG,          "Corrupt RedoLog",                            EBADF       )\
+   DEFINE_VMK_ERR(VMK_STATUS_PENDING,           "Status pending",                             EAGAIN      )\
+   DEFINE_VMK_ERR(VMK_STATUS_FREE,              "Status free",                                EAGAIN      )\
+   DEFINE_VMK_ERR(VMK_UNSUPPORTED_CPU,          "Unsupported CPU",                            ENODEV      )\
+   DEFINE_VMK_ERR(VMK_NOT_SUPPORTED,            "Not supported",                              ENOSYS      )\
+   DEFINE_VMK_ERR(VMK_TIMEOUT,                  "Timeout",                                    ETIMEDOUT   )\
+   DEFINE_VMK_ERR(VMK_READ_ONLY,                "Read only",                                  EROFS       )\
+   DEFINE_VMK_ERR(VMK_RESERVATION_CONFLICT,     "SCSI reservation conflict",                  EAGAIN      )\
+   DEFINE_VMK_ERR(VMK_FS_LOCKED,                "File system locked",                         EADDRINUSE  )\
+   DEFINE_VMK_ERR(VMK_NOT_ENOUGH_SLOTS,         "Out of slots",                               ENFILE      )\
+   DEFINE_VMK_ERR(VMK_INVALID_ADDRESS,          "Invalid address",                            EFAULT      )\
+   DEFINE_VMK_ERR(VMK_NOT_SHARED,               "Not shared",                                 ENOMEM      )\
+   DEFINE_VMK_ERR(VMK_SHARED,                   "Page is shared",                             ENOMEM      )\
+   DEFINE_VMK_ERR(VMK_KSEG_PAIR_FLUSHED,        "Kseg pair flushed",                          ENOMEM      )\
+   DEFINE_VMK_ERR(VMK_MAX_ASYNCIO_PENDING,      "Max async I/O requests pending",             ENOMEM      )\
+   DEFINE_VMK_ERR(VMK_VERSION_MISMATCH_MINOR,   "Minor version mismatch",                     ENOSYS      )\
+   DEFINE_VMK_ERR(VMK_VERSION_MISMATCH_MAJOR,   "Major version mismatch",                     ENOSYS      )\
+   DEFINE_VMK_ERR(VMK_IS_CONNECTED,             "Already connected",                          EINVAL      )\
+   DEFINE_VMK_ERR(VMK_IS_DISCONNECTED,          "Already disconnected",                       ENOTCONN    )\
+   DEFINE_VMK_ERR(VMK_IS_ENABLED,               "Already enabled",                            EINVAL      )\
+   DEFINE_VMK_ERR(VMK_IS_DISABLED,              "Already disabled",                           EINVAL      )\
+   DEFINE_VMK_ERR(VMK_NOT_INITIALIZED,          "Not initialized",                            EINVAL      )\
+   DEFINE_VMK_ERR(VMK_WAIT_INTERRUPTED,         "Wait interrupted",                           EINTR       )\
+   DEFINE_VMK_ERR(VMK_NAME_TOO_LONG,            "Name too long",                              ENAMETOOLONG)\
+   DEFINE_VMK_ERR(VMK_MISSING_FS_PES,           "VMFS volume missing physical extents",       ENOTDIR     )\
+   DEFINE_VMK_ERR(VMK_NICTEAMING_VALID_MASTER,  "NIC teaming master valid",                   EINVAL      )\
+   DEFINE_VMK_ERR(VMK_NICTEAMING_SLAVE,         "NIC teaming slave",                          EEXIST      )\
+   DEFINE_VMK_ERR(VMK_NICTEAMING_REGULAR_VMNIC, "NIC teaming regular VMNIC",                  EINVAL      )\
+   DEFINE_VMK_ERR(VMK_ABORT_NOT_RUNNING,        "Abort not running",                          ECANCELED   )\
+   DEFINE_VMK_ERR(VMK_NOT_READY,                "Not ready",                                  EIO         )\
+   DEFINE_VMK_ERR(VMK_CHECKSUM_MISMATCH,        "Checksum mismatch",                          EIO         )\
+   DEFINE_VMK_ERR(VMK_VLAN_NO_HW_ACCEL,         "VLan HW Acceleration not supported",         EINVAL      )\
+   DEFINE_VMK_ERR(VMK_NO_VLAN_SUPPORT,          "VLan is not supported in vmkernel",          EOPNOTSUPP  )\
+   DEFINE_VMK_ERR(VMK_NOT_VLAN_HANDLE,          "Not a VLan handle",                          EINVAL      )\
+   DEFINE_VMK_ERR(VMK_BAD_VLANID,               "Couldn't retrieve VLan id",                  EBADF       )\
+   DEFINE_VMK_ERR(VMK_MIG_PROTO_ERROR,          "Migration protocol error",                   EINVAL      )\
+   DEFINE_VMK_ERR(VMK_NO_CONNECT,               "No connection",                              EIO         )\
+   DEFINE_VMK_ERR(VMK_SEGMENT_OVERLAP,          "Segment overlap",                            EINVAL      )\
+   DEFINE_VMK_ERR(VMK_BAD_MPS,                  "Error parsing MPS Table",                    EIO         )\
+   DEFINE_VMK_ERR(VMK_BAD_ACPI,                 "Error parsing ACPI Table",                   EIO         )\
+   DEFINE_VMK_ERR(VMK_RESUME_ERROR,             "Failed to resume VM",                        EIO         )\
+   DEFINE_VMK_ERR(VMK_NO_ADDRESS_SPACE,         "Insufficient address space for operation",   ENOMEM      )\
+   DEFINE_VMK_ERR(VMK_BAD_ADDR_RANGE,           "Bad address range",                          EINVAL      )\
+   DEFINE_VMK_ERR(VMK_ENETDOWN,                 "Network is down",                            ENETDOWN    )\
+   DEFINE_VMK_ERR(VMK_ENETUNREACH,              "Network unreachable",                        ENETUNREACH )\
+   DEFINE_VMK_ERR(VMK_ENETRESET,                "Network dropped connection on reset",        ENETRESET   )\
+   DEFINE_VMK_ERR(VMK_ECONNABORTED,             "Software caused connection abort",           ECONNABORTED)\
+   DEFINE_VMK_ERR(VMK_ECONNRESET,               "Connection reset by peer",                   ECONNRESET  )\
+   DEFINE_VMK_ERR(VMK_ENOTCONN,                 "Socket is not connected",                    ENOTCONN    )\
+   DEFINE_VMK_ERR(VMK_ESHUTDOWN,                "Can't send after socket shutdown",           ESHUTDOWN   )\
+   DEFINE_VMK_ERR(VMK_ETOOMANYREFS,             "Too many references: can't splice",          ETOOMANYREFS)\
+   DEFINE_VMK_ERR(VMK_ECONNREFUSED,             "Connection refused",                         ECONNREFUSED)\
+   DEFINE_VMK_ERR(VMK_EHOSTDOWN,                "Host is down",                               EHOSTDOWN   )\
+   DEFINE_VMK_ERR(VMK_EHOSTUNREACH,             "No route to host",                           EHOSTUNREACH)\
+   DEFINE_VMK_ERR(VMK_EADDRINUSE,               "Address already in use",                     EADDRINUSE  )\
+   DEFINE_VMK_ERR(VMK_BROKEN_PIPE,              "Broken pipe",                                EPIPE       )\
+   DEFINE_VMK_ERR(VMK_NOT_A_DIRECTORY,          "Not a directory",                            ENOTDIR     )\
+   DEFINE_VMK_ERR(VMK_IS_A_DIRECTORY,           "Is a directory",                             EISDIR      )\
+   DEFINE_VMK_ERR(VMK_NOT_EMPTY,                "Directory not empty",                        ENOTEMPTY   )\
+   DEFINE_VMK_ERR(VMK_NOT_IMPLEMENTED,          "Not implemented",                            ENOSYS      )\
+   DEFINE_VMK_ERR(VMK_NO_SIGNAL_HANDLER,        "No signal handler",                          EINVAL      )\
+   DEFINE_VMK_ERR(VMK_FATAL_SIGNAL_BLOCKED,     "Fatal signal blocked",                       EINVAL      )\
+   DEFINE_VMK_ERR(VMK_NO_ACCESS,                "Permission denied",                          EACCES      )\
+   DEFINE_VMK_ERR(VMK_NO_PERMISSION,            "Operation not permitted",                    EPERM       )\
+   DEFINE_VMK_ERR(VMK_UNDEFINED_SYSCALL,        "Undefined syscall",                          ENOSYS      )\
+   DEFINE_VMK_ERR(VMK_RESULT_TOO_LARGE,         "Result too large",                           ERANGE      )\
+   DEFINE_VMK_ERR(VMK_VLAN_FILTERED,            "Pkts dropped because of VLAN (support) mismatch", ERANGE )\
+   DEFINE_VMK_ERR(VMK_BAD_EXCFRAME,             "Unsafe exception frame",                     EFAULT      )\
+   DEFINE_VMK_ERR(VMK_MODULE_NOT_LOADED,        "Necessary module isn't loaded",              ENODEV      )\
+   DEFINE_VMK_ERR(VMK_NO_SUCH_ZOMBIE,           "No dead world by that name",                 ECHILD      )\
+   DEFINE_VMK_ERR(VMK_NO_SUCH_CARTEL,           "No cartel by that name",                     ESRCH       )\
+   DEFINE_VMK_ERR(VMK_IS_A_SYMLINK,             "Is a symbolic link",                         ELOOP       )\
+   DEFINE_VMK_ERR(VMK_CROSS_DEVICE_LINK,        "Cross-device link" ,                         EXDEV       )\
+   DEFINE_VMK_ERR(VMK_NOT_A_SOCKET,		"Not a socket",				      ENOTSOCK    )\
+   DEFINE_VMK_ERR(VMK_ILLEGAL_SEEK,		"Illegal seek",				      ESPIPE      )\
+   DEFINE_VMK_ERR(VMK_ADDRFAM_UNSUPP,		"Unsupported address family",		      EAFNOSUPPORT)\
+   DEFINE_VMK_ERR(VMK_ALREADY_CONNECTED,	"Already connected",			      EISCONN	  )\
+   DEFINE_VMK_ERR(VMK_DEATH_PENDING,            "World is marked for death",		      ENOENT	  )\
+   DEFINE_VMK_ERR(VMK_NO_CELL_ASSIGNMENT,       "No valid scheduler cell assignment",         EINVAL	  )\
+   DEFINE_VMK_ERR(VMK_CPU_MIN_INVALID,          "Invalid cpu min",                            EINVAL	  )\
+   DEFINE_VMK_ERR(VMK_CPU_MINLIMIT_INVALID,     "Invalid cpu minLimit",                       EINVAL	  )\
+   DEFINE_VMK_ERR(VMK_CPU_MAX_INVALID,          "Invalid cpu max",                            EINVAL	  )\
+   DEFINE_VMK_ERR(VMK_CPU_SHARES_INVALID,       "Invalid cpu shares",                         EINVAL	  )\
+   DEFINE_VMK_ERR(VMK_CPU_MIN_OVERFLOW,         "Cpu min outside valid range",                EINVAL	  )\
+   DEFINE_VMK_ERR(VMK_CPU_MINLIMIT_OVERFLOW,    "Cpu minLimit outside valid range",           EINVAL	  )\
+   DEFINE_VMK_ERR(VMK_CPU_MAX_OVERFLOW,         "Cpu max outside valid range" ,               EINVAL	  )\
+   DEFINE_VMK_ERR(VMK_CPU_MIN_GT_MINLIMIT,      "Cpu min exceeds minLimit",                   EINVAL	  )\
+   DEFINE_VMK_ERR(VMK_CPU_MIN_GT_MAX,           "Cpu min exceeds max",                        EINVAL	  )\
+   DEFINE_VMK_ERR(VMK_CPU_MINLIMIT_LT_RESERVED, "Cpu minLimit less than cpu already reserved by children", ENOSPC	  )\
+   DEFINE_VMK_ERR(VMK_CPU_MAX_LT_RESERVED,      "Cpu max less than cpu already reserved by children", ENOSPC	  )\
+   DEFINE_VMK_ERR(VMK_CPU_ADMIT_FAILED,         "Admission check failed for cpu resource",    ENOSPC	  )\
+   DEFINE_VMK_ERR(VMK_MEM_MIN_INVALID,          "Invalid memory min",                         EINVAL	  )\
+   DEFINE_VMK_ERR(VMK_MEM_MINLIMIT_INVALID,     "Invalid memory minLimit",                    EINVAL	  )\
+   DEFINE_VMK_ERR(VMK_MEM_MAX_INVALID,          "Invalid memory max",                         EINVAL	  )\
+   DEFINE_VMK_ERR(VMK_MEM_MIN_OVERFLOW,         "Memory min outside valid range",             EINVAL	  )\
+   DEFINE_VMK_ERR(VMK_MEM_MINLIMIT_OVERFLOW,    "Memory minLimit outside valid range",        EINVAL	  )\
+   DEFINE_VMK_ERR(VMK_MEM_MAX_OVERFLOW,         "Memory max outside valid range",             EINVAL	  )\
+   DEFINE_VMK_ERR(VMK_MEM_MIN_GT_MINLIMIT,      "Memory min exceeds minLimit",                EINVAL	  )\
+   DEFINE_VMK_ERR(VMK_MEM_MIN_GT_MAX,           "Memory min exceeds max",                     EINVAL	  )\
+   DEFINE_VMK_ERR(VMK_MEM_MINLIMIT_LT_RESERVED, "Memory minLimit less than memory already reserved by children", ENOSPC	  )\
+   DEFINE_VMK_ERR(VMK_MEM_MAX_LT_RESERVED,      "Memory max less than memory already reserved by children", ENOSPC	  )\
+   DEFINE_VMK_ERR(VMK_MEM_ADMIT_FAILED,         "Admission check failed for memory resource", ENOSPC	  )\
+   DEFINE_VMK_ERR(VMK_NO_SWAP_FILE,             "No swap file",                               ENOENT	  )\
+   DEFINE_VMK_ERR(VMK_BAD_PARAM_COUNT,          "Bad parameter count",                        EINVAL      )\
+   DEFINE_VMK_ERR(VMK_BAD_PARAM_TYPE,           "Bad parameter type",                         EINVAL      )\
+   DEFINE_VMK_ERR(VMK_UNMAP_RETRY,              "Dueling unmaps (ok to retry)",               ENOMEM      )\
+   DEFINE_VMK_ERR(VMK_INVALID_IOCTL,            "Inappropriate ioctl for device",             ENOTTY      )\
+   DEFINE_VMK_ERR(VMK_MAPFAULT_RETRY,           "Mmap changed under page fault (ok to retry)",EBUSY       )\
+   DEFINE_VMK_ERR(VMK_EINPROGRESS,              "Operation now in progress",                  EINPROGRESS )\
+   DEFINE_VMK_ERR(VMK_ADDR_UNMAPPED,            "Address temporarily unmapped",               EFAULT      )\
+   DEFINE_VMK_ERR(VMK_INVALID_BUDDY_TYPE,       "Invalid buddy type",                         ENOMEM      )\
+   DEFINE_VMK_ERR(VMK_LPAGE_INFO_NOT_FOUND,     "Large page info not found",                   ENOMEM      )\
+   DEFINE_VMK_ERR(VMK_LPAGE_INFO_INVALID,       "Invalid large page info",                     EINVAL      )\
+   DEFINE_VMK_ERR(VMK_SNAPSHOT_DEV,             "SCSI LUN is in snapshot state",              EIO         )\
+   DEFINE_VMK_ERR(VMK_IN_TRANSITION,            "SCSI LUN is in transition",                  EIO         )\
+   DEFINE_VMK_ERR(VMK_TXN_FULL,                 "Transaction ran out of lock space or log space", ENOSPC  )\
+   DEFINE_VMK_ERR(VMK_LOCK_NOT_FREE,            "Lock was not free",			      EBUSY       )\
+   DEFINE_VMK_ERR(VMK_NUM_FILES_EXCEEDED,       "Exceed maximum number of files on the filesystem", ENOSPC)\
+   DEFINE_VMK_ERR(VMK_MIGRATE_VMX_FAILURE,	"Migration determined a failure by the VMX",  EINVAL      )\
+   DEFINE_VMK_ERR(VMK_VSI_LIST_OVERFLOW,	"VSI GetList handler overflow",               EFBIG       )\
+   DEFINE_VMK_ERR(VMK_INVALID_WORLD,            "Invalid world",                              EINVAL      )\
+   DEFINE_VMK_ERR(VMK_INVALID_VMM,              "Invalid vmm",                                EINVAL      )\
+   DEFINE_VMK_ERR(VMK_INVALID_TXN,              "Invalid transaction",                        EINVAL      )\
+   DEFINE_VMK_ERR(VMK_FS_RETRY_OPERATION,	"Transient file system condition, suggest retry", EAGAIN  )\
+   DEFINE_VMK_ERR(VMK_VCPU_LIMIT_EXCEEDED,      "Number of running VCPUs limit exceeded",     EINVAL      )\
+   DEFINE_VMK_ERR(VMK_INVALID_METADATA,         "Invalid metadata",                           EINVAL      )\
+   DEFINE_VMK_ERR(VMK_INVALID_PAGE_NUMBER,	"Invalid page number",                        EINVAL      )\
+   DEFINE_VMK_ERR(VMK_NOT_EXEC,                 "Not in executable format",                   ENOEXEC     )\
+   DEFINE_VMK_ERR(VMK_NFS_CONNECT_FAILURE,      "Unable to connect to NFS server",            EHOSTDOWN) \
+   DEFINE_VMK_ERR(VMK_NFS_MOUNT_NOT_SUPPORTED,  "The NFS server does not support MOUNT version 3 over TCP",     EINVAL) \
+   DEFINE_VMK_ERR(VMK_NFS_NFS_NOT_SUPPORTED,    "The NFS server does not support NFS version 3 over TCP",       EINVAL) \
+   DEFINE_VMK_ERR(VMK_NFS_MOUNT_DENIED,         "The mount request was denied by the NFS server. Check that the export exists and that the client is permitted to mount it",  EPERM)\
+   DEFINE_VMK_ERR(VMK_NFS_MOUNT_NOT_DIR,        "The specified mount path was not a directory",                 ENOTDIR) \
+   DEFINE_VMK_ERR(VMK_NFS_BAD_FSINFO,           "Unable to query remote mount point's attributes",              EACCES) \
+   DEFINE_VMK_ERR(VMK_NFS_VOLUME_LIMIT_EXCEEDED,"NFS has reached the maximum number of supported volumes",      EINVAL) \
+   DEFINE_VMK_ERR(VMK_NO_MEMORY_NICE,           "Out of nice memory",                         ENOMEM      )\
+   DEFINE_VMK_ERR(VMK_MIGRATE_PREEMPTIVE_FAIL,	"VMotion failed to start due to lack of cpu or memory resources",     ENOMEM)\
+   DEFINE_VMK_ERR(VMK_CACHE_MISS,               "Cache miss",                                 EFAULT      )\
+   DEFINE_VMK_ERR(VMK_STRESS_INDUCED_ERROR,     "Error induced when stress options are enabled",    EIO)\
+   DEFINE_VMK_ERR(VMK_TOO_MANY_LOCK_HOLDERS,    "Maximum number of concurrent hosts are already accessing this resource",    EUSERS)\
+   DEFINE_VMK_ERR(VMK_NO_JOURNAL,               "Host doesn't have a journal",                EIO)\
+   DEFINE_VMK_ERR(VMK_RANK_VIOLATION,           "Lock rank violation detected",               EDEADLK)\
+   DEFINE_VMK_ERR(VMK_MODULE_FAILED,            "Module failed",                              ENODEV      )\
+   DEFINE_VMK_ERR(VMK_NO_MASTER_PTY,            "Unable to open slave if no master pty",      ENXIO       )\
+   DEFINE_VMK_ERR(VMK_NOT_IOABLE,               "Not IOAble",                                 EFAULT      )\
+   DEFINE_VMK_ERR(VMK_NO_FREE_INODES,           "No free inodes",                             ENOSPC      )\
+   DEFINE_VMK_ERR(VMK_NO_MEMORY_FOR_FILEDATA,   "No free memory for file data",               ENOSPC      )\
+   DEFINE_VMK_ERR(VMK_NO_TAR_SPACE,             "No free space to expand file or meta data",  ENOSPC      )\
+   DEFINE_VMK_ERR(VMK_NO_FIFO_READER,           "Unable to open writer if no fifo reader",    ENXIO       )\
+   DEFINE_VMK_ERR(VMK_NO_SUCH_DEVICE,           "No underlying device for major,minor",       EINVAL      )\
+   DEFINE_VMK_ERR(VMK_MEM_MIN_GT_MEMSIZE,       "Memory min exceeds memSize",                 EINVAL      )\
+   DEFINE_VMK_ERR(VMK_NO_SUCH_VT,               "No virtual terminal for number",             ENXIO       )\
+   DEFINE_VMK_ERR(VMK_TOO_MANY_ELEMENTS,        "Too many elements for list",                 E2BIG       )\
+   DEFINE_VMK_ERR(VMK_SHAREDAREA_MISMATCH,      "VMM<->VMK shared are mismatch",              ENOSYS      )\
+   DEFINE_VMK_ERR(VMK_EXEC_FAILURE,             "Failure during exec while original state already lost", ESRCH)\
+   DEFINE_VMK_ERR(VMK_VMNIXMOD_NOT_LOADED,      "vmnixmod kernel module not loaded",          ENOSYS      )\
+   DEFINE_VMK_ERR(VMK_INVALID_MODULE,		"Invalid module",			      EINVAL      )\
+   DEFINE_VMK_ERR(VMK_UNALIGNED_ADDRESS,        "Address is not aligned on page boundary",    EINVAL      )\
+   DEFINE_VMK_ERR(VMK_NOT_MAPPED,               "Address is not mapped in address space",     ENOMEM      )\
+   DEFINE_VMK_ERR(VMK_NO_MESSAGE_SPACE,         "No space to record a message",               ENOMEM      )\
+   DEFINE_VMK_ERR(VMK_PDI_STACK_OVERFLOW,       "No space left on PDI stack",                 EFBIG      )\
+   DEFINE_VMK_ERR(VMK_EXCEPTION_HANDLER_INVALID,"Invalid exception handler",                  EINVAL      )\
+   DEFINE_VMK_ERR(VMK_EXCEPTION_NOT_HANDLED,    "Exception not handled by exception handler", EINVAL      )\
+   DEFINE_VMK_ERR(VMK_INVALID_MULTIWRITER_OBJECT, "Can't open sparse/TBZ files in multiwriter mode", EDEADLK)\
+   DEFINE_VMK_ERR(VMK_STORAGE_RETRY_OPERATION,	"Transient storage condition, suggest retry",     EAGAIN)\
+   DEFINE_VMK_ERR(VMK_HBA_ERROR,		"Storage initiator error",                    EIO)\
+   DEFINE_VMK_ERR(VMK_TIMER_INIT_FAILED,	"Timer initialization failed",                EINVAL)\
+   DEFINE_VMK_ERR(VMK_MODULE_NOT_FOUND,	        "Module not found",                           ENOENT)\
+   DEFINE_VMK_ERR(VMK_NOT_SOCKET_OWNER,         "Socket not owned by cartel",                 EINVAL)\
+   DEFINE_VMK_ERR(VMK_VSI_HANDLER_NOT_FOUND,    "No VSI handler found for the requested node",ENOENT)\
+   DEFINE_VMK_ERR(VMK_INVALID_MMAPPROTFLAGS,    "Invalid mmap protection flags",              EINVAL)\
+   DEFINE_VMK_ERR(VMK_INVALID_MAPCONTIG_SIZE,   "Invalid chunk size for contiguous mmap ",    EINVAL)\
+   DEFINE_VMK_ERR(VMK_INVALID_MAPCONTIG_MAX,    "Invalid MPN max for contiguous mmap ",       EINVAL)\
+   DEFINE_VMK_ERR(VMK_INVALID_MAPCONTIG_FLAG,   "Invalid mmap flag on contiguous mmap ",      EINVAL)\
+   DEFINE_VMK_ERR(VMK_NOT_LAZY_MMINFO,          "Unexpected fault on pre-faulted memory region",EINVAL)\
+   DEFINE_VMK_ERR(VMK_MMINFO_WONT_SPLIT,        "Memory region cannot be split (remap/unmap)",EINVAL)\
+   DEFINE_VMK_ERR(VMK_NO_CACHE_INFO,            "Cache Information not available",            ENOENT)\
+   DEFINE_VMK_ERR(VMK_CANNOT_REMAP_PINNED_MEMORY, "Cannot remap pinned memory",               EINVAL)\
+   DEFINE_VMK_ERR(VMK_NO_SUCH_CARTELGROUP,      "No cartel group by that name",               ESRCH)\
+   DEFINE_VMK_ERR(VMK_SPLOCKSTATS_DISABLED,     "SPLock stats collection disabled",           EINVAL)\
+   DEFINE_VMK_ERR(VMK_BAD_TAR_IMAGE,            "Boot image is corrupted",                    EINVAL)\
+   DEFINE_VMK_ERR(VMK_BRANCHED_ALREADY,         "Branched file cannot be modified",           EPERM)\
+   DEFINE_VMK_ERR(VMK_NAME_RESERVED_FOR_BRANCH, "Name is reserved for branched file",         EPERM)\
+   DEFINE_VMK_ERR(VMK_CANNOT_BRANCH_UNLINKED,   "Unlinked file cannot be branched",           EPERM)\
+   DEFINE_VMK_ERR(VMK_MAX_RETRIES_EXCEEDED,     "Maximum kernel-level retries exceeded",      EAGAIN)\
+   DEFINE_VMK_ERR(VMK_OPTLOCK_STOLEN,           "Optimistic lock acquired by another host",   EAGAIN)\
+   DEFINE_VMK_ERR(VMK_NOT_MMAPABLE,             "Object cannot be mmapped",                   ENODEV)\
+   DEFINE_VMK_ERR(VMK_INVALID_CPU_AFFINITY,     "Invalid cpu affinity",                       EINVAL)\
+   DEFINE_VMK_ERR(VMK_DEVICE_NOT_PARTOF_LV,     "Device does not contain a logical volume",   ENXIO)\
+   DEFINE_VMK_ERR(VMK_NO_SPACE,                 "No space left on device",                    ENOSPC)\
+   DEFINE_VMK_ERR(VMK_VSI_INVALID_NODE_ID,      "Invalid vsi node ID",                        EINVAL)\
+   DEFINE_VMK_ERR(VMK_TOO_MANY_USERS,           "Too many users accessing this resource",     EUSERS)\
+   DEFINE_VMK_ERR(VMK_EALREADY,			"Operation already in progress",	      EALREADY)\
+   DEFINE_VMK_ERR(VMK_BUF_TOO_SMALL,            "Buffer too small to complete the operation", EINVAL) \
+   DEFINE_VMK_ERR(VMK_SNAPSHOT_DEV_DISALLOWED,  "Snapshot device disallowed",                 EACCES)\
+   DEFINE_VMK_ERR(VMK_LVM_DEVICE_UNREACHABLE,   "LVM device unreachable",                     EIO)\
+   DEFINE_VMK_ERR(VMK_CPU_INVALID_RESOURCE_UNITS, "Invalid cpu resource units",               EINVAL)\
+   DEFINE_VMK_ERR(VMK_MEM_INVALID_RESOURCE_UNITS, "Invalid memory resource units",            EINVAL)\
+   DEFINE_VMK_ERR(VMK_ABORTED,                  "IO was aborted",                             ECANCELED)\
+   DEFINE_VMK_ERR(VMK_MEM_MIN_LT_RESERVED,      "Memory min less than memory already reserved by children", ENOSPC	  )\
+   DEFINE_VMK_ERR(VMK_MEM_MIN_LT_CONSUMED,      "Memory min less than memory required to support current consumption", ENOSPC	  )\
+   DEFINE_VMK_ERR(VMK_MEM_MAX_LT_CONSUMED,      "Memory max less than memory required to support current consumption", ENOSPC	  )\
+   DEFINE_VMK_ERR(VMK_TIMEOUT_RETRY,            "Timeout (ok to retry)",                      ETIMEDOUT)\
+   DEFINE_VMK_ERR(VMK_RESERVATION_LOST,         "Reservation Lost",                           EBUSY)\
+   DEFINE_VMK_ERR(VMK_FS_STALE_METADATA,        "Cached metadata is stale",                   ENOENT)\
+   DEFINE_VMK_ERR(VMK_NO_FCNTL_LOCK,            "No fcntl lock slot left",                    ENOLCK)\
+   DEFINE_VMK_ERR(VMK_NO_FCNTL_LOCK_HOLDER,     "No fcntl lock holder slot left",             ENOLCK)\
+   DEFINE_VMK_ERR(VMK_NO_LICENSE,               "Not licensed to access VMFS volumes",        EACCES)\
+   DEFINE_VMK_ERR(VMK_VSI_MODULE_NOT_FOUND,     "Vmkernel module necessary for this vsi call not loaded",    ENOENT)\
+   DEFINE_VMK_ERR(VMK_LVM_RETRY_OPERATION,      "Transient LVM device condition, suggest retry", EAGAIN)\
+   DEFINE_VMK_ERR(VMK_SNAPSHOT_LV_INCOMPLETE,   "Snapshot LV incomplete",                        EAGAIN)\
+   DEFINE_VMK_ERR(VMK_MEDIUM_NOT_FOUND,         "Medium not found",                           EIO)\
+   DEFINE_VMK_ERR(VMK_MAX_PATHS_CLAIMED,        "Maximum allowed SCSI paths have already been claimed",  ENOMEM)\
+   DEFINE_VMK_ERR(VMK_NOT_MOUNTABLE,            "Filesystem is not mountable",                ENODEV)\
+   DEFINE_VMK_ERR(VMK_MEMSIZE_GT_MEMSIZELIMIT,  "Memory size exceeds memSizeLimit",           EINVAL)\
+   DEFINE_VMK_ERR(VMK_RECORD_WRITE_ERROR,       "An error occurred trying to write to the log",                EIO)\
+   DEFINE_VMK_ERR(VMK_REPLAY_READ_ERROR,        "An error occurred trying to read from the log",                EIO)\
+   DEFINE_VMK_ERR(VMK_REPLAY_TYPE_MISMATCH,     "There was a type mismatch while reading from the log",                EIO)\
+   DEFINE_VMK_ERR(VMK_REPLAY_DIVERGENCE,        "A divergence was detected during replay",                EIO)\
+   DEFINE_VMK_ERR(VMK_FT_NOT_RESPONDING,        "The remote side of an FT pair isn't responding",                ENOTCONN)\
+   DEFINE_VMK_ERR(VMK_NET_REPLAY_ERROR,         "An error occurred during replay of networking.",                EIO)\
+/* 
+ * --- ADD NEW ERROR CODES ABOVE THIS COMMENT. --- VMK_GENERIC_LINUX_ERROR must be last.                   \
+ */                                                                                                        \
+   DEFINE_VMK_ERR_AT(VMK_GENERIC_LINUX_ERROR,   "Generic service console error", 0x2bad0000,  EIO         )
+/* --- Don't add ERR_AT with negative value. --- */
+
+
+
+/*
+ * types
+ */ 
+#define DEFINE_VMK_ERR(_err, _str, _uerr) _err,
+#define DEFINE_VMK_ERR_AT(_err, _str, _val, _uerr) _err = _val,
+typedef enum {
+   VMK_ERROR_CODES
+} VMK_ReturnStatus;
+#undef DEFINE_VMK_ERR
+#undef DEFINE_VMK_ERR_AT
+
+#endif //_VMKAPI_STATUS_H_
--- kernel/linux-2.6.26.3/drivers/net/vmxnet/vmkapi_types.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/net/vmxnet/vmkapi_types.h	2008-09-03 09:57:35.000000000 -0500
@@ -0,0 +1,109 @@
+/*********************************************************
+ * Copyright (C) 1998-2004 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * @VMKAPIMOD_LICENSE@
+ */
+
+/*
+ * vmkapi_types.h --
+ *
+ *	Defines the basic types used in the VMKernel API
+ */
+
+#ifndef _VMKAPI_TYPES_H_
+#define _VMKAPI_TYPES_H_
+
+#define INCLUDE_ALLOW_VMKERNEL
+#define INCLUDE_ALLOW_VMKDRIVERS
+#define INCLUDE_ALLOW_VMK_MODULE
+#define INCLUDE_ALLOW_VMK_MODULE
+#define INCLUDE_ALLOW_DISTRIBUTE
+#define INCLUDE_ALLOW_VMNIXMOD
+#define INCLUDE_ALLOW_VMMEXT
+#define INCLUDE_ALLOW_USERLEVEL
+#define INCLUDE_ALLOW_MODULE
+
+#include "includeCheck.h"
+
+/*
+ * Branch prediction hints:
+ *     VMK_LIKELY(exp)   - Expression exp is likely true.
+ *     VMK_UNLIKELY(exp) - Expression exp is likely false.
+ */
+
+#if (__GNUC__ >= 3)
+/*
+ * gcc3 uses __builtin_expect() to inform the compiler of an expected value.
+ * We use this to inform the static branch predictor. The '!!' in VMK_LIKELY
+ * will convert any !=0 to a 1.
+ */
+#  define VMK_LIKELY(_exp)     __builtin_expect(!!(_exp), 1)
+#  define VMK_UNLIKELY(_exp)   __builtin_expect((_exp), 0)
+#else
+#  define VMK_LIKELY(_exp)      (_exp)
+#  define VMK_UNLIKELY(_exp)    (_exp)
+#endif
+
+typedef enum { VMK_FALSE, VMK_TRUE } vmk_Bool;
+
+typedef signed char        vmk_int8;
+typedef unsigned char      vmk_uint8;
+typedef short              vmk_int16;
+typedef unsigned short     vmk_uint16;
+typedef int                vmk_int32;
+typedef unsigned int       vmk_uint32;
+
+#if defined(__ia64__) || defined(__x86_64__)
+typedef long               vmk_int64;
+typedef unsigned long      vmk_uint64;
+typedef vmk_uint64         vmk_VirtAddr;
+#else
+typedef long long          vmk_int64;
+typedef unsigned long long vmk_uint64;
+typedef vmk_uint32         vmk_VirtAddr;
+#endif
+
+typedef vmk_uint32	   vmk_MachPage;
+typedef vmk_uint64         vmk_MachAddr;
+typedef unsigned long      vmk_size_t;
+typedef long               vmk_ssize_t;
+typedef long long          vmk_loff_t;
+
+/**
+ * \brief Abstract address
+ */
+typedef union {
+   vmk_VirtAddr addr;
+   void *ptr;
+} vmk_AddrCookie __attribute__ ((__transparent_union__));
+
+/**
+ *  \brief Wrapper for 64 bit signed and unsigned constants
+ */
+#if defined(__ia64__) || defined(__x86_64__)
+#define VMK_CONST64(c)     c##L
+#define VMK_CONST64U(c)    c##UL
+#else
+#define VMK_CONST64(c)     c##LL
+#define VMK_CONST64U(c)    c##ULL
+#endif
+
+
+
+#endif //_VMKAPI_TYPES_H_
--- kernel/linux-2.6.26.3/drivers/net/vmxnet/vmnet_def.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/net/vmxnet/vmnet_def.h	2008-09-03 10:07:45.000000000 -0500
@@ -0,0 +1,64 @@
+/*********************************************************
+ * Copyright (C) 2004 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * vmnet_def.h 
+ *
+ *     - definitions which are (mostly) not vmxnet or vlance specific
+ */
+
+#ifndef _VMNET_DEF_H_
+#define _VMNET_DEF_H_
+
+#define INCLUDE_ALLOW_USERLEVEL
+#define INCLUDE_ALLOW_VMMEXT
+#define INCLUDE_ALLOW_MODULE
+#define INCLUDE_ALLOW_VMK_MODULE
+#define INCLUDE_ALLOW_VMKERNEL
+#define INCLUDE_ALLOW_DISTRIBUTE
+#define INCLUDE_ALLOW_VMNIXMOD
+#include "includeCheck.h"
+
+/*
+ * capabilities - not all of these are implemented in the virtual HW
+ *                (eg VLAN support is in the virtual switch)  so even vlance 
+ *                can use them
+ */
+#define VMNET_CAP_SG	        0x0001	/* Can do scatter-gather transmits. */
+#define VMNET_CAP_IP4_CSUM      0x0002	/* Can checksum only TCP/UDP over IPv4. */
+#define VMNET_CAP_HW_CSUM       0x0004	/* Can checksum all packets. */
+#define VMNET_CAP_HIGH_DMA      0x0008	/* Can DMA to high memory. */
+#define VMNET_CAP_TOE	        0x0010	/* Supports TCP/IP offload. */
+#define VMNET_CAP_TSO	        0x0020	/* Supports TCP Segmentation offload */
+#define VMNET_CAP_SW_TSO        0x0040	/* Supports SW TCP Segmentation */
+#define VMNET_CAP_VMXNET_APROM  0x0080	/* Vmxnet APROM support */
+#define VMNET_CAP_HW_TX_VLAN    0x0100  /* Can we do VLAN tagging in HW */
+#define VMNET_CAP_HW_RX_VLAN    0x0200  /* Can we do VLAN untagging in HW */
+#define VMNET_CAP_SW_VLAN       0x0400  /* Can we do VLAN tagging/untagging in SW */
+#define VMNET_CAP_WAKE_PCKT_RCV 0x0800  /* Can wake on network packet recv? */
+#define VMNET_CAP_ENABLE_INT_INLINE 0x1000  /* Enable Interrupt Inline */
+#define VMNET_CAP_ENABLE_HEADER_COPY 0x2000  /* copy header for vmkernel */
+#define VMNET_CAP_TX_CHAIN      0x4000  /* Guest can use multiple tx entries for a pkt */
+#define VMNET_CAP_RX_CHAIN      0x8000  /* a pkt can span multiple rx entries */
+#define VMNET_CAP_LPD           0x10000 /* large pkt delivery */
+#define VMNET_CAP_BPF           0x20000 /* BPF Support in VMXNET Virtual Hardware */
+#define VMNET_CAP_SG_SPAN_PAGES 0x40000	/* Can do scatter-gather span multiple pages transmits. */
+#define VMNET_CAP_IP6_CSUM      0x80000	/* Can do IPv6 csum offload. */
+#define VMNET_CAP_TSO6         0x100000	/* Can do TSO segmentation offload for IPv6 pkts. */
+#define VMNET_CAP_TSO256k      0x200000	/* Can do TSO segmentation offload for pkts up to 256kB. */
+#endif // _VMNET_DEF_H_
--- kernel/linux-2.6.26.3/drivers/net/vmxnet/vmxnet2_def.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/net/vmxnet/vmxnet2_def.h	2008-09-03 10:07:45.000000000 -0500
@@ -0,0 +1,416 @@
+/*********************************************************
+ * Copyright (C) 2004 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef _VMXNET2_DEF_H_
+#define _VMXNET2_DEF_H_
+
+#define INCLUDE_ALLOW_USERLEVEL
+#define INCLUDE_ALLOW_VMMEXT
+#define INCLUDE_ALLOW_MODULE
+#define INCLUDE_ALLOW_VMK_MODULE
+#define INCLUDE_ALLOW_VMKERNEL
+#define INCLUDE_ALLOW_DISTRIBUTE
+#include "includeCheck.h"
+
+#include "net_sg.h"
+#include "vmxnet_def.h"
+
+
+/*
+ * Magic number that identifies this version of the vmxnet protocol.
+ */
+#define VMXNET2_MAGIC			0xbabe864f
+
+/* size of the rx ring */
+#define VMXNET2_MAX_NUM_RX_BUFFERS		128
+#define VMXNET2_DEFAULT_NUM_RX_BUFFERS	        100
+
+
+/* size of the rx ring when enhanced vmxnet is used */
+#define ENHANCED_VMXNET2_MAX_NUM_RX_BUFFERS     512 
+#define ENHANCED_VMXNET2_DEFAULT_NUM_RX_BUFFERS 150 
+
+/* size of the 2nd rx ring */
+#define VMXNET2_MAX_NUM_RX_BUFFERS2             2048 
+#define VMXNET2_DEFAULT_NUM_RX_BUFFERS2	        512
+
+/* size of the tx ring */
+#define VMXNET2_MAX_NUM_TX_BUFFERS		128
+#define VMXNET2_DEFAULT_NUM_TX_BUFFERS	        100
+
+/* size of the tx ring when tso/jf is used */
+#define VMXNET2_MAX_NUM_TX_BUFFERS_TSO          512
+#define VMXNET2_DEFAULT_NUM_TX_BUFFERS_TSO	256
+
+enum {
+   VMXNET2_OWNERSHIP_DRIVER,
+   VMXNET2_OWNERSHIP_DRIVER_PENDING,
+   VMXNET2_OWNERSHIP_NIC,
+   VMXNET2_OWNERSHIP_NIC_PENDING,
+   VMXNET2_OWNERSHIP_NIC_FRAG,
+   VMXNET2_OWNERSHIP_DRIVER_FRAG,
+};
+
+#define VMXNET2_SG_DEFAULT_LENGTH	6
+
+typedef struct Vmxnet2_SG_Array {
+   uint16	addrType;
+   uint16	length;
+   NetSG_Elem	sg[VMXNET2_SG_DEFAULT_LENGTH];
+} Vmxnet2_SG_Array;
+
+typedef struct Vmxnet2_RxRingEntry {
+   uint64		paddr;		/* Physical address of the packet data. */
+   uint32		bufferLength;	/* The length of the data at paddr. */
+   uint32		actualLength;	/* The actual length of the received data. */
+   uint16               ownership;	/* Who owns the packet. */
+   uint16		flags;		/* Flags as defined below. */
+   uint32               index;          /* 
+                                         * Currently:
+                                         *
+                                         * This is being used as an packet index to
+                                         * rx buffers.
+                                         *
+                                         * Originally: 
+                                         *
+					 * was void* driverData ("Driver specific data.")
+					 * which was used for sk_buf**s in Linux and
+                                         * VmxnetRxBuff*s in Windows.  It could not be
+					 * here because the structure needs to be the
+					 * same size between architectures, and it was
+					 * not used on the device side, anyway.  Look
+					 * for its replacement in
+					 * Vmxnet_Private.rxRingBuffPtr on Linux and
+					 * VmxnetAdapter.rxRingBuffPtr on Windows.
+					 */
+} Vmxnet2_RxRingEntry;
+
+/*
+ * Vmxnet2_RxRingEntry flags:
+ * 
+ * VMXNET2_RX_HW_XSUM_OK       The hardware verified the TCP/UDP checksum.
+ * VMXNET2_RX_WITH_FRAG        More data is in the 2nd ring
+ * VMXNET2_RX_FRAG_EOP         This is the last frag, the only valid flag for
+ *                             2nd ring entry
+ *
+ */
+#define VMXNET2_RX_HW_XSUM_OK  0x01
+#define VMXNET2_RX_WITH_FRAG   0x02
+#define VMXNET2_RX_FRAG_EOP    0x04
+
+typedef struct Vmxnet2_TxRingEntry {
+   uint16		flags;		/* Flags as defined below. */
+   uint16 	        ownership;	/* Who owns this packet. */
+   uint32               extra;          /*
+					 * was void* driverData ("Driver specific data.")
+					 * which was used for sk_buf*s in Linux and
+                                         * VmxnetTxInfo*s in Windows.  It could not be
+					 * here because the structure needs to be the
+					 * same size between architectures, and it was
+					 * not used on the device side, anyway.  Look
+					 * for its replacement in
+					 * Vmxnet_Private.txRingBuffPtr on Linux and
+					 * VmxnetAdapter.txRingBuffPtr on Windows.
+					 */
+   uint32               tsoMss;         /* TSO pkt MSS */
+   Vmxnet2_SG_Array	sg;		/* Packet data. */
+} Vmxnet2_TxRingEntry;
+
+/*
+ * Vmxnet2_TxRingEntry flags:
+ *
+ *   VMXNET2_TX_CAN_KEEP	The implementation can return the tx ring entry 
+ *				to the driver when it is ready as opposed to 
+ *				before the transmit call from the driver completes.
+ *   VMXNET2_TX_RING_LOW	The driver's transmit ring buffer is low on free
+ *				slots.
+ *   VMXNET2_TX_HW_XSUM         The hardware should perform the TCP/UDP checksum
+ *   VMXNET2_TX_TSO             The hardware should do TCP segmentation.
+ *   VMXNET2_TX_PINNED_BUFFER   The driver used one of the preallocated vmkernel
+ *                              buffers *and* it has been pinned with Net_PinTxBuffers.
+ *   VMXNET2_TX_MORE            This is *not* the last tx entry for the pkt.
+ *                              All flags except VMXNET2_TX_MORE are ignored
+ *                              for the subsequent tx entries.
+ */
+#define VMXNET2_TX_CAN_KEEP	     0x0001
+#define VMXNET2_TX_RING_LOW	     0x0002
+#define VMXNET2_TX_HW_XSUM           0x0004
+#define VMXNET2_TX_TSO	             0x0008
+#define VMXNET2_TX_PINNED_BUFFER     0x0010
+#define VMXNET2_TX_MORE              0x0020
+
+/*
+ * Structure used by implementations.  This structure allows the inline
+ * functions below to be used.
+ */
+typedef struct Vmxnet2_RxRingInfo {
+   Vmxnet2_RxRingEntry    *base;       /* starting addr of the ring */
+   uint32                  nicNext;    /* next entry to use in the ring */
+   uint32                  ringLength; /* # of entries in the ring */
+   PA                      startPA;    /* PA of the starting addr of the ring */
+#ifdef VMX86_DEBUG
+   const char             *name;
+#endif
+} Vmxnet2_RxRingInfo;
+
+typedef struct Vmxnet2_TxRingInfo {
+   Vmxnet2_TxRingEntry    *base;       /* starting addr of the ring */
+   uint32                  nicNext;    /* next entry to use in the ring */
+   uint32                  ringLength; /* # of entries in the ring */
+   PA                      startPA;    /* PA of the starting addr of the ring */
+#ifdef VMX86_DEBUG
+   const char             *name;
+#endif
+} Vmxnet2_TxRingInfo;
+
+typedef struct Vmxnet2_ImplData {
+   Vmxnet2_RxRingInfo    rxRing;
+   Vmxnet2_RxRingInfo    rxRing2;
+   Vmxnet2_TxRingInfo    txRing;
+
+   struct PhysMem_Token	  *ddPhysMemToken;
+} Vmxnet2_ImplData;
+
+/* 
+ * Used internally for performance studies. By default this will be off so there 
+ * should be no compatibilty or other interferences.
+ */
+
+/* #define ENABLE_VMXNET2_PROFILING    */
+
+
+#ifdef ENABLE_VMXNET2_PROFILING
+typedef struct Vmxnet2_VmmStats {
+   uint64      vIntTSC;             /* the time that virtual int was posted */
+   uint64      actionsCount;        /* Number of actions received */
+   uint64      numWasteActions;     /* Number of non-productive actions */
+}  Vmxnet2_VmmStats;
+#endif
+
+typedef struct Vmxnet2_DriverStats {
+   uint32	transmits;	   /* # of times that the drivers transmit function */
+				   /*   is called. The driver could transmit more */
+				   /*   than one packet per call. */
+   uint32	pktsTransmitted;   /* # of packets transmitted. */
+   uint32	noCopyTransmits;   /* # of packets that are transmitted without */
+				   /*   copying any data. */
+   uint32	copyTransmits;	   /* # of packets that are transmittted by copying */
+				   /*   the data into a buffer. */
+   uint32	maxTxsPending;	   /* Max # of transmits outstanding. */
+   uint32	txStopped;	   /* # of times that transmits got stopped because */
+				   /*   the tx ring was full. */
+   uint32	txRingOverflow;	   /* # of times that transmits got deferred bc */
+				   /*   the tx ring was full.  This must be >= */
+				   /*   txStopped since there will be one */
+				   /*   txStopped when the ring fills up and then */
+				   /*   one txsRingOverflow for each packet that */
+				   /*   that gets deferred until there is space. */
+   uint32	interrupts;	   /* # of times interrupted. */
+   uint32	pktsReceived;	   /* # of packets received. */
+   uint32	rxBuffersLow;	   /* # of times that the driver was low on */
+				   /*   receive buffers. */
+#ifdef ENABLE_VMXNET2_PROFILING
+    Vmxnet2_VmmStats  vmmStats;     /* vmm related stats for perf study */
+#endif
+} Vmxnet2_DriverStats;
+
+/*
+ * Shared data structure between the vm, the vmm, and the vmkernel.
+ * This structure was originally arranged to try to group common data 
+ * on 32-byte cache lines, but bit rot and the fact that we no longer
+ * run on many CPUs with that cacheline size killed that optimization.
+ * vmxnet3 should target 128 byte sizes and alignments to optimize for
+ * the 64 byte cacheline pairs on P4.
+ */
+typedef struct Vmxnet2_DriverData {
+   /*
+    * Magic must be first.
+    */
+   Vmxnet_DDMagic       magic;
+
+   /*
+    * Receive fields. 
+    */
+   uint32		rxRingLength;		/* Length of the receive ring. */
+   uint32		rxDriverNext;		/* Index of the next packet that will */
+						/*   be filled in by the impl */
+
+   uint32		rxRingLength2;	        /* Length of the 2nd receive ring. */
+   uint32		rxDriverNext2;	        /* Index of the next packet that will */
+						/*   be filled in by the impl */
+
+   uint32		notUsed1;               /* was "irq" */
+
+   /*
+    * Interface flags and multicast filter.
+    */
+   uint32		ifflags;
+   uint32		LADRF[VMXNET_MAX_LADRF];
+
+   /*
+    * Transmit fields
+    */
+   uint32               txDontClusterSize;      /* All packets <= this will be transmitted */
+                                                /* immediately, regardless of clustering */
+                                                /* settings [was fill[1]] */
+   uint32		txRingLength;		/* Length of the transmit ring. */
+   uint32		txDriverCur;		/* Index of the next packet to be */
+						/*   returned by the implementation.*/
+   uint32		txDriverNext;		/* Index of the entry in the ring */
+						/*   buffer to use for the next packet.*/
+   uint32		txStopped;  		/* The driver has stopped transmitting */
+						/*   because its ring buffer is full.*/
+   uint32		txClusterLength;	/* Maximum number of packets to */
+						/*   put in the ring buffer before */
+						/*   asking the implementation to */
+						/*   transmit the packets in the buffer.*/
+   uint32		txNumDeferred;          /* Number of packets that have been */
+						/*   queued in the ring buffer since */
+						/*   the last time the implementation */
+						/*   was asked to transmit. */
+   uint32		notUsed3;               /* This field is deprecated but still used */
+                                                /* as minXmitPhysLength on the escher branch. */
+                                                /* It cannot be used for other purposes */
+                                                /* until escher vms no longer are allowed */
+                                                /* to install this driver. */
+
+   uint32              totalRxBuffers;          /* used by esx for max rx buffers */
+   uint64              rxBufferPhysStart;       /* used by esx for pinng rx buffers */
+   /*
+    * Extra fields for future expansion.
+    */
+   uint32		extra[2];
+
+   uint16               maxFrags;               /* # of frags the driver can handle */
+   uint16               featureCtl;             /* for driver to enable some feature */
+
+   /*
+    * The following fields are used to save the nicNext indexes part
+    * of implData in the vmkernel when disconnecting the adapter, we
+    * need them when we reconnect.  This mechanism is used for
+    * checkpointing as well.
+    */
+   uint32               savedRxNICNext;
+   uint32               savedRxNICNext2;
+   uint32               savedTxNICNext;
+
+   /*
+    * Fields used during initialization or debugging.
+    */
+   uint32		length;
+   uint32		rxRingOffset;
+   uint32		rxRingOffset2;
+   uint32		txRingOffset;   
+   uint32		debugLevel;
+   uint32		txBufferPhysStart;
+   uint32		txBufferPhysLength;
+   uint32		txPktMaxSize;
+
+   /*
+    * Driver statistics.
+    */
+   Vmxnet2_DriverStats	stats;
+} Vmxnet2_DriverData;
+
+/* 
+ * Shared between VMM and Vmkernel part of vmxnet2 to optimize action posting
+ * VMM writes 1 (don't post) or 0 (okay to post) and vmk reads this.
+ */
+typedef struct VmxnetVMKShared {
+   uint32  dontPostActions;  
+} VmxnetVMKShared;
+
+/*
+ * Inline functions used to assist the implementation of the vmxnet interface.
+ */
+
+/*
+ * Get the next empty packet out of the receive ring and move to 
+ * the next packet.
+ */
+static INLINE Vmxnet2_RxRingEntry *
+Vmxnet2_GetNextRx(Vmxnet2_RxRingInfo *ri, uint16 ownership)
+{
+   Vmxnet2_RxRingEntry *rre = ri->base + ri->nicNext;
+   if (rre->ownership == ownership) {
+      VMXNET_INC(ri->nicNext, ri->ringLength);
+   } else {
+      rre = NULL;
+   }
+
+   return rre;
+}
+
+/*
+ * Return ownership of a packet in the receive ring to the driver.
+ */
+static INLINE void
+Vmxnet2_PutRx(Vmxnet2_RxRingEntry *rre, uint32 pktLength, uint16 ownership)
+{
+   rre->actualLength = pktLength;
+   rre->ownership = ownership;
+}
+
+/*
+ * Get the next pending packet out of the transmit ring.
+ */
+static INLINE Vmxnet2_TxRingEntry *
+Vmxnet2_GetNextTx(Vmxnet2_TxRingInfo *ri)
+{
+   Vmxnet2_TxRingEntry *txre = ri->base + ri->nicNext;
+   if (txre->ownership == VMXNET2_OWNERSHIP_NIC) {
+      return txre;
+   } else {
+      return NULL;
+   }
+}
+
+/*
+ * Move to the next entry in the transmit ring.
+ */
+static INLINE unsigned int
+Vmxnet2_IncNextTx(Vmxnet2_TxRingInfo *ri)
+{
+   unsigned int prev = ri->nicNext;
+   Vmxnet2_TxRingEntry *txre = ri->base + ri->nicNext;
+   
+   txre->ownership = VMXNET2_OWNERSHIP_NIC_PENDING;
+
+   VMXNET_INC(ri->nicNext, ri->ringLength);
+   return prev;
+}
+
+/*
+ * Get the indicated entry from transmit ring.
+ */
+static INLINE Vmxnet2_TxRingEntry *
+Vmxnet2_GetTxEntry(Vmxnet2_TxRingInfo *ri, unsigned int idx)
+{
+   return ri->base + idx;
+}
+
+/*
+ * Get the indicated entry from the given rx ring
+ */
+static INLINE Vmxnet2_RxRingEntry *
+Vmxnet2_GetRxEntry(Vmxnet2_RxRingInfo *ri, unsigned int idx)
+{
+   return ri->base + idx;
+}
+#endif
+
--- kernel/linux-2.6.26.3/drivers/net/vmxnet/vmxnet.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/net/vmxnet/vmxnet.c	2008-09-03 10:07:45.000000000 -0500
@@ -0,0 +1,2494 @@
+/*********************************************************
+ * Copyright (C) 1999 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * vmxnet.c: A virtual network driver for VMware.
+ */
+#include "driver-config.h"
+#include "compat_module.h"
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 9)
+#include <linux/moduleparam.h>
+#endif
+
+#include "compat_slab.h"
+#include "compat_spinlock.h"
+#include "compat_pci.h"
+#include "compat_init.h"
+#include "compat_timer.h"
+#include <asm/dma.h>
+#include <asm/page.h>
+#include <asm/uaccess.h>
+
+#include "compat_ethtool.h"
+#include "compat_netdevice.h"
+#include "compat_skbuff.h"
+#include <linux/etherdevice.h>
+#include "compat_ioport.h"
+#ifndef KERNEL_2_1
+#include <linux/delay.h>
+#endif
+#include "compat_interrupt.h"
+
+#include "vm_basic_types.h"
+#include "vmnet_def.h"
+#include "vmxnet_def.h"
+#include "vmxnet2_def.h"
+#include "vm_device_version.h"
+#include "vmxnetInt.h"
+#include "net.h"
+#include "vmxnet_version.h"
+
+static int vmxnet_debug = 1;
+
+#define VMXNET_WATCHDOG_TIMEOUT (5 * HZ)
+
+#if defined(CONFIG_NET_POLL_CONTROLLER) || defined(HAVE_POLL_CONTROLLER)
+#define VMW_HAVE_POLL_CONTROLLER
+#endif
+
+static int vmxnet_open(struct net_device *dev);
+static int vmxnet_start_tx(struct sk_buff *skb, struct net_device *dev);
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 19)
+static compat_irqreturn_t vmxnet_interrupt(int irq, void *dev_id,
+					   struct pt_regs * regs);
+#else
+static compat_irqreturn_t vmxnet_interrupt(int irq, void *dev_id);
+#endif
+#ifdef VMW_HAVE_POLL_CONTROLLER
+static void vmxnet_netpoll(struct net_device *dev);
+#endif
+static int vmxnet_close(struct net_device *dev);
+static void vmxnet_set_multicast_list(struct net_device *dev);
+static int vmxnet_set_mac_address(struct net_device *dev, void *addr);
+static struct net_device_stats *vmxnet_get_stats(struct net_device *dev);
+#ifdef HAVE_CHANGE_MTU
+static int vmxnet_change_mtu(struct net_device *dev, int new_mtu);
+#endif
+
+static int vmxnet_probe_device(struct pci_dev *pdev, const struct pci_device_id *id);
+static void vmxnet_remove_device(struct pci_dev *pdev);
+
+#ifdef MODULE
+static int debug = -1;
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 9)
+   module_param(debug, int, 0444);
+#else
+   MODULE_PARM(debug, "i");
+#endif
+#endif
+
+#ifdef VMXNET_DO_ZERO_COPY
+#undef VMXNET_DO_ZERO_COPY
+#endif
+
+#if defined(MAX_SKB_FRAGS) && ( LINUX_VERSION_CODE >= KERNEL_VERSION(2,4,18) ) && ( LINUX_VERSION_CODE != KERNEL_VERSION(2, 6, 0) )
+#define VMXNET_DO_ZERO_COPY
+#endif
+
+#ifdef VMXNET_DO_ZERO_COPY
+#include <net/checksum.h>
+#include <linux/ip.h>
+#include <linux/in.h>
+#include <linux/tcp.h>
+
+/*
+ * Tx buffer size that we need for copying header
+ * max header is: 14(ip) + 4(vlan) + ip (60) + tcp(60) = 138
+ * round it up to the power of 2
+ */
+#define TX_PKT_HEADER_SIZE      256
+
+/* Constants used for Zero Copy Tx */
+#define ETHERNET_HEADER_SIZE           14
+#define VLAN_TAG_LENGTH                4
+#define ETH_FRAME_TYPE_LOCATION        12
+#define ETH_TYPE_VLAN_TAG              0x0081 /* in NBO */
+#define ETH_TYPE_IP                    0x0008 /* in NBO */
+
+#define PKT_OF_PROTO(skb, type) \
+   (*(uint16*)(skb->data + ETH_FRAME_TYPE_LOCATION) == (type) || \
+    (*(uint16*)(skb->data + ETH_FRAME_TYPE_LOCATION) == ETH_TYPE_VLAN_TAG && \
+     *(uint16*)(skb->data + ETH_FRAME_TYPE_LOCATION + VLAN_TAG_LENGTH) == (type)))
+
+#define PKT_OF_IPV4(skb) PKT_OF_PROTO(skb, ETH_TYPE_IP)
+
+#define VMXNET_GET_LO_ADDR(dma)   ((uint32)(dma))
+#define VMXNET_GET_HI_ADDR(dma)   ((uint16)(((uint64)(dma)) >> 32))
+#define VMXNET_GET_DMA_ADDR(sge)  ((dma_addr_t)((((uint64)(sge).addrHi) << 32) | (sge).addrLow))
+
+#define VMXNET_FILL_SG(sg, dma, size)\
+do{\
+   (sg).addrLow = VMXNET_GET_LO_ADDR(dma);\
+   (sg).addrHi  = VMXNET_GET_HI_ADDR(dma);\
+   (sg).length  = size;\
+} while (0)
+
+#if defined(NETIF_F_TSO)
+#define VMXNET_DO_TSO
+
+#if defined(NETIF_F_GSO) /* 2.6.18 and upwards */
+#define VMXNET_SKB_MSS(skb) skb_shinfo(skb)->gso_size
+#else
+#define VMXNET_SKB_MSS(skb) skb_shinfo(skb)->tso_size
+#endif
+#endif
+
+#endif // VMXNET_DO_ZERO_COPY
+
+#ifdef VMXNET_DEBUG
+#define VMXNET_LOG(msg...) printk(KERN_ERR msg)
+#else
+#define VMXNET_LOG(msg...)
+#endif // VMXNET_DEBUG
+
+/* Data structure used when determining what hardware the driver supports. */
+
+static const struct pci_device_id vmxnet_chips[] =
+   {
+      {
+         PCI_DEVICE(PCI_VENDOR_ID_VMWARE, PCI_DEVICE_ID_VMWARE_NET),
+         .driver_data = VMXNET_CHIP,
+      },
+      {
+         PCI_DEVICE(PCI_VENDOR_ID_AMD, PCI_DEVICE_ID_AMD_LANCE),
+         .driver_data = LANCE_CHIP,
+      },
+      {
+         0,
+      },
+   };
+
+static struct pci_driver vmxnet_driver = {
+					    .name = "vmxnet",
+                                            .id_table = vmxnet_chips,
+                                            .probe = vmxnet_probe_device,
+                                            .remove = vmxnet_remove_device,
+                                         };
+
+#ifdef HAVE_CHANGE_MTU
+static int
+vmxnet_change_mtu(struct net_device *dev, int new_mtu)
+{
+   struct Vmxnet_Private *lp = (struct Vmxnet_Private *)dev->priv;
+
+   if (new_mtu < VMXNET_MIN_MTU || new_mtu > VMXNET_MAX_MTU) {
+      return -EINVAL;
+   }
+
+   if (new_mtu > 1500 && !lp->jumboFrame) {
+      return -EINVAL;
+   }
+
+   dev->mtu = new_mtu;
+   return 0;
+}
+
+#endif
+
+
+#ifdef SET_ETHTOOL_OPS
+/*
+ *----------------------------------------------------------------------------
+ *
+ * vmxnet_get_settings --
+ *
+ *      Get device-specific settings.
+ *
+ * Results:
+ *      0 on success, errno on failure.
+ *
+ * Side effects:
+ *      None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+static int
+vmxnet_get_settings(struct net_device *dev,
+                    struct ethtool_cmd *ecmd)
+{
+   ecmd->supported = SUPPORTED_1000baseT_Full | SUPPORTED_TP;
+   ecmd->advertising = ADVERTISED_TP;
+   ecmd->port = PORT_TP;
+   ecmd->transceiver = XCVR_INTERNAL;
+
+   if (netif_carrier_ok(dev)) {
+      ecmd->speed = 1000;
+      ecmd->duplex = DUPLEX_FULL;
+   } else {
+      ecmd->speed = -1;
+      ecmd->duplex = -1;
+   }
+   return 0;
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * vmxnet_get_drvinfo --
+ *
+ *      Ethtool callback to return driver information
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      Updates *drvinfo
+ *
+ *----------------------------------------------------------------------------
+ */
+
+static void
+vmxnet_get_drvinfo(struct net_device *dev,
+                   struct ethtool_drvinfo *drvinfo)
+{
+   struct Vmxnet_Private *lp = dev->priv;
+
+   strncpy(drvinfo->driver, vmxnet_driver.name, sizeof(drvinfo->driver));
+   drvinfo->driver[sizeof(drvinfo->driver) - 1] = '\0';
+
+   strncpy(drvinfo->version, VMXNET_DRIVER_VERSION_STRING,
+           sizeof(drvinfo->version));
+   drvinfo->driver[sizeof(drvinfo->version) - 1] = '\0';
+
+   strncpy(drvinfo->fw_version, "N/A", sizeof(drvinfo->fw_version));
+   drvinfo->fw_version[sizeof(drvinfo->fw_version) - 1] = '\0';
+
+   strncpy(drvinfo->bus_info, compat_pci_name(lp->pdev), ETHTOOL_BUSINFO_LEN);
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ *  vmxnet_set_tso --
+ *
+ *    Ethtool handler to set TSO. If the data is non-zero, TSO is
+ *    enabled. Othewrise, it is disabled.
+ *
+ *  Results:
+ *    0 if successful, error code otherwise.
+ *
+ *  Side effects:
+ *    None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+#ifdef VMXNET_DO_TSO
+static int
+vmxnet_set_tso(struct net_device *dev, u32 data)
+{
+   if (data) {
+      struct Vmxnet_Private *lp = (struct Vmxnet_Private *)dev->priv;
+
+      if (!lp->tso) {
+         return -EINVAL;
+      }
+      dev->features |= NETIF_F_TSO;
+   } else {
+      dev->features &= ~NETIF_F_TSO;
+   }
+   return 0;
+}
+#endif
+
+
+static struct ethtool_ops
+vmxnet_ethtool_ops = {
+   .get_settings        = vmxnet_get_settings,
+   .get_drvinfo         = vmxnet_get_drvinfo,
+   .get_link            = ethtool_op_get_link,
+   .get_sg              = ethtool_op_get_sg,
+   .set_sg              = ethtool_op_set_sg,
+#ifdef VMXNET_DO_TSO
+   .get_tso             = ethtool_op_get_tso,
+   .set_tso             = vmxnet_set_tso,
+#endif
+};
+
+
+#else   /* !defined(SET_ETHTOOL_OPS) */
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ *  vmxnet_get_settings --
+ *
+ *    Ethtool handler to get device settings.
+ *
+ *  Results:
+ *    0 if successful, error code otherwise. Settings are copied to addr.
+ *
+ *  Side effects:
+ *    None.
+ *
+ *
+ *----------------------------------------------------------------------------
+ */
+
+#ifdef ETHTOOL_GSET
+static int
+vmxnet_get_settings(struct net_device *dev, void *addr)
+{
+   struct ethtool_cmd cmd;
+   memset(&cmd, 0, sizeof(cmd));
+   cmd.speed = 1000;     // 1 Gb
+   cmd.duplex = 1;       // full-duplex
+   cmd.maxtxpkt = 1;     // no tx coalescing
+   cmd.maxrxpkt = 1;     // no rx coalescing
+   cmd.autoneg = 0;      // no autoneg
+   cmd.advertising = 0;  // advertise nothing
+
+   return copy_to_user(addr, &cmd, sizeof(cmd));
+}
+#endif
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ *  vmxnet_get_link --
+ *
+ *    Ethtool handler to get the link state.
+ *
+ *  Results:
+ *    0 if successful, error code otherwise. The link status is copied to
+ *    addr.
+ *
+ *  Side effects:
+ *    None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+#ifdef ETHTOOL_GLINK
+static int
+vmxnet_get_link(struct net_device *dev, void *addr)
+{
+   compat_ethtool_value value = {ETHTOOL_GLINK};
+   value.data = netif_carrier_ok(dev) ? 1 : 0;
+   return copy_to_user(addr, &value, sizeof(value));
+}
+#endif
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ *  vmxnet_get_tso --
+ *
+ *    Ethtool handler to get the TSO setting.
+ *
+ *  Results:
+ *    0 if successful, error code otherwise. The TSO setting is copied to
+ *    addr.
+ *
+ *  Side effects:
+ *    None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+#ifdef VMXNET_DO_TSO
+static int
+vmxnet_get_tso(struct net_device *dev, void *addr)
+{
+   compat_ethtool_value value = { ETHTOOL_GTSO };
+   value.data = (dev->features & NETIF_F_TSO) ? 1 : 0;
+   if (copy_to_user(addr, &value, sizeof(value))) {
+       return -EFAULT;
+   }
+   return 0;
+}
+#endif
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ *  vmxnet_set_tso --
+ *
+ *    Ethtool handler to set TSO. If the data in addr is non-zero, TSO is
+ *    enabled. Othewrise, it is disabled.
+ *
+ *  Results:
+ *    0 if successful, error code otherwise.
+ *
+ *  Side effects:
+ *    None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+#ifdef VMXNET_DO_TSO
+static int
+vmxnet_set_tso(struct net_device *dev, void *addr)
+{
+   compat_ethtool_value value;
+   if (copy_from_user(&value, addr, sizeof(value))) {
+      return -EFAULT;
+   }
+
+   if (value.data) {
+      struct Vmxnet_Private *lp = (struct Vmxnet_Private *)dev->priv;
+
+      if (!lp->tso) {
+         return -EINVAL;
+      }
+      dev->features |= NETIF_F_TSO;
+   } else {
+      dev->features &= ~NETIF_F_TSO;
+   }
+   return 0;
+}
+#endif
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ *  vmxnet_ethtool_ioctl --
+ *
+ *    Handler for ethtool ioctl calls.
+ *
+ *  Results:
+ *    If ethtool op is supported, the outcome of the op. Otherwise,
+ *    -EOPNOTSUPP.
+ *
+ *  Side effects:
+ *
+ *
+ *----------------------------------------------------------------------------
+ */
+
+#ifdef SIOCETHTOOL
+static int
+vmxnet_ethtool_ioctl(struct net_device *dev, struct ifreq *ifr)
+{
+   uint32_t cmd;
+   if (copy_from_user(&cmd, ifr->ifr_data, sizeof(cmd))) {
+      return -EFAULT;
+   }
+   switch (cmd) {
+#ifdef ETHTOOL_GSET
+      case ETHTOOL_GSET:
+         return vmxnet_get_settings(dev, ifr->ifr_data);
+#endif
+#ifdef ETHTOOL_GLINK
+      case ETHTOOL_GLINK:
+         return vmxnet_get_link(dev, ifr->ifr_data);
+#endif
+#ifdef VMXNET_DO_TSO
+      case ETHTOOL_GTSO:
+         return vmxnet_get_tso(dev, ifr->ifr_data);
+      case ETHTOOL_STSO:
+         return vmxnet_set_tso(dev, ifr->ifr_data);
+#endif
+      default:
+         printk(KERN_DEBUG" ethtool operation %d not supported\n", cmd);
+         return -EOPNOTSUPP;
+   }
+}
+#endif
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * vmxnet_ioctl --
+ *
+ *    Handler for ioctl calls.
+ *
+ * Results:
+ *    If ioctl is supported, the result of that operation. Otherwise,
+ *    -EOPNOTSUPP.
+ *
+ * Side effects:
+ *    None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+static int
+vmxnet_ioctl(struct net_device *dev, struct ifreq *ifr, int cmd)
+{
+   switch (cmd) {
+#ifdef SIOCETHTOOL
+      case SIOCETHTOOL:
+         return vmxnet_ethtool_ioctl(dev, ifr);
+#endif
+   }
+   printk(KERN_DEBUG" ioctl operation %d not supported\n", cmd);
+   return -EOPNOTSUPP;
+}
+#endif /* SET_ETHTOOL_OPS */
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * vmxnet_init --
+ *
+ *      Initialization, called by Linux when the module is loaded.
+ *
+ * Results:
+ *      Returns 0 for success, negative errno value otherwise.
+ *
+ * Side effects:
+ *      See vmxnet_probe_device, which does all the work.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static int
+vmxnet_init(void)
+{
+   int err;
+
+   if (vmxnet_debug > 0) {
+      vmxnet_debug = debug;
+   }
+
+   printk(KERN_INFO "VMware vmxnet virtual NIC driver\n");
+
+   err = pci_register_driver(&vmxnet_driver);
+   if (err < 0) {
+      return err;
+   }
+   return 0;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * vmxnet_exit --
+ *
+ *      Cleanup, called by Linux when the module is unloaded.
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      Unregisters all vmxnet devices with Linux and frees memory.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static void
+vmxnet_exit(void)
+{
+   pci_unregister_driver(&vmxnet_driver);
+}
+
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,3,43)
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * vmxnet_tx_timeout --
+ *
+ *      Network device tx_timeout routine.  Called by Linux when the tx
+ *      queue has been stopped for more than dev->watchdog_timeo jiffies.
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      Tries to restart the transmit queue.
+ *
+ *-----------------------------------------------------------------------------
+ */
+static void
+vmxnet_tx_timeout(struct net_device *dev)
+{
+   compat_netif_wake_queue(dev);
+}
+#endif /* LINUX_VERSION_CODE >= KERNEL_VERSION(2,3,43) */
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * vmxnet_link_check --
+ *
+ *      Propagate device link status to netdev.
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      Rearms timer for next check.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static void
+vmxnet_link_check(unsigned long data)   // IN: netdevice pointer
+{
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,3,43)
+   struct net_device *dev = (struct net_device *)data;
+   struct Vmxnet_Private *lp;
+   uint32 status;
+   int ok;
+
+   lp = dev->priv;
+   status = inl(dev->base_addr + VMXNET_STATUS_ADDR);
+   ok = (status & VMXNET_STATUS_CONNECTED) != 0;
+   if (ok != netif_carrier_ok(dev)) {
+      if (ok) {
+         netif_carrier_on(dev);
+      } else {
+         netif_carrier_off(dev);
+      }
+   }
+
+   /*
+    * It would be great if vmxnet2 could generate interrupt when link
+    * state changes.  Maybe next time.  Let's just poll media every
+    * two seconds (2 seconds is same interval pcnet32 uses).
+    */
+   mod_timer(&lp->linkCheckTimer, jiffies + 2 * HZ);
+#else
+   /*
+    * Nothing to do on kernels before 2.3.43.  They do not have
+    * netif_carrier_*, and as we've lived without link state for
+    * years, let's live without it forever on these kernels.
+    */
+#endif /* LINUX_VERSION_CODE >= KERNEL_VERSION(2,3,43) */
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * vmxnet_probe_device --
+ *
+ *      Most of the initialization at module load time is done here.
+ *
+ * Results:
+ *      Returns 0 for success, an error otherwise.
+ *
+ * Side effects:
+ *      Switches device from vlance to vmxnet mode, creates ethernet
+ *      structure for device, and registers device with network stack.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static int
+vmxnet_probe_device(struct pci_dev             *pdev, // IN: vmxnet PCI device
+                    const struct pci_device_id *id)   // IN: matching device ID
+{
+   struct Vmxnet_Private *lp;
+   struct net_device *dev;
+   unsigned int ioaddr, reqIOAddr, reqIOSize;
+   unsigned int irq_line;
+   /* VMware's version of the magic number */
+   unsigned int low_vmware_version;
+   unsigned int numRxBuffers, numRxBuffers2, maxNumRxBuffers, defNumRxBuffers;
+   unsigned int numTxBuffers, maxNumTxBuffers, defNumTxBuffers;
+   Bool morphed = FALSE;
+   Bool enhanced = FALSE;
+   int i;
+   unsigned int driverDataSize;
+
+   i = compat_pci_enable_device(pdev);
+   if (i) {
+      printk(KERN_ERR "Cannot enable vmxnet adapter %s: error %d\n",
+             compat_pci_name(pdev), i);
+      return i;
+   }
+   compat_pci_set_master(pdev);
+   irq_line = pdev->irq;
+   ioaddr = compat_pci_resource_start(pdev, 0);
+
+   reqIOAddr = ioaddr;
+   /* Found adapter, adjust ioaddr to match the adapter we found. */
+   if (id->driver_data == VMXNET_CHIP) {
+      reqIOSize = VMXNET_CHIP_IO_RESV_SIZE;
+   } else {
+      /*
+       * Since this is a vlance adapter we can only use it if
+       * its I/0 space is big enough for the adapter to be
+       * capable of morphing. This is the first requirement
+       * for this adapter to potentially be morphable. The
+       * layout of a morphable LANCE adapter is
+       *
+       * I/O space:
+       *
+       * |------------------|
+       * | LANCE IO PORTS   |
+       * |------------------|
+       * | MORPH PORT       |
+       * |------------------|
+       * | VMXNET IO PORTS  |
+       * |------------------|
+       *
+       * VLance has 8 ports of size 4 bytes, the morph port is 4 bytes, and
+       * Vmxnet has 10 ports of size 4 bytes.
+       *
+       * We shift up the ioaddr with the size of the LANCE I/O space since
+       * we want to access the vmxnet ports. We also shift the ioaddr up by
+       * the MORPH_PORT_SIZE so other port access can be independent of
+       * whether we are Vmxnet or a morphed VLance. This means that when
+       * we want to access the MORPH port we need to subtract the size
+       * from ioaddr to get to it.
+       */
+
+      ioaddr += LANCE_CHIP_IO_RESV_SIZE + MORPH_PORT_SIZE;
+      reqIOSize = LANCE_CHIP_IO_RESV_SIZE + MORPH_PORT_SIZE +
+                  VMXNET_CHIP_IO_RESV_SIZE;
+   }
+   /* Do not attempt to morph non-morphable AMD PCnet */
+   if (reqIOSize > compat_pci_resource_len(pdev, 0)) {
+      printk(KERN_INFO "vmxnet: Device in slot %s is not supported by this driver.\n",
+             compat_pci_name(pdev));
+      goto pci_disable;
+   }
+
+   /*
+    * Request I/O region with adjusted base address and size. The adjusted
+    * values are needed and used if we release the region in case of failure.
+    */
+
+   if (!compat_request_region(reqIOAddr, reqIOSize, VMXNET_CHIP_NAME)) {
+      printk(KERN_INFO "vmxnet: Another driver already loaded for device in slot %s.\n",
+             compat_pci_name(pdev));
+      goto pci_disable;
+   }
+
+   /* Morph the underlying hardware if we found a VLance adapter. */
+   if (id->driver_data == LANCE_CHIP) {
+      uint16 magic;
+
+      /* Read morph port to verify that we can morph the adapter. */
+
+      magic = inw(ioaddr - MORPH_PORT_SIZE);
+      if (magic != LANCE_CHIP &&
+          magic != VMXNET_CHIP) {
+         printk(KERN_ERR "Invalid magic, read: 0x%08X\n", magic);
+         goto release_reg;
+      }
+
+      /* Morph adapter. */
+
+      outw(VMXNET_CHIP, ioaddr - MORPH_PORT_SIZE);
+      morphed = TRUE;
+
+      /* Verify that we morphed correctly. */
+
+      magic = inw(ioaddr - MORPH_PORT_SIZE);
+      if (magic != VMXNET_CHIP) {
+         printk(KERN_ERR "Couldn't morph adapter. Invalid magic, read: 0x%08X\n",
+                magic);
+         goto morph_back;
+      }
+   }
+
+   printk(KERN_INFO "Found vmxnet/PCI at %#x, irq %u.\n", ioaddr, irq_line);
+
+   low_vmware_version = inl(ioaddr + VMXNET_LOW_VERSION);
+   if ((low_vmware_version & 0xffff0000) != (VMXNET2_MAGIC & 0xffff0000)) {
+      printk(KERN_ERR "Driver version 0x%08X doesn't match version 0x%08X\n",
+             VMXNET2_MAGIC, low_vmware_version);
+      goto morph_back;
+   } else {
+      /*
+       * The low version looked OK so get the high version and make sure that
+       * our version is supported.
+       */
+      unsigned int high_vmware_version = inl(ioaddr + VMXNET_HIGH_VERSION);
+      if ((VMXNET2_MAGIC < low_vmware_version) ||
+          (VMXNET2_MAGIC > high_vmware_version)) {
+         printk(KERN_ERR
+                "Driver version 0x%08X doesn't match version 0x%08X, 0x%08X\n",
+                VMXNET2_MAGIC, low_vmware_version, high_vmware_version);
+         goto morph_back;
+      }
+   }
+
+   dev = compat_alloc_etherdev(sizeof *lp);
+   if (!dev) {
+      printk(KERN_ERR "Unable to allocate ethernet device\n");
+      goto morph_back;
+   }
+
+   lp = dev->priv;
+   lp->pdev = pdev;
+
+   dev->base_addr = ioaddr;
+
+   outl(VMXNET_CMD_GET_FEATURES, dev->base_addr + VMXNET_COMMAND_ADDR);
+   lp->features = inl(dev->base_addr + VMXNET_COMMAND_ADDR);
+
+   outl(VMXNET_CMD_GET_CAPABILITIES, dev->base_addr + VMXNET_COMMAND_ADDR);
+   lp->capabilities = inl(dev->base_addr + VMXNET_COMMAND_ADDR);
+
+   /* determine the features supported */
+   lp->zeroCopyTx = FALSE;
+   lp->partialHeaderCopyEnabled = FALSE;
+   lp->tso = FALSE;
+   lp->chainTx = FALSE;
+   lp->chainRx = FALSE;
+   lp->jumboFrame = FALSE;
+   lp->lpd = FALSE;
+
+   printk(KERN_INFO "features:");
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,4,0)
+   if (lp->capabilities & VMNET_CAP_IP4_CSUM) {
+      dev->features |= NETIF_F_IP_CSUM;
+      printk(" ipCsum");
+   }
+   if (lp->capabilities & VMNET_CAP_HW_CSUM) {
+      dev->features |= NETIF_F_HW_CSUM;
+      printk(" hwCsum");
+   }
+#endif
+
+#ifdef VMXNET_DO_ZERO_COPY
+   if (lp->capabilities & VMNET_CAP_SG &&
+       lp->features & VMXNET_FEATURE_ZERO_COPY_TX){
+      dev->features |= NETIF_F_SG;
+      lp->zeroCopyTx = TRUE;
+      printk(" zeroCopy");
+
+      if (lp->capabilities & VMNET_CAP_ENABLE_HEADER_COPY) {
+         lp->partialHeaderCopyEnabled = TRUE;
+         printk(" partialHeaderCopy");
+      }
+
+      if (lp->capabilities & VMNET_CAP_TX_CHAIN) {
+         lp->chainTx = TRUE;
+      }
+
+      if (lp->capabilities & VMNET_CAP_RX_CHAIN) {
+         lp->chainRx = TRUE;
+      }
+
+      if (lp->chainRx && lp->chainTx &&
+          (lp->features & VMXNET_FEATURE_JUMBO_FRAME)) {
+         lp->jumboFrame = TRUE;
+         printk(" jumboFrame");
+      }
+   }
+
+#ifdef VMXNET_DO_TSO
+   if ((lp->capabilities & VMNET_CAP_TSO) &&
+       (lp->capabilities & (VMNET_CAP_IP4_CSUM | VMNET_CAP_HW_CSUM)) &&
+       // tso only makes sense if we have hw csum offload
+       lp->chainTx && lp->zeroCopyTx &&
+       lp->features & VMXNET_FEATURE_TSO) {
+      dev->features |= NETIF_F_TSO;
+      lp->tso = TRUE;
+      printk(" tso");
+   }
+
+   if ((lp->capabilities & VMNET_CAP_LPD) &&
+       (lp->features & VMXNET_FEATURE_LPD)) {
+      lp->lpd = TRUE;
+      printk(" lpd");
+   }
+#endif
+#endif
+
+   printk("\n");
+
+   /* check if this is enhanced vmxnet device */
+   if ((lp->features & VMXNET_FEATURE_TSO) && 
+       (lp->features & VMXNET_FEATURE_JUMBO_FRAME)) {
+	enhanced = TRUE;
+   }
+
+   /* determine rx/tx ring sizes */ 
+   if (enhanced) {
+      maxNumRxBuffers = ENHANCED_VMXNET2_MAX_NUM_RX_BUFFERS;
+      defNumRxBuffers = ENHANCED_VMXNET2_DEFAULT_NUM_RX_BUFFERS;
+   } else {
+      maxNumRxBuffers = VMXNET2_MAX_NUM_RX_BUFFERS;
+      defNumRxBuffers = VMXNET2_DEFAULT_NUM_RX_BUFFERS;
+   }
+
+   outl(VMXNET_CMD_GET_NUM_RX_BUFFERS, dev->base_addr + VMXNET_COMMAND_ADDR);
+   numRxBuffers = inl(dev->base_addr + VMXNET_COMMAND_ADDR);
+   if (numRxBuffers == 0 || numRxBuffers > maxNumRxBuffers) {
+      numRxBuffers = defNumRxBuffers;
+   }
+
+   if (lp->jumboFrame || lp->lpd) {
+      numRxBuffers2 = numRxBuffers * 4;
+      if (numRxBuffers2 > VMXNET2_MAX_NUM_RX_BUFFERS2) {
+         numRxBuffers2 = VMXNET2_MAX_NUM_RX_BUFFERS2;
+      }
+   } else {
+      numRxBuffers2 = 1;
+   }
+
+   printk("numRxBuffers = %d, numRxBuffers2 = %d\n", numRxBuffers, numRxBuffers2);
+   if (lp->tso || lp->jumboFrame) {
+      maxNumTxBuffers = VMXNET2_MAX_NUM_TX_BUFFERS_TSO;
+      defNumTxBuffers = VMXNET2_DEFAULT_NUM_TX_BUFFERS_TSO;
+   } else {
+      maxNumTxBuffers = VMXNET2_MAX_NUM_TX_BUFFERS;
+      defNumTxBuffers = VMXNET2_DEFAULT_NUM_TX_BUFFERS;
+   }
+
+   outl(VMXNET_CMD_GET_NUM_TX_BUFFERS, dev->base_addr + VMXNET_COMMAND_ADDR);
+   numTxBuffers = inl(dev->base_addr + VMXNET_COMMAND_ADDR);
+   if (numTxBuffers == 0 || numTxBuffers > maxNumTxBuffers) {
+      numTxBuffers = defNumTxBuffers;
+   }
+
+   driverDataSize =
+            sizeof(Vmxnet2_DriverData) +
+            (numRxBuffers + numRxBuffers2) * sizeof(Vmxnet2_RxRingEntry) +
+            numTxBuffers * sizeof(Vmxnet2_TxRingEntry);
+   VMXNET_LOG("vmxnet: numRxBuffers=((%d+%d)*%d) numTxBuffers=(%d*%d) driverDataSize=%d\n",
+              numRxBuffers, numRxBuffers2, (uint32)sizeof(Vmxnet2_RxRingEntry),
+              numTxBuffers, (uint32)sizeof(Vmxnet2_TxRingEntry),
+              driverDataSize);
+   lp->ddAllocated = kmalloc(driverDataSize + 15, GFP_DMA | GFP_KERNEL);
+
+   if (!lp->ddAllocated) {
+      printk(KERN_ERR "Unable to allocate memory for driver data\n");
+      goto free_dev;
+   }
+   if ((uintptr_t)virt_to_bus(lp->ddAllocated) > SHARED_MEM_MAX) {
+      printk(KERN_ERR
+             "Unable to initialize driver data, address outside of shared area (0x%p)\n",
+             (void*)virt_to_bus(lp->ddAllocated));
+      goto free_dev_dd;
+   }
+
+   /* Align on paragraph boundary */
+   lp->dd = (Vmxnet2_DriverData*)(((unsigned long)lp->ddAllocated + 15) & ~15UL);
+   memset(lp->dd, 0, driverDataSize);
+   spin_lock_init(&lp->txLock);
+   lp->numRxBuffers = numRxBuffers;
+   lp->numRxBuffers2 = numRxBuffers2;
+   lp->numTxBuffers = numTxBuffers;
+   /* So that the vmkernel can check it is compatible */
+   lp->dd->magic = VMXNET2_MAGIC;
+   lp->dd->length = driverDataSize;
+   lp->name = VMXNET_CHIP_NAME;
+
+   /*
+    * Store whether we are morphed so we can figure out how to
+    * clean up when we unload.
+    */
+   lp->morphed = morphed;
+
+   if (lp->capabilities & VMNET_CAP_VMXNET_APROM) {
+      for (i = 0; i < ETH_ALEN; i++) {
+         dev->dev_addr[i] = inb(ioaddr + VMXNET_APROM_ADDR + i);
+      }
+      for (i = 0; i < ETH_ALEN; i++) {
+         outb(dev->dev_addr[i], ioaddr + VMXNET_MAC_ADDR + i);
+      }
+   } else {
+      /*
+       * Be backwards compatible and use the MAC address register to
+       * get MAC address.
+       */
+      for (i = 0; i < ETH_ALEN; i++) {
+         dev->dev_addr[i] = inb(ioaddr + VMXNET_MAC_ADDR + i);
+      }
+   }
+
+#ifdef VMXNET_DO_ZERO_COPY
+   lp->txBufferStart = NULL;
+   lp->dd->txBufferPhysStart = 0;
+   lp->dd->txBufferPhysLength = 0;
+
+   if (lp->partialHeaderCopyEnabled) {
+      unsigned int txBufferSize;
+
+      txBufferSize = numTxBuffers * TX_PKT_HEADER_SIZE;
+      lp->txBufferStartRaw = kmalloc(txBufferSize + PAGE_SIZE,
+                                     GFP_DMA | GFP_KERNEL);
+      if (lp->txBufferStartRaw) {
+         lp->txBufferStart = (char*)((unsigned long)(lp->txBufferStartRaw + PAGE_SIZE - 1) &
+                                     (unsigned long)~(PAGE_SIZE - 1));
+         lp->dd->txBufferPhysStart = virt_to_phys(lp->txBufferStart);
+         lp->dd->txBufferPhysLength = txBufferSize;
+         lp->dd->txPktMaxSize = TX_PKT_HEADER_SIZE;
+      } else {
+         lp->partialHeaderCopyEnabled = FALSE;
+         printk(KERN_INFO "failed to allocate tx buffer, disable partialHeaderCopy\n");
+      }
+   }
+#endif
+
+   dev->irq = irq_line;
+
+   dev->open = &vmxnet_open;
+   dev->hard_start_xmit = &vmxnet_start_tx;
+   dev->stop = &vmxnet_close;
+   dev->get_stats = &vmxnet_get_stats;
+   dev->set_multicast_list = &vmxnet_set_multicast_list;
+#ifdef HAVE_CHANGE_MTU
+   dev->change_mtu = &vmxnet_change_mtu;
+#endif
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,3,43)
+   dev->tx_timeout = &vmxnet_tx_timeout;
+   dev->watchdog_timeo = VMXNET_WATCHDOG_TIMEOUT;
+#endif
+#ifdef VMW_HAVE_POLL_CONTROLLER
+   dev->poll_controller = vmxnet_netpoll;
+#endif
+
+   /* Do this after ether_setup(), which sets the default value. */
+   dev->set_mac_address = &vmxnet_set_mac_address;
+
+#ifdef SET_ETHTOOL_OPS
+   SET_ETHTOOL_OPS(dev, &vmxnet_ethtool_ops);
+#else
+   dev->do_ioctl = vmxnet_ioctl;
+#endif
+
+   COMPAT_SET_MODULE_OWNER(dev);
+   COMPAT_SET_NETDEV_DEV(dev, &pdev->dev);
+
+   if (register_netdev(dev)) {
+      printk(KERN_ERR "Unable to register device\n");
+      goto free_dev_dd;
+   }
+   /*
+    * Use deferrable timer - we want 2s interval, but if it will
+    * be 2 seconds or 10 seconds, we do not care.
+    */
+   compat_init_timer_deferrable(&lp->linkCheckTimer);
+   lp->linkCheckTimer.data = (unsigned long)dev;
+   lp->linkCheckTimer.function = vmxnet_link_check;
+   vmxnet_link_check(lp->linkCheckTimer.data);
+
+   /* Do this after register_netdev(), which sets device name */
+   VMXNET_LOG("%s: %s at %#3lx assigned IRQ %d.\n",
+              dev->name, lp->name, dev->base_addr, dev->irq);
+
+   pci_set_drvdata(pdev, dev);
+   return 0;
+
+free_dev_dd:;
+   kfree(lp->ddAllocated);
+free_dev:;
+   compat_free_netdev(dev);
+morph_back:;
+   if (morphed) {
+      /* Morph back to LANCE hw. */
+      outw(LANCE_CHIP, ioaddr - MORPH_PORT_SIZE);
+   }
+release_reg:;
+   release_region(reqIOAddr, reqIOSize);
+pci_disable:;
+   compat_pci_disable_device(pdev);
+   return -EBUSY;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * vmxnet_remove_device --
+ *
+ *      Cleanup, called for each device on unload.
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      Unregisters vmxnet device with Linux and frees memory.
+ *
+ *-----------------------------------------------------------------------------
+ */
+static void
+vmxnet_remove_device(struct pci_dev* pdev)
+{
+   struct net_device *dev = pci_get_drvdata(pdev);
+   struct Vmxnet_Private *lp = dev->priv;
+
+   /*
+    * Do this before device is gone so we never call netif_carrier_* after
+    * unregistering netdevice.
+    */
+   compat_del_timer_sync(&lp->linkCheckTimer);
+   unregister_netdev(dev);
+
+   /* Unmorph adapter if it was morphed. */
+
+   if (lp->morphed) {
+      uint16 magic;
+
+      /* Read morph port to verify that we can morph the adapter. */
+
+      magic = inw(dev->base_addr - MORPH_PORT_SIZE);
+      if (magic != VMXNET_CHIP) {
+         printk(KERN_ERR "Adapter not morphed. read magic: 0x%08X\n", magic);
+      }
+
+      /* Morph adapter back to LANCE. */
+
+      outw(LANCE_CHIP, dev->base_addr - MORPH_PORT_SIZE);
+
+      /* Verify that we unmorphed correctly. */
+
+      magic = inw(dev->base_addr - MORPH_PORT_SIZE);
+      if (magic != LANCE_CHIP) {
+         printk(KERN_ERR "Couldn't unmorph adapter. Invalid magic, read: 0x%08X\n",
+                magic);
+      }
+
+      release_region(dev->base_addr -
+                     (LANCE_CHIP_IO_RESV_SIZE + MORPH_PORT_SIZE),
+                     VMXNET_CHIP_IO_RESV_SIZE +
+                     (LANCE_CHIP_IO_RESV_SIZE + MORPH_PORT_SIZE));
+   } else {
+      release_region(dev->base_addr, VMXNET_CHIP_IO_RESV_SIZE);
+   }
+
+#ifdef VMXNET_DO_ZERO_COPY
+   if (lp->partialHeaderCopyEnabled){
+      kfree(lp->txBufferStartRaw);
+   }
+#endif
+
+   kfree(lp->ddAllocated);
+   compat_free_netdev(dev);
+   compat_pci_disable_device(pdev);
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * vmxnet_init_ring --
+ *
+ *      Initializes buffer rings in Vmxnet_Private structure.  Allocates skbs
+ *      to receive into.  Called by vmxnet_open.
+ *
+ * Results:
+ *      0 on success; -1 on failure to allocate skbs.
+ *
+ * Side effects:
+ *
+ *-----------------------------------------------------------------------------
+ */
+static int
+vmxnet_init_ring(struct net_device *dev)
+{
+   struct Vmxnet_Private *lp = (Vmxnet_Private *)dev->priv;
+   Vmxnet2_DriverData *dd = lp->dd;
+   unsigned int i;
+   size_t offset;
+
+   offset = sizeof(*dd);
+
+   dd->rxRingLength = lp->numRxBuffers;
+   dd->rxRingOffset = offset;
+   lp->rxRing = (Vmxnet2_RxRingEntry *)((uintptr_t)dd + offset);
+   offset += lp->numRxBuffers * sizeof(Vmxnet2_RxRingEntry);
+
+   dd->rxRingLength2 = lp->numRxBuffers2;
+   dd->rxRingOffset2 = offset;
+   lp->rxRing2 = (Vmxnet2_RxRingEntry *)((uintptr_t)dd + offset);
+   offset += lp->numRxBuffers2 * sizeof(Vmxnet2_RxRingEntry);
+
+   dd->txRingLength = lp->numTxBuffers;
+   dd->txRingOffset = offset;
+   lp->txRing = (Vmxnet2_TxRingEntry *)((uintptr_t)dd + offset);
+   offset += lp->numTxBuffers * sizeof(Vmxnet2_TxRingEntry);
+
+   VMXNET_LOG("vmxnet_init_ring: offset=%"FMT64"d length=%d\n",
+              (uint64)offset, dd->length);
+
+   for (i = 0; i < lp->numRxBuffers; i++) {
+      lp->rxSkbuff[i] = dev_alloc_skb(PKT_BUF_SZ);
+      if (lp->rxSkbuff[i] == NULL) {
+         unsigned int j;
+
+	 printk (KERN_ERR "%s: vmxnet_init_ring dev_alloc_skb failed.\n", dev->name);
+         for (j = 0; j < i; j++) {
+            compat_dev_kfree_skb(lp->rxSkbuff[j], FREE_WRITE);
+            lp->rxSkbuff[j] = NULL;
+         }
+	 return -ENOMEM;
+      }
+
+      lp->rxRing[i].paddr = virt_to_bus(compat_skb_tail_pointer(lp->rxSkbuff[i]));
+      lp->rxRing[i].bufferLength = PKT_BUF_SZ;
+      lp->rxRing[i].actualLength = 0;
+      lp->rxRing[i].ownership = VMXNET2_OWNERSHIP_NIC;
+   }
+
+#ifdef VMXNET_DO_ZERO_COPY
+   if (lp->jumboFrame || lp->lpd) {
+      struct pci_dev *pdev = lp->pdev;
+
+      dd->maxFrags = MAX_SKB_FRAGS;
+
+      for (i = 0; i < lp->numRxBuffers2; i++) {
+         lp->rxPages[i] = alloc_page(GFP_KERNEL);
+         if (lp->rxPages[i] == NULL) {
+            unsigned int j;
+
+            printk (KERN_ERR "%s: vmxnet_init_ring alloc_page failed.\n", dev->name);
+            for (j = 0; j < i; j++) {
+               put_page(lp->rxPages[j]);
+               lp->rxPages[j] = NULL;
+            }
+            for (j = 0; j < lp->numRxBuffers; j++) {
+               compat_dev_kfree_skb(lp->rxSkbuff[j], FREE_WRITE);
+               lp->rxSkbuff[j] = NULL;
+            }
+            return -ENOMEM;
+         }
+
+         lp->rxRing2[i].paddr = pci_map_page(pdev, lp->rxPages[i], 0,
+                                             PAGE_SIZE, PCI_DMA_FROMDEVICE);
+         lp->rxRing2[i].bufferLength = PAGE_SIZE;
+         lp->rxRing2[i].actualLength = 0;
+         lp->rxRing2[i].ownership = VMXNET2_OWNERSHIP_NIC_FRAG;
+      }
+   } else
+#endif
+   {
+      // dummy rxRing2 tacked on to the end, with a single unusable entry
+      lp->rxRing2[0].paddr = 0;
+      lp->rxRing2[0].bufferLength = 0;
+      lp->rxRing2[0].actualLength = 0;
+      lp->rxRing2[0].ownership = VMXNET2_OWNERSHIP_DRIVER;
+   }
+
+   dd->rxDriverNext = 0;
+   dd->rxDriverNext2 = 0;
+
+   for (i = 0; i < lp->numTxBuffers; i++) {
+      lp->txRing[i].ownership = VMXNET2_OWNERSHIP_DRIVER;
+      lp->txBufInfo[i].skb = NULL;
+      lp->txBufInfo[i].eop = 0;
+      lp->txRing[i].sg.sg[0].addrHi = 0;
+      lp->txRing[i].sg.addrType = NET_SG_PHYS_ADDR;
+   }
+
+   dd->txDriverCur = dd->txDriverNext = 0;
+   dd->savedRxNICNext = dd->savedRxNICNext2 = dd->savedTxNICNext = 0;
+   dd->txStopped = FALSE;
+
+   if (lp->lpd) {
+      dd->featureCtl |= VMXNET_FEATURE_LPD;
+   }
+
+   return 0;
+}
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * vmxnet_open --
+ *
+ *      Network device open routine.  Called by Linux when the interface is
+ *      brought up.
+ *
+ * Results:
+ *      0 on success; else negative errno value.
+ *
+ * Side effects:
+ *      Allocates an IRQ if not already allocated.  Sets our Vmxnet_Private
+ *      structure to be the shared area with the lower layer.
+ *
+ *-----------------------------------------------------------------------------
+ */
+static int
+vmxnet_open(struct net_device *dev)
+{
+   struct Vmxnet_Private *lp = (Vmxnet_Private *)dev->priv;
+   unsigned int ioaddr = dev->base_addr;
+   u32 paddr;
+
+   if (dev->irq == 0 ||	request_irq(dev->irq, &vmxnet_interrupt,
+			            COMPAT_IRQF_SHARED, lp->name, (void *)dev)) {
+      return -EAGAIN;
+   }
+
+   if (vmxnet_debug > 1) {
+      printk(KERN_DEBUG "%s: vmxnet_open() irq %d lp %#x.\n",
+	     dev->name, dev->irq,
+	     (u32) virt_to_bus(lp));
+   }
+
+   if (vmxnet_init_ring(dev)) {
+      return -ENOMEM;
+   }
+
+   paddr = virt_to_bus(lp->dd);
+
+   outl(paddr, ioaddr + VMXNET_INIT_ADDR);
+   outl(lp->dd->length, ioaddr + VMXNET_INIT_LENGTH);
+
+#ifdef VMXNET_DO_ZERO_COPY
+   if (lp->partialHeaderCopyEnabled) {
+      outl(VMXNET_CMD_PIN_TX_BUFFERS, ioaddr + VMXNET_COMMAND_ADDR);
+   }
+   // Pin the Tx buffers if partial header copy is enabled
+#endif
+
+   lp->dd->txStopped = FALSE;
+   compat_netif_start_queue(dev);
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,3,43)
+   dev->interrupt = 0;
+   dev->start = 1;
+#endif
+
+   lp->devOpen = TRUE;
+
+   COMPAT_NETDEV_MOD_INC_USE_COUNT;
+
+   return 0;
+}
+
+#ifdef VMXNET_DO_ZERO_COPY
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * vmxnet_unmap_buf  --
+ *
+ *      Unmap the PAs of the tx entry that we pinned for DMA.
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      None
+ *-----------------------------------------------------------------------------
+ */
+
+void
+vmxnet_unmap_buf(struct sk_buff *skb,
+                 struct Vmxnet2_TxBuf *tb,
+                 Vmxnet2_TxRingEntry *xre,
+                 struct pci_dev *pdev)
+{
+   int sgIdx;
+
+   // unmap the mapping for skb->data if needed
+   if (tb->sgForLinear >= 0) {
+      pci_unmap_single(pdev,
+                       VMXNET_GET_DMA_ADDR(xre->sg.sg[(int)tb->sgForLinear]),
+                       xre->sg.sg[(int)tb->sgForLinear].length,
+                       PCI_DMA_TODEVICE);
+      VMXNET_LOG("vmxnet_unmap_buf: sg[%d] (%uB)\n", (int)tb->sgForLinear,
+                 xre->sg.sg[(int)tb->sgForLinear].length);
+   }
+
+   // unmap the mapping for skb->frags[]
+   for (sgIdx = tb->firstSgForFrag; sgIdx < xre->sg.length; sgIdx++) {
+      pci_unmap_page(pdev,
+                     VMXNET_GET_DMA_ADDR(xre->sg.sg[sgIdx]),
+                     xre->sg.sg[sgIdx].length,
+                     PCI_DMA_TODEVICE);
+      VMXNET_LOG("vmxnet_unmap_buf: sg[%d] (%uB)\n", sgIdx,
+                      xre->sg.sg[sgIdx].length);
+   }
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * vmxnet_map_pkt  --
+ *
+ *      Map the buffers/pages that we need for DMA and populate the SG.
+ *
+ *      "offset" indicates the position inside the pkt where mapping should start.
+ *      "startSgIdx" indicates the first free sg slot of the first tx entry
+ *      (pointed to by txDriverNext).
+ *
+ *      The caller should guarantee the first tx has at least one sg slot
+ *      available. The caller should also ensure that enough tx entries are
+ *      available for this pkt.
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      1. Ownership of all tx entries used (EXCEPT the 1st one) are updated.
+ *         The only flag set is VMXNET2_TX_MORE if needed. caller is
+ *         responsible to set up other flags after this call returns.
+ *      2. lp->dd->numTxPending is updated
+ *      3. txBufInfo corresponding to used tx entries (including the 1st one)
+ *         are updated
+ *      4. txDriverNext is advanced accordingly
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+void
+vmxnet_map_pkt(struct sk_buff *skb,
+               int offset,
+               struct Vmxnet_Private *lp,
+               int startSgIdx)
+{
+   int nextFrag = 0, nextSg = startSgIdx;
+   struct skb_frag_struct *frag;
+   Vmxnet2_DriverData *dd = lp->dd;
+   Vmxnet2_TxRingEntry *xre;
+   struct Vmxnet2_TxBuf *tb;
+   dma_addr_t dma;
+
+   VMXNET_ASSERT(startSgIdx < VMXNET2_SG_DEFAULT_LENGTH);
+
+   lp->numTxPending ++;
+   tb = &lp->txBufInfo[dd->txDriverNext];
+   xre = &lp->txRing[dd->txDriverNext];
+
+   if (offset == skb_headlen(skb)) {
+      tb->sgForLinear = -1;
+      tb->firstSgForFrag = nextSg;
+   } else if (offset < skb_headlen(skb)) {
+      /* we need to map some of the non-frag data. */
+      dma = pci_map_single(lp->pdev,
+                           skb->data + offset,
+                           skb_headlen(skb) - offset,
+                           PCI_DMA_TODEVICE);
+      VMXNET_FILL_SG(xre->sg.sg[nextSg], dma, skb_headlen(skb) - offset);
+      VMXNET_LOG("vmxnet_map_pkt: txRing[%u].sg[%d] -> data %p offset %u size %u\n",
+                 dd->txDriverNext, nextSg, skb->data, offset, skb_headlen(skb) - offset);
+      tb->sgForLinear = nextSg++;
+      tb->firstSgForFrag = nextSg;
+   } else {
+      // all non-frag data is copied, skip it
+      tb->sgForLinear = -1;
+      tb->firstSgForFrag = nextSg;
+
+      offset -= skb_headlen(skb);
+
+      for ( ; nextFrag < skb_shinfo(skb)->nr_frags; nextFrag++){
+         frag = &skb_shinfo(skb)->frags[nextFrag];
+
+         // skip those frags that are completely copied
+         if (offset >= frag->size){
+            offset -= frag->size;
+         } else {
+            // map the part of the frag that is not copied
+            dma = pci_map_page(lp->pdev,
+                               frag->page,
+                               frag->page_offset + offset,
+                               frag->size - offset,
+                               PCI_DMA_TODEVICE);
+            VMXNET_FILL_SG(xre->sg.sg[nextSg], dma, frag->size - offset);
+            VMXNET_LOG("vmxnet_map_tx: txRing[%u].sg[%d] -> frag[%d]+%u (%uB)\n",
+                       dd->txDriverNext, nextSg, nextFrag, offset, frag->size - offset);
+            nextSg++;
+            nextFrag++;
+
+            break;
+         }
+      }
+   }
+
+   // map the remaining frags, we might need to use additional tx entries
+   for ( ; nextFrag < skb_shinfo(skb)->nr_frags; nextFrag++) {
+      frag = &skb_shinfo(skb)->frags[nextFrag];
+      dma = pci_map_page(lp->pdev,
+                         frag->page,
+                         frag->page_offset,
+                         frag->size,
+                         PCI_DMA_TODEVICE);
+
+      if (nextSg == VMXNET2_SG_DEFAULT_LENGTH) {
+         xre->flags = VMXNET2_TX_MORE;
+         xre->sg.length = VMXNET2_SG_DEFAULT_LENGTH;
+         tb->skb = skb;
+         tb->eop = 0;
+
+         // move to the next tx entry
+         VMXNET_INC(dd->txDriverNext, dd->txRingLength);
+         xre = &lp->txRing[dd->txDriverNext];
+         tb = &lp->txBufInfo[dd->txDriverNext];
+
+         // the new tx entry must be available
+         VMXNET_ASSERT(xre->ownership == VMXNET2_OWNERSHIP_DRIVER && tb->skb == NULL);
+
+         /*
+          * we change it even before the sg are populated but this is
+          * fine, because the first tx entry's ownership is not
+          * changed yet
+          */
+         xre->ownership = VMXNET2_OWNERSHIP_NIC;
+         tb->sgForLinear = -1;
+         tb->firstSgForFrag = 0;
+         lp->numTxPending ++;
+
+         nextSg = 0;
+      }
+      VMXNET_FILL_SG(xre->sg.sg[nextSg], dma, frag->size);
+      VMXNET_LOG("vmxnet_map_tx: txRing[%u].sg[%d] -> frag[%d] (%uB)\n",
+                 dd->txDriverNext, nextSg, nextFrag, frag->size);
+      nextSg++;
+   }
+
+   // setup the last tx entry
+   xre->flags = 0;
+   xre->sg.length = nextSg;
+   tb->skb = skb;
+   tb->eop = 1;
+
+   VMXNET_ASSERT(nextSg <= VMXNET2_SG_DEFAULT_LENGTH);
+   VMXNET_INC(dd->txDriverNext, dd->txRingLength);
+}
+#endif
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * check_tx_queue --
+ *
+ *      Loop through the tx ring looking for completed transmits.
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+static void
+check_tx_queue(struct net_device *dev)
+{
+   Vmxnet_Private *lp = (Vmxnet_Private *)dev->priv;
+   Vmxnet2_DriverData *dd = lp->dd;
+   int completed = 0;
+
+   while (1) {
+      Vmxnet2_TxRingEntry *xre = &lp->txRing[dd->txDriverCur];
+      struct sk_buff *skb = lp->txBufInfo[dd->txDriverCur].skb;
+
+      if (xre->ownership != VMXNET2_OWNERSHIP_DRIVER || skb == NULL) {
+	 break;
+      }
+#ifdef VMXNET_DO_ZERO_COPY
+      if (lp->zeroCopyTx){
+         VMXNET_LOG("unmap txRing[%u]\n", dd->txDriverCur);
+         vmxnet_unmap_buf(skb, &lp->txBufInfo[dd->txDriverCur], xre, lp->pdev);
+      }
+#endif
+
+      if (lp->txBufInfo[dd->txDriverCur].eop) {
+         compat_dev_kfree_skb_irq(skb, FREE_WRITE);
+      }
+      lp->txBufInfo[dd->txDriverCur].skb = NULL;
+
+      completed ++;
+
+      VMXNET_INC(dd->txDriverCur, dd->txRingLength);
+   }
+
+   if (completed){
+      lp->numTxPending -= completed;
+
+      // XXX conditionally wake up the queue based on the # of freed entries
+      if (compat_netif_queue_stopped(dev)) {
+	 compat_netif_wake_queue(dev);
+         dd->txStopped = FALSE;
+      }
+   }
+}
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * vmxnet_tx --
+ *
+ *      Network device hard_start_xmit helper routine.  This is called by
+ *	the drivers hard_start_xmit routine when it wants to send a packet.
+ *
+ * Results:
+ *      VMXNET_CALL_TRANSMIT:	The driver should ask the virtual NIC to
+ *				transmit a packet.
+ *      VMXNET_DEFER_TRANSMIT:	This transmit is deferred because of
+ *				transmit clustering.
+ *      VMXNET_STOP_TRANSMIT:	We ran out of queue space so the caller
+ *				should stop transmitting.
+ *
+ * Side effects:
+ *	The drivers tx ring may get modified.
+ *
+ *-----------------------------------------------------------------------------
+ */
+Vmxnet_TxStatus
+vmxnet_tx(struct sk_buff *skb, struct net_device *dev)
+{
+   Vmxnet_TxStatus status = VMXNET_DEFER_TRANSMIT;
+   struct Vmxnet_Private *lp = (struct Vmxnet_Private *)dev->priv;
+   Vmxnet2_DriverData *dd = lp->dd;
+   unsigned long flags;
+   Vmxnet2_TxRingEntry *xre;
+#ifdef VMXNET_DO_TSO
+   int mss;
+#endif
+
+   xre = &lp->txRing[dd->txDriverNext];
+
+#ifdef VMXNET_DO_ZERO_COPY
+   if (lp->zeroCopyTx) {
+      int txEntries, sgCount;
+      unsigned int headerSize;
+
+      /* conservatively estimate the # of tx entries needed in the worse case */
+      sgCount = (lp->partialHeaderCopyEnabled ? 2 : 1) + skb_shinfo(skb)->nr_frags;
+      txEntries = (sgCount + VMXNET2_SG_DEFAULT_LENGTH - 1) / VMXNET2_SG_DEFAULT_LENGTH;
+
+      if (UNLIKELY(!lp->chainTx && txEntries > 1)) {
+         /*
+          * rare case, no tx desc chaining support but the pkt need more than 1
+          * tx entry, linearize it
+          */
+         if (compat_skb_linearize(skb) != 0) {
+            VMXNET_LOG("vmxnet_tx: skb_linearize failed\n");
+            compat_dev_kfree_skb(skb, FREE_WRITE);
+            return VMXNET_DEFER_TRANSMIT;
+         }
+
+         txEntries = 1;
+      }
+
+      VMXNET_LOG("\n%d(%d) bytes, %d frags, %d tx entries\n", skb->len,
+                 skb_headlen(skb), skb_shinfo(skb)->nr_frags, txEntries);
+
+      spin_lock_irqsave(&lp->txLock, flags);
+
+      /* check for the availability of tx ring entries */
+      if (dd->txRingLength - lp->numTxPending < txEntries) {
+         dd->txStopped = TRUE;
+         compat_netif_stop_queue(dev);
+         check_tx_queue(dev);
+
+         spin_unlock_irqrestore(&lp->txLock, flags);
+         VMXNET_LOG("queue stopped\n");
+         return VMXNET_STOP_TRANSMIT;
+      }
+
+      /* copy protocol headers if needed */
+      if (LIKELY(lp->partialHeaderCopyEnabled)) {
+         unsigned int pos = dd->txDriverNext * dd->txPktMaxSize;
+         char *header = lp->txBufferStart + pos;
+
+         /* figure out the protocol and header sizes */
+
+         /* PR 171928
+          * compat_skb_ip_header isn't updated in rhel5 for
+          * vlan tagging.  using these macros causes incorrect
+          * computation of the headerSize
+          */
+         headerSize = ETHERNET_HEADER_SIZE;
+         if (UNLIKELY((skb_headlen(skb) < headerSize))) {
+
+            if (skb_is_nonlinear(skb)) {
+               compat_skb_linearize(skb);
+            }
+            /*
+             * drop here if we don't have a complete ETH header for delivery
+             */
+            if (skb_headlen(skb) < headerSize) {
+               compat_dev_kfree_skb(skb, FREE_WRITE);
+               spin_unlock_irqrestore(&lp->txLock, flags);
+               return VMXNET_DEFER_TRANSMIT;
+            }
+         }
+         if (UNLIKELY(*(uint16*)(skb->data + ETH_FRAME_TYPE_LOCATION) == ETH_TYPE_VLAN_TAG)) {
+            headerSize += VLAN_TAG_LENGTH;
+            if (UNLIKELY(skb_headlen(skb) < headerSize)) {
+
+               if (skb_is_nonlinear(skb)) {
+                  compat_skb_linearize(skb);
+               }
+               /*
+                * drop here if we don't have a ETH header and a complete VLAN tag
+                */
+               if (skb_headlen(skb) < headerSize) {
+                  compat_dev_kfree_skb(skb, FREE_WRITE);
+                  spin_unlock_irqrestore(&lp->txLock, flags);
+                  return VMXNET_DEFER_TRANSMIT;
+               }
+            }
+         }
+         if (LIKELY(PKT_OF_IPV4(skb))){
+            // PR 171928 -- compat_skb_ip_header broken with vconfig
+            // please do not rewrite using compat_skb_ip_header
+            struct iphdr *ipHdr = (struct iphdr *)(skb->data + headerSize);
+
+            if (UNLIKELY(skb_headlen(skb) < headerSize + sizeof(*ipHdr))) {
+
+               if (skb_is_nonlinear(skb)) {
+                    compat_skb_linearize(skb);
+               }
+            }
+            if (LIKELY(skb_headlen(skb) > headerSize + sizeof(*ipHdr)) &&
+               (LIKELY(ipHdr->version == 4))) {
+               headerSize += ipHdr->ihl << 2;
+               if (LIKELY(ipHdr->protocol == IPPROTO_TCP)) {
+                  /*
+                   * tcp traffic, copy all protocol headers
+                   * refrain from using compat_skb macros PR 171928
+                   */
+                  struct tcphdr *tcpHdr = (struct tcphdr *)
+                     (skb->data + headerSize);
+                  /*
+                   * tcp->doff is near the end of the tcpHdr, use the
+                   * entire struct as the required size
+                   */
+                  if (skb->len < headerSize + sizeof(*tcpHdr)) {
+                     compat_dev_kfree_skb(skb, FREE_WRITE);
+                     spin_unlock_irqrestore(&lp->txLock, flags);
+                     return VMXNET_DEFER_TRANSMIT;
+                  }
+                  if (skb_headlen(skb) < (headerSize + sizeof(*tcpHdr))) {
+                     /*
+                      * linearized portion of the skb doesn't have a tcp header
+                      */
+                     compat_skb_linearize(skb);
+                  }
+                  headerSize += tcpHdr->doff << 2;
+               }
+            }
+         }
+
+         if (skb_copy_bits(skb, 0, header, headerSize) != 0) {
+            compat_dev_kfree_skb(skb, FREE_WRITE);
+            spin_unlock_irqrestore(&lp->txLock, flags);
+            return VMXNET_DEFER_TRANSMIT;
+         }
+
+         xre->sg.sg[0].addrLow = (uint32)dd->txBufferPhysStart + pos;
+         xre->sg.sg[0].addrHi = 0;
+         xre->sg.sg[0].length = headerSize;
+         vmxnet_map_pkt(skb, headerSize, lp, 1);
+      } else {
+         headerSize = 0;
+         vmxnet_map_pkt(skb, 0, lp, 0);
+      }
+
+#ifdef VMXNET_DO_TSO
+      mss = VMXNET_SKB_MSS(skb);
+      if (mss) {
+         xre->flags |= VMXNET2_TX_TSO;
+         xre->tsoMss = mss;
+         dd->txNumDeferred += ((skb->len - headerSize) + mss - 1) / mss;
+      } else
+#endif
+      {
+         dd->txNumDeferred++;
+      }
+   } else /* zero copy not enabled */
+#endif
+   {
+      struct Vmxnet2_TxBuf *tb;
+
+      spin_lock_irqsave(&lp->txLock, flags);
+
+      if (lp->txBufInfo[dd->txDriverNext].skb != NULL) {
+         dd->txStopped = TRUE;
+         compat_netif_stop_queue(dev);
+         check_tx_queue(dev);
+
+         spin_unlock_irqrestore(&lp->txLock, flags);
+         return VMXNET_STOP_TRANSMIT;
+      }
+
+      lp->numTxPending ++;
+
+      xre->sg.sg[0].addrLow = virt_to_bus(skb->data);
+      xre->sg.sg[0].addrHi = 0;
+      xre->sg.sg[0].length = skb->len;
+      xre->sg.length = 1;
+      xre->flags = 0;
+
+      tb = &lp->txBufInfo[dd->txDriverNext];
+      tb->skb = skb;
+      tb->sgForLinear = -1;
+      tb->firstSgForFrag = -1;
+      tb->eop = 1;
+
+      VMXNET_INC(dd->txDriverNext, dd->txRingLength);
+      dd->txNumDeferred++;
+      dd->stats.copyTransmits++;
+   }
+
+   /* at this point, xre must point to the 1st tx entry for the pkt */
+   if (skb->ip_summed == VM_TX_CHECKSUM_PARTIAL) {
+      xre->flags |= VMXNET2_TX_HW_XSUM | VMXNET2_TX_CAN_KEEP;
+   } else {
+      xre->flags |= VMXNET2_TX_CAN_KEEP;
+   }
+   if (lp->numTxPending > dd->txRingLength - 5) {
+      xre->flags |= VMXNET2_TX_RING_LOW;
+      status = VMXNET_CALL_TRANSMIT;
+   }
+
+   wmb();
+   xre->ownership = VMXNET2_OWNERSHIP_NIC;
+
+   if (dd->txNumDeferred >= dd->txClusterLength) {
+      dd->txNumDeferred = 0;
+      status = VMXNET_CALL_TRANSMIT;
+   }
+
+   dev->trans_start = jiffies;
+
+   lp->stats.tx_packets++;
+   dd->stats.pktsTransmitted++;
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,2,0)
+   lp->stats.tx_bytes += skb->len;
+#endif
+
+   if (lp->numTxPending > dd->stats.maxTxsPending) {
+      dd->stats.maxTxsPending = lp->numTxPending;
+   }
+
+   check_tx_queue(dev);
+
+   spin_unlock_irqrestore(&lp->txLock, flags);
+
+   return status;
+}
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * vmxnet_start_tx --
+ *
+ *      Network device hard_start_xmit routine.  Called by Linux when it has
+ *      a packet for us to transmit.
+ *
+ * Results:
+ *      0 on success; 1 if no resources.
+ *
+ * Side effects:
+ *
+ *-----------------------------------------------------------------------------
+ */
+static int
+vmxnet_start_tx(struct sk_buff *skb, struct net_device *dev)
+{
+   int retVal = 0;
+   Vmxnet_TxStatus xs = vmxnet_tx(skb, dev);
+   switch (xs) {
+   case VMXNET_CALL_TRANSMIT:
+      inl(dev->base_addr + VMXNET_TX_ADDR);
+      break;
+   case VMXNET_DEFER_TRANSMIT:
+      break;
+   case VMXNET_STOP_TRANSMIT:
+      retVal = 1;
+      break;
+   }
+
+   return retVal;
+}
+
+#ifdef VMXNET_DO_ZERO_COPY
+/*
+ *----------------------------------------------------------------------------
+ *
+ * vmxnet_drop_frags --
+ *
+ *    return the entries in the 2nd ring to the hw. The entries returned are
+ *    from rxDriverNext2 to the entry with VMXNET2_RX_FRAG_EOP set.
+ *
+ * Result:
+ *    None
+ *
+ * Side-effects:
+ *    None
+ *
+ *----------------------------------------------------------------------------
+ */
+static void
+vmxnet_drop_frags(Vmxnet_Private *lp)
+{
+   Vmxnet2_DriverData *dd = lp->dd;
+   Vmxnet2_RxRingEntry *rre2;
+   uint16 flags;
+
+   do {
+      rre2 = &lp->rxRing2[dd->rxDriverNext2];
+      flags = rre2->flags;
+      VMXNET_ASSERT(rre2->ownership == VMXNET2_OWNERSHIP_DRIVER_FRAG);
+
+      rre2->ownership = VMXNET2_OWNERSHIP_NIC_FRAG;
+      VMXNET_INC(dd->rxDriverNext2, dd->rxRingLength2);
+   }  while(!(flags & VMXNET2_RX_FRAG_EOP));
+}
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * vmxnet_rx_frags --
+ *
+ *    get data from the 2nd rx ring and append the frags to the skb. Multiple
+ *    rx entries in the 2nd rx ring are processed until the one with
+ *    VMXNET2_RX_FRAG_EOP set.
+ *
+ * Result:
+ *    0 on success
+ *    -1 on error
+ *
+ * Side-effects:
+ *    frags are appended to skb. related fields in skb are updated
+ *
+ *----------------------------------------------------------------------------
+ */
+static int
+vmxnet_rx_frags(Vmxnet_Private *lp, struct sk_buff *skb)
+{
+   Vmxnet2_DriverData *dd = lp->dd;
+   struct pci_dev *pdev = lp->pdev;
+   struct page *newPage;
+   int numFrags = 0;
+   Vmxnet2_RxRingEntry *rre2;
+   uint16 flags;
+#ifdef VMXNET_DEBUG
+   uint32 firstFrag = dd->rxDriverNext2;
+#endif
+
+   do {
+      rre2 = &lp->rxRing2[dd->rxDriverNext2];
+      flags = rre2->flags;
+      VMXNET_ASSERT(rre2->ownership == VMXNET2_OWNERSHIP_DRIVER_FRAG);
+
+      if (rre2->actualLength > 0) {
+         newPage = alloc_page(GFP_ATOMIC);
+         if (UNLIKELY(newPage == NULL)) {
+            skb_shinfo(skb)->nr_frags = numFrags;
+            skb->len += skb->data_len;
+            skb->truesize += skb->data_len;
+
+            compat_dev_kfree_skb(skb, FREE_WRITE);
+
+            vmxnet_drop_frags(lp);
+
+            return -1;
+         }
+
+         pci_unmap_page(pdev, rre2->paddr, PAGE_SIZE, PCI_DMA_FROMDEVICE);
+         skb_shinfo(skb)->frags[numFrags].page = lp->rxPages[dd->rxDriverNext2];
+         skb_shinfo(skb)->frags[numFrags].page_offset = 0;
+         skb_shinfo(skb)->frags[numFrags].size = rre2->actualLength;
+         skb->data_len += rre2->actualLength;
+         numFrags++;
+
+         /* refill the buffer */
+         lp->rxPages[dd->rxDriverNext2] = newPage;
+         rre2->paddr = pci_map_page(pdev, newPage, 0, PAGE_SIZE, PCI_DMA_FROMDEVICE);
+         rre2->bufferLength = PAGE_SIZE;
+         rre2->actualLength = 0;
+         wmb();
+      }
+
+      rre2->ownership = VMXNET2_OWNERSHIP_NIC_FRAG;
+      VMXNET_INC(dd->rxDriverNext2, dd->rxRingLength2);
+   } while (!(flags & VMXNET2_RX_FRAG_EOP));
+
+   VMXNET_ASSERT(numFrags > 0);
+   skb_shinfo(skb)->nr_frags = numFrags;
+   skb->len += skb->data_len;
+   skb->truesize += skb->data_len;
+   VMXNET_LOG("vmxnet_rx: %dB from rxRing[%d](%dB)+rxRing2[%d, %d)(%dB)\n",
+              skb->len, dd->rxDriverNext, skb_headlen(skb),
+              firstFrag, dd->rxDriverNext2, skb->data_len);
+   return 0;
+}
+#endif
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * vmxnet_rx --
+ *
+ *      Receive a packet.
+ *
+ * Results:
+ *      0
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+static int
+vmxnet_rx(struct net_device *dev)
+{
+   Vmxnet_Private *lp = (Vmxnet_Private *)dev->priv;
+   Vmxnet2_DriverData *dd = lp->dd;
+
+   if (!lp->devOpen) {
+      return 0;
+   }
+
+   while (1) {
+      struct sk_buff *skb, *newSkb;
+      Vmxnet2_RxRingEntry *rre;
+
+      rre = &lp->rxRing[dd->rxDriverNext];
+      if (rre->ownership != VMXNET2_OWNERSHIP_DRIVER) {
+	 break;
+      }
+
+      if (UNLIKELY(rre->actualLength == 0)) {
+#ifdef VMXNET_DO_ZERO_COPY
+         if (rre->flags & VMXNET2_RX_WITH_FRAG) {
+            vmxnet_drop_frags(lp);
+         }
+#endif
+         lp->stats.rx_errors++;
+         goto next_pkt;
+      }
+
+      skb = lp->rxSkbuff[dd->rxDriverNext];
+
+      /* refill the rx ring */
+      newSkb = dev_alloc_skb(PKT_BUF_SZ);
+      if (UNLIKELY(newSkb == NULL)) {
+         printk(KERN_DEBUG "%s: Memory squeeze, dropping packet.\n", dev->name);
+#ifdef VMXNET_DO_ZERO_COPY
+         if (rre->flags & VMXNET2_RX_WITH_FRAG) {
+            vmxnet_drop_frags(lp);
+         }
+#endif
+         lp->stats.rx_errors++;
+         goto next_pkt;
+      }
+
+      lp->rxSkbuff[dd->rxDriverNext] = newSkb;
+      rre->paddr = virt_to_bus(newSkb->data);
+      rre->bufferLength = PKT_BUF_SZ;
+
+      skb_put(skb, rre->actualLength);
+
+#ifdef VMXNET_DO_ZERO_COPY
+      if (rre->flags & VMXNET2_RX_WITH_FRAG) {
+         if (vmxnet_rx_frags(lp, skb) < 0) {
+            lp->stats.rx_errors++;
+            goto next_pkt;
+         }
+      } else
+#endif
+      {
+         VMXNET_LOG("vmxnet_rx: %dB from rxRing[%d]\n", skb->len, dd->rxDriverNext);
+      }
+
+      if (skb->len < (ETH_MIN_FRAME_LEN - 4)) {
+         /*
+          * Ethernet header vlan tags are 4 bytes.  Some vendors generate
+          *  ETH_MIN_FRAME_LEN frames including vlan tags.  When vlan tag
+          *  is stripped, such frames become ETH_MIN_FRAME_LEN - 4. (PR106153)
+          */
+         if (skb->len != 0) {
+	    printk(KERN_DEBUG "%s: Runt pkt (%d bytes) entry %d!\n", dev->name,
+                   skb->len, dd->rxDriverNext);
+         }
+	 lp->stats.rx_errors++;
+      } else {
+         if (rre->flags & VMXNET2_RX_HW_XSUM_OK) {
+            skb->ip_summed = CHECKSUM_UNNECESSARY;
+         }
+
+         skb->dev = dev;
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,2,0)
+         lp->stats.rx_bytes += skb->len;
+#endif
+         skb->protocol = eth_type_trans(skb, dev);
+         netif_rx(skb);
+         lp->stats.rx_packets++;
+         dd->stats.pktsReceived++;
+      }
+
+next_pkt:
+      rre->ownership = VMXNET2_OWNERSHIP_NIC;
+      VMXNET_INC(dd->rxDriverNext, dd->rxRingLength);
+   }
+
+   return 0;
+}
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * vmxnet_interrupt --
+ *
+ *      Interrupt handler.  Calls vmxnet_rx to receive a packet.
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 19)
+static compat_irqreturn_t
+vmxnet_interrupt(int irq, void *dev_id, struct pt_regs * regs)
+#else
+static compat_irqreturn_t
+vmxnet_interrupt(int irq, void *dev_id)
+#endif
+{
+   struct net_device *dev = (struct net_device *)dev_id;
+   struct Vmxnet_Private *lp;
+   Vmxnet2_DriverData *dd;
+
+   if (dev == NULL) {
+      printk (KERN_DEBUG "vmxnet_interrupt(): irq %d for unknown device.\n", irq);
+      return COMPAT_IRQ_NONE;
+   }
+
+
+   lp = (struct Vmxnet_Private *)dev->priv;
+   outl(VMXNET_CMD_INTR_ACK, dev->base_addr + VMXNET_COMMAND_ADDR);
+
+   dd = lp->dd;
+   dd->stats.interrupts++;
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,3,43)
+   if (dev->interrupt) {
+      printk(KERN_DEBUG "%s: Re-entering the interrupt handler.\n", dev->name);
+   }
+   dev->interrupt = 1;
+#endif
+
+   vmxnet_rx(dev);
+
+   if (lp->numTxPending > 0) {
+      spin_lock(&lp->txLock);
+      check_tx_queue(dev);
+      spin_unlock(&lp->txLock);
+   }
+
+   if (compat_netif_queue_stopped(dev) && !lp->dd->txStopped) {
+      compat_netif_wake_queue(dev);
+   }
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,3,43)
+   dev->interrupt = 0;
+#endif
+   return COMPAT_IRQ_HANDLED;
+}
+
+
+#ifdef VMW_HAVE_POLL_CONTROLLER
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * vmxnet_netpoll --
+ *
+ *      Poll network controller.  We reuse hardware interrupt for this.
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      Packets received/transmitted/whatever.
+ *
+ *-----------------------------------------------------------------------------
+ */
+static void
+vmxnet_netpoll(struct net_device *dev)
+{
+   disable_irq(dev->irq);
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 19)
+   vmxnet_interrupt(dev->irq, dev, NULL);
+#else
+   vmxnet_interrupt(dev->irq, dev);
+#endif
+   enable_irq(dev->irq);
+}
+#endif /* VMW_HAVE_POLL_CONTROLLER */
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * vmxnet_close --
+ *
+ *      Network device stop (close) routine.  Called by Linux when the
+ *      interface is brought down.
+ *
+ * Results:
+ *      0 for success (always).
+ *
+ * Side effects:
+ *      Flushes pending transmits.  Frees IRQs and shared memory area.
+ *
+ *-----------------------------------------------------------------------------
+ */
+static int
+vmxnet_close(struct net_device *dev)
+{
+   unsigned int ioaddr = dev->base_addr;
+   Vmxnet_Private *lp = (Vmxnet_Private *)dev->priv;
+   int i;
+   unsigned long flags;
+
+   if (vmxnet_debug > 1) {
+      printk(KERN_DEBUG "%s: Shutting down ethercard\n", dev->name);
+   }
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,3,43)
+   dev->start = 0;
+#endif
+
+   compat_netif_stop_queue(dev);
+
+   lp->devOpen = FALSE;
+
+   spin_lock_irqsave(&lp->txLock, flags);
+   if (lp->numTxPending > 0) {
+      //Wait absurdly long (2sec) for all the pending packets to be returned.
+      printk(KERN_DEBUG "vmxnet_close: Pending tx = %d\n", lp->numTxPending);
+      for (i = 0; i < 200 && lp->numTxPending > 0; i++) {
+	 outl(VMXNET_CMD_CHECK_TX_DONE, dev->base_addr + VMXNET_COMMAND_ADDR);
+	 udelay(10000);
+	 check_tx_queue(dev);
+      }
+
+      //This can happen when the related vmxnet device is disabled or when
+      //something's wrong with the pNIC, or even both.
+      //Will go ahead and free these skb's anyways (possibly dangerous,
+      //but seems to work in practice)
+      if (lp->numTxPending > 0) {
+         printk(KERN_EMERG "vmxnet_close: Failed to finish all pending tx.\n"
+	        "Is the related vmxnet device disabled?\n"
+                "This virtual machine may be in an inconsistent state.\n");
+         lp->numTxPending = 0;
+      }
+   }
+   spin_unlock_irqrestore(&lp->txLock, flags);
+
+   outl(0, ioaddr + VMXNET_INIT_ADDR);
+
+   free_irq(dev->irq, dev);
+
+   for (i = 0; i < lp->dd->txRingLength; i++) {
+      if (lp->txBufInfo[i].skb != NULL && lp->txBufInfo[i].eop) {
+	 compat_dev_kfree_skb(lp->txBufInfo[i].skb, FREE_WRITE);
+	 lp->txBufInfo[i].skb = NULL;
+      }
+   }
+
+   for (i = 0; i < lp->numRxBuffers; i++) {
+      if (lp->rxSkbuff[i] != NULL) {
+	 compat_dev_kfree_skb(lp->rxSkbuff[i], FREE_WRITE);
+	 lp->rxSkbuff[i] = NULL;
+      }
+   }
+#ifdef VMXNET_DO_ZERO_COPY
+   if (lp->jumboFrame || lp->lpd) {
+      for (i = 0; i < lp->numRxBuffers2; i++) {
+         if (lp->rxPages[i] != NULL) {
+            pci_unmap_page(lp->pdev, lp->rxRing2[i].paddr, PAGE_SIZE, PCI_DMA_FROMDEVICE);
+            put_page(lp->rxPages[i]);
+            lp->rxPages[i] = NULL;
+         }
+      }
+   }
+#endif
+
+   COMPAT_NETDEV_MOD_DEC_USE_COUNT;
+
+   return 0;
+}
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * vmxnet_load_multicast --
+ *
+ *      Load the multicast filter.
+ *
+ * Results:
+ *      return number of entries used to compute LADRF
+ *
+ * Side effects:
+ *
+ *-----------------------------------------------------------------------------
+ */
+static int
+vmxnet_load_multicast (struct net_device *dev)
+{
+    Vmxnet_Private *lp = (Vmxnet_Private *) dev->priv;
+    volatile u16 *mcast_table = (u16 *)lp->dd->LADRF;
+    struct dev_mc_list *dmi = dev->mc_list;
+    char *addrs;
+    int i, j, bit, byte;
+    u32 crc, poly = CRC_POLYNOMIAL_LE;
+
+    /* clear the multicast filter */
+    lp->dd->LADRF[0] = 0;
+    lp->dd->LADRF[1] = 0;
+
+    /* Add addresses */
+    for (i = 0; i < dev->mc_count; i++){
+	addrs = dmi->dmi_addr;
+	dmi   = dmi->next;
+
+	/* multicast address? */
+	if (!(*addrs & 1))
+	    continue;
+
+	crc = 0xffffffff;
+	for (byte = 0; byte < 6; byte++) {
+	    for (bit = *addrs++, j = 0; j < 8; j++, bit >>= 1) {
+		int test;
+
+		test = ((bit ^ crc) & 0x01);
+		crc >>= 1;
+
+		if (test) {
+		    crc = crc ^ poly;
+		}
+	    }
+	 }
+
+	 crc = crc >> 26;
+	 mcast_table [crc >> 4] |= 1 << (crc & 0xf);
+    }
+    return i;
+}
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * vmxnet_set_multicast_list --
+ *
+ *      Network device set_multicast_list routine.  Called by Linux when the
+ *      set of addresses to listen to changes, including both the multicast
+ *      list and the broadcast, promiscuous, multicast, and allmulti flags.
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      Informs lower layer of the changes.
+ *
+ *-----------------------------------------------------------------------------
+ */
+static void
+vmxnet_set_multicast_list(struct net_device *dev)
+{
+   unsigned int ioaddr = dev->base_addr;
+   Vmxnet_Private *lp = (Vmxnet_Private *)dev->priv;
+
+   lp->dd->ifflags = ~(VMXNET_IFF_PROMISC
+                      |VMXNET_IFF_BROADCAST
+                      |VMXNET_IFF_MULTICAST);
+
+   if (dev->flags & IFF_PROMISC) {
+      printk(KERN_DEBUG "%s: Promiscuous mode enabled.\n", dev->name);
+      lp->dd->ifflags |= VMXNET_IFF_PROMISC;
+   }
+   if (dev->flags & IFF_BROADCAST) {
+      lp->dd->ifflags |= VMXNET_IFF_BROADCAST;
+   }
+
+   if (dev->flags & IFF_ALLMULTI) {
+      lp->dd->LADRF[0] = 0xffffffff;
+      lp->dd->LADRF[1] = 0xffffffff;
+      lp->dd->ifflags |= VMXNET_IFF_MULTICAST;
+   } else {
+      if (vmxnet_load_multicast(dev)) {
+         lp->dd->ifflags |= VMXNET_IFF_MULTICAST;
+      }
+   }
+   outl(VMXNET_CMD_UPDATE_LADRF, ioaddr + VMXNET_COMMAND_ADDR);
+
+   outl(VMXNET_CMD_UPDATE_IFF, ioaddr + VMXNET_COMMAND_ADDR);
+}
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * vmxnet_set_mac_address --
+ *
+ *      Network device set_mac_address routine.  Called by Linux when someone
+ *      asks to change the interface's MAC address.
+ *
+ * Results:
+ *      0 for success; -EBUSY if interface is up.
+ *
+ * Side effects:
+ *
+ *-----------------------------------------------------------------------------
+ */
+static int
+vmxnet_set_mac_address(struct net_device *dev, void *p)
+{
+   struct sockaddr *addr=p;
+   unsigned int ioaddr = dev->base_addr;
+   int i;
+
+   if (compat_netif_running(dev))
+      return -EBUSY;
+
+   memcpy(dev->dev_addr, addr->sa_data, dev->addr_len);
+
+   for (i = 0; i < ETH_ALEN; i++) {
+      outb(addr->sa_data[i], ioaddr + VMXNET_MAC_ADDR + i);
+   }
+   return 0;
+}
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * vmxnet_get_stats --
+ *
+ *      Network device get_stats routine.  Called by Linux when interface
+ *      statistics are requested.
+ *
+ * Results:
+ *      Returns a pointer to our private stats structure.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+static struct net_device_stats *
+vmxnet_get_stats(struct net_device *dev)
+{
+   Vmxnet_Private *lp = (Vmxnet_Private *)dev->priv;
+
+   return &lp->stats;
+}
+
+module_init(vmxnet_init);
+module_exit(vmxnet_exit);
+MODULE_DEVICE_TABLE(pci, vmxnet_chips);
+
+/* Module information. */
+MODULE_AUTHOR("VMware, Inc.");
+MODULE_DESCRIPTION("VMware Virtual Ethernet driver");
+MODULE_LICENSE("GPL v2");
+MODULE_VERSION(VMXNET_DRIVER_VERSION_STRING);
--- kernel/linux-2.6.26.3/drivers/net/vmxnet/vmxnet_def.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/net/vmxnet/vmxnet_def.h	2008-09-03 10:07:45.000000000 -0500
@@ -0,0 +1,170 @@
+/*********************************************************
+ * Copyright (C) 1999 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef _VMXNET_DEF_H_
+#define _VMXNET_DEF_H_
+
+#define INCLUDE_ALLOW_USERLEVEL
+#define INCLUDE_ALLOW_VMMEXT
+#define INCLUDE_ALLOW_MODULE
+#define INCLUDE_ALLOW_VMK_MODULE
+#define INCLUDE_ALLOW_VMKERNEL
+#define INCLUDE_ALLOW_DISTRIBUTE
+#include "includeCheck.h"
+
+#include "net_sg.h"
+#include "vmnet_def.h"
+
+
+/*
+ *   Vmxnet I/O ports, used by both the vmxnet driver and 
+ *   the device emulation code.
+ */
+
+#define VMXNET_INIT_ADDR		0x00
+#define VMXNET_INIT_LENGTH		0x04
+#define VMXNET_TX_ADDR		        0x08
+#define VMXNET_COMMAND_ADDR		0x0c
+#define VMXNET_MAC_ADDR			0x10
+#define VMXNET_LOW_VERSION		0x18
+#define VMXNET_HIGH_VERSION		0x1c
+#define VMXNET_STATUS_ADDR		0x20
+#define VMXNET_TOE_INIT_ADDR            0x24
+#define VMXNET_APROM_ADDR               0x28
+#define VMXNET_INT_ENABLE_ADDR          0x30
+#define VMXNET_WAKE_PKT_PATTERNS        0x34
+
+/*
+ * Vmxnet command register values.
+ */
+#define VMXNET_CMD_INTR_ACK		0x0001
+#define VMXNET_CMD_UPDATE_LADRF		0x0002
+#define VMXNET_CMD_UPDATE_IFF		0x0004
+#define VMXNET_CMD_UNUSED 1		0x0008
+#define VMXNET_CMD_UNUSED_2		0x0010
+#define VMXNET_CMD_INTR_DISABLE  	0x0020
+#define VMXNET_CMD_INTR_ENABLE   	0x0040
+#define VMXNET_CMD_UNUSED_3		0x0080
+#define VMXNET_CMD_CHECK_TX_DONE	0x0100
+#define VMXNET_CMD_GET_NUM_RX_BUFFERS	0x0200
+#define VMXNET_CMD_GET_NUM_TX_BUFFERS	0x0400
+#define VMXNET_CMD_PIN_TX_BUFFERS	0x0800
+#define VMXNET_CMD_GET_CAPABILITIES	0x1000
+#define VMXNET_CMD_GET_FEATURES		0x2000
+#define VMXNET_CMD_SET_POWER_FULL       0x4000
+#define VMXNET_CMD_SET_POWER_LOW        0x8000
+
+/*
+ * Vmxnet status register values.
+ */
+#define VMXNET_STATUS_CONNECTED		0x0001
+#define VMXNET_STATUS_ENABLED		0x0002
+#define VMXNET_STATUS_TX_PINNED         0x0004
+
+/*
+ * Values for the interface flags.
+ */
+#define VMXNET_IFF_PROMISC		0x01
+#define VMXNET_IFF_BROADCAST		0x02
+#define VMXNET_IFF_MULTICAST		0x04
+#define VMXNET_IFF_DIRECTED             0x08
+
+/*
+ * Length of the multicast address filter.
+ */
+#define VMXNET_MAX_LADRF		2
+
+/*
+ * Size of Vmxnet APROM. 
+ */
+#define VMXNET_APROM_SIZE 6
+
+/*
+ * An invalid ring index.
+ */
+#define VMXNET_INVALID_RING_INDEX	(-1)
+
+/*
+ * Features that are implemented by the driver.  These are driver
+ * specific so not all features will be listed here.  In addition not all
+ * drivers have to pay attention to these feature flags.
+ *
+ *  VMXNET_FEATURE_ZERO_COPY_TX 	The driver won't do any copies as long as
+ *					the packet length is > 
+ *					Vmxnet_DriverData.minTxPhysLength.
+ * 
+ *  VMXNET_FEATURE_TSO                  The driver will use the TSO capabilities
+ *                                      of the underlying hardware if available 
+ *                                      and enabled.
+ *
+ *  VMXNET_FEATURE_JUMBO_FRAME          The driver can send/rcv jumbo frame 
+ *
+ *  VMXNET_FEATURE_LPD                  The backend can deliver large pkts
+ */
+#define VMXNET_FEATURE_ZERO_COPY_TX             0x01
+#define VMXNET_FEATURE_TSO                      0x02
+#define VMXNET_FEATURE_JUMBO_FRAME              0x04
+#define VMXNET_FEATURE_LPD                      0x08
+
+/*
+ * Define the set of capabilities required by each feature above
+ */
+#define VMXNET_FEATURE_ZERO_COPY_TX_CAPS        VMXNET_CAP_SG
+#define VMXNET_FEATURE_TSO_CAPS                 VMXNET_CAP_TSO
+#define VMXNET_HIGHEST_FEATURE_BIT              VMXNET_FEATURE_TSO
+
+#define VMXNET_INC(val, max)     \
+   val++;                        \
+   if (UNLIKELY(val == max)) {   \
+      val = 0;                   \
+   }
+
+/*
+ * code that just wants to switch on the different versions of the
+ * guest<->implementation protocol can cast driver data to this.
+ */
+typedef uint32 Vmxnet_DDMagic;
+
+/*
+ * Wake packet pattern commands sent through VMXNET_WAKE_PKT_PATTERNS port
+ */
+
+#define VMXNET_PM_OPCODE_START 3 /* args: cnt of wake packet patterns */
+#define VMXNET_PM_OPCODE_LEN   2 /* args: index of wake packet pattern */
+                                 /*       number of pattern byte values */
+#define VMXNET_PM_OPCODE_DATA  1 /* args: index of wake packet pattern */
+                                 /*       offset in pattern byte values list */
+                                 /*       packet byte offset */
+                                 /*       packet byte value */
+#define VMXNET_PM_OPCODE_END   0 /* args: <none> */
+
+typedef union Vmxnet_WakePktCmd {
+   uint32 pktData : 32;
+   struct {
+      unsigned cmd : 2; /* wake packet pattern cmd [from list above] */
+      unsigned cnt : 3; /* cnt wk pkt pttrns 1..MAX_NUM_FILTER_PTTRNS */
+      unsigned ind : 3; /* ind wk pkt pttrn 0..MAX_NUM_FILTER_PTTRNS-1 */
+      unsigned lenOff : 8; /* num pttrn byte vals 1..MAX_PKT_FILTER_SIZE */
+                           /* OR offset in pattern byte values list */
+                           /* 0..MAX_PKT_FILTER_SIZE-1 */
+      unsigned byteOff : 8; /* pkt byte offset 0..MAX_PKT_FILTER_SIZE-1 */
+      unsigned byteVal : 8; /* packet byte value 0..255 */
+   } pktPttrn;
+} Vmxnet_WakePktCmd;
+
+#endif /* _VMXNET_DEF_H_ */
--- kernel/linux-2.6.26.3/drivers/net/vmxnet/vmxnetInt.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/net/vmxnet/vmxnetInt.h	2008-09-03 10:07:45.000000000 -0500
@@ -0,0 +1,110 @@
+/*********************************************************
+ * Copyright (C) 1998 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __VMXNETINT_H__
+#define __VMXNETINT_H__
+
+#define INCLUDE_ALLOW_MODULE
+#include "includeCheck.h"
+
+#define VMXNET_CHIP_NAME "vmxnet ether"
+
+#define CRC_POLYNOMIAL_LE 0xedb88320UL  /* Ethernet CRC, little endian */
+
+#define PKT_BUF_SZ			1536
+#define VMXNET_MIN_MTU                  (ETH_MIN_FRAME_LEN - 14)
+#define VMXNET_MAX_MTU                  (16 * 1024 - 18)
+
+/* Largest address able to be shared between the driver and the device */
+#define SHARED_MEM_MAX 0xFFFFFFFF
+
+typedef enum Vmxnet_TxStatus {
+   VMXNET_CALL_TRANSMIT,
+   VMXNET_DEFER_TRANSMIT,
+   VMXNET_STOP_TRANSMIT
+} Vmxnet_TxStatus;
+
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,1,0))
+#   define MODULE_PARM(var, type)
+#   define net_device_stats enet_statistics
+#endif
+
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,2,0))
+#   define le16_to_cpu(x) ((__u16)(x))
+#   define le32_to_cpu(x) ((__u32)(x))
+#endif
+
+#if defined(BUG_ON)
+#define VMXNET_ASSERT(cond) BUG_ON(!(cond))
+#else
+#define VMXNET_ASSERT(cond)
+#endif
+
+struct Vmxnet2_TxBuf {
+   struct sk_buff *skb;
+   char    sgForLinear; /* the sg entry mapping the linear part 
+                         * of the skb, -1 means this tx entry only
+                         * mapps the frags of the skb
+                         */ 
+   char    firstSgForFrag;   /* the first sg entry mapping the frags */
+   Bool    eop;
+};
+
+/*
+ * Private data area, pointed to by priv field of our struct net_device.
+ * dd field is shared with the lower layer.
+ */
+typedef struct Vmxnet_Private {
+   Vmxnet2_DriverData	       *dd;
+   const char 		       *name;
+   struct net_device_stats	stats;
+   struct sk_buff	       *rxSkbuff[ENHANCED_VMXNET2_MAX_NUM_RX_BUFFERS];
+   struct page                 *rxPages[VMXNET2_MAX_NUM_RX_BUFFERS2];
+   struct Vmxnet2_TxBuf         txBufInfo[VMXNET2_MAX_NUM_TX_BUFFERS_TSO];
+   spinlock_t                   txLock;
+   int				numTxPending;
+   unsigned int			numRxBuffers;
+   unsigned int			numRxBuffers2;
+   unsigned int			numTxBuffers;
+   Vmxnet2_RxRingEntry         *rxRing;
+   Vmxnet2_RxRingEntry         *rxRing2;
+   Vmxnet2_TxRingEntry         *txRing;
+
+   Bool				devOpen;
+   uint32			portID;
+
+   uint32                       capabilities;
+   uint32                       features;
+
+   Bool                         zeroCopyTx;
+   Bool                         partialHeaderCopyEnabled;
+   Bool                         tso;
+   Bool                         chainTx;
+   Bool                         chainRx;
+   Bool                         jumboFrame;
+   Bool                         lpd;
+   
+   Bool                         morphed;           // Indicates whether adapter is morphed
+   void                        *ddAllocated;
+   char                        *txBufferStartRaw;
+   char                        *txBufferStart;
+   struct pci_dev              *pdev;
+   struct timer_list            linkCheckTimer;
+} Vmxnet_Private;
+
+#endif /* __VMXNETINT_H__ */
--- kernel/linux-2.6.26.3/drivers/net/vmxnet/vmxnet_version.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/drivers/net/vmxnet/vmxnet_version.h	2008-09-03 10:07:45.000000000 -0500
@@ -0,0 +1,32 @@
+/*********************************************************
+ * Copyright (C) 2007 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * vmxnet_version.h --
+ *
+ * Version definitions for the Linux vmxnet driver.
+ */
+
+#ifndef _VMXNET_VERSION_H_
+#define _VMXNET_VERSION_H_
+
+#define VMXNET_DRIVER_VERSION          2.0.1.1
+#define VMXNET_DRIVER_VERSION_COMMAS   2,0,1,1
+#define VMXNET_DRIVER_VERSION_STRING   "2.0.1.1"
+
+#endif /* _VMXNET_VERSION_H_ */
--- kernel/linux-2.6.26.3/fs/Kconfig	2008-09-03 09:55:44.000000000 -0500
+++ linux-2.6.26.3.vmtools/fs/Kconfig	2008-09-03 09:57:35.000000000 -0500
@@ -1656,6 +1656,24 @@ config UFS_DEBUG
 	  Y here.  This will result in _many_ additional debugging messages to be
 	  written to the system log.
 
+config VMBLOCK
+	tristate "VMware vmblock"
+	help
+	  When loaded, vmblock will establish itself in /proc/fs/vmblock and create
+	  two nodes therein, dev and mountPoint. Before mounting a vmblock filesystem,
+	  ensure that /tmp/VMwareDnD exists as a directory with permissions 1777,
+	  otherwise host to guest drag n' drop operations won't work.
+
+config VMHGFS
+	tristate "VMware vmhgfs"
+	help
+	  When mounting, one must use an NFS-like "<host>:<export>" syntax. The <host>
+	  field must be ".host", while the <export> field can be "/", a path to a specific
+	  Shared Folder, or a path to a subdirectory within that Shared Folder. To mount,
+	  you must first build vmware-hgfsmounter and install it setuid as /sbin/mount.vmhgfs,
+	  otherwise the mount program won't properly call out to it. Note that mounting may fail
+	  if Shared Folders are disabled in the host; don't be alarmed.
+
 endmenu
 
 menuconfig NETWORK_FILESYSTEMS
--- kernel/linux-2.6.26.3/fs/Makefile	2008-09-03 09:55:44.000000000 -0500
+++ linux-2.6.26.3.vmtools/fs/Makefile	2008-09-03 09:57:35.000000000 -0500
@@ -121,3 +121,5 @@ obj-$(CONFIG_HPPFS)		+= hppfs/
 obj-$(CONFIG_DEBUG_FS)		+= debugfs/
 obj-$(CONFIG_OCFS2_FS)		+= ocfs2/
 obj-$(CONFIG_GFS2_FS)           += gfs2/
+obj-$(CONFIG_VMBLOCK)		+= vmblock/
+obj-$(CONFIG_VMHGFS)		+= vmhgfs/
--- kernel/linux-2.6.26.3/fs/vmblock/block.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmblock/block.c	2008-09-03 09:58:40.000000000 -0500
@@ -0,0 +1,612 @@
+/*********************************************************
+ * Copyright (C) 2006 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * block.c --
+ *
+ *      Blocking operation implementions for the vmblock driver.
+ */
+
+/* os.h includes necessary OS-specific headers. */
+#include "os.h"
+
+#if defined(vmblock_fuse)
+#elif defined(linux)
+# include "vmblockInt.h"
+#elif defined(sun)
+# include "module.h"
+#elif defined(__FreeBSD__)
+# include "vmblock_k.h"
+#endif
+#include "block.h"
+#include "stubs.h"
+#include "dbllnklst.h"
+
+typedef struct BlockInfo {
+   DblLnkLst_Links links;
+   os_atomic_t refcount;
+   os_blocker_id_t blocker;
+   os_completion_t completion;
+   char filename[OS_PATH_MAX];
+} BlockInfo;
+
+
+/* XXX: Is it worth turning this into a hash table? */
+static DblLnkLst_Links blockedFiles;
+static os_rwlock_t blockedFilesLock;
+static os_kmem_cache_t *blockInfoCache = NULL;
+
+/* Utility functions */
+static Bool BlockExists(const char *filename);
+static BlockInfo *GetBlock(const char *filename, const os_blocker_id_t blocker);
+static BlockInfo *AllocBlock(os_kmem_cache_t *cache,
+                             const char *filename, const os_blocker_id_t blocker);
+static void FreeBlock(os_kmem_cache_t *cache, BlockInfo *block);
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * BlockInit --
+ *
+ *    Initializes blocking portion of module.
+ *
+ * Results:
+ *    Zero on success, error code on failure.
+ *
+ * Side effects:
+ *    None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+int
+BlockInit(void)
+{
+   ASSERT(!blockInfoCache);
+
+   blockInfoCache = os_kmem_cache_create("blockInfoCache",
+                                         sizeof (BlockInfo),
+                                         0,
+                                         NULL);
+   if (!blockInfoCache) {
+      return OS_ENOMEM;
+   }
+
+   DblLnkLst_Init(&blockedFiles);
+   os_rwlock_init(&blockedFilesLock);
+
+   return 0;
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * BlockCleanup --
+ *
+ *    Cleans up the blocking portion of the module.
+ *
+ * Results:
+ *    None.
+ *
+ * Side effects:
+ *    None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+void
+BlockCleanup(void)
+{
+   ASSERT(blockInfoCache);
+   ASSERT(!DblLnkLst_IsLinked(&blockedFiles));
+
+   os_rwlock_destroy(&blockedFilesLock);
+   os_kmem_cache_destroy(blockInfoCache);
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * BlockAddFileBlock --
+ *
+ *    Adds a block for the provided filename.  filename should be the name of
+ *    the actual file being blocked, not the name within our namespace.  The
+ *    provided blocker ID should uniquely identify this blocker.
+ *
+ *    All calls to BlockWaitOnFile() with the same filename will not return
+ *    until BlockRemoveFileBlock() is called.
+ *
+ *    Note that this function assumes a block on filename does not already
+ *    exist.
+ *
+ * Results:
+ *    Zero on success, error code on failure.
+ *
+ * Side effects:
+ *    None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+int
+BlockAddFileBlock(const char *filename,           // IN: name of file to block
+                  const os_blocker_id_t blocker)  // IN: blocker adding the block
+{
+   BlockInfo *block;
+
+   ASSERT(filename);
+
+   /* Create a new block. */
+   block = AllocBlock(blockInfoCache, filename, blocker);
+   if (!block) {
+      Warning("BlockAddFileBlock: out of memory\n");
+      return OS_ENOMEM;
+   }
+   os_write_lock(&blockedFilesLock);
+
+   /*
+    * Prevent duplicate blocks of any filename.  Done under same lock as list
+    * addition to ensure check for and adding of file are atomic.
+    */
+   if (BlockExists(filename)) {
+      Warning("BlockAddFileBlock: block already exists for [%s]\n", filename);
+      os_write_unlock(&blockedFilesLock);
+      FreeBlock(blockInfoCache, block);
+      return OS_EEXIST;
+   }
+
+   DblLnkLst_LinkLast(&blockedFiles, &block->links);
+
+   os_write_unlock(&blockedFilesLock);
+
+   LOG(4, "added block for [%s]\n", filename);
+
+   return 0;
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * BlockRemoveFileBlock --
+ *
+ *    Removes the provided file block and wakes up any threads waiting within
+ *    BlockWaitOnFile().  Note that only the blocker that added a block can
+ *    remove it.
+ *
+ * Results:
+ *    Zero on success, error code on failure.
+ *
+ * Side effects:
+ *    None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+int
+BlockRemoveFileBlock(const char *filename,          // IN: block to remove
+                     const os_blocker_id_t blocker) // IN: blocker removing this block
+{
+   BlockInfo *block;
+
+   ASSERT(filename);
+
+   os_write_lock(&blockedFilesLock);
+
+   block = GetBlock(filename, blocker);
+   if (!block) {
+      os_write_unlock(&blockedFilesLock);
+      return OS_ENOENT;
+   }
+
+   DblLnkLst_Unlink1(&block->links);
+   os_write_unlock(&blockedFilesLock);
+
+   /* Undo GetBlock's refcount increment first. */
+   os_atomic_dec(&block->refcount);
+
+   /*
+    * Now remove /our/ reference.  (As opposed to references by waiting
+    * threads.)
+    */
+   if (os_atomic_dec_and_test(&block->refcount)) {
+      /* No threads are waiting, so clean up ourself. */
+      LOG(4, "Freeing block with no waiters on [%s]\n", filename);
+      FreeBlock(blockInfoCache, block);
+   } else {
+      /* Wake up waiters; the last one will free the BlockInfo */
+      LOG(4, "Completing block on [%s]\n", filename);
+      os_complete_all(&block->completion);
+   }
+
+   return 0;
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * BlockRemoveAllBlocks --
+ *
+ *    Removes all blocks added by the provided blocker.
+ *
+ * Results:
+ *    Returns the number of entries removed from the blocklist.
+ *
+ * Side effects:
+ *    None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+unsigned int
+BlockRemoveAllBlocks(const os_blocker_id_t blocker)  // IN: blocker to remove blocks for
+{
+   struct DblLnkLst_Links *curr;
+   struct DblLnkLst_Links *tmp;
+   unsigned int removed = 0;
+
+   os_write_lock(&blockedFilesLock);
+
+   DblLnkLst_ForEachSafe(curr, tmp, &blockedFiles) {
+      BlockInfo *currBlock = DblLnkLst_Container(curr, BlockInfo, links);
+      if (currBlock->blocker == blocker || blocker == OS_UNKNOWN_BLOCKER) {
+
+         DblLnkLst_Unlink1(&currBlock->links);
+
+         /*
+          * We count only entries removed from the -list-, regardless of whether
+          * or not other waiters exist.
+          */
+         ++removed;
+
+         /*
+          * BlockInfos, as the result of placing a block on a file or directory,
+          * reference themselves.  When the block is lifted, we need to remove
+          * this self-reference and handle the result appropriately.
+          */
+         if (os_atomic_dec_and_test(&currBlock->refcount)) {
+            /* Free blocks without any waiters ... */
+            LOG(4, "Freeing block with no waiters for blocker [%p] (%s)\n",
+                blocker, currBlock->filename);
+            FreeBlock(blockInfoCache, currBlock);
+         } else {
+            /* ... or wakeup the waiting threads */
+            LOG(4, "Completing block for blocker [%p] (%s)\n",
+                blocker, currBlock->filename);
+            os_complete_all(&currBlock->completion);
+         }
+      }
+   }
+
+   os_write_unlock(&blockedFilesLock);
+
+   return removed;
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * BlockWaitOnFile --
+ *
+ *    Searches for a block on the provided filename.  If one exists, this
+ *    function does not return until that block has been lifted; otherwise, it
+ *    returns right away.
+ *
+ * Results:
+ *    Zero on success, otherwise an appropriate system error if our sleep/
+ *    block is interrupted.
+ *
+ * Side effects:
+ *    None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+int
+BlockWaitOnFile(const char *filename,   // IN: file to block on
+                BlockHandle cookie)     // IN: previously found block
+{
+   BlockInfo *block = NULL;
+   int error = 0;
+
+   ASSERT(filename);
+
+   /*
+    * Caller may have used BlockLookup to conditionally search for a
+    * block before actually going to sleep.  (This allows the caller to
+    * do a little housekeeping, such as releasing vnode locks, before
+    * blocking here.)
+    */
+   if (cookie == NULL) {
+      os_read_lock(&blockedFilesLock);
+      block = GetBlock(filename, OS_UNKNOWN_BLOCKER);
+      os_read_unlock(&blockedFilesLock);
+
+      if (!block) {
+         /* This file is not blocked, just return */
+         return 0;
+      }
+   } else {
+      /*
+       * Note that the "cookie's" reference count was incremented when it
+       * was fetched via BlockLookup, so this is completely safe.  (We'll
+       * decrement it below.)
+       */
+      block = cookie;
+   }
+
+   LOG(4, "(%"OS_FMTTID") Waiting for completion on [%s]\n", os_threadid, filename);
+   error = os_wait_for_completion(&block->completion);
+   LOG(4, "(%"OS_FMTTID") Wokeup from block on [%s]\n", os_threadid, filename);
+
+   /*
+    * The assumptions here are as follows:
+    *   1.  The BlockInfo holds a reference to itself.  (BlockInfo's refcount
+    *       is initialized to 1.)
+    *   2.  BlockInfo's self reference is deleted only when BlockInfo is
+    *       /also/ removed removed from the block list.
+    *
+    * Therefore, if the reference count hits zero, it's because the block is
+    * no longer in the list, and there is no chance of another thread finding
+    * and referencing this block between our dec_and_test and freeing it.
+    */
+   if (os_atomic_dec_and_test(&block->refcount)) {
+      /* We were the last thread, so clean up */
+      LOG(4, "(%"OS_FMTTID") I am the last to wakeup, freeing the block on [%s]\n",
+          os_threadid, filename);
+      FreeBlock(blockInfoCache, block);
+   }
+
+   return error;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * BlockLookup --
+ *
+ *      VFS-exported function for searching for blocks.
+ *
+ * Results:
+ *      Opaque pointer to a blockInfo if a block is found, NULL otherwise.
+ *
+ * Side effects:
+ *      Located blockInfo, if any, has an incremented reference count.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+BlockHandle
+BlockLookup(const char *filename,               // IN: pathname to test for
+                                                //     blocking
+            const os_blocker_id_t blocker)      // IN: specific blocker to
+                                                //     search for
+{
+   BlockInfo *block;
+
+   os_read_lock(&blockedFilesLock);
+
+   block = GetBlock(filename, blocker);
+
+   os_read_unlock(&blockedFilesLock);
+
+   return block;
+}
+
+
+#ifdef VMX86_DEVEL
+/*
+ *----------------------------------------------------------------------------
+ *
+ * BlockListFileBlocks --
+ *
+ *    Lists all the current file blocks.
+ *
+ * Results:
+ *    None.
+ *
+ * Side effects:
+ *    None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+void
+BlockListFileBlocks(void)
+{
+   DblLnkLst_Links *curr;
+   int count = 0;
+
+   os_read_lock(&blockedFilesLock);
+
+   DblLnkLst_ForEach(curr, &blockedFiles) {
+      BlockInfo *currBlock = DblLnkLst_Container(curr, BlockInfo, links);
+      LOG(1, "BlockListFileBlocks: (%d) Filename: [%s], Blocker: [%p]\n",
+          count++, currBlock->filename, currBlock->blocker);
+   }
+
+   os_read_unlock(&blockedFilesLock);
+
+   if (!count) {
+      LOG(1, "BlockListFileBlocks: No blocks currently exist.\n");
+   }
+}
+#endif
+
+
+/* Utility functions */
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * BlockExists --
+ *
+ *    Checks if a block already exists for the provided filename.
+ *
+ *    Note that this assumes the proper locking has been done on the data
+ *    structure holding the blocked files (including ensuring the atomic_dec()
+ *    without a kmem_cache_free() is safe).
+ *
+ * Results:
+ *    TRUE if a block exists, FALSE otherwise.
+ *
+ * Side effects:
+ *    If a block exists, its refcount is incremented and decremented.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+static Bool
+BlockExists(const char *filename)
+{
+   BlockInfo *block = GetBlock(filename, OS_UNKNOWN_BLOCKER);
+
+   if (block) {
+      os_atomic_dec(&block->refcount);
+      return TRUE;
+   }
+
+   return FALSE;
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * GetBlock --
+ *
+ *    Searches for a block on the provided filename by the provided blocker.
+ *    If blocker is NULL, it is ignored and any matching filename is returned.
+ *    If a block is found, the refcount is incremented.
+ *
+ *    Note that this assumes the proper locking has been done on the data
+ *    structure holding the blocked files.
+ *
+ * Results:
+ *    A pointer to the corresponding BlockInfo if found, NULL otherwise.
+ *
+ * Side effects:
+ *    None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+static BlockInfo *
+GetBlock(const char *filename,          // IN: file to find block for
+         const os_blocker_id_t blocker) // IN: blocker associated with this block
+{
+   struct DblLnkLst_Links *curr;
+
+   /* XXX The following is only temporary. */
+#ifdef __FreeBSD__
+   os_assert_rwlock_held(&blockedFilesLock);
+#else
+   ASSERT(os_rwlock_held(&blockedFilesLock));
+#endif
+
+   DblLnkLst_ForEach(curr, &blockedFiles) {
+      BlockInfo *currBlock = DblLnkLst_Container(curr, BlockInfo, links);
+      if ((blocker == OS_UNKNOWN_BLOCKER || currBlock->blocker == blocker) &&
+          strcmp(currBlock->filename, filename) == 0) {
+         os_atomic_inc(&currBlock->refcount);
+         return currBlock;
+      }
+   }
+
+   return NULL;
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * AllocBlock --
+ *
+ *    Allocates and initializes a new block structure.
+ *
+ * Results:
+ *    Pointer to the struct on success, NULL on failure.
+ *
+ * Side effects:
+ *    None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+BlockInfo *
+AllocBlock(os_kmem_cache_t *cache,        // IN: cache to allocate from
+           const char *filename,          // IN: filname of block
+           const os_blocker_id_t blocker) // IN: blocker id
+{
+   BlockInfo *block;
+   size_t ret;
+
+   /* Initialize this file's block structure. */
+   block = os_kmem_cache_alloc(blockInfoCache);
+   if (!block) {
+      return NULL;
+   }
+
+   ret = strlcpy(block->filename, filename, sizeof block->filename);
+   if (ret >= sizeof block->filename) {
+      Warning("BlockAddFileBlock: filename is too large\n");
+      os_kmem_cache_free(blockInfoCache, block);
+      return NULL;
+   }
+
+   DblLnkLst_Init(&block->links);
+   os_atomic_set(&block->refcount, 1);
+   os_completion_init(&block->completion);
+   block->blocker = blocker;
+
+   return block;
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * FreeBlock --
+ *
+ *    Frees the provided block structure.
+ *
+ * Results:
+ *    None.
+ *
+ * Side effects:
+ *    None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+static void
+FreeBlock(os_kmem_cache_t *cache,       // IN: cache block was allocated from
+          BlockInfo *block)             // IN: block to free
+{
+   ASSERT(cache);
+   ASSERT(block);
+
+   os_completion_destroy(&block->completion);
+   os_kmem_cache_free(cache, block);
+}
--- kernel/linux-2.6.26.3/fs/vmblock/block.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmblock/block.h	2008-09-03 09:57:35.000000000 -0500
@@ -0,0 +1,47 @@
+/*********************************************************
+ * Copyright (C) 2006 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * block.h --
+ *
+ *   Blocking operations for the vmblock driver.
+ */
+
+#ifndef __BLOCK_H__
+#define __BLOCK_H__
+
+#include "os.h"
+
+typedef struct BlockInfo * BlockHandle;
+
+/*
+ * Global functions
+ */
+
+int BlockInit(void);
+void BlockCleanup(void);
+int BlockAddFileBlock(const char *filename, const os_blocker_id_t blocker);
+int BlockRemoveFileBlock(const char *filename, const os_blocker_id_t blocker);
+unsigned int BlockRemoveAllBlocks(const os_blocker_id_t blocker);
+int BlockWaitOnFile(const char *filename, BlockHandle cookie);
+BlockHandle BlockLookup(const char *filename, const os_blocker_id_t blocker);
+#ifdef VMX86_DEVEL
+void BlockListFileBlocks(void);
+#endif
+
+#endif /* __BLOCK_H__ */
--- kernel/linux-2.6.26.3/fs/vmblock/compat_completion.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmblock/compat_completion.h	2008-09-03 09:58:40.000000000 -0500
@@ -0,0 +1,175 @@
+/*********************************************************
+ * Copyright (C) 2004 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_COMPLETION_H__
+#   define __COMPAT_COMPLETION_H__
+
+/*
+ * The kernel's completion objects were made available for module use in 2.4.9.
+ * 
+ * Between 2.4.0 and 2.4.9, we implement completions on our own using 
+ * waitqueues and counters. This was done so that we could safely support
+ * functions like complete_all(), which cannot be implemented using semaphores.
+ *
+ * Prior to that, the waitqueue API is substantially different, and since none 
+ * of our modules that are built against older kernels need complete_all(), 
+ * we fallback on a simple semaphore-based implementation. 
+ */
+
+/* 
+ * Native completions.
+ */ 
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 4, 9)
+
+#include <linux/completion.h>
+#define compat_completion struct completion
+#define compat_init_completion(comp) init_completion(comp)
+#define COMPAT_DECLARE_COMPLETION DECLARE_COMPLETION
+#define compat_wait_for_completion(comp) wait_for_completion(comp)
+#define compat_complete(comp) complete(comp)
+
+/* complete_all() was exported in 2.6.6. */
+# if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 6)
+#  include "compat_wait.h"
+#  include "compat_list.h"
+#  include "compat_spinlock.h"
+#  include "compat_sched.h"
+#  define compat_complete_all(x)         \
+      ({                                 \
+          struct list_head *currLinks;   \
+          spin_lock(&(x)->wait.lock);    \
+          (x)->done += UINT_MAX/2;       \
+                                         \
+          list_for_each(currLinks, &(x)->wait.task_list) { \
+             wait_queue_t *currQueue = list_entry(currLinks, wait_queue_t, task_list); \
+             wake_up_process(currQueue->task); \
+          }                              \
+          spin_unlock(&(x)->wait.lock);  \
+      })
+# else
+#  define compat_complete_all complete_all
+# endif
+
+/* 
+ * Completions via waitqueues.
+ */
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(2, 4, 0)
+
+/*
+ * Kernel completions in 2.4.9 and beyond use a counter and a waitqueue, and 
+ * our implementation is quite similar. Because __wake_up_common() is not 
+ * exported, our implementations of compat_complete() and compat_complete_all()
+ * are somewhat racy: the counter is incremented outside of the waitqueue's 
+ * lock. 
+ *
+ * As a result, our completion cannot guarantee in-order wake ups. For example,
+ * suppose thread A is entering compat_complete(), thread B is sleeping inside
+ * compat_wait_for_completion(), and thread C is just now entering
+ * compat_wait_for_completion(). If Thread A is scheduled first and increments 
+ * the counter, then gets swapped out, thread C may get scheduled and will 
+ * quickly go through compat_wait_for_completion() (since done != 0) while 
+ * thread B continues to sleep, even though thread B should have been the one 
+ * to wake up.
+ */
+
+#include <asm/current.h>
+#include "compat_sched.h"
+#include "compat_list.h"
+#include <linux/smp_lock.h> // for lock_kernel()/unlock_kernel()
+#include "compat_wait.h"
+
+typedef struct compat_completion {
+   unsigned int done;
+   wait_queue_head_t wq;
+} compat_completion;
+
+#define compat_init_completion(comp) do { \
+   (comp)->done = 0; \
+   init_waitqueue_head(&(comp)->wq); \
+} while (0)
+#define COMPAT_DECLARE_COMPLETION(comp) \
+   compat_completion comp = { \
+     .done = 0, \
+     .wq = __WAIT_QUEUE_HEAD_INITIALIZER((comp).wq), \
+   }
+
+/*
+ * Locking and unlocking the kernel lock here ensures that the thread
+ * is no longer running in module code: compat_complete_and_exit
+ * performs the sequence { lock_kernel(); up(comp); compat_exit(); }, with
+ * the final unlock_kernel performed implicitly by the resident kernel
+ * in do_exit.
+ */
+#define compat_wait_for_completion(comp) do { \
+   spin_lock_irq(&(comp)->wq.lock); \
+   if (!(comp)->done) { \
+      DECLARE_WAITQUEUE(wait, current); \
+      wait.flags |= WQ_FLAG_EXCLUSIVE; \
+      __add_wait_queue_tail(&(comp)->wq, &wait); \
+      do { \
+         __set_current_state(TASK_UNINTERRUPTIBLE); \
+         spin_unlock_irq(&(comp)->wq.lock); \
+         schedule(); \
+         spin_lock_irq(&(comp)->wq.lock); \
+      } while (!(comp)->done); \
+      __remove_wait_queue(&(comp)->wq, &wait); \
+   } \
+   (comp)->done--; \
+   spin_unlock_irq(&(comp)->wq.lock); \
+   lock_kernel(); \
+   unlock_kernel(); \
+} while (0)
+
+/* XXX: I don't think I need to touch the BKL. */
+#define compat_complete(comp) do { \
+   unsigned long flags; \
+   spin_lock_irqsave(&(comp)->wq.lock, flags); \
+   (comp)->done++; \
+   spin_unlock_irqrestore(&(comp)->wq.lock, flags); \
+   wake_up(&(comp)->wq); \
+} while (0)
+
+#define compat_complete_all(comp) do { \
+   unsigned long flags; \
+   spin_lock_irqsave(&(comp)->wq.lock, flags); \
+   (comp)->done += UINT_MAX / 2; \
+   spin_unlock_irqrestore(&(comp)->wq.lock, flags); \
+   wake_up_all(&(comp)->wq); \
+} while (0)
+
+/*
+ * Completions via semaphores.
+ */ 
+#else
+
+#include "compat_semaphore.h"
+#define compat_completion struct semaphore 
+#define compat_init_completion(comp) init_MUTEX_LOCKED(comp)
+#define COMPAT_DECLARE_COMPLETION(comp) DECLARE_MUTEX_LOCKED(comp) 
+
+#define compat_wait_for_completion(comp) do { \
+   down(comp); \
+   lock_kernel(); \
+   unlock_kernel(); \
+} while (0)
+
+#define compat_complete(comp) up(comp)
+
+#endif
+
+#endif /* __COMPAT_COMPLETION_H__ */
--- kernel/linux-2.6.26.3/fs/vmblock/compat_file.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmblock/compat_file.h	2008-09-03 09:58:40.000000000 -0500
@@ -0,0 +1,56 @@
+/*********************************************************
+ * Copyright (C) 2002 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_FILE_H__
+#   define __COMPAT_FILE_H__
+
+
+/* The fput() API is modified in 2.2.0 --hpreg */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 2, 0)
+#   define compat_fput(_file) fput(_file)
+#else
+#   define compat_fput(_file) fput(_file, (_file)->f_inode)
+#endif
+
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 4, 0)
+#   define compat_get_file(_file) get_file(_file)
+#   define compat_file_count(_file) file_count(_file)
+#else
+#   define compat_get_file(_file) (_file)->f_count++
+#   define compat_file_count(_file) (_file)->f_count
+#endif
+
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 2, 4)
+#   define compat_filp_close(_file, _files) filp_close(_file, _files)
+#else
+static inline void compat_filp_close(struct file* filp, fl_owner_t files) {
+   if (filp->f_op && filp->f_op->flush) {
+      filp->f_op->flush(filp);
+   }
+   /*
+    * Hopefully there are no locks to release on this filp. 
+    * locks_remove_posix is not exported so we cannot use it...
+    */
+   fput(filp);
+}
+#endif
+
+
+#endif /* __COMPAT_FILE_H__ */
--- kernel/linux-2.6.26.3/fs/vmblock/compat_fs.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmblock/compat_fs.h	2008-09-03 09:58:40.000000000 -0500
@@ -0,0 +1,247 @@
+/*********************************************************
+ * Copyright (C) 2006 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_FS_H__
+#   define __COMPAT_FS_H__
+
+#include <linux/fs.h>
+
+/*
+ * 2.6.5+ kernels define FS_BINARY_MOUNTDATA. Since it didn't exist and
+ * wasn't used prior, it's safe to define it to zero.
+ */
+
+#ifndef FS_BINARY_MOUNTDATA
+#define FS_BINARY_MOUNTDATA 0
+#endif
+
+/*
+ * MAX_LFS_FILESIZE wasn't defined until 2.5.4.
+ */
+#ifndef MAX_LFS_FILESIZE
+#   include <linux/pagemap.h>
+#   if BITS_PER_LONG == 32
+#      define MAX_LFS_FILESIZE       (((u64)PAGE_CACHE_SIZE << (BITS_PER_LONG - 1)) - 1)
+#   elif BITS_PER_LONG == 64
+#      define MAX_LFS_FILESIZE       0x7fffffffffffffffUL
+#   endif
+#endif
+
+
+/*
+ * sendfile as a VFS op was born in 2.5.30. Unfortunately, it also changed
+ * signatures, first in 2.5.47, then again in 2.5.70, then again in 2.6.8.
+ * Luckily, the 2.6.8+ signature is the same as the 2.5.47 signature.  And
+ * as of 2.6.23-rc1 sendfile is gone, replaced by splice_read...
+ *
+ * Let's not support sendfile from 2.5.30 to 2.5.47, because the 2.5.30
+ * signature is much different and file_send_actor isn't externed.
+ */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 23)
+#define VMW_SENDFILE_NONE
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 8)
+#define VMW_SENDFILE_NEW
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(2, 5, 70)
+#define VMW_SENDFILE_OLD
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(2, 5, 47)
+#define VMW_SENDFILE_NEW
+#else
+#define VMW_SENDFILE_NONE
+#endif
+
+/*
+ * splice_read is there since 2.6.17, but let's avoid 2.6.17-rcX kernels...
+ * After all nobody is using splice system call until 2.6.23 using it to
+ * implement sendfile.
+ */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 18)
+#define VMW_SPLICE_READ 1
+#endif
+
+/*
+ * Filesystems wishing to use generic page cache read/write routines are
+ * supposed to implement aio_read and aio_write (calling into
+ * generic_file_aio_read() and generic_file_aio_write() if necessary).
+ *
+ * The VFS exports do_sync_read() and do_sync_write() as the "new"
+ * generic_file_read() and generic_file_write(), but filesystems need not
+ * actually implement read and write- the VFS will automatically call
+ * do_sync_write() and do_sync_read() when applications invoke the standard
+ * read() and write() system calls.
+ *
+ * In 2.6.19, generic_file_read() and generic_file_write() were removed,
+ * necessitating this change. AIO dates as far back as 2.5.42, but the API has
+ * changed over time, so for simplicity, we'll only enable it from 2.6.19 and
+ * on.
+ */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 19)
+# define VMW_USE_AIO
+#endif
+
+
+/*
+ * The alloc_inode and destroy_inode VFS ops didn't exist prior to 2.4.21.
+ * Without these functions, file systems can't embed inodes.
+ */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 4, 21)
+# define VMW_EMBED_INODE
+#endif
+
+
+/*
+ * iget() was removed from the VFS as of 2.6.25-rc1. The replacement for iget()
+ * is iget_locked() which was added in 2.5.17.
+ */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 5, 17)
+# define VMW_USE_IGET_LOCKED
+#endif
+
+/*
+ * parent_ino was born in 2.5.5. For older kernels, let's use 2.5.5
+ * implementation. It uses the dcache lock which is OK because per-dentry
+ * locking appeared after 2.5.5.
+ */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 5, 5)
+#define compat_parent_ino(dentry) parent_ino(dentry)
+#else
+#define compat_parent_ino(dentry)                                             \
+({                                                                            \
+   ino_t res;                                                                 \
+   spin_lock(&dcache_lock);                                                   \
+   res = dentry->d_parent->d_inode->i_ino;                                    \
+   spin_unlock(&dcache_lock);                                                 \
+   res;                                                                       \
+})
+#endif
+
+
+/*
+ * putname changed to __putname in 2.6.6.
+ */
+#define compat___getname() __getname()
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 6)
+#define compat___putname(name) putname(name)
+#else
+#define compat___putname(name) __putname(name)
+#endif
+
+
+/*
+ * inc_nlink, drop_nlink, and clear_nlink were added in 2.6.19.
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 19)
+#define compat_inc_nlink(inode) ((inode)->i_nlink++)
+#define compat_drop_nlink(inode) ((inode)->i_nlink--)
+#define compat_clear_nlink(inode) ((inode)->i_nlink = 0)
+#else
+#define compat_inc_nlink(inode) inc_nlink(inode)
+#define compat_drop_nlink(inode) drop_nlink(inode)
+#define compat_clear_nlink(inode) clear_nlink(inode)
+#endif
+
+
+/*
+ * i_size_write and i_size_read were introduced in 2.6.0-test1 
+ * (though we'll look for them as of 2.6.1). They employ slightly different
+ * locking in order to guarantee atomicity, depending on the length of a long,
+ * whether the kernel is SMP, or whether the kernel is preemptible. Prior to
+ * i_size_write and i_size_read, there was no such locking, so that's the
+ * behavior we'll emulate.
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 1)
+#define compat_i_size_read(inode) ((inode)->i_size)
+#define compat_i_size_write(inode, size) ((inode)->i_size = size)
+#else
+#define compat_i_size_read(inode) i_size_read(inode)
+#define compat_i_size_write(inode, size) i_size_write(inode, size)
+#endif
+
+
+/*
+ * filemap_fdatawrite was introduced in 2.5.12. Prior to that, modules used
+ * filemap_fdatasync instead. In 2.4.18, both filemap_fdatawrite and 
+ * filemap_fdatawait began returning status codes. Prior to that, they were 
+ * void functions, so we'll just have them return 0.
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 18)
+#define compat_filemap_fdatawrite(mapping)                                    \
+({                                                                            \
+   int result = 0;                                                            \
+   filemap_fdatasync(mapping);                                                \
+   result;                                                                    \
+})
+#define compat_filemap_fdatawait(mapping)                                     \
+({                                                                            \
+   int result = 0;                                                            \
+   filemap_fdatawait(mapping);                                                \
+   result;                                                                    \
+})
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 12)
+#define compat_filemap_fdatawrite(mapping) filemap_fdatasync(mapping)
+#define compat_filemap_fdatawait(mapping) filemap_fdatawait(mapping)
+#else
+#define compat_filemap_fdatawrite(mapping) filemap_fdatawrite(mapping)
+#define compat_filemap_fdatawait(mapping) filemap_fdatawait(mapping)
+#endif
+
+
+/*
+ * filemap_write_and_wait was introduced in 2.6.6 and exported for module use
+ * in 2.6.16. It's really just a simple wrapper around filemap_fdatawrite and 
+ * and filemap_fdatawait, which initiates a flush of all dirty pages, then 
+ * waits for the pages to flush. The implementation here is a simplified form 
+ * of the one found in 2.6.20-rc3.
+ *
+ * Unfortunately, it just isn't possible to implement this prior to 2.4.5, when
+ * neither filemap_fdatawait nor filemap_fdatasync were exported for module
+ * use. So we'll define it out and hope for the best.
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 5)
+#define compat_filemap_write_and_wait(mapping)
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 16)
+#define compat_filemap_write_and_wait(mapping)                                \
+({                                                                            \
+   int result = 0;                                                            \
+   if (mapping->nrpages) {                                                    \
+      result = compat_filemap_fdatawrite(mapping);                            \
+      if (result != -EIO) {                                                   \
+         int result2 = compat_filemap_fdatawait(mapping);                     \
+         if (!result) {                                                       \
+            result = result2;                                                 \
+         }                                                                    \
+      }                                                                       \
+   }                                                                          \
+   result;                                                                    \
+})
+#else
+#define compat_filemap_write_and_wait(mapping) filemap_write_and_wait(mapping)
+#endif
+
+
+/*
+ * invalidate_remote_inode was introduced in 2.6.0-test5. Prior to that, 
+ * filesystems wishing to invalidate pages belonging to an inode called 
+ * invalidate_inode_pages.
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 0)
+#define compat_invalidate_remote_inode(inode) invalidate_inode_pages(inode)
+#else
+#define compat_invalidate_remote_inode(inode) invalidate_remote_inode(inode)
+#endif
+
+#endif /* __COMPAT_FS_H__ */
--- kernel/linux-2.6.26.3/fs/vmblock/compat_init.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmblock/compat_init.h	2008-09-03 09:58:40.000000000 -0500
@@ -0,0 +1,38 @@
+/*********************************************************
+ * Copyright (C) 1999 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * compat_init.h: Initialization compatibility wrappers.
+ */
+
+#ifndef __COMPAT_INIT_H__
+#define __COMPAT_INIT_H__
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 2, 0)
+#include <linux/init.h>
+#endif
+
+#ifndef module_init
+#define module_init(x) int init_module(void)     { return x(); }
+#endif
+
+#ifndef module_exit
+#define module_exit(x) void cleanup_module(void) { x(); }
+#endif
+
+#endif /* __COMPAT_INIT_H__ */
--- kernel/linux-2.6.26.3/fs/vmblock/compat_kernel.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmblock/compat_kernel.h	2008-09-03 09:58:40.000000000 -0500
@@ -0,0 +1,83 @@
+/*********************************************************
+ * Copyright (C) 2004 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_KERNEL_H__
+#   define __COMPAT_KERNEL_H__
+
+#include <asm/unistd.h>
+#include <linux/kernel.h>
+
+/*
+ * container_of was introduced in 2.5.28 but it's easier to check like this.
+ */
+#ifndef container_of
+#define container_of(ptr, type, member) ({			\
+        const typeof( ((type *)0)->member ) *__mptr = (ptr);	\
+        (type *)( (char *)__mptr - offsetof(type,member) );})
+#endif
+
+/*
+ * wait_for_completion and friends did not exist before 2.4.9.
+ */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 4, 9)
+
+#define compat_complete_and_exit(comp, status) complete_and_exit(comp, status)
+
+#else
+
+#include "compat_completion.h"
+
+/*
+ * Used by _syscallX macros. Note that this is global variable, so
+ * do not rely on its contents too much. As exit() is only function
+ * we use, and we never check return value from exit(), we have
+ * no problem...
+ */
+extern int errno;
+
+/*
+ * compat_exit() provides an access to the exit() function. It must 
+ * be named compat_exit(), as exit() (with different signature) is 
+ * provided by x86-64, arm and other (but not by i386).
+ */
+#define __NR_compat_exit __NR_exit
+static inline _syscall1(int, compat_exit, int, exit_code);
+
+/*
+ * See compat_wait_for_completion in compat_completion.h.
+ * compat_exit implicitly performs an unlock_kernel, in resident code,
+ * ensuring that the thread is no longer running in module code when the
+ * module is unloaded.
+ */
+#define compat_complete_and_exit(comp, status) do { \
+   lock_kernel(); \
+   compat_complete(comp); \
+   compat_exit(status); \
+} while (0)
+
+#endif
+
+/*
+ * vsnprintf became available in 2.4.10. For older kernels, just fall back on
+ * vsprintf.
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 10)
+#define vsnprintf(str, size, fmt, args) vsprintf(str, fmt, args)
+#endif
+
+#endif /* __COMPAT_KERNEL_H__ */
--- kernel/linux-2.6.26.3/fs/vmblock/compat_list.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmblock/compat_list.h	2008-09-03 09:58:40.000000000 -0500
@@ -0,0 +1,55 @@
+/*********************************************************
+ * Copyright (C) 2006 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_LIST_H__
+#   define __COMPAT_LIST_H__
+
+#include <linux/list.h>
+
+/*
+ * list_add_tail is with us since 2.4.0, or something like that.
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 0)
+#define list_add_tail(newe, head) do {  \
+   struct list_head *__h = (head);      \
+   __list_add((newe), __h->prev, __h);  \
+} while (0)
+#endif
+
+/*
+ * list_for_each_safe() showed up in 2.4.10, but it may be backported so we
+ * just check for its existence.
+ */
+#ifndef list_for_each_safe
+# define list_for_each_safe(pos, n, head) \
+         for (pos = (head)->next, n = pos->next; pos != (head); \
+                 pos = n, n = pos->next)
+#endif
+
+/*
+ * list_for_each_entry() showed up in 2.4.20, but it may be backported so we
+ * just check for its existence.
+ */
+#ifndef list_for_each_entry
+# define list_for_each_entry(pos, head, member) \
+         for (pos = list_entry((head)->next, typeof(*pos), member); \
+              &pos->member != (head); \
+              pos = list_entry(pos->member.next, typeof(*pos), member))
+#endif
+
+#endif /* __COMPAT_LIST_H__ */
--- kernel/linux-2.6.26.3/fs/vmblock/compat_mm.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmblock/compat_mm.h	2008-09-03 09:58:40.000000000 -0500
@@ -0,0 +1,134 @@
+/*********************************************************
+ * Copyright (C) 2002 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_MM_H__
+#   define __COMPAT_MM_H__
+
+
+#include <linux/mm.h>
+
+
+/* The get_page() API appeared in 2.3.7 --hpreg */
+/* Sometime during development it became function instead of macro --petr */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 0) && !defined(get_page) 
+#   define get_page(_page) atomic_inc(&(_page)->count)
+/* The __free_page() API is exported in 2.1.67 --hpreg */
+#   if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 1, 67)
+#      define put_page __free_page
+#   else
+#      include "compat_page.h"
+
+#      define page_to_phys(_page) (page_to_pfn(_page) << PAGE_SHIFT)
+#      define put_page(_page) free_page(page_to_phys(_page))
+#   endif
+#endif
+
+
+/* page_count() is 2.4.0 invention. Unfortunately unavailable in some RedHat 
+ * kernels (for example 2.4.21-4-RHEL3). */
+/* It is function since 2.6.0, and hopefully RedHat will not play silly games
+ * with mm_inline.h again... */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 0) && !defined(page_count)
+#  define page_count(page) atomic_read(&(page)->count)
+#endif
+
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 0)
+#  define compat_vm_pgoff(vma) ((vma)->vm_offset >> PAGE_SHIFT)
+
+static inline unsigned long compat_do_mmap_pgoff(struct file *file, unsigned long addr,
+   unsigned long len, unsigned long prot,
+   unsigned long flag, unsigned long pgoff)
+{
+   unsigned long ret = -EINVAL;
+
+   if (pgoff < 1 << (32 - PAGE_SHIFT)) {
+      ret = do_mmap(file, addr, len, prot, flag, pgoff << PAGE_SHIFT);
+   }
+   return ret;
+}
+
+#else
+#  define compat_vm_pgoff(vma) (vma)->vm_pgoff
+#  ifdef VMW_SKAS_MMAP
+#    define compat_do_mmap_pgoff(f, a, l, p, g, o) \
+				do_mmap_pgoff(current->mm, f, a, l, p, g, o)
+#  else
+#    define compat_do_mmap_pgoff(f, a, l, p, g, o) \
+				do_mmap_pgoff(f, a, l, p, g, o)
+#  endif
+#endif
+
+
+/* 2.2.x uses 0 instead of some define */
+#ifndef NOPAGE_SIGBUS
+#define NOPAGE_SIGBUS (0)
+#endif
+
+
+/* 2.2.x does not have HIGHMEM support */
+#ifndef GFP_HIGHUSER
+#define GFP_HIGHUSER (GFP_USER)
+#endif
+
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 0)
+
+#include "compat_page.h"
+
+static inline struct page * alloc_pages(unsigned int gfp_mask, unsigned int order)
+{
+   unsigned long addr;
+   
+   addr = __get_free_pages(gfp_mask, order);
+   if (!addr) {
+      return NULL;
+   }
+   return virt_to_page(addr);
+}
+#define alloc_page(gfp_mask) alloc_pages(gfp_mask, 0)
+
+#endif
+
+/*
+ * In 2.4.14, the logic behind the UnlockPage macro was moved to the 
+ * unlock_page() function. Later (in 2.5.12), the UnlockPage macro was removed
+ * altogether, and nowadays everyone uses unlock_page().
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 14)
+#define compat_unlock_page(page) UnlockPage(page)
+#else
+#define compat_unlock_page(page) unlock_page(page)
+#endif
+
+/*
+ * In 2.4.10, vmtruncate was changed from returning void to returning int.
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 10)
+#define compat_vmtruncate(inode, size)                                        \
+({                                                                            \
+   int result = 0;                                                            \
+   vmtruncate(inode, size);                                                   \
+   result;                                                                    \
+})
+#else
+#define compat_vmtruncate(inode, size) vmtruncate(inode, size)
+#endif
+
+
+#endif /* __COMPAT_MM_H__ */
--- kernel/linux-2.6.26.3/fs/vmblock/compat_module.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmblock/compat_module.h	2008-09-03 09:58:40.000000000 -0500
@@ -0,0 +1,72 @@
+/*********************************************************
+ * Copyright (C) 2007 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * compat_module.h --
+ */
+
+#ifndef __COMPAT_MODULE_H__
+#   define __COMPAT_MODULE_H__
+
+
+#include <linux/module.h>
+
+
+/*
+ * Modules wishing to use the GPL license are required to include a
+ * MODULE_LICENSE definition in their module source as of 2.4.10.
+ */
+#ifndef MODULE_LICENSE
+#define MODULE_LICENSE(license)
+#endif
+
+/*
+ * To make use of our own home-brewed MODULE_INFO, we need macros to
+ * concatenate two expressions to "__mod_", and and to convert an
+ * expression into a string. I'm sure we've got these in our codebase,
+ * but I'd rather not introduce such a dependency in a compat header.
+ */
+#ifndef __module_cat
+#define __module_cat_1(a, b) __mod_ ## a ## b
+#define __module_cat(a, b) __module_cat_1(a, b)
+#endif
+
+#ifndef __stringify
+#define __stringify_1(x) #x
+#define __stringify(x) __stringify_1(x)
+#endif
+
+/*
+ * MODULE_INFO was born in 2.5.69.
+ */
+#ifndef MODULE_INFO
+#define MODULE_INFO(tag, info)                                                \
+static const char __module_cat(tag, __LINE__)[]                               \
+  __attribute__((section(".modinfo"), unused)) = __stringify(tag) "=" info
+#endif
+
+/*
+ * MODULE_VERSION was born in 2.6.4. The earlier form appends a long "\0xxx"
+ * string to the module's version, but that was removed in 2.6.10, so we'll
+ * ignore it in our wrapper.
+ */
+#ifndef MODULE_VERSION
+#define MODULE_VERSION(_version) MODULE_INFO(version, _version)
+#endif
+
+#endif /* __COMPAT_MODULE_H__ */
--- kernel/linux-2.6.26.3/fs/vmblock/compat_namei.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmblock/compat_namei.h	2008-09-03 09:58:40.000000000 -0500
@@ -0,0 +1,57 @@
+/*********************************************************
+ * Copyright (C) 2006 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_NAMEI_H__
+#   define __COMPAT_NAMEI_H__
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 5, 18)
+#include <linux/namei.h>
+#endif
+
+/*
+ * In 2.6.25-rc2, dentry and mount objects were removed from the nameidata
+ * struct. They were both replaced with a struct path.
+ */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 25)
+#define compat_vmw_nd_to_dentry(nd) (nd).path.dentry
+#else
+#define compat_vmw_nd_to_dentry(nd) (nd).dentry
+#endif
+
+/* In 2.6.25-rc2, path_release(&nd) was replaced with path_put(&nd.path). */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 25)
+#define compat_path_release(nd) path_put(&(nd)->path)
+#else
+#define compat_path_release(nd) path_release(nd)
+#endif
+
+/* path_lookup was exported in 2.4.25 */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 4, 25)
+#define compat_path_lookup(path, flags, nd)     path_lookup(path, flags, nd)
+#else
+#define compat_path_lookup(path, flags, nd)     \
+         ({                                     \
+            int ret = 0;                        \
+            if (path_init(path, flags, nd)) {   \
+               ret = path_walk(path, nd);       \
+            }                                   \
+            ret;                                \
+         })
+#endif
+
+#endif /* __COMPAT_NAMEI_H__ */
--- kernel/linux-2.6.26.3/fs/vmblock/compat_page.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmblock/compat_page.h	2008-09-03 09:58:40.000000000 -0500
@@ -0,0 +1,75 @@
+/*********************************************************
+ * Copyright (C) 2002 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_PAGE_H__
+#   define __COMPAT_PAGE_H__
+
+
+#include <linux/mm.h>
+#include <asm/page.h>
+
+
+/* The pfn_to_page() API appeared in 2.5.14 and changed to function during 2.6.x */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 0) && !defined(pfn_to_page)
+#   define pfn_to_page(_pfn) (mem_map + (_pfn))
+#   define page_to_pfn(_page) ((_page) - mem_map)
+#endif
+
+
+/* The virt_to_page() API appeared in 2.4.0 --hpreg */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 0) && !defined(virt_to_page)
+#   define virt_to_page(_kvAddr) pfn_to_page(MAP_NR(_kvAddr))
+#endif
+
+
+/*
+ * The get_order() API appeared at some point in 2.3.x, and was then backported
+ * in 2.2.17-21mdk and in the stock 2.2.18. Because we can only detect its
+ * definition through makefile tricks, we provide our own for now --hpreg
+ */
+static inline int
+compat_get_order(unsigned long size) // IN
+{
+   int order;
+
+   size = (size - 1) >> (PAGE_SHIFT - 1);
+   order = -1;
+   do {
+      size >>= 1;
+      order++;
+   } while (size);
+
+   return order;
+}
+
+/* 
+ * BUG() was added to <asm/page.h> in 2.2.18, and was moved to <asm/bug.h>
+ * in 2.5.58.
+ * 
+ * XXX: Technically, this belongs in some sort of "compat_asm_page.h" file, but
+ * since our compatibility wrappers don't distinguish between <asm/xxx.h> and
+ * <linux/xxx.h>, putting it here is reasonable.
+ */
+#ifndef BUG
+#define BUG() do {                                                            \
+   printk("kernel BUG at %s:%d!\n", __FILE__, __LINE__);                      \
+  __asm__ __volatile__(".byte 0x0f,0x0b");                                    \
+} while (0)
+#endif
+
+#endif /* __COMPAT_PAGE_H__ */
--- kernel/linux-2.6.26.3/fs/vmblock/compat_sched.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmblock/compat_sched.h	2008-09-03 09:58:40.000000000 -0500
@@ -0,0 +1,291 @@
+/*********************************************************
+ * Copyright (C) 2002 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_SCHED_H__
+#   define __COMPAT_SCHED_H__
+
+
+#include <linux/sched.h>
+
+/* CLONE_KERNEL available in 2.5.35 and higher. */
+#ifndef CLONE_KERNEL
+#define CLONE_KERNEL CLONE_FILES | CLONE_FS | CLONE_SIGHAND
+#endif
+
+/* TASK_COMM_LEN become available in 2.6.11. */
+#ifndef TASK_COMM_LEN
+#define TASK_COMM_LEN 16
+#endif
+
+/* The capable() API appeared in 2.1.92 --hpreg */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 1, 92)
+#   define capable(_capability) suser()
+#endif
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 2, 0)
+#   define need_resched() need_resched
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 3)
+#   define need_resched() (current->need_resched)
+#endif
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 3)
+#   define cond_resched() (need_resched() ? schedule() : (void) 0)
+#endif
+
+/* Oh well.  We need yield...  Happy us! */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 20)
+#   ifdef __x86_64__
+#      define compat_yield() there_is_nothing_like_yield()
+#   else
+#      include <linux/unistd.h>
+#      include <linux/kernel.h>
+
+/*
+ * Used by _syscallX macros. Note that this is global variable, so
+ * do not rely on its contents too much. As exit() is only function
+ * we use, and we never check return value from exit(), we have
+ * no problem...
+ */
+extern int errno;
+
+/*
+ * compat_exit() provides an access to the exit() function. It must 
+ * be named compat_exit(), as exit() (with different signature) is 
+ * provided by x86-64, arm and other (but not by i386).
+ */
+#      define __NR_compat_yield __NR_sched_yield
+static inline _syscall0(int, compat_yield);
+#   endif
+#else
+#   define compat_yield() yield()
+#endif
+
+
+/*
+ * Since 2.5.34 there are two methods to enumerate tasks:
+ * for_each_process(p) { ... } which enumerates only tasks and
+ * do_each_thread(g,t) { ... } while_each_thread(g,t) which enumerates
+ *     also threads even if they share same pid.
+ */
+#ifndef for_each_process
+#   define for_each_process(p) for_each_task(p)
+#endif
+
+#ifndef do_each_thread
+#   define do_each_thread(g, t) for_each_task(g) { t = g; do
+#   define while_each_thread(g, t) while (0) }
+#endif
+
+
+/*
+ * Lock for signal mask is moving target...
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 40) && defined(CLONE_PID)
+/* 2.4.x without NPTL patches or early 2.5.x */
+#define compat_sigmask_lock sigmask_lock
+#define compat_dequeue_signal_current(siginfo_ptr) \
+   dequeue_signal(&current->blocked, (siginfo_ptr))
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 60) && !defined(INIT_SIGHAND)
+/* RedHat's 2.4.x with first version of NPTL support, or 2.5.40 to 2.5.59 */
+#define compat_sigmask_lock sig->siglock
+#define compat_dequeue_signal_current(siginfo_ptr) \
+   dequeue_signal(&current->blocked, (siginfo_ptr))
+#else
+/* RedHat's 2.4.x with second version of NPTL support, or 2.5.60+. */
+#define compat_sigmask_lock sighand->siglock
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 0)
+#define compat_dequeue_signal_current(siginfo_ptr) \
+   dequeue_signal(&current->blocked, (siginfo_ptr))
+#else
+#define compat_dequeue_signal_current(siginfo_ptr) \
+   dequeue_signal(current, &current->blocked, (siginfo_ptr))
+#endif
+#endif
+
+/*
+ * recalc_sigpending() had task argument in the past
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 29) && defined(CLONE_PID)
+/* 2.4.x without NPTL patches or early 2.5.x */
+#define compat_recalc_sigpending() recalc_sigpending(current)
+#else
+/* RedHat's 2.4.x with NPTL support, or 2.5.29+ */
+#define compat_recalc_sigpending() recalc_sigpending()
+#endif
+
+
+/*
+ * reparent_to_init() was introduced in 2.4.8.  In 2.5.38 (or possibly
+ * earlier, but later than 2.5.31) a call to it was added into
+ * daemonize(), so compat_daemonize no longer needs to call it.
+ *
+ * In 2.4.x kernels reparent_to_init() forgets to do correct refcounting
+ * on current->user. It is better to count one too many than one too few...
+ */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 4, 8) && LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 38)
+#define compat_reparent_to_init() do { \
+					reparent_to_init(); \
+					atomic_inc(&current->user->__count); \
+				  } while (0)
+#else
+#define compat_reparent_to_init() do {} while (0)
+#endif
+
+
+/*
+ * daemonize appeared in 2.2.18. Except 2.2.17-4-RH7.0, which has it too.
+ * Fortunately 2.2.17-4-RH7.0 uses versioned symbols, so we can check
+ * its existence with defined().
+ */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2, 2, 18)) && !defined(daemonize)
+static inline void daemonize(void) {
+   struct fs_struct *fs;
+
+   exit_mm(current);
+   current->session = 1;
+   current->pgrp = 1;
+   exit_fs(current);
+   fs = init_task.fs;
+   current->fs = fs;
+   atomic_inc(&fs->count);
+}
+#endif
+
+
+/*
+ * flush_signals acquires sighand->siglock since 2.5.61... Verify RH's kernels!
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 61)
+#define compat_flush_signals(task) do { \
+				      spin_lock_irq(&task->compat_sigmask_lock); \
+				      flush_signals(task); \
+				      spin_unlock_irq(&task->compat_sigmask_lock); \
+				   } while (0)
+#else
+#define compat_flush_signals(task) flush_signals(task)
+#endif
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 61)
+#define compat_allow_signal(signr) do { \
+                                      spin_lock_irq(&current->compat_sigmask_lock); \
+                                      sigdelset(&current->blocked, signr); \
+                                      compat_recalc_sigpending(); \
+                                      spin_unlock_irq(&current->compat_sigmask_lock); \
+                                   } while (0)
+#else
+#define compat_allow_signal(signr) allow_signal(signr)
+#endif
+
+/*
+ * daemonize can set process name since 2.5.61. Prior to 2.5.61, daemonize
+ * didn't block signals on our behalf.
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 61)
+#define compat_daemonize(x...)                                                \
+({                                                                            \
+   /* Beware! No snprintf here, so verify arguments! */                       \
+   sprintf(current->comm, x);                                                 \
+                                                                              \
+   /* Block all signals. */                                                   \
+   spin_lock_irq(&current->compat_sigmask_lock);                              \
+   sigfillset(&current->blocked);                                             \
+   compat_recalc_sigpending();                                                \
+   spin_unlock_irq(&current->compat_sigmask_lock);                            \
+   compat_flush_signals(current);                                             \
+                                                                              \
+   daemonize();                                                               \
+   compat_reparent_to_init();                                                 \
+})
+#else
+#define compat_daemonize(x...) daemonize(x)
+#endif
+
+
+/*
+ * set priority for specified thread. Exists on 2.6.x kernels and some
+ * 2.4.x vendor's kernels.
+ */
+#if defined(VMW_HAVE_SET_USER_NICE)
+#define compat_set_user_nice(task, n) set_user_nice((task), (n))
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 0)
+#define compat_set_user_nice(task, n) do { (task)->priority = 20 - (n); } while (0)
+#elif !defined(VMW_HAVE_SET_USER_NICE)
+#define compat_set_user_nice(task, n) do { (task)->nice = (n); } while (0)
+#endif
+
+/*
+ * try to freeze a process. For kernels 2.6.11 or newer, we know how to choose
+ * the interface. The problem is that the oldest interface, introduced in
+ * 2.5.18, was backported to 2.4.x kernels. So if we're older than 2.6.11,
+ * we'll decide what to do based on whether or not swsusp was configured
+ * for the kernel.  For kernels 2.6.20 and newer, we'll also need to include
+ * freezer.h since the try_to_freeze definition was pulled out of sched.h.
+ */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 20)
+#include <linux/freezer.h>
+#endif
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 13) || defined(VMW_TL10S64_WORKAROUND)
+#define compat_try_to_freeze() try_to_freeze()
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 11)
+#define compat_try_to_freeze() try_to_freeze(PF_FREEZE)
+#elif defined(CONFIG_SOFTWARE_SUSPEND) || defined(CONFIG_SOFTWARE_SUSPEND2)
+#include "compat_mm.h"
+#include <linux/errno.h>
+#include <linux/suspend.h>
+static inline int compat_try_to_freeze(void)  { 
+   if (current->flags & PF_FREEZE) {
+      refrigerator(PF_FREEZE); 
+      return 1;
+   } else {
+      return 0;
+   }
+}
+#else
+static inline int compat_try_to_freeze(void) { return 0; }
+#endif
+
+/*
+ * As of 2.6.23-rc1, kernel threads are no longer freezable by
+ * default. Instead, kernel threads that need to be frozen must opt-in
+ * by calling set_freezable() as soon as the thread is created.
+ */
+
+#if LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 22)
+#define compat_set_freezable() do { set_freezable(); } while (0)
+#else
+#define compat_set_freezable() do {} while (0)
+#endif
+
+/*
+ * Since 2.6.27-rc2 kill_proc() is gone... Replacement (GPL-only!)
+ * API is available since 2.6.19.  Use them from 2.6.27-rc1 up.
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 27)
+typedef int compat_pid;
+#define compat_find_get_pid(pid) (pid)
+#define compat_put_pid(pid) do { } while (0)
+#define compat_kill_pid(pid, sig, flag) kill_proc(pid, sig, flag)
+#else
+typedef struct pid * compat_pid;
+#define compat_find_get_pid(pid) find_get_pid(pid)
+#define compat_put_pid(pid) put_pid(pid)
+#define compat_kill_pid(pid, sig, flag) kill_pid(pid, sig, flag)
+#endif
+
+
+#endif /* __COMPAT_SCHED_H__ */
--- kernel/linux-2.6.26.3/fs/vmblock/compat_semaphore.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmblock/compat_semaphore.h	2008-09-03 09:58:40.000000000 -0500
@@ -0,0 +1,49 @@
+/*********************************************************
+ * Copyright (C) 2002 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_SEMAPHORE_H__
+#   define __COMPAT_SEMAPHORE_H__
+
+
+/* <= 2.6.25 have asm only, 2.6.26 has both, and 2.6.27-rc2+ has linux only. */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 27)
+#   include <asm/semaphore.h>
+#else
+#   include <linux/semaphore.h>
+#endif
+
+
+/*
+* The init_MUTEX_LOCKED() API appeared in 2.2.18, and is also in
+* 2.2.17-21mdk --hpreg
+*/
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 2, 18)
+   #ifndef init_MUTEX_LOCKED
+      #define init_MUTEX_LOCKED(_sem) *(_sem) = MUTEX_LOCKED
+   #endif
+   #ifndef DECLARE_MUTEX
+      #define DECLARE_MUTEX(name) struct semaphore name = MUTEX
+   #endif
+   #ifndef DECLARE_MUTEX_LOCKED
+      #define DECLARE_MUTEX_LOCKED(name) struct semaphore name = MUTEX_LOCKED
+   #endif
+#endif
+
+
+#endif /* __COMPAT_SEMAPHORE_H__ */
--- kernel/linux-2.6.26.3/fs/vmblock/compat_slab.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmblock/compat_slab.h	2008-09-03 09:58:40.000000000 -0500
@@ -0,0 +1,85 @@
+/*********************************************************
+ * Copyright (C) 2005 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_SLAB_H__
+#   define __COMPAT_SLAB_H__
+
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 2, 0)
+#   include <linux/slab.h>
+#else
+#   include <linux/malloc.h>
+#endif
+
+/*
+ * Before 2.6.20, kmem_cache_t was the accepted way to refer to a kmem_cache
+ * structure.  Prior to 2.6.15, this structure was called kmem_cache_s, and
+ * afterwards it was renamed to kmem_cache.  Here we keep things simple and use
+ * the accepted typedef until it became deprecated, at which point we switch
+ * over to the kmem_cache name.
+ */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 20)
+#   define compat_kmem_cache struct kmem_cache
+#else
+#   define compat_kmem_cache kmem_cache_t
+#endif
+
+/*
+ * Up to 2.6.22 kmem_cache_create has 6 arguments - name, size, alignment, flags,
+ * constructor, and destructor.  Then for some time kernel was asserting that
+ * destructor is NULL, and since 2.6.23-pre1 kmem_cache_create takes only 5
+ * arguments - destructor is gone.
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 22) || defined(VMW_KMEMCR_HAS_DTOR)
+#define compat_kmem_cache_create(name, size, align, flags, ctor) \
+		kmem_cache_create(name, size, align, flags, ctor, NULL)
+#else
+#define compat_kmem_cache_create(name, size, align, flags, ctor) \
+		kmem_cache_create(name, size, align, flags, ctor)
+#endif
+
+/*
+ * Up to 2.6.23 kmem_cache constructor has three arguments - pointer to block to
+ * prepare (aka "this"), from which cache it came, and some unused flags.  After
+ * 2.6.23 flags were removed, and order of "this" and cache parameters was swapped...
+ * Since 2.6.27-rc2 everything is different again, and ctor has only one argument.
+ *
+ * HAS_3_ARGS has precedence over HAS_2_ARGS if both are defined.
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 23) && !defined(VMW_KMEMCR_CTOR_HAS_3_ARGS)
+#  define VMW_KMEMCR_CTOR_HAS_3_ARGS
+#endif
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 26) && !defined(VMW_KMEMCR_CTOR_HAS_2_ARGS)
+#  define VMW_KMEMCR_CTOR_HAS_2_ARGS
+#endif
+
+#if defined(VMW_KMEMCR_CTOR_HAS_3_ARGS)
+typedef void compat_kmem_cache_ctor(void *, compat_kmem_cache *, unsigned long);
+#define COMPAT_KMEM_CACHE_CTOR_ARGS(arg) void *arg, \
+                                         compat_kmem_cache *cache, \
+                                         unsigned long flags
+#elif defined(VMW_KMEMCR_CTOR_HAS_2_ARGS)
+typedef void compat_kmem_cache_ctor(compat_kmem_cache *, void *);
+#define COMPAT_KMEM_CACHE_CTOR_ARGS(arg) compat_kmem_cache *cache, \
+                                         void *arg
+#else
+typedef void compat_kmem_cache_ctor(void *);
+#define COMPAT_KMEM_CACHE_CTOR_ARGS(arg) void *arg
+#endif
+
+#endif /* __COMPAT_SLAB_H__ */
--- kernel/linux-2.6.26.3/fs/vmblock/compat_spinlock.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmblock/compat_spinlock.h	2008-09-03 09:58:40.000000000 -0500
@@ -0,0 +1,68 @@
+/*********************************************************
+ * Copyright (C) 2005 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_SPINLOCK_H__
+#   define __COMPAT_SPINLOCK_H__
+
+
+/*
+ * The spin_lock() API appeared in 2.1.25 in asm/smp_lock.h
+ * It moved in 2.1.30 to asm/spinlock.h
+ * It moved again in 2.3.18 to linux/spinlock.h
+ *
+ *   --hpreg
+ */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 3, 18)
+#   include <linux/spinlock.h>
+#else
+#   if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 1, 30)
+#      include <asm/spinlock.h>
+#   else
+typedef struct {} spinlock_t;
+#      define spin_lock_init(lock)
+#      define spin_lock(lock)
+#      define spin_unlock(lock)
+#      define spin_lock_irqsave(lock, flags) do {      \
+                    save_flags(flags);                 \
+                    cli();                             \
+                    spin_lock(lock);                   \
+                 } while (0)
+#      define spin_unlock_irqrestore(lock, flags) do { \
+                    spin_unlock(lock);                 \
+                    restore_flags(flags);              \
+                 } while (0)
+#   endif
+#endif
+
+
+/*
+ * Preempt support was added during 2.5.x development cycle, and later
+ * it was backported to 2.4.x.  In 2.4.x backport these definitions
+ * live in linux/spinlock.h, that's why we put them here (in 2.6.x they
+ * are defined in linux/preempt.h which is included by linux/spinlock.h).
+ */
+#ifdef CONFIG_PREEMPT
+#define compat_preempt_disable() preempt_disable()
+#define compat_preempt_enable()  preempt_enable()
+#else
+#define compat_preempt_disable() do { } while (0)
+#define compat_preempt_enable()  do { } while (0)
+#endif
+
+
+#endif /* __COMPAT_SPINLOCK_H__ */
--- kernel/linux-2.6.26.3/fs/vmblock/compat_statfs.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmblock/compat_statfs.h	2008-09-03 09:58:40.000000000 -0500
@@ -0,0 +1,32 @@
+/*********************************************************
+ * Copyright (C) 2006 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_STATFS_H__
+#   define __COMPAT_STATFS_H__
+
+/* vfs.h simply include statfs.h, but it knows what directory statfs.h is in. */
+#include <linux/vfs.h>
+
+/* 2.5.74 renamed struct statfs to kstatfs. */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 5, 74)
+#define compat_kstatfs kstatfs
+#else
+#define compat_kstatfs statfs
+#endif
+
+#endif /* __COMPAT_STATFS_H__ */
--- kernel/linux-2.6.26.3/fs/vmblock/compat_string.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmblock/compat_string.h	2008-09-03 09:58:40.000000000 -0500
@@ -0,0 +1,42 @@
+/*********************************************************
+ * Copyright (C) 2007 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_STRING_H__
+#   define __COMPAT_STRING_H__
+
+#include <linux/string.h>
+
+/*
+ * kstrdup was born in 2.6.13. This implementation is almost identical to the
+ * one found there.
+ */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 13)
+#define compat_kstrdup(s, gfp) kstrdup(s, gfp)
+#else
+#define compat_kstrdup(s, gfp)                                                \
+({                                                                            \
+   size_t len;                                                                \
+   char *buf;                                                                 \
+   len = strlen(s) + 1;                                                       \
+   buf = kmalloc(len, gfp);                                                   \
+   memcpy(buf, s, len);                                                       \
+   buf;                                                                       \
+})                                                                            
+#endif
+
+#endif /* __COMPAT_STRING_H__ */
--- kernel/linux-2.6.26.3/fs/vmblock/compat_uaccess.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmblock/compat_uaccess.h	2008-09-03 09:58:40.000000000 -0500
@@ -0,0 +1,79 @@
+/*********************************************************
+ * Copyright (C) 2002 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_UACCESS_H__
+#   define __COMPAT_UACCESS_H__
+
+
+/* User space access functions moved in 2.1.7 to asm/uaccess.h --hpreg */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 1, 7)
+#   include <asm/uaccess.h>
+#else
+#   include <asm/segment.h>
+#endif
+
+
+/* get_user() API modified in 2.1.4 to take 2 arguments --hpreg */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 1, 4)
+#   define compat_get_user get_user
+#else
+/*
+ * We assign 0 to the variable in case of failure to prevent "`_var' might be
+ * used uninitialized in this function" compiler warnings. I think it is OK,
+ * because the hardware-based version in newer kernels probably has the same
+ * semantics and does not guarantee that the value of _var will not be
+ * modified, should the access fail --hpreg
+ */
+#   define compat_get_user(_var, _uvAddr) ({                        \
+   int _status;                                                     \
+                                                                    \
+   _status = verify_area(VERIFY_READ, _uvAddr, sizeof(*(_uvAddr))); \
+   if (_status == 0) {                                              \
+      (_var) = get_user(_uvAddr);                                   \
+   } else {                                                         \
+      (_var) = 0;                                                   \
+   }                                                                \
+   _status;                                                         \
+})
+#endif
+
+
+/*
+ * The copy_from_user() API appeared in 2.1.4
+ *
+ * The emulation is not perfect here, but it is conservative: on failure, we
+ * always return the total size, instead of the potentially smaller faulty
+ * size --hpreg
+ *
+ * Since 2.5.55 copy_from_user() is no longer macro.
+ */
+#if !defined(copy_from_user) && LINUX_VERSION_CODE < KERNEL_VERSION(2, 2, 0)
+#   define copy_from_user(_to, _from, _size) ( \
+   verify_area(VERIFY_READ, _from, _size)      \
+       ? (_size)                               \
+       : (memcpy_fromfs(_to, _from, _size), 0) \
+)
+#   define copy_to_user(_to, _from, _size) ( \
+   verify_area(VERIFY_WRITE, _to, _size)     \
+       ? (_size)                             \
+       : (memcpy_tofs(_to, _from, _size), 0) \
+)
+#endif
+
+
+#endif /* __COMPAT_UACCESS_H__ */
--- kernel/linux-2.6.26.3/fs/vmblock/compat_version.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmblock/compat_version.h	2008-09-03 09:59:44.000000000 -0500
@@ -0,0 +1,120 @@
+/*********************************************************
+ * Copyright (C) 1998 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_VERSION_H__
+#   define __COMPAT_VERSION_H__
+
+#define INCLUDE_ALLOW_VMMON
+#define INCLUDE_ALLOW_MODULE
+#define INCLUDE_ALLOW_VMCORE
+#define INCLUDE_ALLOW_VMNIXMOD
+#define INCLUDE_ALLOW_DISTRIBUTE
+
+
+#ifndef __linux__
+#   error "linux-version.h"
+#endif
+
+
+#include <linux/version.h>
+
+/* Appeared in 2.1.90 --hpreg */
+#ifndef KERNEL_VERSION
+#   define KERNEL_VERSION(a, b, c) (((a) << 16) + ((b) << 8) + (c))
+#endif
+
+
+/*
+ * Distinguish relevant classes of Linux kernels.
+ *
+ * The convention is that version X defines all
+ * the KERNEL_Y symbols where Y <= X.
+ *
+ * XXX Do not add more definitions here. This way of doing things does not
+ *     scale, and we are going to phase it out soon --hpreg
+ */
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 1, 0)
+#   define KERNEL_2_1
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 2, 0)
+#   define KERNEL_2_2
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 3, 1)
+#   define KERNEL_2_3_1
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 3, 15)
+/*   new networking */
+#   define KERNEL_2_3_15
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 3, 25)
+/*  new procfs */
+#   define KERNEL_2_3_25
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 3, 29)
+/*  even newer procfs */
+#   define KERNEL_2_3_29
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 3, 43)
+/*  softnet changes */
+#   define KERNEL_2_3_43
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 3, 47)
+/*  more softnet changes */
+#   define KERNEL_2_3_47
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 3, 99)
+/*  name in netdevice struct is array and not pointer */
+#   define KERNEL_2_3_99
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 4, 0)
+/*  New 'owner' member at the beginning of struct file_operations */
+#      define KERNEL_2_4_0
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 4, 8)
+/*  New netif_rx_ni() --hpreg */
+#   define KERNEL_2_4_8
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 4, 22)
+/*  New vmap() */
+#   define KERNEL_2_4_22
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 5, 2)
+/*  New kdev_t, major()/minor() API --hpreg */
+#   define KERNEL_2_5_2
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 5, 5)
+/*  New sk_alloc(), pte_offset_map()/pte_unmap() --hpreg */
+#   define KERNEL_2_5_5
+#endif
+
+
+#endif /* __COMPAT_VERSION_H__ */
--- kernel/linux-2.6.26.3/fs/vmblock/compat_wait.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmblock/compat_wait.h	2008-09-03 09:58:40.000000000 -0500
@@ -0,0 +1,225 @@
+/*********************************************************
+ * Copyright (C) 2002 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_WAIT_H__
+#   define __COMPAT_WAIT_H__
+
+
+#include <linux/wait.h>
+#include <linux/poll.h>
+#include <linux/file.h>
+
+#include "compat_file.h"
+
+
+/*
+ * The DECLARE_WAITQUEUE() API appeared in 2.3.1
+ * It was back ported in 2.2.18
+ *
+ *  --hpreg
+ */
+
+#ifndef DECLARE_WAITQUEUE
+
+typedef struct wait_queue *wait_queue_head_t;
+#   define init_waitqueue_head(_headPtr) *(_headPtr) = NULL
+#   define DECLARE_WAITQUEUE(_var, _task) \
+   struct wait_queue _var = {_task, NULL, }
+
+typedef struct wait_queue wait_queue_t;
+#   define init_waitqueue_entry(_wait, _task) ((_wait)->task = (_task))
+
+#endif
+
+/*
+ * The 'struct poll_wqueues' appeared in 2.5.48, when global
+ * /dev/epoll interface was added.  It was backported to the
+ * 2.4.20-wolk4.0s.
+ */
+
+#ifdef VMW_HAVE_EPOLL // {
+#define compat_poll_wqueues struct poll_wqueues
+#else // } {
+#define compat_poll_wqueues poll_table
+#endif // }
+
+#ifdef VMW_HAVE_EPOLL // {
+
+/* If prototype does not match, build will abort here */
+extern void poll_initwait(compat_poll_wqueues *);
+
+#define compat_poll_initwait(wait, table) ( \
+   poll_initwait((table)), \
+   (wait) = &(table)->pt \
+)
+
+#define compat_poll_freewait(wait, table) ( \
+   poll_freewait((table)) \
+)
+
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(2, 4, 0) // {
+
+/* If prototype does not match, build will abort here */
+extern void poll_initwait(compat_poll_wqueues *);
+
+#define compat_poll_initwait(wait, table) ( \
+   (wait) = (table), \
+   poll_initwait(wait) \
+)
+
+#define compat_poll_freewait(wait, table) ( \
+   poll_freewait((table)) \
+)
+
+#else // } {
+
+#define compat_poll_initwait(wait, table) ( \
+   (wait) = (table), /* confuse compiler */ \
+   (wait) = (poll_table *) __get_free_page(GFP_KERNEL), \
+   (wait)->nr = 0, \
+   (wait)->entry = (struct poll_table_entry *)((wait) + 1), \
+   (wait)->next = NULL \
+)
+
+static inline void
+poll_freewait(poll_table *wait)
+{
+   while (wait) {
+      struct poll_table_entry * entry;
+      poll_table *old;
+
+      entry = wait->entry + wait->nr;
+      while (wait->nr > 0) {
+	 wait->nr--;
+	 entry--;
+	 remove_wait_queue(entry->wait_address, &entry->wait);
+	 compat_fput(entry->filp);
+      }
+      old = wait;
+      wait = wait->next;
+      free_page((unsigned long) old);
+   }
+}
+
+#define compat_poll_freewait(wait, table) ( \
+   poll_freewait((wait)) \
+)
+
+#endif // }
+
+/*
+ * The wait_event_interruptible_timeout() interface is not
+ * defined in pre-2.6 kernels.
+ */
+#ifndef wait_event_interruptible_timeout
+#define __wait_event_interruptible_timeout(wq, condition, ret)		\
+do {									\
+   wait_queue_t __wait;						        \
+   init_waitqueue_entry(&__wait, current);				\
+									\
+   add_wait_queue(&wq, &__wait);					\
+   for (;;) {							        \
+      set_current_state(TASK_INTERRUPTIBLE);			        \
+      if (condition)						        \
+	 break;						                \
+      if (!signal_pending(current)) {				        \
+	 ret = schedule_timeout(ret);			                \
+	 if (!ret)					                \
+	    break;					                \
+	 continue;					                \
+      }							                \
+      ret = -ERESTARTSYS;					        \
+      break;							        \
+   }								        \
+   set_current_state(TASK_RUNNING);				        \
+   remove_wait_queue(&wq, &__wait);				        \
+} while (0)
+
+#define wait_event_interruptible_timeout(wq, condition, timeout)	\
+({									\
+   long __ret = timeout;						\
+   if (!(condition))						        \
+      __wait_event_interruptible_timeout(wq, condition, __ret);         \
+   __ret;								\
+})
+#endif
+
+/*
+ * The wait_event_timeout() interface is not
+ * defined in pre-2.6 kernels.
+ */
+#ifndef wait_event_timeout
+#define __wait_event_timeout(wq, condition, ret)        		\
+do {									\
+   wait_queue_t __wait;						        \
+   init_waitqueue_entry(&__wait, current);				\
+									\
+   add_wait_queue(&wq, &__wait);					\
+   for (;;) {							        \
+      set_current_state(TASK_UNINTERRUPTIBLE);        	                \
+      if (condition)						        \
+         break;						                \
+      ret = schedule_timeout(ret);			                \
+      if (!ret)					                        \
+         break;					                        \
+   }								        \
+   set_current_state(TASK_RUNNING);				        \
+   remove_wait_queue(&wq, &__wait);				        \
+} while (0)
+
+#define wait_event_timeout(wq, condition, timeout)	                \
+({									\
+   long __ret = timeout;						\
+   if (!(condition))						        \
+      __wait_event_timeout(wq, condition, __ret);                       \
+   __ret;								\
+})
+#endif
+
+/*
+ * DEFINE_WAIT() and friends were added in 2.5.39 and backported to 2.4.28.
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 28) || \
+   (LINUX_VERSION_CODE >= KERNEL_VERSION(2, 5, 0) && \
+    LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 39))
+# define COMPAT_DEFINE_WAIT(_wait)                              \
+   DECLARE_WAITQUEUE(_wait, current)
+# define compat_init_prepare_to_wait(_sleep, _wait, _state)     \
+   do {                                                         \
+      __set_current_state(_state);                              \
+      add_wait_queue(_sleep, _wait);                            \
+   } while (0)
+# define compat_cont_prepare_to_wait(_sleep, _wait, _state)     \
+   set_current_state(_state)
+# define compat_finish_wait(_sleep, _wait, _state)              \
+   do {                                                         \
+      __set_current_state(_state);                              \
+      remove_wait_queue(_sleep, _wait);                         \
+   } while (0)
+#else
+# define COMPAT_DEFINE_WAIT(_wait)                              \
+   DEFINE_WAIT(_wait)
+# define compat_init_prepare_to_wait(_sleep, _wait, _state)     \
+   prepare_to_wait(_sleep, _wait, _state)
+# define compat_cont_prepare_to_wait(_sleep, _wait, _state)     \
+   prepare_to_wait(_sleep, _wait, _state)
+# define compat_finish_wait(_sleep, _wait, _state)              \
+   finish_wait(_sleep, _wait)
+#endif
+
+#endif /* __COMPAT_WAIT_H__ */
--- kernel/linux-2.6.26.3/fs/vmblock/control.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmblock/control.c	2008-09-03 09:58:40.000000000 -0500
@@ -0,0 +1,332 @@
+/*********************************************************
+ * Copyright (C) 2006 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * control.c --
+ *
+ *   Control operations for the vmblock driver.
+ *
+ */
+
+#include "driver-config.h"
+#include <linux/module.h>
+#include <linux/proc_fs.h>
+#include <linux/stat.h>
+#include "compat_uaccess.h"
+#include "compat_fs.h"
+
+#include "vmblockInt.h"
+#include "block.h"
+
+
+/* procfs initialization/cleanup functions */
+static int SetupProcDevice(void);
+static int CleanupProcDevice(void);
+
+/* procfs entry file operations */
+ssize_t ControlFileOpWrite(struct file *filp, const char __user *buf,
+                           size_t cmd, loff_t *ppos);
+static int ControlFileOpRelease(struct inode *inode, struct file *file);
+
+
+static struct proc_dir_entry *controlProcDirEntry;
+struct file_operations ControlFileOps = {
+   .owner   = THIS_MODULE,
+   .write   = ControlFileOpWrite,
+   .release = ControlFileOpRelease,
+};
+
+
+/* Public initialization/cleanup routines */
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VMBlockInitControlOps --
+ *
+ *    Sets up state for control operations.
+ *
+ * Results:
+ *    Zero on success, negative error code on failure.
+ *
+ * Side effects:
+ *    None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+int
+VMBlockInitControlOps(void)
+{
+   int ret;
+
+   ret = BlockInit();
+   if (ret < 0) {
+      Warning("VMBlockInitControlOps: could not initialize blocking ops.\n");
+      return ret;
+   }
+
+   ret = SetupProcDevice();
+   if (ret < 0) {
+      Warning("VMBlockInitControlOps: could not setup proc device.\n");
+      BlockCleanup();
+      return ret;
+   }
+
+   return 0;
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VMBlockCleanupControlOps --
+ *
+ *    Cleans up state for control operations.
+ *
+ * Results:
+ *    Zero on success, negative error code on failure.
+ *
+ * Side effects:
+ *    None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+int
+VMBlockCleanupControlOps(void)
+{
+   int ret;
+
+   ret = CleanupProcDevice();
+   if (ret < 0) {
+      Warning("VMBlockCleanupControlOps: could not cleanup proc device.\n");
+      return ret;
+   }
+
+   BlockCleanup();
+   return 0;
+}
+
+
+/* Private initialization/cleanup routines */
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * SetupProcDevice --
+ *
+ *    Adds entries to /proc used to control file blocks.
+ *
+ * Results:
+ *    Zero on success, negative error code on failure.
+ *
+ * Side effects:
+ *    None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+static int
+SetupProcDevice(void)
+{
+   struct proc_dir_entry *controlProcEntry;
+   struct proc_dir_entry *controlProcMountpoint;
+
+   /* Create /proc/fs/vmblock */
+   controlProcDirEntry = proc_mkdir(VMBLOCK_CONTROL_PROC_DIRNAME, NULL);
+   if (!controlProcDirEntry) {
+      Warning("SetupProcDevice: could not create /proc/"
+              VMBLOCK_CONTROL_PROC_DIRNAME "\n");
+      return -EINVAL;
+   }
+
+   controlProcDirEntry->owner = THIS_MODULE;
+
+   /* Create /proc/fs/vmblock/mountPoint */
+   controlProcMountpoint = proc_mkdir(VMBLOCK_CONTROL_MOUNTPOINT,
+                                      controlProcDirEntry);
+   if (!controlProcMountpoint) {
+      Warning("SetupProcDevice: could not create "
+              VMBLOCK_MOUNT_POINT "\n");
+      remove_proc_entry(VMBLOCK_CONTROL_PROC_DIRNAME, NULL);
+      return -EINVAL;
+   }
+
+   controlProcMountpoint->owner = THIS_MODULE;
+
+   /* Create /proc/fs/vmblock/dev */
+   controlProcEntry = create_proc_entry(VMBLOCK_CONTROL_DEVNAME,
+                                        VMBLOCK_CONTROL_MODE,
+                                        controlProcDirEntry);
+   if (!controlProcEntry) {
+      Warning("SetupProcDevice: could not create " VMBLOCK_DEVICE "\n");
+      remove_proc_entry(VMBLOCK_CONTROL_MOUNTPOINT, controlProcDirEntry);
+      remove_proc_entry(VMBLOCK_CONTROL_PROC_DIRNAME, NULL);
+      return -EINVAL;
+   }
+
+   controlProcEntry->proc_fops = &ControlFileOps;
+   return 0;
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * CleanupProcDevice --
+ *
+ *    Removes /proc entries for controlling file blocks.
+ *
+ * Results:
+ *    Zero on success, negative error code on failure.
+ *
+ * Side effects:
+ *    None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+static int
+CleanupProcDevice(void)
+{
+   if (controlProcDirEntry) {
+      remove_proc_entry(VMBLOCK_CONTROL_MOUNTPOINT, controlProcDirEntry);
+      remove_proc_entry(VMBLOCK_CONTROL_DEVNAME, controlProcDirEntry);
+      remove_proc_entry(VMBLOCK_CONTROL_PROC_DIRNAME, NULL);
+   }
+   return 0;
+}
+
+
+/* procfs file operations */
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * ControlFileOpWrite --
+ *
+ *    write implementation for our control file.  This accepts either add or
+ *    delete commands and the buffer contains the file to block.
+ *
+ * Results:
+ *    Zero on success, negative error code on failure.
+ *
+ * Side effects:
+ *    None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+ssize_t
+ControlFileOpWrite(struct file *file,       // IN: Opened file, used for ID
+                   const char __user *buf,  // IN: NUL-terminated filename
+                   size_t cmd,              // IN: VMBlock command (usually count)
+                   loff_t *ppos)            // IN/OUT: File offset (unused)
+{
+   int ret;
+   ssize_t i;
+   char *filename;
+
+#ifdef VMX86_DEVEL
+   if (cmd == VMBLOCK_LIST_FILEBLOCKS) {
+      BlockListFileBlocks();
+      return 0;
+   }
+#endif
+
+   /*
+    * XXX: Can we GPL our modules already?  This is gross.  On kernels 2.6.6
+    * through 2.6.12 when CONFIG_AUDITSYSCALL is defined, putname() turns into
+    * a macro that calls audit_putname(), which happens to only be exported to
+    * GPL modules (until 2.6.9).  Here we work around this by calling
+    * __getname() and __putname() to get our path buffer directly,
+    * side-stepping the syscall auditing and doing the copy from user space
+    * ourself.  Change this back once we GPL the module.
+    */
+   filename = compat___getname();
+   if (!filename) {
+      Warning("ControlFileOpWrite: Could not obtain memory for filename.\n");
+      return -ENOMEM;
+   }
+
+   /*
+    * XXX: compat___getname() returns a pointer to a PATH_MAX-sized buffer.
+    * Hard-coding this size is also gross, but it's our only option here and
+    * InodeOpLookup() already set a bad example by doing this.
+    */
+   ret = strncpy_from_user(filename, buf, PATH_MAX);
+   if (ret < 0 || ret >= PATH_MAX) {
+      Warning("ControlFileOpWrite: Could not access provided user buffer.\n");
+      ret = ret < 0 ? ret : -ENAMETOOLONG;
+      goto exit;
+   }
+
+   /* Remove all trailing path separators. */
+   for (i = ret - 1; i >= 0 && filename[i] == '/'; i--) {
+      filename[i] = '\0';
+   }
+
+   if (i < 0) {
+      ret = -EINVAL;
+      goto exit;
+   }
+
+   switch (cmd) {
+   case VMBLOCK_ADD_FILEBLOCK:
+      ret = BlockAddFileBlock(filename, file);
+      break;
+   case VMBLOCK_DEL_FILEBLOCK:
+      ret = BlockRemoveFileBlock(filename, file);
+      break;
+   default:
+      Warning("ControlFileOpWrite: unrecognized command (%u) recieved\n",
+              (unsigned)cmd);
+      ret = -EINVAL;
+      break;
+   }
+
+exit:
+   compat___putname(filename);
+   return ret;
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * ControlFileOpRelease --
+ *
+ *    Called when the file is closed.
+ *
+ * Results:
+ *    Zero on success, negative error code on failure.
+ *
+ * Side effects:
+ *    None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+static int
+ControlFileOpRelease(struct inode *inode,  // IN
+                     struct file *file)    // IN
+{
+   BlockRemoveAllBlocks(file);
+   return 0;
+}
--- kernel/linux-2.6.26.3/fs/vmblock/COPYING	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmblock/COPYING	2008-09-03 09:57:35.000000000 -0500
@@ -0,0 +1,339 @@
+		    GNU GENERAL PUBLIC LICENSE
+		       Version 2, June 1991
+
+ Copyright (C) 1989, 1991 Free Software Foundation, Inc.,
+ 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ Everyone is permitted to copy and distribute verbatim copies
+ of this license document, but changing it is not allowed.
+
+			    Preamble
+
+  The licenses for most software are designed to take away your
+freedom to share and change it.  By contrast, the GNU General Public
+License is intended to guarantee your freedom to share and change free
+software--to make sure the software is free for all its users.  This
+General Public License applies to most of the Free Software
+Foundation's software and to any other program whose authors commit to
+using it.  (Some other Free Software Foundation software is covered by
+the GNU Lesser General Public License instead.)  You can apply it to
+your programs, too.
+
+  When we speak of free software, we are referring to freedom, not
+price.  Our General Public Licenses are designed to make sure that you
+have the freedom to distribute copies of free software (and charge for
+this service if you wish), that you receive source code or can get it
+if you want it, that you can change the software or use pieces of it
+in new free programs; and that you know you can do these things.
+
+  To protect your rights, we need to make restrictions that forbid
+anyone to deny you these rights or to ask you to surrender the rights.
+These restrictions translate to certain responsibilities for you if you
+distribute copies of the software, or if you modify it.
+
+  For example, if you distribute copies of such a program, whether
+gratis or for a fee, you must give the recipients all the rights that
+you have.  You must make sure that they, too, receive or can get the
+source code.  And you must show them these terms so they know their
+rights.
+
+  We protect your rights with two steps: (1) copyright the software, and
+(2) offer you this license which gives you legal permission to copy,
+distribute and/or modify the software.
+
+  Also, for each author's protection and ours, we want to make certain
+that everyone understands that there is no warranty for this free
+software.  If the software is modified by someone else and passed on, we
+want its recipients to know that what they have is not the original, so
+that any problems introduced by others will not reflect on the original
+authors' reputations.
+
+  Finally, any free program is threatened constantly by software
+patents.  We wish to avoid the danger that redistributors of a free
+program will individually obtain patent licenses, in effect making the
+program proprietary.  To prevent this, we have made it clear that any
+patent must be licensed for everyone's free use or not licensed at all.
+
+  The precise terms and conditions for copying, distribution and
+modification follow.
+
+		    GNU GENERAL PUBLIC LICENSE
+   TERMS AND CONDITIONS FOR COPYING, DISTRIBUTION AND MODIFICATION
+
+  0. This License applies to any program or other work which contains
+a notice placed by the copyright holder saying it may be distributed
+under the terms of this General Public License.  The "Program", below,
+refers to any such program or work, and a "work based on the Program"
+means either the Program or any derivative work under copyright law:
+that is to say, a work containing the Program or a portion of it,
+either verbatim or with modifications and/or translated into another
+language.  (Hereinafter, translation is included without limitation in
+the term "modification".)  Each licensee is addressed as "you".
+
+Activities other than copying, distribution and modification are not
+covered by this License; they are outside its scope.  The act of
+running the Program is not restricted, and the output from the Program
+is covered only if its contents constitute a work based on the
+Program (independent of having been made by running the Program).
+Whether that is true depends on what the Program does.
+
+  1. You may copy and distribute verbatim copies of the Program's
+source code as you receive it, in any medium, provided that you
+conspicuously and appropriately publish on each copy an appropriate
+copyright notice and disclaimer of warranty; keep intact all the
+notices that refer to this License and to the absence of any warranty;
+and give any other recipients of the Program a copy of this License
+along with the Program.
+
+You may charge a fee for the physical act of transferring a copy, and
+you may at your option offer warranty protection in exchange for a fee.
+
+  2. You may modify your copy or copies of the Program or any portion
+of it, thus forming a work based on the Program, and copy and
+distribute such modifications or work under the terms of Section 1
+above, provided that you also meet all of these conditions:
+
+    a) You must cause the modified files to carry prominent notices
+    stating that you changed the files and the date of any change.
+
+    b) You must cause any work that you distribute or publish, that in
+    whole or in part contains or is derived from the Program or any
+    part thereof, to be licensed as a whole at no charge to all third
+    parties under the terms of this License.
+
+    c) If the modified program normally reads commands interactively
+    when run, you must cause it, when started running for such
+    interactive use in the most ordinary way, to print or display an
+    announcement including an appropriate copyright notice and a
+    notice that there is no warranty (or else, saying that you provide
+    a warranty) and that users may redistribute the program under
+    these conditions, and telling the user how to view a copy of this
+    License.  (Exception: if the Program itself is interactive but
+    does not normally print such an announcement, your work based on
+    the Program is not required to print an announcement.)
+
+These requirements apply to the modified work as a whole.  If
+identifiable sections of that work are not derived from the Program,
+and can be reasonably considered independent and separate works in
+themselves, then this License, and its terms, do not apply to those
+sections when you distribute them as separate works.  But when you
+distribute the same sections as part of a whole which is a work based
+on the Program, the distribution of the whole must be on the terms of
+this License, whose permissions for other licensees extend to the
+entire whole, and thus to each and every part regardless of who wrote it.
+
+Thus, it is not the intent of this section to claim rights or contest
+your rights to work written entirely by you; rather, the intent is to
+exercise the right to control the distribution of derivative or
+collective works based on the Program.
+
+In addition, mere aggregation of another work not based on the Program
+with the Program (or with a work based on the Program) on a volume of
+a storage or distribution medium does not bring the other work under
+the scope of this License.
+
+  3. You may copy and distribute the Program (or a work based on it,
+under Section 2) in object code or executable form under the terms of
+Sections 1 and 2 above provided that you also do one of the following:
+
+    a) Accompany it with the complete corresponding machine-readable
+    source code, which must be distributed under the terms of Sections
+    1 and 2 above on a medium customarily used for software interchange; or,
+
+    b) Accompany it with a written offer, valid for at least three
+    years, to give any third party, for a charge no more than your
+    cost of physically performing source distribution, a complete
+    machine-readable copy of the corresponding source code, to be
+    distributed under the terms of Sections 1 and 2 above on a medium
+    customarily used for software interchange; or,
+
+    c) Accompany it with the information you received as to the offer
+    to distribute corresponding source code.  (This alternative is
+    allowed only for noncommercial distribution and only if you
+    received the program in object code or executable form with such
+    an offer, in accord with Subsection b above.)
+
+The source code for a work means the preferred form of the work for
+making modifications to it.  For an executable work, complete source
+code means all the source code for all modules it contains, plus any
+associated interface definition files, plus the scripts used to
+control compilation and installation of the executable.  However, as a
+special exception, the source code distributed need not include
+anything that is normally distributed (in either source or binary
+form) with the major components (compiler, kernel, and so on) of the
+operating system on which the executable runs, unless that component
+itself accompanies the executable.
+
+If distribution of executable or object code is made by offering
+access to copy from a designated place, then offering equivalent
+access to copy the source code from the same place counts as
+distribution of the source code, even though third parties are not
+compelled to copy the source along with the object code.
+
+  4. You may not copy, modify, sublicense, or distribute the Program
+except as expressly provided under this License.  Any attempt
+otherwise to copy, modify, sublicense or distribute the Program is
+void, and will automatically terminate your rights under this License.
+However, parties who have received copies, or rights, from you under
+this License will not have their licenses terminated so long as such
+parties remain in full compliance.
+
+  5. You are not required to accept this License, since you have not
+signed it.  However, nothing else grants you permission to modify or
+distribute the Program or its derivative works.  These actions are
+prohibited by law if you do not accept this License.  Therefore, by
+modifying or distributing the Program (or any work based on the
+Program), you indicate your acceptance of this License to do so, and
+all its terms and conditions for copying, distributing or modifying
+the Program or works based on it.
+
+  6. Each time you redistribute the Program (or any work based on the
+Program), the recipient automatically receives a license from the
+original licensor to copy, distribute or modify the Program subject to
+these terms and conditions.  You may not impose any further
+restrictions on the recipients' exercise of the rights granted herein.
+You are not responsible for enforcing compliance by third parties to
+this License.
+
+  7. If, as a consequence of a court judgment or allegation of patent
+infringement or for any other reason (not limited to patent issues),
+conditions are imposed on you (whether by court order, agreement or
+otherwise) that contradict the conditions of this License, they do not
+excuse you from the conditions of this License.  If you cannot
+distribute so as to satisfy simultaneously your obligations under this
+License and any other pertinent obligations, then as a consequence you
+may not distribute the Program at all.  For example, if a patent
+license would not permit royalty-free redistribution of the Program by
+all those who receive copies directly or indirectly through you, then
+the only way you could satisfy both it and this License would be to
+refrain entirely from distribution of the Program.
+
+If any portion of this section is held invalid or unenforceable under
+any particular circumstance, the balance of the section is intended to
+apply and the section as a whole is intended to apply in other
+circumstances.
+
+It is not the purpose of this section to induce you to infringe any
+patents or other property right claims or to contest validity of any
+such claims; this section has the sole purpose of protecting the
+integrity of the free software distribution system, which is
+implemented by public license practices.  Many people have made
+generous contributions to the wide range of software distributed
+through that system in reliance on consistent application of that
+system; it is up to the author/donor to decide if he or she is willing
+to distribute software through any other system and a licensee cannot
+impose that choice.
+
+This section is intended to make thoroughly clear what is believed to
+be a consequence of the rest of this License.
+
+  8. If the distribution and/or use of the Program is restricted in
+certain countries either by patents or by copyrighted interfaces, the
+original copyright holder who places the Program under this License
+may add an explicit geographical distribution limitation excluding
+those countries, so that distribution is permitted only in or among
+countries not thus excluded.  In such case, this License incorporates
+the limitation as if written in the body of this License.
+
+  9. The Free Software Foundation may publish revised and/or new versions
+of the General Public License from time to time.  Such new versions will
+be similar in spirit to the present version, but may differ in detail to
+address new problems or concerns.
+
+Each version is given a distinguishing version number.  If the Program
+specifies a version number of this License which applies to it and "any
+later version", you have the option of following the terms and conditions
+either of that version or of any later version published by the Free
+Software Foundation.  If the Program does not specify a version number of
+this License, you may choose any version ever published by the Free Software
+Foundation.
+
+  10. If you wish to incorporate parts of the Program into other free
+programs whose distribution conditions are different, write to the author
+to ask for permission.  For software which is copyrighted by the Free
+Software Foundation, write to the Free Software Foundation; we sometimes
+make exceptions for this.  Our decision will be guided by the two goals
+of preserving the free status of all derivatives of our free software and
+of promoting the sharing and reuse of software generally.
+
+			    NO WARRANTY
+
+  11. BECAUSE THE PROGRAM IS LICENSED FREE OF CHARGE, THERE IS NO WARRANTY
+FOR THE PROGRAM, TO THE EXTENT PERMITTED BY APPLICABLE LAW.  EXCEPT WHEN
+OTHERWISE STATED IN WRITING THE COPYRIGHT HOLDERS AND/OR OTHER PARTIES
+PROVIDE THE PROGRAM "AS IS" WITHOUT WARRANTY OF ANY KIND, EITHER EXPRESSED
+OR IMPLIED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
+MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE.  THE ENTIRE RISK AS
+TO THE QUALITY AND PERFORMANCE OF THE PROGRAM IS WITH YOU.  SHOULD THE
+PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF ALL NECESSARY SERVICING,
+REPAIR OR CORRECTION.
+
+  12. IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING
+WILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MAY MODIFY AND/OR
+REDISTRIBUTE THE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES,
+INCLUDING ANY GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING
+OUT OF THE USE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED
+TO LOSS OF DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY
+YOU OR THIRD PARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER
+PROGRAMS), EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE
+POSSIBILITY OF SUCH DAMAGES.
+
+		     END OF TERMS AND CONDITIONS
+
+	    How to Apply These Terms to Your New Programs
+
+  If you develop a new program, and you want it to be of the greatest
+possible use to the public, the best way to achieve this is to make it
+free software which everyone can redistribute and change under these terms.
+
+  To do so, attach the following notices to the program.  It is safest
+to attach them to the start of each source file to most effectively
+convey the exclusion of warranty; and each file should have at least
+the "copyright" line and a pointer to where the full notice is found.
+
+    <one line to give the program's name and a brief idea of what it does.>
+    Copyright (C) <year>  <name of author>
+
+    This program is free software; you can redistribute it and/or modify
+    it under the terms of the GNU General Public License as published by
+    the Free Software Foundation; either version 2 of the License, or
+    (at your option) any later version.
+
+    This program is distributed in the hope that it will be useful,
+    but WITHOUT ANY WARRANTY; without even the implied warranty of
+    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+    GNU General Public License for more details.
+
+    You should have received a copy of the GNU General Public License along
+    with this program; if not, write to the Free Software Foundation, Inc.,
+    51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA.
+
+Also add information on how to contact you by electronic and paper mail.
+
+If the program is interactive, make it output a short notice like this
+when it starts in an interactive mode:
+
+    Gnomovision version 69, Copyright (C) year name of author
+    Gnomovision comes with ABSOLUTELY NO WARRANTY; for details type `show w'.
+    This is free software, and you are welcome to redistribute it
+    under certain conditions; type `show c' for details.
+
+The hypothetical commands `show w' and `show c' should show the appropriate
+parts of the General Public License.  Of course, the commands you use may
+be called something other than `show w' and `show c'; they could even be
+mouse-clicks or menu items--whatever suits your program.
+
+You should also get your employer (if you work as a programmer) or your
+school, if any, to sign a "copyright disclaimer" for the program, if
+necessary.  Here is a sample; alter the names:
+
+  Yoyodyne, Inc., hereby disclaims all copyright interest in the program
+  `Gnomovision' (which makes passes at compilers) written by James Hacker.
+
+  <signature of Ty Coon>, 1 April 1989
+  Ty Coon, President of Vice
+
+This General Public License does not permit incorporating your program into
+proprietary programs.  If your program is a subroutine library, you may
+consider it more useful to permit linking proprietary applications with the
+library.  If this is what you want to do, use the GNU Lesser General
+Public License instead of this License.
--- kernel/linux-2.6.26.3/fs/vmblock/dbllnklst.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmblock/dbllnklst.c	2008-09-03 09:58:40.000000000 -0500
@@ -0,0 +1,399 @@
+/*********************************************************
+ * Copyright (C) 1998 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#include "vmware.h"
+#include "dbllnklst.h"
+
+/*
+ * dbllnklst.c --
+ *
+ *    Light (but nonetheless powerful) implementation of doubly linked lists
+ */
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * DblLnkLst_Init --
+ *
+ *    Initialize a member of a doubly linked list
+ *
+ * Result
+ *    None
+ *
+ * Side effects:
+ *    None
+ *
+ *----------------------------------------------------------------------
+ */
+
+void
+DblLnkLst_Init(DblLnkLst_Links *l) // IN
+{
+   ASSERT(l);
+
+   l->prev = l->next = l;
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * DblLnkLst_Link --
+ *
+ *    Merge two doubly linked lists into one
+ *
+ *    The operation is commutative
+ *    The operation is inversible (its inverse is DblLnkLst_Unlink)
+ *
+ * Result
+ *    None
+ *
+ * Side effects:
+ *    None
+ *
+ *----------------------------------------------------------------------
+ */
+
+void
+DblLnkLst_Link(DblLnkLst_Links *l1, // IN
+               DblLnkLst_Links *l2) // IN
+{
+   DblLnkLst_Links *tmp;
+
+   ASSERT(l1);
+   ASSERT(l2);
+
+   (tmp      = l1->prev)->next = l2;
+   (l1->prev = l2->prev)->next = l1;
+    l2->prev = tmp                 ;
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * DblLnkLst_Unlink --
+ *
+ *    Split one doubly linked list into two
+ *
+ *    No check is performed: the caller must ensure that both members
+ *    belong to the same doubly linked list
+ *
+ *    The operation is commutative
+ *    The operation is inversible (its inverse is DblLnkLst_Link)
+ *
+ * Result
+ *    None
+ *
+ * Side effects:
+ *    None
+ *
+ *----------------------------------------------------------------------
+ */
+
+void
+DblLnkLst_Unlink(DblLnkLst_Links *l1, // IN
+                 DblLnkLst_Links *l2) // IN
+{
+   DblLnkLst_Links *tmp;
+
+   ASSERT(l1);
+   ASSERT(l2);
+
+   tmp       = l1->prev            ;
+   (l1->prev = l2->prev)->next = l1;
+   (l2->prev = tmp     )->next = l2;
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * DblLnkLst_Unlink1 --
+ *
+ *    Unlink an element from its list.
+ *
+ * Result
+ *    None
+ *
+ * Side effects:
+ *    None
+ *
+ *----------------------------------------------------------------------
+ */
+
+void
+DblLnkLst_Unlink1(DblLnkLst_Links *l) // IN
+{
+   ASSERT(l);
+
+   DblLnkLst_Unlink(l, l->next);
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * DblLnkLst_IsLinked --
+ *
+ *    Determines whether an element is linked with any other elements.
+ *
+ * Results:
+ *    TRUE if link is linked, FALSE otherwise.
+ *
+ * Side effects:
+ *    None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+Bool
+DblLnkLst_IsLinked(DblLnkLst_Links const *l) // IN
+{
+   ASSERT(l);
+
+   ASSERT((l->prev == l && l->next == l) ||
+          (l->prev != l && l->next != l));
+
+   /*
+    * A DblLnkLst_Links is either linked to itself (not linked) or linked to
+    * other elements in a list (linked).
+    */
+   return l->prev != l;
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * DblLnkLst_LinkFirst --
+ *
+ *    Insert 'l' at the beginning of the list anchored at 'head'
+ *
+ * Result
+ *    None
+ *
+ * Side effects:
+ *    None
+ *
+ *----------------------------------------------------------------------
+ */
+
+void
+DblLnkLst_LinkFirst(DblLnkLst_Links *head, // IN
+                    DblLnkLst_Links *l)    // IN
+{
+   ASSERT(head);
+   ASSERT(l);
+
+   DblLnkLst_Link(head->next, l);
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * DblLnkLst_LinkLast --
+ *
+ *    Insert 'l' at the end of the list anchored at 'head'
+ *
+ * Result
+ *    None
+ *
+ * Side effects:
+ *    None
+ *
+ *----------------------------------------------------------------------
+ */
+
+void
+DblLnkLst_LinkLast(DblLnkLst_Links *head, // IN
+                   DblLnkLst_Links *l)    // IN
+{
+   ASSERT(head);
+   ASSERT(l);
+
+   DblLnkLst_Link(head, l);
+}
+
+
+#if 0
+/*
+ * Test code (which also demonstrates how to use this library)
+ */
+
+/*
+ * Add the double linked list capability to any of your data structure just by
+ * adding a DblLnkLst_Links field inside it. It is not required that the field
+ * comes first, but if it does, the execution will be slighly faster.
+ *
+ * Here we create a doubly linked list of integers
+ */
+
+#include <stdlib.h>
+#include <stdio.h>
+
+typedef struct member {
+   int i;
+   DblLnkLst_Links l;
+} member;
+
+
+/* Member constructor */
+member *
+make_member(int i)
+{
+   member *m;
+
+   m = malloc(sizeof(*m));
+   DblLnkLst_Init(&m->l);
+   m->i = i;
+
+   return m;
+}
+
+
+/* Dump a circular list */
+void
+dump_circular(const member *c) // IN
+{
+   const member *current;
+
+   printf("forward: ");
+   current = c;
+   do {
+      printf("%d ", current->i);
+      current = DblLnkLst_Container(current->l.next, member, l);
+   } while (current != c);
+   printf("backward: ");
+   do {
+      printf("%d ", current->i);
+      current = DblLnkLst_Container(current->l.prev, member, l);
+   } while (current != c);
+   printf("\n");
+}
+
+
+/* Dump an anchored list */
+void
+dump_anchored(const DblLnkLst_Links *h) // IN
+{
+   DblLnkLst_Links *cur_l;
+
+   printf("forward: ");
+   for (cur_l = h->next; cur_l != h; cur_l = cur_l->next) {
+      member *current;
+
+      current = DblLnkLst_Container(cur_l, member, l);
+      printf("%d ", current->i);
+   }
+   printf("backward: ");
+   for (cur_l = h->prev; cur_l != h; cur_l = cur_l->prev) {
+      member *current;
+
+      current = DblLnkLst_Container(cur_l, member, l);
+      printf("%d ", current->i);
+   }
+   printf("\n");
+}
+
+
+/* Test code entry point */
+int
+main(int argc,    // IN
+     char **argv) // IN
+{
+   member *c1;
+   member *c2;
+   member *c3;
+   member *c4;
+
+   DblLnkLst_Links h;
+   member *a1;
+   member *a2;
+   member *a3;
+
+   printf("Circular list: there is no origin\n");
+
+   /* Create the 1st member */
+   c1 = make_member(1);
+   /* Special case: there is no list to merge with, initially */
+
+   /* Add the 2nd member _after_ the 1st one */
+   c2 = make_member(2);
+   DblLnkLst_Link(&c1->l, &c2->l);
+
+   /* Add the 3rd member _after_ the 2nd one */
+   c3 = make_member(3);
+   DblLnkLst_Link(&c1->l, &c3->l);
+
+   /* Add the 4th member _before_ the 3rd one */
+   c4 = make_member(4);
+   DblLnkLst_Link(&c3->l, &c4->l);
+
+   printf("See it from this member...\n");
+   dump_circular(c1);
+   printf("...Or from this one\n");
+   dump_circular(c4);
+
+   printf("\n");
+   printf("Anchored (linear) list: it has a beginning and an end\n");
+
+   /* Create the 'head' of the list */
+   DblLnkLst_Init(&h);
+
+   /* Add the 1st member at the _end_ */
+   a1 = make_member(5);
+   DblLnkLst_LinkLast(&h, &a1->l);
+
+   /* Add the 2nd member at the _beginning_ */
+   a2 = make_member(6);
+   DblLnkLst_LinkFirst(&h, &a2->l);
+
+   /* Add the 3rd member _before_ the 1st one */
+   a3 = make_member(7);
+   DblLnkLst_Link(&a1->l, &a3->l);
+
+   dump_anchored(&h);
+
+   printf("\n");
+   printf("Merge both lists: the result is an anchored list\n");
+
+   DblLnkLst_Link(&h, &c4->l);
+
+   dump_anchored(&h);
+
+   printf("\n");
+   printf("Remove a member\n");
+
+   DblLnkLst_Unlink1(&c3->l);
+
+   dump_anchored(&h);
+
+   printf("\n");
+   printf("Split the result in two lists: an anchored one and a circular "
+          "one\n");
+   DblLnkLst_Unlink(&h, &a1->l);
+
+   dump_anchored(&h);
+   dump_circular(a1);
+
+   return 0;
+}
+#endif
--- kernel/linux-2.6.26.3/fs/vmblock/dbllnklst.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmblock/dbllnklst.h	2008-09-03 09:57:35.000000000 -0500
@@ -0,0 +1,68 @@
+/*********************************************************
+ * Copyright (C) 1998 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * dbllnklst.h --
+ *
+ *    Double linked lists
+ */
+
+#ifndef _DBLLNKLST_H_
+#define _DBLLNKLST_H_
+
+#include "vm_basic_types.h"
+
+#define INCLUDE_ALLOW_MODULE
+#define INCLUDE_ALLOW_USERLEVEL
+
+
+#define DblLnkLst_OffsetOf(type, field) ((intptr_t)&((type *)0)->field)
+
+#define DblLnkLst_Container(addr, type, field) \
+   ((type *)((char *)addr - DblLnkLst_OffsetOf(type, field)))
+
+#define DblLnkLst_ForEach(curr, head)                   \
+      for (curr = (head)->next; curr != (head); curr = (curr)->next)
+
+/* Safe from list element removal within loop body. */
+#define DblLnkLst_ForEachSafe(curr, nextElem, head)             \
+      for (curr = (head)->next, nextElem = (curr)->next;        \
+           curr != (head);                                      \
+           curr = nextElem, nextElem = (curr)->next)
+
+typedef struct DblLnkLst_Links {
+   struct DblLnkLst_Links *prev;
+   struct DblLnkLst_Links *next;
+} DblLnkLst_Links;
+
+
+/* Functions for both circular and anchored lists. --hpreg */
+
+void DblLnkLst_Init(DblLnkLst_Links *l);
+void DblLnkLst_Link(DblLnkLst_Links *l1, DblLnkLst_Links *l2);
+void DblLnkLst_Unlink(DblLnkLst_Links *l1, DblLnkLst_Links *l2);
+void DblLnkLst_Unlink1(DblLnkLst_Links *l);
+Bool DblLnkLst_IsLinked(DblLnkLst_Links const *l);
+
+/* Functions specific to anchored lists. --hpreg */
+
+void DblLnkLst_LinkFirst(DblLnkLst_Links *head, DblLnkLst_Links *l);
+void DblLnkLst_LinkLast(DblLnkLst_Links *head, DblLnkLst_Links *l);
+
+
+#endif /* _DBLLNKLST_H_ */
--- kernel/linux-2.6.26.3/fs/vmblock/dentry.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmblock/dentry.c	2008-09-03 09:58:40.000000000 -0500
@@ -0,0 +1,132 @@
+/*********************************************************
+ * Copyright (C) 2006 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * dentry.c --
+ *
+ *   Dentry operations for the file system of the vmblock driver.
+ *
+ */
+
+#include "driver-config.h"
+#include "compat_fs.h"
+#include "compat_namei.h"
+
+#include "vmblockInt.h"
+#include "filesystem.h"
+#include "block.h"
+
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 5, 75)
+static int DentryOpRevalidate(struct dentry *dentry, struct nameidata *nd);
+#else
+static int DentryOpRevalidate(struct dentry *dentry, int flags);
+#endif
+
+struct dentry_operations LinkDentryOps = {
+   .d_revalidate = DentryOpRevalidate,
+};
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * DentryOpRevalidate --
+ *
+ *    This function is invoked every time the dentry is accessed from the cache
+ *    to ensure it is still valid.  We use it to block since any threads
+ *    looking up this dentry after the initial lookup should still block if the
+ *    block has not been cleared.
+ *
+ * Results:
+ *    1 if the dentry is valid, 0 if it is not.
+ *
+ * Side effects:
+ *    None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 5, 75)
+static int
+DentryOpRevalidate(struct dentry *dentry,  // IN: dentry revalidating
+                   struct nameidata *nd)   // IN: lookup flags & intent
+#else
+static int
+DentryOpRevalidate(struct dentry *dentry,  // IN: dentry revalidating
+                   int flags)              // IN: lookup flags (e.g., LOOKUP_CONTINUE)
+#endif
+{
+   VMBlockInodeInfo *iinfo;
+   struct nameidata actualNd;
+   struct dentry *actualDentry;
+   int ret;
+
+   if (!dentry) {
+      Warning("DentryOpRevalidate: invalid args from kernel\n");
+      return 0;
+   }
+
+   /*
+    * If a dentry does not have an inode associated with it then
+    * we are dealing with a negative dentry. Always invalidate a negative
+    * dentry which will cause a fresh lookup.
+    */
+   if (!dentry->d_inode) {
+      return 0;
+   }
+
+
+   iinfo = INODE_TO_IINFO(dentry->d_inode);
+   if (!iinfo) {
+      Warning("DentryOpRevalidate: dentry has no fs-specific data\n");
+      return 0;
+   }
+
+   /* Block if there is a pending block on this file */
+   BlockWaitOnFile(iinfo->name, NULL);
+
+   /*
+    * If the actual dentry has a revalidate function, we'll let it figure out
+    * whether the dentry is still valid.  If not, do a path lookup to ensure
+    * that the file still exists.
+    */
+   actualDentry = iinfo->actualDentry;
+
+   if (actualDentry &&
+       actualDentry->d_op &&
+       actualDentry->d_op->d_revalidate) {
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 5, 75)
+      return actualDentry->d_op->d_revalidate(actualDentry, nd);
+#else
+      return actualDentry->d_op->d_revalidate(actualDentry, flags);
+#endif
+   }
+
+   if (compat_path_lookup(iinfo->name, 0, &actualNd)) {
+      LOG(4, "DentryOpRevalidate: [%s] no longer exists\n", iinfo->name);
+      return 0;
+   }
+   ret = compat_vmw_nd_to_dentry(actualNd) &&
+         compat_vmw_nd_to_dentry(actualNd)->d_inode;
+   compat_path_release(&actualNd);
+
+   LOG(8, "DentryOpRevalidate: [%s] %s revalidated\n",
+       iinfo->name, ret ? "" : "not");
+   return ret;
+}
--- kernel/linux-2.6.26.3/fs/vmblock/driver-config.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmblock/driver-config.h	2008-09-03 09:59:51.000000000 -0500
@@ -0,0 +1,77 @@
+/*********************************************************
+ * Copyright (C) 1998 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * Sets the proper defines from the Linux header files
+ *
+ * This file must be included before the inclusion of any kernel header file,
+ * with the exception of linux/autoconf.h and linux/version.h --hpreg
+ */
+
+#ifndef __VMX_CONFIG_H__
+#define __VMX_CONFIG_H__
+
+#define INCLUDE_ALLOW_VMCORE
+#define INCLUDE_ALLOW_VMMON
+#define INCLUDE_ALLOW_MODULE
+#define INCLUDE_ALLOW_VMNIXMOD
+
+#include <linux/autoconf.h>
+#include "compat_version.h"
+
+/*
+ * We rely on Kernel Module support.  Check here.
+ */
+#ifndef CONFIG_MODULES
+#   error "No Module support in this kernel.  Please configure with CONFIG_MODULES"
+#endif
+
+/*
+ * 2.2 kernels still use __SMP__ (derived from CONFIG_SMP
+ * in the main Makefile), so we do it here.
+ */
+
+#ifdef CONFIG_SMP
+#   define __SMP__ 1
+#endif
+
+#if defined(CONFIG_MODVERSIONS) && defined(KERNEL_2_1)
+#   if LINUX_VERSION_CODE < KERNEL_VERSION(2,5,60)
+/*
+ * MODVERSIONS might be already defined when using kernel's Makefiles.
+ */
+#      ifndef MODVERSIONS
+#         define MODVERSIONS
+#      endif
+#      include <linux/modversions.h>
+#   endif
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 24)
+/*
+ * Force the uintptr_t definition to come from linux/types.h instead of vm_basic_types.h.
+ */
+#   include <linux/types.h>
+#   define _STDINT_H 1
+#endif
+
+#ifndef __KERNEL__
+#   define __KERNEL__
+#endif
+
+#endif
--- kernel/linux-2.6.26.3/fs/vmblock/file.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmblock/file.c	2008-09-03 09:58:40.000000000 -0500
@@ -0,0 +1,274 @@
+/*********************************************************
+ * Copyright (C) 2006 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * file.c --
+ *
+ *   File operations for the file system of the vmblock driver.
+ *
+ */
+
+#include "driver-config.h"
+#include <linux/module.h>
+#include "compat_fs.h"
+#include "compat_sched.h"
+
+#include "vmblockInt.h"
+#include "filesystem.h"
+
+/* Specifically for our filldir_t callback */
+typedef struct FilldirInfo {
+   filldir_t filldir;
+   void *dirent;
+} FilldirInfo;
+
+/* File operations */
+static int FileOpOpen(struct inode *inode, struct file *file);
+static int FileOpReaddir(struct file *file, void *dirent, filldir_t filldir);
+static int FileOpRelease(struct inode *inode, struct file *file);
+
+/* Local functions */
+#if defined(VMW_FILLDIR_2618)
+static int Filldir(void *buf, const char *name, int namelen,
+                   loff_t offset, u64 ino, unsigned int d_type);
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(2, 4, 9)
+static int Filldir(void *buf, const char *name, int namelen,
+                   loff_t offset, ino_t ino, unsigned int d_type);
+#else
+static int Filldir(void *buf, const char *name, int namelen,
+                   off_t offset, ino_t ino, unsigned int d_type);
+#endif
+
+struct file_operations RootFileOps = {
+   .readdir = FileOpReaddir,
+   .open    = FileOpOpen,
+   .release = FileOpRelease,
+};
+
+
+/* File operations */
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * FileOpOpen --
+ *
+ *    Invoked when open(2) has been called on our root inode.  We get an open
+ *    file instance of the actual file that we are providing indirect access
+ *    to.
+ *
+ * Results:
+ *    0 on success, negative error code on failure.
+ *
+ * Side effects:
+ *    None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+static int
+FileOpOpen(struct inode *inode,  // IN
+           struct file *file)    // IN
+{
+   VMBlockInodeInfo *iinfo;
+   struct file *actualFile;
+
+   if (!inode || !file || !INODE_TO_IINFO(inode)) {
+      Warning("FileOpOpen: invalid args from kernel\n");
+      return -EINVAL;
+   }
+
+   iinfo = INODE_TO_IINFO(inode);
+
+   /*
+    * Get an open file for the directory we are redirecting to.  This ensure we
+    * can gracefully handle cases where that directory is removed after we are
+    * mounted.
+    */
+   actualFile = filp_open(iinfo->name, file->f_flags, file->f_flags);
+   if (IS_ERR(actualFile)) {
+      Warning("FileOpOpen: could not open file [%s]\n", iinfo->name);
+      file->private_data = NULL;
+      return PTR_ERR(actualFile);
+   }
+
+   /*
+    * If the file opened is the same as the one retrieved for the file then we
+    * shouldn't allow the open to happen.  This can only occur if the
+    * redirected root directory specified at mount time is the same as where
+    * the mount is placed.  Later in FileOpReaddir() we'd call vfs_readdir()
+    * and that would try to acquire the inode's semaphore; if the two inodes
+    * are the same we'll deadlock.
+    */
+   if (actualFile->f_dentry && inode == actualFile->f_dentry->d_inode) {
+      Warning("FileOpOpen: identical inode encountered, open cannot succeed.\n");
+      if (filp_close(actualFile, current->files) < 0) {
+         Warning("FileOpOpen: unable to close opened file.\n");
+      }
+      return -EINVAL;
+   }
+
+   file->private_data = actualFile;
+   return 0;
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * FileOpReaddir --
+ *
+ *    Invoked when a user invokes getdents(2) or readdir(2) on the root of our
+ *    file system.  We perform a readdir on the actual underlying file but
+ *    interpose the callback by providing our own Filldir() function.  This
+ *    enables us to change dentry types to symlinks.
+ *
+ * Results:
+ *    0 on success, negative error code on error.
+ *
+ * Side effects:
+ *    None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+static int
+FileOpReaddir(struct file *file,  // IN
+              void *dirent,       // IN
+              filldir_t filldir)  // IN
+{
+   int ret;
+   FilldirInfo info;
+   struct file *actualFile;
+
+   if (!file) {
+      Warning("FileOpReaddir: invalid args from kernel\n");
+      return -EINVAL;
+   }
+
+   actualFile = file->private_data;
+   if (!actualFile) {
+      Warning("FileOpReaddir: no actual file found\n");
+      return -EINVAL;
+   }
+
+   info.filldir = filldir;
+   info.dirent = dirent;
+
+   actualFile->f_pos = file->f_pos;
+   ret = vfs_readdir(actualFile, Filldir, &info);
+   file->f_pos = actualFile->f_pos;
+
+   return ret;
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * FileOpRelease --
+ *
+ *    Invoked when a user close(2)s the root of our file system.  Here we just
+ *    close the actual file we opened in FileOpOpen().
+ *
+ * Results:
+ *    0 on success, negative value on error.
+ *
+ * Side effects:
+ *    None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+static int
+FileOpRelease(struct inode *inode, // IN
+              struct file *file)   // IN
+{
+   int ret;
+   struct file *actualFile;
+
+   if (!inode || !file) {
+      Warning("FileOpRelease: invalid args from kerel\n");
+      return -EINVAL;
+   }
+
+   actualFile = file->private_data;
+   if (!actualFile) {
+      Warning("FileOpRelease: no actual file found\n");
+      return -EINVAL;
+   }
+
+   ret = filp_close(actualFile, current->files);
+
+   return ret;
+}
+
+
+/* Local functions */
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * Filldir --
+ *
+ *    Callback function for readdir that we use in place of the one provided.
+ *    This allows us to specify that each dentry is a symlink, but pass through
+ *    everything else to the original filldir function.
+ *
+ * Results:
+ *    Original filldir's return value.
+ *
+ * Side effects:
+ *    Directory information gets copied to user's buffer.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+#if defined(VMW_FILLDIR_2618)
+static int
+Filldir(void *buf,              // IN: Dirent buffer passed from FileOpReaddir
+        const char *name,       // IN: Dirent name
+        int namelen,            // IN: len of dirent's name
+        loff_t offset,          // IN: Offset
+        u64 ino,                // IN: Inode number of dirent
+        unsigned int d_type)    // IN: Type of file
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(2, 4, 9)
+static int
+Filldir(void *buf,              // IN: Dirent buffer passed from FileOpReaddir
+        const char *name,       // IN: Dirent name
+        int namelen,            // IN: len of dirent's name
+        loff_t offset,          // IN: Offset
+        ino_t ino,              // IN: Inode number of dirent
+        unsigned int d_type)    // IN: Type of file
+#else
+static int
+Filldir(void *buf,              // IN: Dirent buffer passed from FileOpReaddir
+        const char *name,       // IN: Dirent name
+        int namelen,            // IN: len of dirent's name
+        off_t offset,           // IN: Offset
+        ino_t ino,              // IN: Inode number of dirent
+        unsigned int d_type)    // IN: Type of file
+#endif
+{
+   FilldirInfo *info = (FilldirInfo *)buf;
+
+   /* Specify DT_LNK regardless */
+   return info->filldir(info->dirent, name, namelen, offset, ino, DT_LNK);
+}
+
+
--- kernel/linux-2.6.26.3/fs/vmblock/filesystem.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmblock/filesystem.c	2008-09-03 09:58:40.000000000 -0500
@@ -0,0 +1,688 @@
+/*********************************************************
+ * Copyright (C) 2006 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * filesystem.c --
+ *
+ *   File system for the vmblock driver.
+ *
+ */
+
+#include "driver-config.h"
+#include "compat_kernel.h"
+#include <linux/module.h>
+#include <linux/proc_fs.h>
+#include <linux/mount.h>
+#include "compat_fs.h"
+#include "compat_spinlock.h"
+#include "compat_namei.h"
+#include "compat_slab.h"
+
+#include "os.h"
+#include "vmblockInt.h"
+#include "filesystem.h"
+
+#define VMBLOCK_ROOT_INO  1
+#define GetRootInode(sb)  Iget(sb, NULL, NULL, VMBLOCK_ROOT_INO)
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 25)
+#   define KERNEL_25_FS 0
+#else
+#   define KERNEL_25_FS 1
+#endif
+
+static struct inode *GetInode(struct super_block *sb, ino_t ino);
+
+/* File system operations */
+#if KERNEL_25_FS /* { */
+#   if defined(VMW_GETSB_2618)
+static int FsOpGetSb(struct file_system_type *fsType, int flags,
+                     const char *devName, void *rawData, struct vfsmount *mnt);
+#   elif LINUX_VERSION_CODE >= KERNEL_VERSION(2, 5, 70)
+static struct super_block *FsOpGetSb(struct file_system_type *fsType, int flags,
+                                     const char *devName, void *rawData);
+#   else
+static struct super_block *FsOpGetSb(struct file_system_type *fsType, int flags,
+                                     char *devName, void *rawData);
+#   endif
+#else /* } { */
+static struct super_block *FsOpReadSuper24(struct super_block *sb, void *rawData,
+                                           int flags);
+#endif /* } */
+static int FsOpReadSuper(struct super_block *sb, void *rawData, int flags);
+
+
+/* Utility */
+static compat_kmem_cache_ctor InodeCacheCtor;
+
+
+/* Variables */
+compat_kmem_cache *VMBlockInodeCache;
+
+/* Local variables */
+static char const *fsRoot;
+static size_t fsRootLen;
+static struct file_system_type fsType = {
+   .owner = THIS_MODULE,
+   .name = VMBLOCK_FS_NAME,
+#if KERNEL_25_FS
+   .get_sb = FsOpGetSb,
+   .kill_sb = kill_anon_super,
+#else
+   .read_super = FsOpReadSuper24,
+#endif
+};
+
+
+/*
+ * Public functions (with respect to the module)
+ */
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VMBlockInitFileSystem --
+ *
+ *    Initializes the file system and registers it with the kernel.
+ *
+ * Results:
+ *    Zero on success, negative error code on failure.
+ *
+ * Side effects:
+ *    None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+int
+VMBlockInitFileSystem(char const *root)  // IN: directory redirecting to
+{
+   int ret;
+
+   if (!root) {
+      Warning("VMBlockInitFileSystem: root not provided "
+              "(missing module parameter?)\n");
+      return -EINVAL;
+   }
+
+   /*
+    * Here we assume that the provided root is valid so the module will load.
+    * The mount operation will fail if that is not the case.
+    */
+   fsRoot = root;
+   fsRootLen = strlen(fsRoot);
+
+   if (fsRootLen >= PATH_MAX) {
+      return -ENAMETOOLONG;
+   }
+
+   /* Initialize our inode slab allocator */
+   VMBlockInodeCache = os_kmem_cache_create("VMBlockInodeCache",
+                                            sizeof (VMBlockInodeInfo),
+                                            0,
+                                            InodeCacheCtor);
+   if (!VMBlockInodeCache) {
+      Warning("VMBlockInitFileSystem: could not initialize inode cache\n");
+      return -ENOMEM;
+   }
+
+   /* Tell the kernel about our file system */
+   ret = register_filesystem(&fsType);
+   if (ret < 0) {
+      Warning("VMBlockInitFileSystem: could not initialize file system\n");
+      kmem_cache_destroy(VMBlockInodeCache);
+      return ret;
+   }
+
+   LOG(4, "file system registered with root of [%s]\n", fsRoot);
+
+   return 0;
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VMBlockCleanupFileSystem --
+ *
+ *    Cleans up file system and unregisters it with the kernel.
+ *
+ * Results:
+ *    Zero on success, negative error code on failure.
+ *
+ * Side effects:
+ *    None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+int
+VMBlockCleanupFileSystem(void)
+{
+   int ret;
+
+   kmem_cache_destroy(VMBlockInodeCache);
+
+   ret = unregister_filesystem(&fsType);
+   if (ret < 0) {
+      Warning("VMBlockCleanupFileSystem: could not unregister file system\n");
+      return ret;
+   }
+
+   return 0;
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ *  VMBlockReadInode --
+ *
+ *    A filesystem wide function that is called to initialize a new inode.
+ *    This is called from two different places depending on the kernel version.
+ *    In older kernels that provide the iget() interface, this function is
+ *    called by the kernel as part of inode initialization (from
+ *    SuperOpReadInode). In newer kernels that call iget_locked(), this
+ *    function is called by filesystem code to initialize the new inode.
+ *
+ * Results:
+ *    None.
+ *
+ * Side effects:
+ *    None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+void
+VMBlockReadInode(struct inode *inode)  // IN: Inode to initialize
+{
+   VMBlockInodeInfo *iinfo = INODE_TO_IINFO(inode);
+
+   iinfo->name[0] = '\0';
+   iinfo->nameLen = 0;
+   iinfo->actualDentry = NULL;
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * GetNextIno --
+ *
+ *    Gets the next available inode number.
+ *
+ * Results:
+ *    The next available inode number.
+ *
+ * Side effects:
+ *    None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+ino_t
+GetNextIno(void)
+{
+   static spinlock_t inoLock = SPIN_LOCK_UNLOCKED;
+   static ino_t nextIno = VMBLOCK_ROOT_INO + 1;
+   ino_t ret;
+
+   /* Too bad atomic_t's don't provide an atomic increment and read ... */
+   spin_lock(&inoLock);
+   ret = nextIno++;
+   spin_unlock(&inoLock);
+
+   return ret;
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * GetInode --
+ *
+ *    This function replaces iget() and should be called instead of it. In newer
+ *    kernels that have removed the iget() interface,  GetInode() obtains an inode
+ *    and if it is a new one, then initializes the inode by calling
+ *    VMBlockReadInode(). In older kernels that support the iget() interface,
+ *    VMBlockReadInode() is called by iget() internally by the superblock function
+ *    SuperOpReadInode.
+ *
+ * Results:
+ *    A new inode object on success, NULL on error.
+ *
+ * Side effects:
+ *    None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+static struct inode *
+GetInode(struct super_block *sb, // IN: file system superblock object
+	 ino_t ino)              // IN: inode number to assign to new inode
+{
+#ifdef VMW_USE_IGET_LOCKED
+   struct inode *inode;
+
+   inode = iget_locked(sb, ino);
+   if (!inode) {
+      return NULL;
+   } else if (inode->i_state & I_NEW) {
+      VMBlockReadInode(inode);
+      unlock_new_inode(inode);
+   }
+   return inode;
+#else
+   return iget(sb, ino);
+#endif
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * Iget --
+ *
+ *    Lookup or create a new inode.
+ *
+ *    Inode creation in detail:
+ *    Throughout the file system, we call the VFS iget() function to get a new
+ *    inode.  This in turn invokes our file system's SuperOpAllocInode()
+ *    function, which allocates an inode info structure (VMBlockInodeInfo)
+ *    using the kernel's slab allocator.  When a new slab is created, each
+ *    object is initialized with the constructor (InodeCacheCtor()), but that
+ *    occurs only once per struct (e.g., when a struct from a slab is freed and
+ *    reused, the constructor is not invoked again).  SuperOpAllocInode() then
+ *    returns the address of the inode struct that is embedded within the inode
+ *    info we have allocated.  iget() also invokes our SuperOpReadInode()
+ *    function to do any further file system wide initialization to the inode,
+ *    then returns the inode to us (this function).
+ *
+ *    Note that in older kernels that don't have the alloc_inode operation
+ *    (where VMW_EMBED_INODE is undefined), the allocation is delayed until
+ *    this function and is contained within the INODE_TO_IINFO macro.  That
+ *    allocation is freed in the SuperOpClearInode() function.
+ *
+ *    This function then constructs the full path of the actual file name and
+ *    does a path_lookup() to see if it exists.  If it does, we save a pointer
+ *    to the actual dentry within our inode info for future use.  If it
+ *    doesn't, we still provide an inode but indicate that it doesn't exist by
+ *    setting the actual dentry to NULL.  Callers that need to handle this case
+ *    differently check for the existence of the actual dentry (and actual
+ *    inode) to ensure the actual file exists.
+ *
+ * Results:
+ *    A new inode object on success, NULL on error.
+ *
+ * Side effects:
+ *    A path lookup is done for the actual file.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+struct inode *
+Iget(struct super_block *sb,    // IN: file system superblock object
+     struct inode *dir,         // IN: containing directory
+     struct dentry *dentry,     // IN: dentry within directory
+     ino_t ino)                 // IN: inode number to assign to new inode
+{
+   VMBlockInodeInfo *iinfo;
+   struct inode *inode;
+   struct nameidata actualNd;
+
+   ASSERT(sb);
+
+   inode = GetInode(sb, ino);
+   if (!inode) {
+      return NULL;
+   }
+
+   iinfo = INODE_TO_IINFO(inode);
+   if (!iinfo) {
+      Warning("Iget: invalid inode provided, or unable to allocate inode info\n");
+      goto error_inode;
+   }
+
+   /* Populate iinfo->name with the full path of the target file */
+   if (MakeFullName(dir, dentry, iinfo->name, sizeof iinfo->name) < 0) {
+      Warning("Iget: could not make full name\n");
+      goto error_inode;
+   }
+
+   if (compat_path_lookup(iinfo->name, 0, &actualNd)) {
+      /*
+       * This file does not exist, so we create an inode that doesn't know
+       * about its underlying file.  Operations that create files and
+       * directories need an inode to operate on even if there is no actual
+       * file yet.
+       */
+      iinfo->actualDentry = NULL;
+      return inode;
+   }
+
+   iinfo->actualDentry = compat_vmw_nd_to_dentry(actualNd);
+   compat_path_release(&actualNd);
+
+   return inode;
+
+error_inode:
+   iput(inode);
+   return NULL;
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * InodeCacheCtor --
+ *
+ *    The constructor for inode info structs that occurs once at slab
+ *    allocation.  That is, this is called once for each piece of memory that
+ *    is used to satisfy inode info allocations; it should only be used to
+ *    initialized items that will naturally return to their initialized state
+ *    before deallocation (such as locks, list_heads).
+ *
+ *    We only invoke the inode's initialization routine since all of the inode
+ *    info members need to be initialized on each allocation (in
+ *    SuperOpReadInode()).
+ *
+ * Results:
+ *    None.
+ *
+ * Side effects:
+ *    None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+static void
+InodeCacheCtor(COMPAT_KMEM_CACHE_CTOR_ARGS(slabElem))  // IN: allocated slab item to initialize
+{
+#ifdef VMW_EMBED_INODE
+   VMBlockInodeInfo *iinfo = slabElem;
+
+   inode_init_once(&iinfo->inode);
+#endif
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * MakeFullName --
+ *
+ *    Constructs the full filename from the provided directory and a dentry
+ *    contained within it.
+ *
+ * Results:
+ *    Zero on success, negative error code on failure.
+ *
+ * Side effects:
+ *    None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+int
+MakeFullName(struct inode *dir,       // IN : directory
+             struct dentry *dentry,   // IN : dentry in that directory
+             char *bufOut,            // OUT: output buffer
+             size_t bufOutSize)       // IN : size of output buffer
+{
+   ASSERT(bufOut);
+
+   /*
+    * If dir is supplied, contruct the full path of the actual file, otherwise
+    * it's the root directory.
+    */
+   if (dir == NULL) {
+      if (fsRootLen >= bufOutSize) {
+         Warning("MakeFullName: root path was too long.\n");
+         return -ENAMETOOLONG;
+      }
+      memcpy(bufOut, fsRoot, fsRootLen);
+      bufOut[fsRootLen] = '\0';
+   } else {
+      VMBlockInodeInfo *dirIinfo;
+
+      ASSERT(dir);
+      ASSERT(dentry);
+
+      if (!dentry->d_name.name) {
+         Warning("MakeFullName: dentry name is empty\n");
+         return -EINVAL;
+      }
+
+      dirIinfo = INODE_TO_IINFO(dir);
+      /*
+       * If dirIinfo->name[1] is '\0', then it is "/" and we don't need
+       * another '/' between it and the additional name.
+       */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 4, 10)
+      {
+         int ret;
+
+         ret = snprintf(bufOut, bufOutSize,
+                        dirIinfo->name[1] == '\0' ? "%s%s" : "%s/%s",
+                        dirIinfo->name, dentry->d_name.name);
+         if (ret >= bufOutSize) {
+            Warning("MakeFullName: path was too long.\n");
+            return -ENAMETOOLONG;
+         }
+      }
+#else
+      {
+         /* snprintf was not exported prior to 2.4.10 */
+         size_t dirLen;
+         size_t pathSepLen;
+         size_t dentryLen;
+         size_t pathLen;
+
+         dirLen = strlen(dirIinfo->name);
+         pathSepLen = dirLen == 1 ? 0 : 1;
+         dentryLen = strlen(dentry->d_name.name);
+         pathLen = dirLen + dentryLen + pathSepLen;
+         if (pathLen >= bufOutSize) {
+            Warning("MakeFullName: path was too long.\n");
+            return -ENAMETOOLONG;
+         }
+         memcpy(bufOut, dirIinfo->name, dirLen);
+         if (pathSepLen == 1) {
+            ASSERT(dirLen == 1);
+            bufOut[dirLen] = '/';
+         }
+         memcpy(bufOut + dirLen + pathSepLen, dentry->d_name.name, dentryLen);
+         bufOut[pathLen] = '\0';
+      }
+#endif
+   }
+
+   return 0;
+}
+
+
+/* File system operations */
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * FsOpReadSuper --
+ *
+ *    The main entry point of the filesystem side of the driver. Called when
+ *    a userland process does a mount(2) of an hgfs filesystem. This makes the
+ *    whole driver transition from its initial state to state 1. Fill the
+ *    content of the uninitialized superblock provided by the kernel.
+ *
+ *    'rawData' is a pointer (that can be NULL) to a kernel buffer (whose
+ *    size is <= PAGE_SIZE) that corresponds to the filesystem-specific 'data'
+ *    argument passed to mount(2).
+ *
+ * Results:
+ *    zero and initialized superblock on success
+ *    negative value on failure
+ *
+ * Side effects:
+ *    None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static int
+FsOpReadSuper(struct super_block *sb, // OUT: Superblock object
+              void *rawData,          // IN: Fs-specific mount data
+              int flags)              // IN: Mount flags
+{
+   struct inode *rootInode;
+   struct dentry *rootDentry;
+
+   if (!sb) {
+      Warning("FsOpReadSuper: invalid arg from kernel\n");
+      return -EINVAL;
+   }
+
+   sb->s_magic = VMBLOCK_SUPER_MAGIC;
+   sb->s_blocksize = 1024;
+   sb->s_op = &VMBlockSuperOps;
+
+   /*
+    * Make root inode and dentry.  Ensure that the directory we are redirecting
+    * to has an actual dentry and inode, and that it is in fact a directory.
+    */
+   rootInode = GetRootInode(sb);
+   if (!rootInode) {
+      return -EINVAL;
+   }
+
+   if (!INODE_TO_IINFO(rootInode) ||
+       !INODE_TO_ACTUALDENTRY(rootInode) ||
+       !INODE_TO_ACTUALINODE(rootInode) ||
+       !S_ISDIR(INODE_TO_ACTUALINODE(rootInode)->i_mode)) {
+      iput(rootInode);
+      return -EINVAL;
+   }
+
+   rootDentry = d_alloc_root(rootInode);
+   if (!rootDentry) {
+      iput(rootInode);
+      return -ENOMEM;
+   }
+   sb->s_root = rootDentry;
+
+   rootInode->i_op = &RootInodeOps;
+   rootInode->i_fop = &RootFileOps;
+   rootInode->i_mode = S_IFDIR | S_IRUGO | S_IXUGO;
+
+   LOG(4, "%s file system mounted\n", VMBLOCK_FS_NAME);
+   return 0;
+}
+
+
+#if KERNEL_25_FS /* { */
+#if defined(VMW_GETSB_2618)
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * FsOpGetSb --
+ *
+ *    Invokes generic kernel code to prepare superblock for
+ *    deviceless filesystem.
+ *
+ * Results:
+ *    0 on success
+ *    negative error code on failure
+ *
+ * Side effects:
+ *    None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static int
+FsOpGetSb(struct file_system_type *fs_type, // IN: file system type of mount
+          int flags,                        // IN: mount flags
+          const char *dev_name,             // IN: device mounting on
+          void *rawData,                    // IN: mount arguments
+          struct vfsmount *mnt)             // IN: vfs mount
+{
+   return get_sb_nodev(fs_type, flags, rawData, FsOpReadSuper, mnt);
+}
+#else
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * FsOpGetSb --
+ *
+ *    Invokes generic kernel code to prepare superblock for
+ *    deviceless filesystem.
+ *
+ * Results:
+ *    The initialized superblock on success
+ *    NULL on failure
+ *
+ * Side effects:
+ *    None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 5, 70)
+static struct super_block *
+FsOpGetSb(struct file_system_type *fs_type, // IN: file system type of mount
+          int flags,                        // IN: mount flags
+          const char *dev_name,             // IN: device mounting on
+          void *rawData)                    // IN: mount arguments
+#else
+static struct super_block *
+FsOpGetSb(struct file_system_type *fs_type, // IN: file system type of mount
+          int flags,                        // IN: mount flags
+          char *dev_name,                   // IN: device mounting on
+          void *rawData)                    // IN: mount arguments
+#endif
+{
+   return get_sb_nodev(fs_type, flags, rawData, FsOpReadSuper);
+}
+#endif
+#else /* } { */
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * FsOpReadSuper24 --
+ *
+ *    Compatibility wrapper for 2.4.x kernels read_super.
+ *    Converts success to sb, and failure to NULL.
+ *
+ * Results:
+ *    The initialized superblock on success
+ *    NULL on failure
+ *
+ * Side effects:
+ *    None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static struct super_block *
+FsOpReadSuper24(struct super_block *sb,  // OUT: Superblock object
+                void *rawData,           // IN : mount arguments
+                int flags)               // IN : mount flags
+{
+   return FsOpReadSuper(sb, rawData, flags) ? NULL : sb;
+}
+#endif /* } */
--- kernel/linux-2.6.26.3/fs/vmblock/filesystem.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmblock/filesystem.h	2008-09-03 09:57:35.000000000 -0500
@@ -0,0 +1,111 @@
+/*********************************************************
+ * Copyright (C) 2006 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * filesystem.h --
+ *
+ *  Definitions and prototypes for file system portion of vmblock driver.
+ *
+ *  There are currently two classes of files in the blocking file system: the
+ *  root directory and symlinks to actual files on the file system.  The root
+ *  directory provides a way to lookup directory entries in the directory we
+ *  are redirecting to; each of these directory entries is presented as
+ *  a symlink.  These symlinks within the root directory contain the path of
+ *  the actual file and will block any time the inode is accessed or dentry is
+ *  revalidated (if there is a pending block).  This blocking ensures that any
+ *  access to the file through the symlink will not proceed until the block is
+ *  lifted.
+ *
+ *  Operation tables for the root directory and symlinks are are named Root*Ops
+ *  and Link*Ops respectively.  All operations are preceded by their operation
+ *  type (e.g., the file_operation table's open is named FileOpOpen and the
+ *  inode_operation table's lookup is named InodeOpLookup).
+ *
+ *  The use of symlinks greatly simplifies the driver's implementation but also
+ *  limits blocking to a depth of one level within the redirected directory
+ *  (since after the symlink is followed all operations are passed on to the
+ *  actual file system and are out of our control).  This limitation is fine
+ *  under the current use of this driver.
+ */
+
+#ifndef __FILESYSTEM_H__
+#define __FILESYSTEM_H__
+
+#include "compat_slab.h"
+#include "compat_fs.h"
+
+#include "vm_basic_types.h"
+
+#ifndef container_of
+#define container_of(ptr, type, memb)   ((type *)((char *)(ptr) - offsetof(type, memb)))
+#endif
+
+#ifdef VMW_EMBED_INODE
+# define INODE_SET_IINFO(inode, iinfo)
+# define INODE_TO_IINFO(_inode)         container_of(_inode, VMBlockInodeInfo, inode)
+#else
+# define INODE_SET_IINFO(inode, iinfo)  (inode)->u.generic_ip = iinfo
+# define INODE_TO_IINFO(_inode)                                              \
+         ({                                                                  \
+            /* Allocate an inode info for new inodes */                      \
+            if ((_inode)->u.generic_ip == NULL) {                            \
+               VMBlockInodeInfo *_iinfo;                                     \
+               ASSERT(VMBlockInodeCache);                                    \
+               _iinfo = kmem_cache_alloc(VMBlockInodeCache, SLAB_KERNEL);    \
+               /* We must set the inode info for new inodes */               \
+               INODE_SET_IINFO(_inode, _iinfo);                              \
+            }                                                                \
+            ((VMBlockInodeInfo *)((_inode)->u.generic_ip));                  \
+         })
+#endif
+
+#define INODE_TO_ACTUALDENTRY(inode)    INODE_TO_IINFO(inode)->actualDentry
+#define INODE_TO_ACTUALINODE(inode)     INODE_TO_IINFO(inode)->actualDentry->d_inode
+
+#define VMBLOCK_SUPER_MAGIC 0xabababab
+
+typedef struct VMBlockInodeInfo {
+   char name[PATH_MAX];
+   size_t nameLen;
+   struct dentry *actualDentry;
+#ifdef VMW_EMBED_INODE
+   /* Embedded inode */
+   struct inode inode;
+#endif
+} VMBlockInodeInfo;
+
+
+ino_t GetNextIno(void);
+struct inode *Iget(struct super_block *sb, struct inode *dir,
+                   struct dentry *dentry, ino_t ino);
+int MakeFullName(struct inode *dir, struct dentry *dentry,
+                  char *bufOut, size_t bufOutSize);
+void VMBlockReadInode(struct inode *inode);
+
+/* Variables */
+extern compat_kmem_cache *VMBlockInodeCache;
+/* File system wide superblock operations */
+extern struct super_operations VMBlockSuperOps;
+/* File operations on fs's root inode to read directory entries. */
+extern struct file_operations RootFileOps;
+/* Inode operations to lookup inodes of directory entries in fs's root inode. */
+extern struct inode_operations RootInodeOps;
+/* Dentry operations for our symlinks to actual files (to enable blocking). */
+extern struct dentry_operations LinkDentryOps;
+
+#endif /* __FILESYSTEM_H__ */
--- kernel/linux-2.6.26.3/fs/vmblock/inode.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmblock/inode.c	2008-09-03 09:58:40.000000000 -0500
@@ -0,0 +1,244 @@
+/*********************************************************
+ * Copyright (C) 2006 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * inode.c --
+ *
+ *   Inode operations for the file system of the vmblock driver.
+ *
+ */
+
+#include "driver-config.h"
+#include <linux/module.h>
+#include "compat_fs.h"
+#include <linux/time.h>
+#include "compat_namei.h"
+#include "compat_uaccess.h"
+#include "compat_sched.h"
+
+#include "vmblockInt.h"
+#include "filesystem.h"
+#include "block.h"
+
+
+/* Inode operations */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 5, 75)
+static struct dentry *InodeOpLookup(struct inode *dir,
+                                    struct dentry *dentry, struct nameidata *nd);
+#else
+static struct dentry *InodeOpLookup(struct inode *dir, struct dentry *dentry);
+#endif
+static int InodeOpReadlink(struct dentry *dentry, char __user *buffer, int buflen);
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 13)
+static void *InodeOpFollowlink(struct dentry *dentry, struct nameidata *nd);
+#else
+static int InodeOpFollowlink(struct dentry *dentry, struct nameidata *nd);
+#endif
+
+
+struct inode_operations RootInodeOps = {
+   .lookup = InodeOpLookup,
+};
+
+static struct inode_operations LinkInodeOps = {
+   .readlink    = InodeOpReadlink,
+   .follow_link = InodeOpFollowlink,
+};
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * InodeOpLookup --
+ *
+ *    Looks up a name (dentry) in provided directory.  Invoked every time
+ *    a directory entry is traversed in path lookups.
+ *
+ * Results:
+ *    NULL on success, negative error code on error.
+ *
+ * Side effects:
+ *    None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 5, 75)
+static struct dentry *
+InodeOpLookup(struct inode *dir,      // IN: parent directory's inode
+              struct dentry *dentry,  // IN: dentry to lookup
+              struct nameidata *nd)   // IN: lookup intent and information
+#else
+static struct dentry *
+InodeOpLookup(struct inode *dir,      // IN: parent directory's inode
+              struct dentry *dentry)  // IN: dentry to lookup
+#endif
+{
+   char *filename;
+   struct inode *inode;
+   int ret;
+
+   if (!dir || !dentry) {
+      Warning("InodeOpLookup: invalid args from kernel\n");
+      return ERR_PTR(-EINVAL);
+   }
+
+   /* The kernel should only pass us our own inodes, but check just to be safe. */
+   if (!INODE_TO_IINFO(dir)) {
+      Warning("InodeOpLookup: invalid inode provided\n");
+      return ERR_PTR(-EINVAL);
+   }
+
+   /* Get a slab from the kernel's names_cache of PATH_MAX-sized buffers. */
+   filename = compat___getname();
+   if (!filename) {
+      Warning("InodeOpLookup: unable to obtain memory for filename.\n");
+      return ERR_PTR(-ENOMEM);
+   }
+
+   ret = MakeFullName(dir, dentry, filename, PATH_MAX);
+   if (ret < 0) {
+      Warning("InodeOpLookup: could not construct full name\n");
+      compat___putname(filename);
+      return ERR_PTR(ret);
+   }
+
+   /* Block if there is a pending block on this file */
+   BlockWaitOnFile(filename, NULL);
+   compat___putname(filename);
+
+   inode = Iget(dir->i_sb, dir, dentry, GetNextIno());
+   if (!inode) {
+      Warning("InodeOpLookup: failed to get inode\n");
+      return ERR_PTR(-ENOMEM);
+   }
+
+   dentry->d_op = &LinkDentryOps;
+   dentry->d_time = jiffies;
+
+   /*
+    * If the actual file's dentry doesn't have an inode, it means the file we
+    * are redirecting to doesn't exist.  Give back the inode that was created
+    * for this and add a NULL dentry->inode entry in the dcache.  (The NULL
+    * entry is added so ops to create files/directories are invoked by VFS.)
+    */
+   if (!INODE_TO_ACTUALDENTRY(inode) || !INODE_TO_ACTUALINODE(inode)) {
+      iput(inode);
+      d_add(dentry, NULL);
+      return NULL;
+   }
+
+   inode->i_mode = S_IFLNK | S_IRWXUGO;
+   inode->i_size = INODE_TO_IINFO(inode)->nameLen;
+   inode->i_version = 1;
+   inode->i_atime = inode->i_mtime = inode->i_ctime = CURRENT_TIME;
+   inode->i_uid = inode->i_gid = 0;
+   inode->i_op = &LinkInodeOps;
+
+   d_add(dentry, inode);
+   return NULL;
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * InodeOpReadlink --
+ *
+ *    Provides the symbolic link's contents to the user.  Invoked when
+ *    readlink(2) is invoked on our symlinks.
+ *
+ * Results:
+ *    0 on success, negative error code on failure.
+ *
+ * Side effects:
+ *    None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+static int
+InodeOpReadlink(struct dentry *dentry,  // IN : dentry of symlink
+                char __user *buffer,    // OUT: output buffer (user space)
+                int buflen)             // IN : length of output buffer
+{
+   VMBlockInodeInfo *iinfo;
+
+   if (!dentry || !buffer) {
+      Warning("InodeOpReadlink: invalid args from kernel\n");
+      return -EINVAL;
+   }
+
+   iinfo = INODE_TO_IINFO(dentry->d_inode);
+   if (!iinfo) {
+      return -EINVAL;
+   }
+
+   return vfs_readlink(dentry, buffer, buflen, iinfo->name);
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * InodeOpFollowlink --
+ *
+ *    Provides the inode corresponding to this symlink through the nameidata
+ *    structure.
+ *
+ * Results:
+ *    0 on success, negative error on failure.
+ *
+ * Side effects:
+ *    None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 13)
+static void *
+#else
+static int
+#endif
+InodeOpFollowlink(struct dentry *dentry,  // IN : dentry of symlink
+                  struct nameidata *nd)   // OUT: stores result
+{
+   int ret;
+   VMBlockInodeInfo *iinfo;
+
+   if (!dentry) {
+      Warning("InodeOpReadlink: invalid args from kernel\n");
+      ret = -EINVAL;
+      goto out;
+   }
+
+   iinfo = INODE_TO_IINFO(dentry->d_inode);
+   if (!iinfo) {
+      ret = -EINVAL;
+      goto out;
+   }
+
+   ret = vfs_follow_link(nd, iinfo->name);
+
+out:
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 13)
+   return ERR_PTR(ret);
+#else
+   return ret;
+#endif
+}
--- kernel/linux-2.6.26.3/fs/vmblock/Makefile	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmblock/Makefile	2008-09-03 09:57:35.000000000 -0500
@@ -0,0 +1,28 @@
+#############################################################
+# Copyright 2006 VMware, Inc.  All rights reserved. 
+#############################################################
+####
+#### This program is free software; you can redistribute it and/or modify it
+#### under the terms of the GNU General Public License as published by the
+#### Free Software Foundation version 2 and no later version.
+####
+#### This program is distributed in the hope that it will be useful, but
+#### WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+#### or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+#### for more details.
+####
+#### You should have received a copy of the GNU General Public License along
+#### with this program; if not, write to the Free Software Foundation, Inc.,
+#### 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+
+####
+####  VMware vmblock Makefile to be distributed externally
+####
+####
+
+obj-m += vmblock.o
+
+vmblock-objs := block.o control.o dbllnklst.o dentry.o file.o filesystem.o inode.o module.o stubs.o super.o
+
+EXTRA_CFLAGS += -DVMW_USING_KBUILD -DVMW_HAVE_SET_USER_NICE -DVMW_HAVE_EPOLL
+EXTRA_CFLAGS += -DVMW_GETSB_2618 -DVMW_STATFS_2618 -DVMW_FILLDIR_2618
--- kernel/linux-2.6.26.3/fs/vmblock/module.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmblock/module.c	2008-09-03 09:58:40.000000000 -0500
@@ -0,0 +1,175 @@
+/*********************************************************
+ * Copyright (C) 2006 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * module.c --
+ *
+ *   Module loading/unloading functions.
+ *
+ */
+
+#include "driver-config.h"
+#include "compat_init.h"
+#include "compat_kernel.h"
+#include "compat_module.h"
+#include <linux/limits.h>
+#include <linux/errno.h>
+#include "compat_string.h"
+
+#include "vmblockInt.h"
+#include "vmblock_version.h"
+
+/* Module parameters */
+#ifdef VMX86_DEVEL /* { */
+int LOGLEVEL_THRESHOLD = 4;
+#  if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 9)
+   module_param(LOGLEVEL_THRESHOLD, int, 0600);
+#  else
+   MODULE_PARM(LOGLEVEL_THRESHOLD, "i");
+#  endif
+MODULE_PARM_DESC(LOGLEVEL_THRESHOLD, "Logging level (0 means no log, "
+                 "10 means very verbose, 4 is default)");
+#endif /* } */
+
+static char *root = "/tmp/VMwareDnD";
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 9)
+module_param(root, charp, 0600);
+#else
+MODULE_PARM(root, "s");
+#endif
+MODULE_PARM_DESC(root, "The directory the file system redirects to.");
+
+/* Module information */
+MODULE_AUTHOR("VMware, Inc.");
+MODULE_DESCRIPTION("VMware Blocking File System");
+MODULE_LICENSE("GPL v2");
+MODULE_VERSION(VMBLOCK_DRIVER_VERSION_STRING);
+
+/* Functions */
+static int VMBlockInit(void);
+static void VMBlockExit(void);
+
+/* Define init/exit routines */
+module_init(VMBlockInit);
+module_exit(VMBlockExit);
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VMBlockInit --
+ *
+ *    Module entry point and initialization.
+ *
+ * Results:
+ *    Zero on success, negative value on failure.
+ *
+ * Side effects:
+ *    /proc entries are available and file system is registered with kernel and
+ *    ready to be mounted.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+static int
+VMBlockInit(void)
+{
+   int ret;
+
+   ret = VMBlockInitControlOps();
+   if (ret < 0) {
+      goto error;
+   }
+
+   ret = VMBlockInitFileSystem(root);
+   if (ret < 0) {
+      VMBlockCleanupControlOps();
+      goto error;
+   }
+
+   LOG(4, "module loaded\n");
+   return 0;
+
+error:
+   Warning("VMBlock: could not initialize module\n");
+   return ret;
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * VMBlockExit --
+ *
+ *    Unloads module from kernel and removes associated state.
+ *
+ * Results:
+ *    None.
+ *
+ * Side effects:
+ *    Opposite of VMBlockInit(): /proc entries go away and file system is
+ *    unregistered.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+static void
+VMBlockExit(void)
+{
+   VMBlockCleanupControlOps();
+   VMBlockCleanupFileSystem();
+
+   LOG(4, "module unloaded\n");
+}
+
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 70)
+/*
+ *----------------------------------------------------------------------------
+ *
+ * strlcpy --
+ *
+ *    2.4 doesn't have strlcpy().
+ *
+ *    Copies at most count - 1 bytes from src to dest, and ensures dest is NUL
+ *    terminated.
+ *
+ * Results:
+ *    Length of src.  If src >= count, src was truncated in copy.
+ *
+ * Side effects:
+ *    None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+size_t
+strlcpy(char *dest,         // OUT: destination to copy string to
+        const char *src,    // IN : source to copy string from
+        size_t count)       // IN : size of destination buffer
+{
+   size_t ret;
+   size_t len;
+
+   ret = strlen(src);
+   len = ret >= count ? count - 1 : ret;
+   memcpy(dest, src, len);
+   dest[len] = '\0';
+   return ret;
+}
+#endif
--- kernel/linux-2.6.26.3/fs/vmblock/os.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmblock/os.h	2008-09-03 09:57:35.000000000 -0500
@@ -0,0 +1,117 @@
+/*********************************************************
+ * Copyright (C) 2007 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+
+/*
+ * os.h --
+ *
+ *      OS-specific definitions.
+ */
+
+
+#ifndef __OS_H__
+#define __OS_H__
+
+#include "driver-config.h"
+#include "compat_list.h"
+#include "compat_completion.h"
+#include <linux/limits.h>
+#include "compat_slab.h"
+#include "compat_wait.h"
+#include <asm/atomic.h>
+#include <asm/errno.h>
+#include "compat_sched.h"
+#include <asm/current.h>
+#include "compat_kernel.h"
+#include "compat_spinlock.h"
+
+typedef rwlock_t os_rwlock_t;
+typedef compat_kmem_cache os_kmem_cache_t;
+typedef compat_completion os_completion_t;
+typedef atomic_t os_atomic_t;
+typedef struct file * os_blocker_id_t;
+
+#define OS_UNKNOWN_BLOCKER              NULL
+#define OS_ENOMEM                       (-ENOMEM)
+#define OS_ENOENT                       (-ENOENT)
+#define OS_EEXIST                       (-EEXIST)
+#define OS_PATH_MAX                     PATH_MAX
+
+#define OS_FMTTID                       "d"
+#define os_threadid                     (current->pid)
+/*
+ * XXX vprintk() wasn't exported until 2.6.9; we should do something more
+ * intelligent here eventually.
+ */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 9)
+# define os_panic(fmt, args)             \
+      ({                                 \
+          vprintk(fmt, args);            \
+          BUG();                         \
+      })
+#else
+# define os_panic(fmt, args)             \
+      ({                                 \
+          BUG();                         \
+      })
+#endif
+
+#define os_rwlock_init(lock)            rwlock_init(lock)
+#define os_rwlock_destroy(lock)
+/*
+ * XXX We'd like to check for kernel version 2.5.34 as the patches indicate,
+ * but SLES10's 2.6.16.21-0.8-i586default doesn't seem to have this defined.
+ */
+#if defined(rwlock_is_locked)
+# define os_rwlock_held(lock)           rwlock_is_locked(lock)
+#else
+/* XXX Is there something we can come up with for this? */
+# define os_rwlock_held(lock)           TRUE
+#endif
+#define os_read_lock(lock)              read_lock(lock)
+#define os_write_lock(lock)             write_lock(lock)
+#define os_read_unlock(lock)            read_unlock(lock)
+#define os_write_unlock(lock)           write_unlock(lock)
+
+#define os_kmem_cache_create(name, size, align, ctor) \
+   compat_kmem_cache_create(name, size, align, SLAB_HWCACHE_ALIGN, ctor)
+#define os_kmem_cache_destroy(cache)    kmem_cache_destroy(cache)
+#define os_kmem_cache_alloc(cache)      kmem_cache_alloc(cache, GFP_KERNEL)
+#define os_kmem_cache_free(cache, elem) kmem_cache_free(cache, elem)
+
+#define os_completion_init(comp)        compat_init_completion(comp)
+#define os_completion_destroy(comp)
+/*
+ * XXX This should be made interruptible using
+ * wait_for_completion_interruptible(), and return a proper value.  Callers
+ * would need to handle interruption, of course.
+ */
+#define os_wait_for_completion(comp)                                    \
+({                                                                      \
+    compat_wait_for_completion(comp);                                   \
+    0;                                                                  \
+ })
+#define os_complete_all(comp)           compat_complete_all(comp)
+
+#define os_atomic_dec_and_test(atomic)  atomic_dec_and_test(atomic)
+#define os_atomic_dec(atomic)           atomic_dec(atomic)
+#define os_atomic_set(atomic, val)      atomic_set(atomic, val)
+#define os_atomic_inc(atomic)           atomic_inc(atomic)
+#define os_atomic_read(atomic)          atomic_read(atomic)
+
+#endif /* __OS_H__ */
--- kernel/linux-2.6.26.3/fs/vmblock/README	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmblock/README	2008-09-03 09:57:35.000000000 -0500
@@ -0,0 +1,17 @@
+This files in this directory and its subdirectories are the kernel module
+for the VMware Blocking File System.  In order to build, make certain the
+Makefile is correct and then just type
+
+	make
+
+from this directory.  A copy of the module will be left in
+
+        driver-<kernel version>/vmblock-<kernel-version>
+
+(e.g. driver-up-2.4.20/vmblock-up-2.4.20) for 2.4 series kernels and in
+
+        ../vmblock.o
+
+for 2.6 series kernels.
+
+If you have any problems or questions, send mail to support@vmware.com
--- kernel/linux-2.6.26.3/fs/vmblock/stubs.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmblock/stubs.c	2008-09-03 09:58:40.000000000 -0500
@@ -0,0 +1,54 @@
+/*********************************************************
+ * Copyright (C) 2007 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+
+/*
+ * stubs.c --
+ *
+ *      Common stubs.
+ */
+
+#include <stdarg.h>
+
+#include "os.h"
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * Panic --
+ *
+ *    Panic implementation.
+ *
+ * Results:
+ *    None.
+ *
+ * Side effects:
+ *    None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+void
+Panic(const char *fmt, ...)
+{
+   va_list args;
+
+   va_start(args, fmt);
+   os_panic(fmt, args);
+   va_end(args);
+}
--- kernel/linux-2.6.26.3/fs/vmblock/stubs.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmblock/stubs.h	2008-09-03 09:57:35.000000000 -0500
@@ -0,0 +1,36 @@
+/*********************************************************
+ * Copyright (C) 2007 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+
+/*
+ * stubs.h --
+ *
+ */
+
+
+#ifndef __STUBS_H__
+#define __STUBS_H__
+
+#ifdef linux
+# include "driver-config.h"
+# include "compat_version.h"
+#endif
+
+void Panic(const char *fmt, ...);
+
+#endif /* __STUBS_H__ */
--- kernel/linux-2.6.26.3/fs/vmblock/super.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmblock/super.c	2008-09-03 09:58:40.000000000 -0500
@@ -0,0 +1,194 @@
+/*********************************************************
+ * Copyright (C) 2006 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * super.c --
+ *
+ *   Super operations for the file system portion of the vmblock driver.
+ *
+ */
+
+#include "driver-config.h"
+#include "compat_fs.h"
+#include "compat_statfs.h"
+
+#include "vmblockInt.h"
+#include "filesystem.h"
+
+/* Super block operations */
+#ifdef VMW_EMBED_INODE
+static struct inode *SuperOpAllocInode(struct super_block *sb);
+static void SuperOpDestroyInode(struct inode *inode);
+#else
+static void SuperOpClearInode(struct inode *inode);
+#endif
+#ifndef VMW_USE_IGET_LOCKED
+static void SuperOpReadInode(struct inode *inode);
+#endif
+#ifdef VMW_STATFS_2618
+static int SuperOpStatfs(struct dentry *dentry, struct compat_kstatfs *stat);
+#else
+static int SuperOpStatfs(struct super_block *sb, struct compat_kstatfs *stat);
+#endif
+
+
+struct super_operations VMBlockSuperOps = {
+#ifdef VMW_EMBED_INODE
+   .alloc_inode   = SuperOpAllocInode,
+   .destroy_inode = SuperOpDestroyInode,
+#else
+   .clear_inode   = SuperOpClearInode,
+#endif
+#ifndef VMW_USE_IGET_LOCKED
+   .read_inode    = SuperOpReadInode,
+#endif
+   .statfs        = SuperOpStatfs,
+};
+
+
+#ifdef VMW_EMBED_INODE
+/*
+ *----------------------------------------------------------------------------
+ *
+ *  SuperOpAllocInode --
+ *
+ *    Allocates an inode info from the cache.  See function comment for Iget()
+ *    for a complete explanation of how inode allocation works.
+ *
+ * Results:
+ *    A pointer to the embedded inode on success, NULL on failure.
+ *
+ * Side effects:
+ *    iinfo is initialized by InodeCacheCtor().
+ *
+ *----------------------------------------------------------------------------
+ */
+
+static struct inode *
+SuperOpAllocInode(struct super_block *sb) // IN: superblock of file system
+{
+   VMBlockInodeInfo *iinfo;
+
+   iinfo = kmem_cache_alloc(VMBlockInodeCache, GFP_KERNEL);
+   if (!iinfo) {
+      Warning("SuperOpAllocInode: could not allocate iinfo\n");
+      return NULL;
+   }
+
+   /* The inode we give back to VFS is embedded within our inode info struct. */
+   return &iinfo->inode;
+}
+#endif
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * SuperOpDestroyInode --
+ * SuperOpClearInode --
+ *
+ *    Destroys the provided inode by freeing the inode info.  In the embedded
+ *    inode case, this includes the actual inode itself; in the non-embedded
+ *    inode case, the inode is freed by the kernel.
+ *
+ * Results:
+ *    None.
+ *
+ * Side effects:
+ *    None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+static void
+#ifdef VMW_EMBED_INODE
+SuperOpDestroyInode(struct inode *inode)  // IN: Inode to free
+#else
+SuperOpClearInode(struct inode *inode)    // IN: Inode to free
+#endif
+{
+   kmem_cache_free(VMBlockInodeCache, INODE_TO_IINFO(inode));
+}
+
+
+#ifndef VMW_USE_IGET_LOCKED
+/*
+ *----------------------------------------------------------------------------
+ *
+ * SuperOpReadInode --
+ *
+ *    Performs any filesystem wide inode initialization. This is only called by
+ *    iget() in older kernels that do not support iget_locked(). Newer kernels
+ *    that use the iget_locked() interface are required to initialize the inode
+ *    after it has been returned to the filesystem.
+ *
+ * Results:
+ *    None.
+ *
+ * Side effects:
+ *    None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+static void
+SuperOpReadInode(struct inode *inode)  // IN: Inode to initialize
+{
+   VMBlockReadInode(inode);
+}
+#endif
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * SuperOpStatfs --
+ *
+ *    Implements a null statfs.
+ *
+ * Results:
+ *    Zero on success, negative error on failure.
+ *
+ * Side effects:
+ *    None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+#ifdef VMW_STATFS_2618
+static int
+SuperOpStatfs(struct dentry *dentry,
+              struct compat_kstatfs *stat)
+#else
+static int
+SuperOpStatfs(struct super_block *sb,
+              struct compat_kstatfs *stat)
+#endif
+{
+   if (!stat) {
+      return -EINVAL;
+   }
+
+   stat->f_type = VMBLOCK_SUPER_MAGIC;
+   stat->f_bsize = 0;
+   stat->f_namelen = NAME_MAX;
+   stat->f_blocks = 0;
+   stat->f_bfree = 0;
+   stat->f_bavail = 0;
+
+   return 0;
+}
--- kernel/linux-2.6.26.3/fs/vmblock/vm_assert.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmblock/vm_assert.h	2008-09-03 10:00:01.000000000 -0500
@@ -0,0 +1,316 @@
+/*********************************************************
+ * Copyright (C) 1998-2004 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * vm_assert.h --
+ *
+ *	The basic assertion facility for all VMware code.
+ *
+ *	For proper use, see
+ *	http://vmweb.vmware.com/~mts/WebSite/guide/programming/asserts.html
+ */
+
+#ifndef _VM_ASSERT_H_
+#define _VM_ASSERT_H_
+
+#define INCLUDE_ALLOW_USERLEVEL
+#define INCLUDE_ALLOW_VMMEXT
+#define INCLUDE_ALLOW_MODULE
+#define INCLUDE_ALLOW_VMMON
+#define INCLUDE_ALLOW_VMNIXMOD
+#define INCLUDE_ALLOW_VMKERNEL
+#define INCLUDE_ALLOW_VMKDRIVERS
+#define INCLUDE_ALLOW_VMK_MODULE
+#define INCLUDE_ALLOW_DISTRIBUTE
+#define INCLUDE_ALLOW_VMCORE
+#define INCLUDE_ALLOW_VMIROM
+
+// XXX not necessary except some places include vm_assert.h improperly
+#include "vm_basic_types.h"
+#include "vm_basic_defs.h"
+
+
+/*
+ * XXX old file code
+ */
+
+#ifdef FILECODEINT
+#error "Don't define FILECODEINT.  It is obsolete."
+#endif
+#ifdef FILECODE
+#error "Don't define FILECODE.  It is obsolete."
+#endif
+
+
+/*
+ * Panic and log functions
+ */
+
+EXTERN void Log(const char *fmt, ...) PRINTF_DECL(1, 2);
+EXTERN void Warning(const char *fmt, ...) PRINTF_DECL(1, 2);
+EXTERN NORETURN void Panic(const char *fmt, ...) PRINTF_DECL(1, 2);
+
+EXTERN void LogThrottled(uint32 *count, const char *fmt, ...)
+            PRINTF_DECL(2, 3);
+EXTERN void WarningThrottled(uint32 *count, const char *fmt, ...)
+            PRINTF_DECL(2, 3);
+
+/* DB family:  messages which are parsed by logfile database system */
+#define WarningDB Warning
+#define LogDB Log
+#define WarningThrottledDB WarningThrottled
+#define LogThrottledDB LogThrottled
+
+
+/*
+ * Stress testing: redefine ASSERT_IFNOT() to taste
+ */
+
+#ifndef ASSERT_IFNOT
+   #ifdef __cplusplus
+      #define ASSERT_IFNOT(cond, panic) (UNLIKELY(!(cond)) ? (panic) : (void)0)
+   #else
+      #define ASSERT_IFNOT(cond, panic) (UNLIKELY(!(cond)) ? (panic) : 0)
+   #endif
+#endif
+
+
+/*
+ * Assert, panic, and log macros
+ *
+ * Some of these are redefined below undef !VMX86_DEBUG.
+ * ASSERT() is special cased because of interaction with Windows DDK.
+ */
+
+#if defined VMX86_DEBUG || defined ASSERT_ALWAYS_AVAILABLE
+#undef ASSERT
+#define ASSERT(cond) \
+           ASSERT_IFNOT(cond, _ASSERT_PANIC(AssertAssert))
+#endif
+#define ASSERT_BUG(bug, cond) \
+           ASSERT_IFNOT(cond, _ASSERT_PANIC_BUG(bug, AssertAssert))
+#define ASSERT_BUG_DEBUGONLY(bug, cond) ASSERT_BUG(bug, cond)
+
+#define PANIC()        _ASSERT_PANIC(AssertPanic)
+#define PANIC_BUG(bug) _ASSERT_PANIC_BUG(bug, AssertPanic)
+
+#define ASSERT_NOT_IMPLEMENTED(cond) \
+           ASSERT_IFNOT(cond, NOT_IMPLEMENTED())
+#define ASSERT_NOT_IMPLEMENTED_BUG(bug, cond) \
+           ASSERT_IFNOT(cond, NOT_IMPLEMENTED_BUG(bug))
+
+#define NOT_IMPLEMENTED()        _ASSERT_PANIC(AssertNotImplemented)
+#define NOT_IMPLEMENTED_BUG(bug) _ASSERT_PANIC_BUG(bug, AssertNotImplemented)
+
+#define NOT_REACHED()            _ASSERT_PANIC(AssertNotReached)
+#define NOT_REACHED_BUG(bug)     _ASSERT_PANIC_BUG(bug, AssertNotReached)
+
+#define ASSERT_MEM_ALLOC(cond) \
+           ASSERT_IFNOT(cond, _ASSERT_PANIC(AssertMemAlloc))
+
+#ifdef VMX86_DEVEL
+   #define ASSERT_LENGTH(real, expected) \
+              ASSERT_IFNOT((real) == (expected), \
+                 Panic(AssertLengthFmt, __FILE__, __LINE__, real, expected))
+#else
+   #define ASSERT_LENGTH(real, expected) ASSERT((real) == (expected))
+#endif
+
+#ifdef VMX86_DEVEL
+   #define ASSERT_DEVEL(cond) ASSERT(cond)
+#else
+   #define ASSERT_DEVEL(cond) ((void) 0)
+#endif
+
+#define ASSERT_NO_INTERRUPTS()  ASSERT(!INTERRUPTS_ENABLED())
+#define ASSERT_HAS_INTERRUPTS() ASSERT(INTERRUPTS_ENABLED())
+
+#define ASSERT_LOG_UNEXPECTED(bug, cond) \
+           (UNLIKELY(!(cond)) ? LOG_UNEXPECTED(bug) : 0)
+#ifdef VMX86_DEVEL
+   #define LOG_UNEXPECTED(bug) \
+              Warning(AssertUnexpectedFmt, __FILE__, __LINE__, bug)
+#else
+   #define LOG_UNEXPECTED(bug) \
+              Log(AssertUnexpectedFmt, __FILE__, __LINE__, bug)
+#endif
+
+#define ASSERT_NOT_TESTED(cond) (UNLIKELY(!(cond)) ? NOT_TESTED() : 0)
+#ifdef VMX86_DEVEL
+   #define NOT_TESTED() Warning(AssertNotTestedFmt, __FILE__, __LINE__)
+#else
+   #define NOT_TESTED() Log(AssertNotTestedFmt, __FILE__, __LINE__)
+#endif
+
+#define NOT_TESTED_ONCE()                                               \
+   do {                                                                 \
+      static Bool alreadyPrinted = FALSE;                               \
+      if (UNLIKELY(!alreadyPrinted)) {                                  \
+	 alreadyPrinted = TRUE;                                         \
+	 NOT_TESTED();                                                  \
+      }                                                                 \
+   } while (0)
+
+#define NOT_TESTED_1024()                                               \
+   do {                                                                 \
+      static uint16 count = 0;                                          \
+      if (UNLIKELY(count == 0)) { NOT_TESTED(); }                       \
+      count = (count + 1) & 1023;                                       \
+   } while (0)
+
+#define LOG_ONCE(_s)                                                    \
+   do {                                                                 \
+      static Bool logged = FALSE;                                       \
+      if (!logged) {                                                    \
+	 Log _s;                                                        \
+         logged = TRUE;                                                 \
+      }                                                                 \
+   } while (0)
+
+
+/*
+ * Redefine macros that are only in debug versions
+ */
+
+#if !defined VMX86_DEBUG && !defined ASSERT_ALWAYS_AVAILABLE // {
+
+#undef  ASSERT
+#define ASSERT(cond) ((void) 0)
+
+#undef  ASSERT_BUG_DEBUGONLY
+#define ASSERT_BUG_DEBUGONLY(bug, cond) ((void) 0)
+
+#undef  ASSERT_LENGTH
+#define ASSERT_LENGTH(real, expected) ((void) 0)
+
+/*
+ * Expand NOT_REACHED() as appropriate for each situation.
+ *
+ * Mainly, we want the compiler to infer the same control-flow
+ * information as it would from Panic().  Otherwise, different
+ * compilation options will lead to different control-flow-derived
+ * errors, causing some make targets to fail while others succeed.
+ *
+ * VC++ has the __assume() built-in function which we don't trust
+ * (see bug 43485); gcc has no such construct; we just panic in
+ * userlevel code.  The monitor doesn't want to pay the size penalty
+ * (measured at 212 bytes for the release vmm for a minimal infinite
+ * loop; panic would cost even more) so it does without and lives
+ * with the inconsistency.
+ */
+
+#ifdef VMM
+#undef  NOT_REACHED
+#define NOT_REACHED() ((void) 0)
+#else
+// keep debug definition
+#endif
+
+#undef  ASSERT_LOG_UNEXPECTED
+#define ASSERT_LOG_UNEXPECTED(bug, cond) ((void) 0)
+
+#undef LOG_UNEXPECTED
+#define LOG_UNEXPECTED(bug) ((void) 0)
+
+#undef  ASSERT_NOT_TESTED
+#define ASSERT_NOT_TESTED(cond) ((void) 0)
+#undef  NOT_TESTED
+#define NOT_TESTED() ((void) 0)
+#undef  NOT_TESTED_ONCE
+#define NOT_TESTED_ONCE() ((void) 0)
+#undef  NOT_TESTED_1024
+#define NOT_TESTED_1024() ((void) 0)
+
+#endif // !VMX86_DEBUG }
+
+
+/*
+ * Compile-time assertions.
+ *
+ * ASSERT_ON_COMPILE does not use the common
+ * switch (0) { case 0: case (e): ; } trick because some compilers (e.g. MSVC)
+ * generate code for it.
+ *
+ * The implementation uses both enum and typedef because the typedef alone is
+ * insufficient; gcc allows arrays to be declared with non-constant expressions
+ * (even in typedefs, where it makes no sense).
+ */
+
+#define ASSERT_ON_COMPILE(e) \
+   do { \
+      enum { AssertOnCompileMisused = ((e) ? 1 : -1) }; \
+      typedef char AssertOnCompileFailed[AssertOnCompileMisused]; \
+   } while (0)
+
+
+/*
+ * To put an ASSERT_ON_COMPILE() outside a function, wrap it
+ * in MY_ASSERTS().  The first parameter must be unique in
+ * each .c file where it appears.  For example,
+ *
+ * MY_ASSERTS(FS3_INT,
+ *    ASSERT_ON_COMPILE(sizeof(FS3_DiskLock) == 128);
+ *    ASSERT_ON_COMPILE(sizeof(FS3_DiskLockReserved) == DISK_BLOCK_SIZE);
+ *    ASSERT_ON_COMPILE(sizeof(FS3_DiskBlock) == DISK_BLOCK_SIZE);
+ *    ASSERT_ON_COMPILE(sizeof(Hardware_DMIUUID) == 16);
+ * )
+ *
+ * Caution: ASSERT() within MY_ASSERTS() is silently ignored.
+ * The same goes for anything else not evaluated at compile time.
+ */
+
+#define MY_ASSERTS(name, assertions) \
+   static INLINE void name(void) { \
+      assertions \
+   }
+
+
+/*
+ * Internal macros, functions, and strings
+ *
+ * The monitor wants to save space at call sites, so it has specialized
+ * functions for each situation.  User level wants to save on implementation
+ * so it uses generic functions.
+ */
+
+#if !defined VMM || defined MONITOR_APP // {
+
+#define _ASSERT_PANIC(name) \
+           Panic(_##name##Fmt "\n", __FILE__, __LINE__)
+#define _ASSERT_PANIC_BUG(bug, name) \
+           Panic(_##name##Fmt " bugNr=%d\n", __FILE__, __LINE__, bug)
+
+#define AssertLengthFmt     _AssertLengthFmt
+#define AssertUnexpectedFmt _AssertUnexpectedFmt
+#define AssertNotTestedFmt  _AssertNotTestedFmt
+
+#endif // }
+
+// these don't have newline so a bug can be tacked on
+#define _AssertPanicFmt            "PANIC %s:%d"
+#define _AssertAssertFmt           "ASSERT %s:%d"
+#define _AssertNotImplementedFmt   "NOT_IMPLEMENTED %s:%d"
+#define _AssertNotReachedFmt       "NOT_REACHED %s:%d"
+#define _AssertMemAllocFmt         "MEM_ALLOC %s:%d"
+
+// these are complete formats with newline
+#define _AssertLengthFmt           "LENGTH %s:%d r=%#x e=%#x\n"
+#define _AssertUnexpectedFmt       "UNEXPECTED %s:%d bugNr=%d\n"
+#define _AssertNotTestedFmt        "NOT_TESTED %s:%d\n"
+
+#endif /* ifndef _VM_ASSERT_H_ */
--- kernel/linux-2.6.26.3/fs/vmblock/vm_basic_defs.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmblock/vm_basic_defs.h	2008-09-03 10:00:12.000000000 -0500
@@ -0,0 +1,605 @@
+/*********************************************************
+ * Copyright (C) 2003 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * vm_basic_defs.h --
+ *
+ *	Standard macros for VMware source code.
+ */
+
+#ifndef _VM_BASIC_DEFS_H_
+#define _VM_BASIC_DEFS_H_
+
+#define INCLUDE_ALLOW_USERLEVEL
+#define INCLUDE_ALLOW_VMMEXT
+#define INCLUDE_ALLOW_MODULE
+#define INCLUDE_ALLOW_VMMON
+#define INCLUDE_ALLOW_VMNIXMOD
+#define INCLUDE_ALLOW_VMKERNEL
+#define INCLUDE_ALLOW_VMKDRIVERS
+#define INCLUDE_ALLOW_VMK_MODULE
+#define INCLUDE_ALLOW_DISTRIBUTE
+#define INCLUDE_ALLOW_VMCORE
+#define INCLUDE_ALLOW_VMIROM
+#include "vm_basic_types.h" // For INLINE.
+
+/* Checks for FreeBSD, filtering out VMKERNEL. */
+#define __IS_FREEBSD__ (!defined(VMKERNEL) && defined(__FreeBSD__))
+#define __IS_FREEBSD_VER__(ver) (__IS_FREEBSD__ && __FreeBSD_version >= (ver))
+
+#if defined _WIN32 && defined USERLEVEL
+   #include <stddef.h>  /*
+                         * We re-define offsetof macro from stddef, make 
+                         * sure that its already defined before we do it
+                         */
+   #include <windows.h>	// for Sleep() and LOWORD() etc.
+#endif
+
+
+/*
+ * Simple macros
+ */
+
+#if (defined __APPLE__ || defined __FreeBSD__) && \
+    (!defined KERNEL && !defined _KERNEL && !defined VMKERNEL && !defined __KERNEL__)
+#   include <stddef.h>
+#else
+// XXX the __cplusplus one matches that of VC++, to prevent redefinition warning
+// XXX the other one matches that of gcc3.3.3/glibc2.2.4 to prevent redefinition warnings
+#ifndef offsetof
+#ifdef __cplusplus
+#define offsetof(s,m)   (size_t)&(((s *)0)->m)
+#else
+#define offsetof(TYPE, MEMBER) ((size_t) &((TYPE *)0)->MEMBER)
+#endif
+#endif
+#endif // __APPLE__
+
+#ifndef ARRAYSIZE
+#define ARRAYSIZE(a) (sizeof (a) / sizeof *(a))
+#endif
+
+#ifndef MIN
+#define MIN(_a, _b)   (((_a) < (_b)) ? (_a) : (_b))
+#endif
+
+/* The Solaris 9 cross-compiler complains about these not being used */
+#ifndef sun
+static INLINE int 
+Min(int a, int b)
+{
+   return a < b ? a : b;
+}
+#endif
+
+#ifndef MAX
+#define MAX(_a, _b)   (((_a) > (_b)) ? (_a) : (_b))
+#endif
+
+#ifndef sun
+static INLINE int 
+Max(int a, int b)
+{
+   return a > b ? a : b;
+}
+#endif
+
+#define ROUNDUP(x,y)		(((x) + (y) - 1) / (y) * (y))
+#define ROUNDDOWN(x,y)		((x) / (y) * (y))
+#define ROUNDUPBITS(x, bits)	(((uintptr_t) (x) + MASK(bits)) & ~MASK(bits))
+#define ROUNDDOWNBITS(x, bits)	((uintptr_t) (x) & ~MASK(bits))
+#define CEILING(x, y)		(((x) + (y) - 1) / (y))
+#if defined __APPLE__
+#include <machine/param.h>
+#undef MASK
+#endif
+#define MASK(n)			((1 << (n)) - 1)	/* make an n-bit mask */
+#define DWORD_ALIGN(x)          ((((x)+3) >> 2) << 2)
+#define QWORD_ALIGN(x)          ((((x)+4) >> 3) << 3)
+
+#define IMPLIES(a,b) (!(a) || (b))
+
+/*
+ * Not everybody (e.g., the monitor) has NULL
+ */
+
+#ifndef NULL
+#ifdef  __cplusplus
+#define NULL    0
+#else
+#define NULL    ((void *)0)
+#endif
+#endif
+
+
+/* 
+ * Token concatenation
+ *
+ * The C preprocessor doesn't prescan arguments when they are
+ * concatenated or stringified.  So we need extra levels of
+ * indirection to convince the preprocessor to expand its
+ * arguments.
+ */
+
+#define CONC(x, y)              x##y
+#define XCONC(x, y)             CONC(x, y)
+#define XXCONC(x, y)            XCONC(x, y)
+#define MAKESTR(x)              #x
+#define XSTR(x)                 MAKESTR(x)
+
+
+/*
+ * Page operations
+ *
+ * It has been suggested that these definitions belong elsewhere
+ * (like x86types.h).  However, I deem them common enough
+ * (since even regular user-level programs may want to do
+ * page-based memory manipulation) to be here.
+ * -- edward
+ */
+
+#ifndef PAGE_SHIFT // {
+#if defined VM_I386
+   #define PAGE_SHIFT    12
+#elif defined __APPLE__
+   #define PAGE_SHIFT    12
+#else
+   #error
+#endif
+#endif // }
+
+#ifndef PAGE_SIZE
+#define PAGE_SIZE     (1<<PAGE_SHIFT)
+#endif
+
+#ifndef PAGE_MASK
+#define PAGE_MASK     (PAGE_SIZE - 1)
+#endif
+
+#ifndef PAGE_OFFSET
+#define PAGE_OFFSET(_addr)  ((uintptr_t)(_addr)&(PAGE_SIZE-1))
+#endif
+
+#ifndef VM_PAGE_BASE
+#define VM_PAGE_BASE(_addr)  ((_addr)&~(PAGE_SIZE-1))
+#endif
+
+#ifndef VM_PAGES_SPANNED
+#define VM_PAGES_SPANNED(_addr, _size) \
+   ((((_addr) & (PAGE_SIZE - 1)) + (_size) + (PAGE_SIZE - 1)) >> PAGE_SHIFT)
+#endif
+
+#ifndef BYTES_2_PAGES
+#define BYTES_2_PAGES(_nbytes) ((_nbytes) >> PAGE_SHIFT)
+#endif
+
+#ifndef PAGES_2_BYTES
+#define PAGES_2_BYTES(_npages) (((uint64)(_npages)) << PAGE_SHIFT)
+#endif
+
+#ifndef MBYTES_2_PAGES
+#define MBYTES_2_PAGES(_nbytes) ((_nbytes) << (20 - PAGE_SHIFT))
+#endif
+
+#ifndef PAGES_2_MBYTES
+#define PAGES_2_MBYTES(_npages) ((_npages) >> (20 - PAGE_SHIFT))
+#endif
+
+#ifndef VM_PAE_LARGE_PAGE_SHIFT
+#define VM_PAE_LARGE_PAGE_SHIFT 21
+#endif 
+
+#ifndef VM_PAE_LARGE_PAGE_SIZE
+#define VM_PAE_LARGE_PAGE_SIZE (1 << VM_PAE_LARGE_PAGE_SHIFT)
+#endif
+
+#ifndef VM_PAE_LARGE_PAGE_MASK
+#define VM_PAE_LARGE_PAGE_MASK (VM_PAE_LARGE_PAGE_SIZE - 1)
+#endif
+
+#ifndef VM_PAE_LARGE_2_SMALL_PAGES
+#define VM_PAE_LARGE_2_SMALL_PAGES (BYTES_2_PAGES(VM_PAE_LARGE_PAGE_SIZE))
+#endif
+
+/*
+ * Word operations
+ */
+
+#ifndef LOWORD
+#define LOWORD(_dw)   ((_dw) & 0xffff)
+#endif
+#ifndef HIWORD
+#define HIWORD(_dw)   (((_dw) >> 16) & 0xffff)
+#endif
+
+#ifndef LOBYTE
+#define LOBYTE(_w)    ((_w) & 0xff)
+#endif
+#ifndef HIBYTE
+#define HIBYTE(_w)    (((_w) >> 8) & 0xff)
+#endif
+
+#define HIDWORD(_qw)   ((uint32)((_qw) >> 32))
+#define LODWORD(_qw)   ((uint32)(_qw))
+#define QWORD(_hi, _lo)   ((((uint64)(_hi)) << 32) | ((uint32)(_lo)))
+
+
+/*
+ * Deposit a field _src at _pos bits from the right,
+ * with a length of _len, into the integer _target.
+ */
+
+#define DEPOSIT_BITS(_src,_pos,_len,_target) { \
+	unsigned mask = ((1 << _len) - 1); \
+	unsigned shiftedmask = ((1 << _len) - 1) << _pos; \
+	_target = (_target & ~shiftedmask) | ((_src & mask) << _pos); \
+}
+
+
+/*
+ * Get return address.
+ */
+
+#ifdef _MSC_VER
+#ifdef __cplusplus
+extern "C"
+#endif 
+void *_ReturnAddress(void);
+#pragma intrinsic(_ReturnAddress)
+#define GetReturnAddress() _ReturnAddress()
+#elif __GNUC__
+#define GetReturnAddress() __builtin_return_address(0)
+#endif
+
+
+#ifdef __GNUC__
+#ifndef sun
+
+/*
+ * Get the frame pointer. We use this assembly hack instead of
+ * __builtin_frame_address() due to a bug introduced in gcc 4.1.1
+ */
+static INLINE_SINGLE_CALLER uintptr_t
+GetFrameAddr(void)
+{
+   uintptr_t bp;
+#if (__GNUC__ < 4 || (__GNUC__ == 4 && __GNUC_MINOR__ == 0))
+   bp = (uintptr_t)__builtin_frame_address(0);
+#elif (__GNUC__ == 4 && __GNUC_MINOR__ == 1 && __GNUC_PATCHLEVEL__ <= 3)
+#  if defined(VMM64) || defined(VM_X86_64)
+     __asm__ __volatile__("movq %%rbp, %0\n" : "=g" (bp));
+#  else
+     __asm__ __volatile__("movl %%ebp, %0\n" : "=g" (bp));
+#  endif
+#else
+   __asm__ __volatile__(
+#ifdef __linux__
+      ".print \"This newer version of GCC may or may not have the "
+               "__builtin_frame_address bug.  Need to update this. "
+               "See bug 147638.\"\n"
+      ".abort"
+#else /* MacOS */
+      ".abort \"This newer version of GCC may or may not have the "
+               "__builtin_frame_address bug.  Need to update this. "
+               "See bug 147638.\"\n"
+#endif
+      : "=g" (bp)
+   );
+#endif
+   return bp;
+}
+
+
+/*
+ * Returns the frame pointer of the calling function.
+ * Equivalent to __builtin_frame_address(1).
+ */
+static INLINE_SINGLE_CALLER uintptr_t
+GetCallerFrameAddr(void)
+{
+   return *(uintptr_t*)GetFrameAddr();
+}
+
+#endif // sun
+#endif // __GNUC__
+
+/*
+ * Data prefetch was added in gcc 3.1.1
+ * http://www.gnu.org/software/gcc/gcc-3.1/changes.html
+ */
+#ifdef __GNUC__
+#  if ((__GNUC__ > 3) || (__GNUC__ == 3 && __GNUC_MINOR__ > 1) || \
+       (__GNUC__ == 3 && __GNUC_MINOR__ == 1 && __GNUC_PATCHLEVEL__ >= 1))
+#     define PREFETCH_R(var) __builtin_prefetch((var), 0 /* read */, \
+                                                3 /* high temporal locality */)
+#     define PREFETCH_W(var) __builtin_prefetch((var), 1 /* write */, \
+                                                3 /* high temporal locality */)
+#  else
+#     define PREFETCH_R(var) ((void)(var))
+#     define PREFETCH_W(var) ((void)(var))
+#  endif
+#endif /* __GNUC__ */
+
+
+#ifdef USERLEVEL // {
+
+/*
+ * Note this might be a problem on NT b/c while sched_yield guarantees it
+ * moves you to the end of your priority list, Sleep(0) offers no such
+ * guarantee.  Bummer.  --Jeremy.
+ */
+
+#if defined(N_PLAT_NLM)
+/* We do not have YIELD() as we do not need it yet... */
+#elif defined(_WIN32)
+#      define YIELD()		Sleep(0)
+#else
+#      include <sched.h>        // For sched_yield.  Don't ask.  --Jeremy.
+#      define YIELD()		sched_yield()
+#endif 
+
+
+/*
+ * Standardize some Posix names on Windows.
+ */
+
+#ifdef _WIN32 // {
+
+#define  snprintf  _snprintf
+#define	vsnprintf _vsnprintf
+
+static INLINE void
+sleep(unsigned int sec)
+{
+   Sleep(sec * 1000);
+}
+
+static INLINE void
+usleep(unsigned long usec)
+{
+   Sleep(CEILING(usec, 1000));
+}
+
+typedef int pid_t;
+#define       F_OK          0
+#define       X_OK          1
+#define       W_OK          2
+#define       R_OK          4
+
+#endif // }
+
+/*
+ * Macro for username comparison.
+ */
+
+#ifdef _WIN32 // {
+#define USERCMP(x,y)  Str_Strcasecmp(x,y)
+#else
+#define USERCMP(x,y)  strcmp(x,y)
+#endif // }
+
+
+#endif // }
+
+#ifndef va_copy
+
+#ifdef _WIN32
+
+/*
+ * Windows needs va_copy. This works for both 32 and 64-bit Windows
+ * based on inspection of how varags.h from the Visual C CRTL is
+ * implemented. (Future versions of the RTL may break this).
+ */
+
+#define va_copy(dest, src) ((dest) = (src))
+
+#elif defined(__APPLE__) && defined(KERNEL)
+
+/*
+ * MacOS kernel-mode needs va_copy. Based on inspection of stdarg.h
+ * from the MacOSX10.4u.sdk kernel framework, this should work.
+ * (Future versions of the SDK may break this).
+ */
+
+#define va_copy(dest, src) ((dest) = (src))
+
+#elif defined(__GNUC__) && (__GNUC__ < 3)
+
+/*
+ * Old versions of gcc recognize __va_copy, but not va_copy.
+ */
+
+#define va_copy(dest, src) __va_copy(dest, src)
+
+#endif // _WIN32
+
+#endif // va_copy
+
+/*
+ * This one is outside USERLEVEL because it's used by
+ * files compiled into the Windows hgfs driver or the display
+ * driver.
+ */
+
+#ifdef _WIN32
+#define PATH_MAX 256
+#ifndef strcasecmp
+#define strcasecmp(_s1,_s2)   _stricmp((_s1),(_s2))
+#endif
+#ifndef strncasecmp
+#define strncasecmp(_s1,_s2,_n)   _strnicmp((_s1),(_s2),(_n))
+#endif
+#endif
+
+/* 
+ * Convenience macro for COMMUNITY_SOURCE
+ */
+#undef EXCLUDE_COMMUNITY_SOURCE
+#ifdef COMMUNITY_SOURCE
+   #define EXCLUDE_COMMUNITY_SOURCE(x) 
+#else
+   #define EXCLUDE_COMMUNITY_SOURCE(x) x
+#endif
+
+#undef COMMUNITY_SOURCE_INTEL_SECRET
+#if !defined(COMMUNITY_SOURCE) || defined(INTEL_SOURCE)
+/*
+ * It's ok to include INTEL_SECRET source code for non-commsrc,
+ * or for drops directed at Intel.
+ */
+   #define COMMUNITY_SOURCE_INTEL_SECRET
+#endif
+
+/*
+ * Convenience macros and definitions. Can often be used instead of #ifdef.
+ */
+
+#undef DEBUG_ONLY
+#undef SL_DEBUG_ONLY
+#undef VMX86_SL_DEBUG
+#ifdef VMX86_DEBUG
+#define vmx86_debug      1
+#define DEBUG_ONLY(x)    x
+/*
+ * Be very, very, very careful with SL_DEBUG. Pls ask ganesh or min before 
+ * using it.
+ */
+#define VMX86_SL_DEBUG
+#define vmx86_sl_debug   1
+#define SL_DEBUG_ONLY(x) x
+#else
+#define vmx86_debug      0
+#define DEBUG_ONLY(x)
+#define vmx86_sl_debug   0
+#define SL_DEBUG_ONLY(x)
+#endif
+
+#ifdef VMX86_STATS
+#define vmx86_stats   1
+#define STATS_ONLY(x) x
+#else
+#define vmx86_stats   0
+#define STATS_ONLY(x)
+#endif
+
+#ifdef VMX86_DEVEL
+#define vmx86_devel   1
+#define DEVEL_ONLY(x) x
+#else
+#define vmx86_devel   0
+#define DEVEL_ONLY(x)
+#endif
+
+#ifdef VMX86_LOG
+#define vmx86_log     1
+#define LOG_ONLY(x)   x
+#else
+#define vmx86_log     0
+#define LOG_ONLY(x)
+#endif
+
+#ifdef VMX86_VMM_SERIAL_LOGGING
+#define vmx86_vmm_serial_log     1
+#define VMM_SERIAL_LOG_ONLY(x)   x
+#else
+#define vmx86_vmm_serial_log     0
+#define VMM_SERIAL_LOG_ONLY(x)
+#endif
+
+#ifdef VMX86_SERVER
+#define vmx86_server 1
+#define SERVER_ONLY(x) x
+#define HOSTED_ONLY(x)
+#else
+#define vmx86_server 0
+#define SERVER_ONLY(x)
+#define HOSTED_ONLY(x) x
+#endif
+
+#ifdef VMX86_WGS
+#define vmx86_wgs 1
+#define WGS_ONLY(x) x
+#else
+#define vmx86_wgs 0
+#define WGS_ONLY(x) 
+#endif
+
+#ifdef VMKERNEL
+#define vmkernel 1
+#define VMKERNEL_ONLY(x) x
+#else
+#define vmkernel 0
+#define VMKERNEL_ONLY(x)
+#endif
+
+#ifdef _WIN32
+#define WIN32_ONLY(x) x
+#define POSIX_ONLY(x)
+#else
+#define WIN32_ONLY(x)
+#define POSIX_ONLY(x) x
+#endif
+
+#ifdef VMM
+#define VMM_ONLY(x) x
+#define USER_ONLY(x)
+#else
+#define VMM_ONLY(x)
+#define USER_ONLY(x) x
+#endif
+
+/* VMVISOR ifdef only allowed in the vmkernel */
+#ifdef VMKERNEL
+#ifdef VMVISOR
+#define vmvisor 1
+#define VMVISOR_ONLY(x) x
+#else
+#define vmvisor 0
+#define VMVISOR_ONLY(x)
+#endif
+#endif
+
+#ifdef _WIN32
+#define VMW_INVALID_HANDLE INVALID_HANDLE_VALUE
+#else
+#define VMW_INVALID_HANDLE (-1)
+#endif
+
+#ifdef _WIN32
+#define fsync(fd) _commit(fd)
+#define fileno(f) _fileno(f)
+#else
+#endif
+
+/*
+ * Debug output macros for Windows drivers (the Eng variant is for
+ * display/printer drivers only.
+ */
+#ifdef _WIN32
+#ifndef USES_OLD_WINDDK
+#if defined(VMX86_DEBUG) || defined(ASSERT_ALWAYS_AVAILABLE)
+#define WinDrvPrint(arg, ...) DbgPrint(arg, __VA_ARGS__)
+#define WinDrvEngPrint(arg, ...) EngDbgPrint(arg, __VA_ARGS__)
+#else
+#define WinDrvPrint(arg, ...)
+#define WinDrvEngPrint(arg, ...)
+#endif
+#endif
+#endif // _WIN32
+
+#endif // ifndef _VM_BASIC_DEFS_H_
--- kernel/linux-2.6.26.3/fs/vmblock/vm_basic_types.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmblock/vm_basic_types.h	2008-09-03 10:00:22.000000000 -0500
@@ -0,0 +1,865 @@
+/*********************************************************
+ * Copyright (C) 1998-2008 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ *
+ * vm_basic_types.h --
+ *
+ *    basic data types.
+ */
+
+
+#ifndef _VM_BASIC_TYPES_H_
+#define _VM_BASIC_TYPES_H_
+
+#define INCLUDE_ALLOW_USERLEVEL
+#define INCLUDE_ALLOW_VMMEXT
+#define INCLUDE_ALLOW_MODULE
+#define INCLUDE_ALLOW_VMMON
+#define INCLUDE_ALLOW_VMNIXMOD
+#define INCLUDE_ALLOW_VMKERNEL
+#define INCLUDE_ALLOW_VMKDRIVERS
+#define INCLUDE_ALLOW_VMK_MODULE
+#define INCLUDE_ALLOW_DISTRIBUTE
+#define INCLUDE_ALLOW_VMCORE
+#define INCLUDE_ALLOW_VMIROM
+
+/* STRICT ANSI means the Xserver build and X defines Bool differently. */
+#if !defined(__STRICT_ANSI__) || defined(__FreeBSD__)
+typedef char           Bool;
+#endif
+
+#ifndef FALSE
+#define FALSE          0
+#endif
+
+#ifndef TRUE
+#define TRUE           1
+#endif
+
+#define IsBool(x)      (((x) & ~1) == 0)
+#define IsBool2(x, y)  ((((x) | (y)) & ~1) == 0)
+
+/*
+ * Macros __i386__ and __ia64 are intrinsically defined by GCC
+ */
+#ifdef __i386__
+#define VM_I386
+#endif
+
+#ifdef _WIN64
+#define __x86_64__
+#endif
+
+#ifdef __x86_64__
+#define VM_X86_64
+#define VM_I386
+#define vm_x86_64 (1)
+#else
+#define vm_x86_64 (0)
+#endif
+
+
+
+#ifdef _WIN32
+/* safe assumption for a while */
+#define VM_I386
+#endif
+
+#ifdef _MSC_VER
+typedef unsigned __int64 uint64;
+typedef signed __int64 int64;
+
+#pragma warning (3 :4505) // unreferenced local function
+#pragma warning (disable :4018) // signed/unsigned mismatch
+#pragma warning (disable :4761) // integral size mismatch in argument; conversion supplied
+#pragma warning (disable :4305) // truncation from 'const int' to 'short'
+#pragma warning (disable :4244) // conversion from 'unsigned short' to 'unsigned char'
+#pragma warning (disable :4267) // truncation of 'size_t'
+#pragma warning (disable :4146) // unary minus operator applied to unsigned type, result still unsigned
+#pragma warning (disable :4142) // benign redefinition of type
+
+#elif __GNUC__
+/* The Xserver source compiles with -ansi -pendantic */
+#ifndef __STRICT_ANSI__
+#if defined(VM_X86_64)
+typedef unsigned long uint64;
+typedef long int64;
+#else
+typedef unsigned long long uint64;
+typedef long long int64;
+#endif
+#elif __FreeBSD__
+typedef unsigned long long uint64;
+typedef long long int64;
+#endif
+#else
+#error - Need compiler define for int64/uint64
+#endif
+
+typedef unsigned int       uint32;
+typedef unsigned short     uint16;
+typedef unsigned char      uint8;
+
+typedef int       int32;
+typedef short     int16;
+typedef char      int8;
+
+/*
+ * FreeBSD (for the tools build) unconditionally defines these in
+ * sys/inttypes.h so don't redefine them if this file has already
+ * been included. [greg]
+ *
+ * This applies to Solaris as well.
+ */
+
+/*
+ * Before trying to do the includes based on OS defines, see if we can use
+ * feature-based defines to get as much functionality as possible
+ */
+
+#ifdef HAVE_INTTYPES_H
+#include <inttypes.h>
+#endif
+#ifdef HAVE_SYS_TYPES_H
+#include <sys/types.h>
+#endif
+#ifdef HAVE_SYS_INTTYPES_H
+#include <sys/inttypes.h>
+#endif
+#ifdef HAVE_STDINT_H
+#include <stdint.h>
+#endif
+#ifdef HAVE_STDLIB_H
+#include <stdlib.h>
+#endif
+
+#ifdef __FreeBSD__
+#include <sys/param.h> /* For __FreeBSD_version */         
+#endif
+
+#if !defined(USING_AUTOCONF)
+#   if defined(__FreeBSD__) || defined(sun)
+#      ifdef KLD_MODULE
+#         include <sys/types.h>
+#      else
+#         if !defined(VMKERNEL) && (__FreeBSD_version >= 500043)
+#            include <inttypes.h>
+#            include <sys/types.h>
+#         else
+#            include <sys/inttypes.h>
+#         endif
+#      endif
+#   elif defined __APPLE__
+#      if KERNEL
+#         include <sys/unistd.h>
+#         include <sys/types.h> /* mostly for size_t */
+#         include <stdint.h>
+#      else
+#         include <unistd.h>
+#         include <inttypes.h>
+#         include <stdlib.h>
+#         include <stdint.h>
+#      endif
+#   else
+#      if !defined(__intptr_t_defined) && !defined(intptr_t)
+#         define __intptr_t_defined
+#         define intptr_t  intptr_t
+#         ifdef VM_I386
+#            ifdef VM_X86_64
+typedef int64     intptr_t;
+#            else
+typedef int32     intptr_t;
+#            endif
+#         endif
+#      endif
+
+#      ifndef _STDINT_H
+#         ifdef VM_I386
+#            ifdef VM_X86_64
+typedef uint64    uintptr_t;
+#            else
+typedef uint32    uintptr_t;
+#            endif
+#         endif
+#      endif
+#   endif
+#endif
+
+
+/*
+ * Time
+ * XXX These should be cleaned up.  -- edward
+ */
+
+typedef int64 VmTimeType;          /* Time in microseconds */
+typedef int64 VmTimeRealClock;     /* Real clock kept in microseconds */
+typedef int64 VmTimeVirtualClock;  /* Virtual Clock kept in CPU cycles */
+
+/*
+ * Printf format specifiers for size_t and 64-bit number.
+ * Use them like this:
+ *    printf("%"FMT64"d\n", big);
+ *
+ * FMTH is for handles/fds.
+ */
+
+#ifdef _MSC_VER
+   #define FMT64      "I64"
+   #ifdef VM_X86_64
+      #define FMTSZ      "I64"
+      #define FMTPD      "I64"
+      #define FMTH       "I64"
+   #else
+      #define FMTSZ      "I"
+      #define FMTPD      "I"
+      #define FMTH       "I"
+   #endif
+#elif __GNUC__
+   #define FMTH ""
+   #if defined(N_PLAT_NLM) || defined(sun) || \
+       (defined(__FreeBSD__) && (__FreeBSD__ + 0) && ((__FreeBSD__ + 0) < 5))
+      /*
+       * Why (__FreeBSD__ + 0)?  See bug 141008.
+       * Yes, we really need to test both (__FreeBSD__ + 0) and
+       * ((__FreeBSD__ + 0) < 5).  No, we can't remove "+ 0" from
+       * ((__FreeBSD__ + 0) < 5).
+       */
+      #ifdef VM_X86_64
+         #define FMTSZ  "l"
+         #define FMTPD  "l"
+      #else
+         #define FMTSZ  ""
+         #define FMTPD  ""
+      #endif
+   #elif defined(__linux__) \
+      || (defined(_POSIX_C_SOURCE) && _POSIX_C_SOURCE >= 200112L) \
+      || (defined(_POSIX_VERSION) && _POSIX_VERSION >= 200112L) \
+      || (defined(_POSIX2_VERSION) && _POSIX2_VERSION >= 200112L)
+      /* BSD/Darwin, Linux */
+      #define FMTSZ     "z"
+
+      #ifdef VM_X86_64
+         #define FMTPD  "l"
+      #else
+         #define FMTPD  ""
+      #endif
+   #else
+      /* Systems with a pre-C99 libc */
+      #define FMTSZ     "Z"
+      #ifdef VM_X86_64
+         #define FMTPD  "l"
+      #else
+         #define FMTPD  ""
+      #endif
+   #endif
+   #ifdef VM_X86_64
+      #define FMT64     "l"
+   #elif defined(sun) || defined(__APPLE__) || defined(__FreeBSD__)
+      #define FMT64     "ll"
+   #else
+      #define FMT64     "L"
+   #endif
+#else
+   #error - Need compiler define for FMT64 and FMTSZ
+#endif
+
+/*
+ * Suffix for 64-bit constants.  Use it like this:
+ *    CONST64(0x7fffffffffffffff) for signed or
+ *    CONST64U(0x7fffffffffffffff) for unsigned.
+ *
+ * 2004.08.30(thutt):
+ *   The vmcore/asm64/gen* programs are compiled as 32-bit
+ *   applications, but must handle 64 bit constants.  If the
+ *   64-bit-constant defining macros are already defined, the
+ *   definition will not be overwritten.
+ */
+
+#if !defined(CONST64) || !defined(CONST64U)
+#ifdef _MSC_VER
+#define CONST64(c) c##I64
+#define CONST64U(c) c##uI64
+#elif __GNUC__
+#ifdef VM_X86_64
+#define CONST64(c) c##L
+#define CONST64U(c) c##uL
+#else
+#define CONST64(c) c##LL
+#define CONST64U(c) c##uLL
+#endif
+#else
+#error - Need compiler define for CONST64
+#endif
+#endif
+
+/*
+ * Use CONST3264/CONST3264U if you want a constant to be
+ * treated as a 32-bit number on 32-bit compiles and
+ * a 64-bit number on 64-bit compiles. Useful in the case
+ * of shifts, like (CONST3264U(1) << x), where x could be
+ * more than 31 on a 64-bit compile.
+ */
+
+#ifdef VM_X86_64
+    #define CONST3264(a) CONST64(a)
+    #define CONST3264U(a) CONST64U(a)
+#else
+    #define CONST3264(a) (a)
+    #define CONST3264U(a) (a)
+#endif
+
+#define MIN_INT32  ((int32)0x80000000)
+#define MAX_INT32  ((int32)0x7fffffff)
+
+#define MIN_UINT32 ((uint32)0)
+#define MAX_UINT32 ((uint32)0xffffffff)
+
+#define MIN_INT64  (CONST64(0x8000000000000000))
+#define MAX_INT64  (CONST64(0x7fffffffffffffff))
+
+#define MIN_UINT64 (CONST64U(0))
+#define MAX_UINT64 (CONST64U(0xffffffffffffffff))
+
+typedef uint8 *TCA;  /* Pointer into TC (usually). */
+
+/*
+ * Type big enough to hold an integer between 0..100
+ */
+typedef uint8 Percent;
+#define AsPercent(v)	((Percent)(v))
+#define CHOOSE_PERCENT  AsPercent(101)
+
+
+typedef uintptr_t VA;
+typedef uintptr_t VPN;
+
+typedef uint64    PA;
+typedef uint32    PPN;
+
+typedef uint64    PhysMemOff;
+typedef uint64    PhysMemSize;
+
+/* The Xserver source compiles with -ansi -pendantic */
+#ifndef __STRICT_ANSI__
+typedef uint64    BA;
+#endif
+typedef uint32    BPN;
+typedef uint32    PageNum;
+typedef unsigned  MemHandle;
+typedef int32     World_ID;
+
+#define INVALID_WORLD_ID ((World_ID)0)
+
+typedef World_ID User_CartelID;
+#define INVALID_CARTEL_ID INVALID_WORLD_ID
+
+typedef User_CartelID User_SessionID;
+#define INVALID_SESSION_ID INVALID_CARTEL_ID
+
+typedef User_CartelID User_CartelGroupID;
+#define INVALID_CARTELGROUP_ID INVALID_CARTEL_ID
+
+typedef uint32 Worldlet_ID;
+#define INVALID_WORLDLET_ID ((Worldlet_ID)0)
+
+/* world page number */
+typedef uint32    WPN;
+
+/* The Xserver source compiles with -ansi -pendantic */
+#ifndef __STRICT_ANSI__
+typedef uint64     MA;
+typedef uint32     MPN;
+#endif
+
+/*
+ * This type should be used for variables that contain sector
+ * position/quantity.
+ */
+typedef uint64 SectorType;
+
+/*
+ * Linear address
+ */
+
+typedef uintptr_t LA;
+typedef uintptr_t LPN;
+#define LA_2_LPN(_la)     ((_la) >> PAGE_SHIFT)
+#define LPN_2_LA(_lpn)    ((_lpn) << PAGE_SHIFT)
+
+#define LAST_LPN   ((((LA)  1) << (8 * sizeof(LA)   - PAGE_SHIFT)) - 1)
+#define LAST_LPN32 ((((LA32)1) << (8 * sizeof(LA32) - PAGE_SHIFT)) - 1)
+#define LAST_LPN64 ((((LA64)1) << (8 * sizeof(LA64) - PAGE_SHIFT)) - 1)
+
+/* Valid bits in a LPN. */
+#define LPN_MASK   LAST_LPN
+#define LPN_MASK32 LAST_LPN32
+#define LPN_MASK64 LAST_LPN64
+
+/*
+ * On 64 bit platform, address and page number types default
+ * to 64 bit. When we need to represent a 32 bit address, we use
+ * types defined below.
+ *
+ * On 32 bit platform, the following types are the same as the
+ * default types.
+ */
+typedef uint32 VA32;
+typedef uint32 VPN32;
+typedef uint32 LA32;
+typedef uint32 LPN32;
+typedef uint32 PA32;
+typedef uint32 PPN32;
+typedef uint32 MA32;
+typedef uint32 MPN32;
+
+/*
+ * On 64 bit platform, the following types are the same as the
+ * default types.
+ */
+typedef uint64 VA64;
+typedef uint64 VPN64;
+typedef uint64 LA64;
+typedef uint64 LPN64;
+typedef uint64 PA64;
+typedef uint64 PPN64;
+typedef uint64 MA64;
+typedef uint64 MPN64;
+
+/*
+ * VA typedefs for user world apps.
+ */
+typedef VA32 UserVA32;
+typedef VA64 UserVA64;
+typedef UserVA32 UserVAConst; /* Userspace ptr to data that we may only read. */
+typedef UserVA64 UserVA64Const; /* Used by 64-bit syscalls until conversion is finished. */
+#ifdef VMKERNEL
+typedef UserVA32 UserVA;
+#else
+typedef void * UserVA;
+#endif
+
+
+/*
+ * Maximal possible PPN value (errors too) that PhysMem can handle.
+ * Must be at least as large as MAX_PPN which is the maximum PPN
+ * for any region other than buserror.
+ */
+#define PHYSMEM_MAX_PPN ((PPN)0xffffffff)
+#define MAX_PPN         ((PPN)0x1fffffff)   /* Maximal observable PPN value. */
+#define INVALID_PPN     ((PPN)0xffffffff)
+
+#define INVALID_BPN  ((BPN) 0x1fffffff)
+
+#define INVALID_MPN  ((MPN)-1)
+#define MEMREF_MPN   ((MPN)-2)
+#define RESERVED_MPN ((MPN) 0)
+/* Support 39 bits of address space, minus one page. */
+#define MAX_MPN      ((MPN) 0x07ffffff)
+
+#define INVALID_LPN ((LPN)-1)
+#define INVALID_VPN ((VPN)-1)
+#define INVALID_LPN64 ((LPN64)-1)
+#define INVALID_PAGENUM ((PageNum)-1)
+#define INVALID_WPN ((WPN) -1)
+
+
+/*
+ * Format modifier for printing VA, LA, and VPN.
+ * Use them like this: Log("%#"FMTLA"x\n", laddr)
+ */
+
+#if defined(VMM64) || defined(FROBOS64) || vm_x86_64 || defined __APPLE__
+#   define FMTLA "l"
+#   define FMTVA "l"
+#   define FMTVPN "l"
+#else
+#   define FMTLA ""
+#   define FMTVA ""
+#   define FMTVPN ""
+#endif
+
+#ifndef EXTERN
+#define EXTERN        extern
+#endif
+#define CONST         const
+
+
+#ifndef INLINE
+#   ifdef _MSC_VER
+#      define INLINE        __inline
+#   else
+#      define INLINE        inline
+#   endif
+#endif
+
+
+/*
+ * Annotation for data that may be exported into a DLL and used by other
+ * apps that load that DLL and import the data.
+ */
+#if defined(_WIN32) && defined(VMX86_IMPORT_DLLDATA)
+#  define VMX86_EXTERN_DATA       extern __declspec(dllimport)
+#else // !_WIN32
+#  define VMX86_EXTERN_DATA       extern
+#endif
+
+#if defined(_WIN32) && !defined(VMX86_NO_THREADS)
+#define THREADSPECIFIC __declspec(thread)
+#else
+#define THREADSPECIFIC
+#endif
+
+/*
+ * Due to the wonderful "registry redirection" feature introduced in
+ * 64-bit Windows, if you access any key under HKLM\Software in 64-bit
+ * code, you need to open/create/delete that key with
+ * VMKEY_WOW64_32KEY if you want a consistent view with 32-bit code.
+ */
+
+#ifdef _WIN32
+#ifdef _WIN64
+#define VMW_KEY_WOW64_32KEY KEY_WOW64_32KEY
+#else
+#define VMW_KEY_WOW64_32KEY 0x0
+#endif
+#endif
+
+
+/*
+ * Consider the following reasons functions are inlined:
+ *
+ *  1) inlined for performance reasons
+ *  2) inlined because it's a single-use function
+ *
+ * Functions which meet only condition 2 should be marked with this
+ * inline macro; It is not critical to be inlined (but there is a
+ * code-space & runtime savings by doing so), so when other callers
+ * are added the inline-ness should be removed.
+ */
+
+#if __GNUC__ > 3 || (__GNUC__ == 3 && __GNUC_MINOR__ >= 3)
+/*
+ * Starting at version 3.3, gcc does not always inline functions marked
+ * 'inline' (it depends on their size). To force gcc to do so, one must use the
+ * extra __always_inline__ attribute.
+ */
+#   define INLINE_SINGLE_CALLER INLINE __attribute__((__always_inline__))
+#   if    defined(VMM) \
+       && (__GNUC__ > 4 || (__GNUC__ == 4 && __GNUC_MINOR__ > 1))
+#      warning Verify INLINE_SINGLE_CALLER '__always_inline__' attribute (did \
+             monitor size change?)
+#   endif
+#else
+#   define INLINE_SINGLE_CALLER INLINE
+#endif
+
+/*
+ * Used when a hard guaranteed of no inlining is needed. Very few
+ * instances need this since the absence of INLINE is a good hint
+ * that gcc will not do inlining.
+ */
+
+#if defined(__GNUC__) && defined(VMM)
+#define ABSOLUTELY_NOINLINE __attribute__((__noinline__))
+#endif
+
+/*
+ * Attributes placed on function declarations to tell the compiler
+ * that the function never returns.
+ */
+
+#ifdef _MSC_VER
+#define NORETURN __declspec(noreturn)
+#elif __GNUC__ > 2 || (__GNUC__ == 2 && __GNUC_MINOR__ >= 9)
+#define NORETURN __attribute__((__noreturn__))
+#else
+#define NORETURN
+#endif
+
+/*
+ * GCC 3.2 inline asm needs the + constraint for input/ouput memory operands.
+ * Older GCCs don't know about it --hpreg
+ */
+
+#if __GNUC__ > 3 || (__GNUC__ == 3 && __GNUC_MINOR__ >= 2)
+#   define VM_ASM_PLUS 1
+#else
+#   define VM_ASM_PLUS 0
+#endif
+
+/*
+ * Branch prediction hints:
+ *     LIKELY(exp)   - Expression exp is likely TRUE.
+ *     UNLIKELY(exp) - Expression exp is likely FALSE.
+ *   Usage example:
+ *        if (LIKELY(excCode == EXC_NONE)) {
+ *               or
+ *        if (UNLIKELY(REAL_MODE(vc))) {
+ *
+ * We know how to predict branches on gcc3 and later (hopefully),
+ * all others we don't so we do nothing.
+ */
+
+#if (__GNUC__ >= 3)
+/*
+ * gcc3 uses __builtin_expect() to inform the compiler of an expected value.
+ * We use this to inform the static branch predictor. The '!!' in LIKELY
+ * will convert any !=0 to a 1.
+ */
+#define LIKELY(_exp)     __builtin_expect(!!(_exp), 1)
+#define UNLIKELY(_exp)   __builtin_expect((_exp), 0)
+#else
+#define LIKELY(_exp)      (_exp)
+#define UNLIKELY(_exp)    (_exp)
+#endif
+
+/*
+ * GCC's argument checking for printf-like functions
+ * This is conditional until we have replaced all `"%x", void *'
+ * with `"0x%08x", (uint32) void *'. Note that %p prints different things
+ * on different platforms.  Argument checking is enabled for the
+ * vmkernel, which has already been cleansed.
+ *
+ * fmtPos is the position of the format string argument, beginning at 1
+ * varPos is the position of the variable argument, beginning at 1
+ */
+
+#if defined(__GNUC__)
+# define PRINTF_DECL(fmtPos, varPos) __attribute__((__format__(__printf__, fmtPos, varPos)))
+#else
+# define PRINTF_DECL(fmtPos, varPos)
+#endif
+
+#if defined(__GNUC__)
+# define SCANF_DECL(fmtPos, varPos) __attribute__((__format__(__scanf__, fmtPos, varPos)))
+#else
+# define SCANF_DECL(fmtPos, varPos)
+#endif
+
+/*
+ * UNUSED_PARAM should surround the parameter name and type declaration,
+ * e.g. "int MyFunction(int var1, UNUSED_PARAM(int var2))"
+ *
+ */
+
+#ifndef UNUSED_PARAM
+# if defined(__GNUC__)
+#  define UNUSED_PARAM(_parm) _parm  __attribute__((__unused__))
+# else
+#  define UNUSED_PARAM(_parm) _parm
+# endif
+#endif
+
+/*
+ * REGPARM defaults to REGPARM3, i.e., a requent that gcc
+ * puts the first three arguments in registers.  (It is fine
+ * if the function has fewer than three args.)  Gcc only.
+ * Syntactically, put REGPARM where you'd put INLINE or NORETURN.
+ */
+
+#if defined(__GNUC__)
+# define REGPARM0 __attribute__((regparm(0)))
+# define REGPARM1 __attribute__((regparm(1)))
+# define REGPARM2 __attribute__((regparm(2)))
+# define REGPARM3 __attribute__((regparm(3)))
+# define REGPARM REGPARM3
+#else
+# define REGPARM0
+# define REGPARM1
+# define REGPARM2
+# define REGPARM3
+# define REGPARM
+#endif
+
+/*
+ * ALIGNED specifies minimum alignment in "n" bytes.
+ */
+
+#ifdef __GNUC__
+#define ALIGNED(n) __attribute__((__aligned__(n)))
+#else
+#define ALIGNED(n)
+#endif
+
+/*
+ * __func__ is a stringified function name that is part of the C99 standard. The block
+ * below defines __func__ on older systems where the compiler does not support that
+ * macro.
+ */
+#if defined(__GNUC__) \
+   && ((__GNUC__ == 2 && __GNUC_MINOR < 96) \
+       || (__GNUC__ < 2))
+#   define __func__ __FUNCTION__
+#endif
+
+/*
+ * Once upon a time, this was used to silence compiler warnings that
+ * get generated when the compiler thinks that a function returns
+ * when it is marked noreturn.  Don't do it.  Use NOT_REACHED().
+ */
+
+#define INFINITE_LOOP()           do { } while (1)
+
+/*
+ * On FreeBSD (for the tools build), size_t is typedef'd if _BSD_SIZE_T_
+ * is defined. Use the same logic here so we don't define it twice. [greg]
+ */
+#ifdef __FreeBSD__
+#   ifdef _BSD_SIZE_T_
+#      undef _BSD_SIZE_T_
+#      ifdef VM_I386
+#         ifdef VM_X86_64
+             typedef uint64 size_t;
+#         else
+             typedef uint32 size_t;
+#         endif
+#      endif /* VM_I386 */
+#   endif
+
+#   ifdef _BSD_SSIZE_T_
+#      undef _BSD_SSIZE_T_
+#      define _SSIZE_T
+#      define __ssize_t_defined
+#      define _SSIZE_T_DECLARED
+#      ifdef VM_I386
+#         ifdef VM_X86_64
+             typedef int64 ssize_t;
+#         else
+             typedef int32 ssize_t;
+#         endif
+#      endif /* VM_I386 */
+#   endif
+
+#else
+#   ifndef _SIZE_T
+#      define _SIZE_T
+#      ifdef VM_I386
+#         ifdef VM_X86_64
+             typedef uint64 size_t;
+#         else
+             typedef uint32 size_t;
+#         endif
+#      endif /* VM_I386 */
+#   endif
+
+#   if !defined(FROBOS) && !defined(_SSIZE_T) && !defined(ssize_t) && \
+       !defined(__ssize_t_defined) && !defined(_SSIZE_T_DECLARED)
+#      define _SSIZE_T
+#      define __ssize_t_defined
+#      define _SSIZE_T_DECLARED
+#      ifdef VM_I386
+#         ifdef VM_X86_64
+             typedef int64 ssize_t;
+#         else
+             typedef int32 ssize_t;
+#         endif
+#      endif /* VM_I386 */
+#   endif
+
+#endif
+
+/*
+ * Format modifier for printing pid_t.  On sun the pid_t is a ulong, but on
+ * Linux it's an int.
+ * Use this like this: printf("The pid is %"FMTPID".\n", pid);
+ */
+#ifdef sun
+#   ifdef VM_X86_64
+#      define FMTPID "d"
+#   else
+#      define FMTPID "lu"
+#   endif
+#else
+# define FMTPID "d"
+#endif
+
+/*
+ * Format modifier for printing uid_t.  On sun the uid_t is a ulong, but on
+ * Linux it's an int.
+ * Use this like this: printf("The uid is %"FMTUID".\n", uid);
+ */
+#ifdef sun
+#   ifdef VM_X86_64
+#      define FMTUID "u"
+#   else
+#      define FMTUID "lu"
+#   endif
+#else
+# define FMTUID "u"
+#endif
+
+/*
+ * Format modifier for printing mode_t.  On sun the mode_t is a ulong, but on
+ * Linux it's an int.
+ * Use this like this: printf("The mode is %"FMTMODE".\n", mode);
+ */
+#ifdef sun
+#   ifdef VM_X86_64
+#      define FMTMODE "o"
+#   else
+#      define FMTMODE "lo"
+#   endif
+#else
+# define FMTMODE "o"
+#endif
+
+/*
+ * Format modifier for printing time_t. Most platforms define a time_t to be
+ * a long int, but on FreeBSD (as of 5.0, it seems), the time_t is a signed
+ * size quantity. Refer to the definition of FMTSZ to see why we need silly
+ * preprocessor arithmetic.
+ * Use this like this: printf("The mode is %"FMTTIME".\n", time);
+ */
+#if defined(__FreeBSD__) && (__FreeBSD__ + 0) && ((__FreeBSD__ + 0) >= 5)
+#   define FMTTIME FMTSZ"d"
+#else
+#   define FMTTIME "ld"
+#endif
+
+/*
+ * Define MXSemaHandle here so both vmmon and vmx see this definition.
+ */
+
+#ifdef _WIN32
+typedef uintptr_t MXSemaHandle;
+#else
+typedef int MXSemaHandle;
+#endif
+
+/*
+ * Define type for poll device handles.
+ */
+
+#ifdef _WIN32
+typedef uintptr_t PollDevHandle;
+#else
+typedef int PollDevHandle;
+#endif
+
+/*
+ * Define the utf16_t type.
+ */
+
+#if defined(_WIN32) && defined(_NATIVE_WCHAR_T_DEFINED)
+typedef wchar_t utf16_t;
+#else
+typedef uint16 utf16_t;
+#endif
+
+#endif  /* _VM_BASIC_TYPES_H_ */
--- kernel/linux-2.6.26.3/fs/vmblock/vmblock.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmblock/vmblock.h	2008-09-03 09:58:40.000000000 -0500
@@ -0,0 +1,186 @@
+/*********************************************************
+ * Copyright (C) 2006-2008 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * vmblock.h --
+ *
+ *   User-level interface to the vmblock device.
+ *
+ *   VMBLOCK_DEVICE should be opened with VMBLOCK_DEVICE_MODE mode. Then
+ *   VMBLOCK_CONTROL should be called to perform blocking operations.
+ *   The links which can be blocked are in the directory VMBLOCK_MOUNT_POINT.
+ *
+ *   VMBLOCK_CONTROL takes the file descriptor of the VMBLOCK_DEVICE, an
+ *   operation, and the path of the target of the file being operated on (if
+ *   applicable).
+ *
+ *   The operation should be one of:
+ *   VMBLOCK_ADD_FILEBLOCK
+ *   VMBLOCK_DEL_FILEBLOCK
+ *   VMBLOCK_LIST_FILEBLOCKS
+ *
+ *   path should be something in /tmp/VMwareDnD/ rather than in
+ *   VMBLOCK_MOUNT_POINT.
+ *
+ *   VMBLOCK_CONTROL returns 0 on success or returns -1 and sets errno on
+ *   failure.
+ */
+
+#ifndef _VMBLOCK_H_
+#define _VMBLOCK_H_
+
+#if defined(sun) || defined(__FreeBSD__)
+# include <sys/ioccom.h>
+#endif
+
+#if defined(__FreeBSD__)
+# include <sys/param.h>
+#endif
+
+#define VMBLOCK_FS_NAME                "vmblock"
+
+/* Commands for the control half of vmblock driver */
+#if defined(vmblock_fuse)
+# include <unistd.h>
+# include <limits.h>
+# include <string.h>
+# include <errno.h>
+# include "vm_basic_types.h"
+# define VMBLOCK_ADD_FILEBLOCK        'a'
+# define VMBLOCK_DEL_FILEBLOCK        'd'
+# ifdef VMX86_DEVEL
+#  define VMBLOCK_LIST_FILEBLOCKS     'l'
+# endif /* VMX86_DEVEL */
+/*
+ * Some of the following names don't actually make much sense on their own.
+ * They're used for consistency with the other ports. See the file header for
+ * explanations of what they're used for.
+ */
+# define VMBLOCK_DEVICE_NAME          "dev"
+# define VMBLOCK_CONTROL_MOUNTPOINT   "blockdir"
+# define VMBLOCK_DEVICE               "/tmp/vmblock/" VMBLOCK_DEVICE_NAME
+# define VMBLOCK_DEVICE_MODE          O_WRONLY
+# define VMBLOCK_MOUNT_POINT          "/tmp/vmblock/" VMBLOCK_CONTROL_MOUNTPOINT
+static INLINE ssize_t
+         VMBLOCK_CONTROL(int fd, char op, const char *path)
+{
+   /*
+    * buffer needs room for an operation character and a string with max length
+    * PATH_MAX - 1.
+    */
+
+   char buffer[PATH_MAX];
+   size_t pathLength;
+
+   pathLength = strlen(path);
+   if (pathLength >= PATH_MAX) {
+      errno = ENAMETOOLONG;
+      return -1;
+   }
+
+   buffer[0] = op;
+   memcpy(buffer + 1, path, pathLength);
+
+   /*
+    * The lseek is only to prevent the file pointer from overflowing;
+    * vmblock-fuse ignores the file pointer / offset. Overflowing the file
+    * pointer causes write to fail:
+    * http://article.gmane.org/gmane.comp.file-systems.fuse.devel/6648
+    * There's also a race condition here where many threads all calling
+    * VMBLOCK_CONTROL at the same time could have all their seeks executed one
+    * after the other, followed by all the writes. Again, it's not a problem
+    * unless the file pointer overflows which is very unlikely with 32 bit
+    * offsets and practically impossible with 64 bit offsets.
+    */
+
+   if (lseek(fd, 0, SEEK_SET) < 0) {
+      return -1;
+   }
+   if (write(fd, buffer, pathLength + 1) < 0) {
+      return -1;
+   }
+   return 0;
+}
+
+#elif defined(linux)
+# define VMBLOCK_ADD_FILEBLOCK          98
+# define VMBLOCK_DEL_FILEBLOCK          99
+# ifdef VMX86_DEVEL
+#  define VMBLOCK_LIST_FILEBLOCKS       100
+# endif
+# define VMBLOCK_CONTROL_DIRNAME        VMBLOCK_FS_NAME
+# define VMBLOCK_CONTROL_DEVNAME        "dev"
+# define VMBLOCK_CONTROL_MOUNTPOINT     "mountPoint"
+# define VMBLOCK_CONTROL_PROC_DIRNAME	"fs/" VMBLOCK_CONTROL_DIRNAME
+
+# define VMBLOCK_MOUNT_POINT            "/proc/" VMBLOCK_CONTROL_PROC_DIRNAME   \
+                                       "/" VMBLOCK_CONTROL_MOUNTPOINT
+# define VMBLOCK_DEVICE                 "/proc/" VMBLOCK_CONTROL_PROC_DIRNAME   \
+                                       "/" VMBLOCK_CONTROL_DEVNAME
+# define VMBLOCK_DEVICE_MODE            O_WRONLY
+# define VMBLOCK_CONTROL(fd, op, path)  write(fd, path, op)
+
+#elif defined(sun) || defined(__FreeBSD__)
+# define VMBLOCK_MOUNT_POINT            "/var/run/" VMBLOCK_FS_NAME
+# define VMBLOCK_DEVICE                 VMBLOCK_MOUNT_POINT
+# define VMBLOCK_DEVICE_MODE            O_RDONLY
+# if defined(sun)                       /* if (sun) { */
+   /*
+    * Construct ioctl(2) commands for blocks.  _IO() is a helper macro to
+    * construct unique command values more easily.  I chose 'v' because I
+    * didn't see it being used elsewhere, and the command numbers begin at one.
+    */
+#  define VMBLOCK_ADD_FILEBLOCK          _IO('v', 1)
+#  define VMBLOCK_DEL_FILEBLOCK          _IO('v', 2)
+#  ifdef VMX86_DEVEL
+#   define VMBLOCK_LIST_FILEBLOCKS       _IO('v', 3)
+#  endif
+#  define VMBLOCK_CONTROL(fd, op, path)  ioctl(fd, op, path)
+
+# elif defined(__FreeBSD__)              /* } else if (FreeBSD) { */
+   /*
+    * Similar to Solaris, construct ioctl(2) commands for block operations.
+    * Since the FreeBSD implementation does not change the user's passed-in
+    * data (pathname), we use the _IOW macro to define commands which write
+    * to the kernel.  (As opposed to _IOR or _IOWR.)  Groups 'v' and 'V'
+    * are taken by terminal drivers, so I opted for group 'Z'.
+    */
+#  define VMBLOCK_ADD_FILEBLOCK          _IOW('Z', 1, char[MAXPATHLEN] )
+#  define VMBLOCK_DEL_FILEBLOCK          _IOW('Z', 2, char[MAXPATHLEN] )
+#  ifdef VMX86_DEVEL
+#   define VMBLOCK_LIST_FILEBLOCKS       _IO('Z', 3)
+#   define VMBLOCK_PURGE_FILEBLOCKS      _IO('Z', 4)
+#  endif
+   /*
+    * FreeBSD's ioctl data parameters must be of fixed size.  Guarantee a safe
+    * buffer of size MAXPATHLEN by copying the user's string to one of our own.
+    */
+#  define VMBLOCK_CONTROL(fd, cmd, path)                                \
+({                                                                      \
+   char tpath[MAXPATHLEN];                                              \
+   if (path != NULL) {                                                  \
+      strlcpy(tpath, path, MAXPATHLEN);                                 \
+   }                                                                    \
+   ioctl((fd), (cmd), tpath);                                           \
+})
+# endif                                 /* } */
+#else
+# error "Unknown platform for vmblock."
+#endif
+
+#endif /* _VMBLOCK_H_ */
--- kernel/linux-2.6.26.3/fs/vmblock/vmblockInt.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmblock/vmblockInt.h	2008-09-03 09:57:35.000000000 -0500
@@ -0,0 +1,94 @@
+/*********************************************************
+ * Copyright (C) 2006 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * vmblockInt.h --
+ *
+ *   Definitions and prototypes for entire module.
+ *
+ *   The module is split into two halves, a control half and a file system
+ *   half, and the halves communicate through the blocking functionality in
+ *   block.c.  The control half creates a device node for a user space program
+ *   (running as root) to add and delete blocks on files in the file system's
+ *   namespace.  The file system provides links to the contents of the
+ *   directory it is redirecting to and blocks according to the file blocks set
+ *   through the control half.
+ */
+
+#ifndef __VMBLOCKINT_H__
+#define __VMBLOCKINT_H__
+
+#include "compat_version.h"
+#include "compat_mm.h"
+
+#include "vmblock.h"
+#include "vm_basic_types.h"
+#include "vm_assert.h"
+
+#ifdef __KERNEL__
+#ifdef VMX86_DEVEL
+extern int LOGLEVEL_THRESHOLD;
+#  define LOG(level, fmt, args...)                              \
+     ((void) (LOGLEVEL_THRESHOLD >= (level) ?                   \
+              printk(KERN_DEBUG "VMBlock: " fmt, ## args) :     \
+              0)                                                \
+     )
+#else
+#  define LOG(level, fmt, args...)
+#endif
+#define Warning(fmt, args...)                                   \
+     printk(KERN_WARNING "VMBlock warning: " fmt, ## args)
+/*
+ * Some kernel versions, bld-2.4.21-32.EL_x86_64-ia32e-RHEL3 and perhaps more,
+ * don't define __user in uaccess.h, so let's do it here so we don't have to
+ * ifdef all the __user annotations.
+ */
+#ifndef __user
+#define __user
+#endif
+#endif /* __KERNEL__ */
+
+#define VMBLOCK_CONTROL_MODE       S_IRUSR | S_IFREG
+
+/*
+ * Our modules may be compatible with kernels built for different processors.
+ * This can cause problems, so we add a reference to the __alloc_pages symbol
+ * below since it is versioned per-processor and will cause modules to only
+ * load on kernels built for the same processor as our module.
+ *
+ * XXX This should go in driver-config.h, but vmmon's hostKernel.h is retarded.
+ */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 3, 29)
+static const void *forceProcessorCheck __attribute__((unused)) = __alloc_pages;
+#endif
+
+
+/*
+ * Initialization and cleanup routines for control and file system halves of
+ * vmblock driver
+ */
+int VMBlockInitControlOps(void);
+int VMBlockCleanupControlOps(void);
+int VMBlockInitFileSystem(char const *root);
+int VMBlockCleanupFileSystem(void);
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 70)
+size_t strlcpy(char *dest, const char *src, size_t count);
+#endif
+
+#endif /* __VMBLOCK_H__ */
--- kernel/linux-2.6.26.3/fs/vmblock/vmblock_version.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmblock/vmblock_version.h	2008-09-03 09:57:35.000000000 -0500
@@ -0,0 +1,32 @@
+/*********************************************************
+ * Copyright (C) 2007 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * vmblock_version.h --
+ *
+ * Version definitions for the Linux vmblock driver.
+ */
+
+#ifndef _VMBLOCK_VERSION_H_
+#define _VMBLOCK_VERSION_H_
+
+#define VMBLOCK_DRIVER_VERSION          1.1.2.0
+#define VMBLOCK_DRIVER_VERSION_COMMAS   1,1,2,0
+#define VMBLOCK_DRIVER_VERSION_STRING   "1.1.2.0"
+
+#endif /* _VMBLOCK_VERSION_H_ */
--- kernel/linux-2.6.26.3/fs/vmblock/vmware.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmblock/vmware.h	2008-09-03 10:00:31.000000000 -0500
@@ -0,0 +1,57 @@
+/*********************************************************
+ * Copyright (C) 2003 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * vmware.h --
+ *
+ *	Standard include file for VMware source code.
+ */
+
+#ifndef _VMWARE_H_
+#define _VMWARE_H_
+
+#define INCLUDE_ALLOW_USERLEVEL
+#define INCLUDE_ALLOW_VMCORE
+#define INCLUDE_ALLOW_MODULE
+#define INCLUDE_ALLOW_VMMON
+#define INCLUDE_ALLOW_VMNIXMOD
+#define INCLUDE_ALLOW_VMKERNEL
+#define INCLUDE_ALLOW_VMK_MODULE
+#define INCLUDE_ALLOW_DISTRIBUTE
+
+#include "vm_basic_types.h"
+#include "vm_basic_defs.h"
+#include "vm_assert.h"
+
+/*
+ * Global error codes. Currently used internally, but may be exported
+ * to customers one day, like VM_E_XXX in vmcontrol_constants.h
+ */
+
+typedef enum VMwareStatus {
+   VMWARE_STATUS_SUCCESS,  /* success */
+   VMWARE_STATUS_ERROR,    /* generic error */
+   VMWARE_STATUS_NOMEM,    /* generic memory allocation error */
+   VMWARE_STATUS_INSUFFICIENT_RESOURCES, /* internal or system resource limit exceeded */
+   VMWARE_STATUS_INVALID_ARGS  /* invalid arguments */
+} VMwareStatus;
+
+#define VMWARE_SUCCESS(s) ((s) == VMWARE_STATUS_SUCCESS)
+
+
+#endif // ifndef _VMWARE_H_
--- kernel/linux-2.6.26.3/fs/vmhgfs/backdoor.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/backdoor.c	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,259 @@
+/*********************************************************
+ * Copyright (C) 1999 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * backdoor.c --
+ *
+ *    First layer of the internal communication channel between guest
+ *    applications and vmware
+ *
+ *    This is the backdoor. By using special ports of the virtual I/O space,
+ *    and the virtual CPU registers, a guest application can send a
+ *    synchroneous basic request to vmware, and vmware can reply to it.
+ */
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+#if defined(__KERNEL__) || defined(_KERNEL)
+#else
+#   include "debug.h"
+#endif
+
+#include "backdoor_def.h"
+#include "backdoor.h"
+#include "backdoorInt.h"
+
+#if defined(BACKDOOR_DEBUG) && defined(USERLEVEL)
+#   include <stdio.h>
+#   define BACKDOOR_LOG(args) Debug args
+#   define BACKDOOR_LOG_PROTO_STRUCT(x) BackdoorPrintProtoStruct((x))
+#   define BACKDOOR_LOG_HB_PROTO_STRUCT(x) BackdoorPrintHbProtoStruct((x))
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * BackdoorPrintProtoStruct --
+ * BackdoorPrintHbProtoStruct --
+ *
+ *      Print the contents of the specified backdoor protocol structure via
+ *      printf.
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      Output to stdout.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+void
+BackdoorPrintProtoStruct(Backdoor_proto *myBp)
+{
+   Debug("magic 0x%08x, command %d, size %"FMTSZ"u, port %d\n",
+         myBp->in.ax.word, myBp->in.cx.halfs.low,
+         myBp->in.size, myBp->in.dx.halfs.low);
+
+#ifndef VM_X86_64
+   Debug("ax %#x, "
+         "bx %#x, "
+         "cx %#x, "
+         "dx %#x, "
+         "si %#x, "
+         "di %#x\n",
+         myBp->out.ax.word,
+         myBp->out.bx.word,
+         myBp->out.cx.word,
+         myBp->out.dx.word,
+         myBp->out.si.word,
+         myBp->out.di.word);
+#else
+   Debug("ax %#"FMT64"x, "
+         "bx %#"FMT64"x, "
+         "cx %#"FMT64"x, "
+         "dx %#"FMT64"x, "
+         "si %#"FMT64"x, "
+         "di %#"FMT64"x\n",
+         myBp->out.ax.quad,
+         myBp->out.bx.quad,
+         myBp->out.cx.quad,
+         myBp->out.dx.quad,
+         myBp->out.si.quad,
+         myBp->out.di.quad);
+#endif
+}
+
+
+void
+BackdoorPrintHbProtoStruct(Backdoor_proto_hb *myBp)
+{
+   Debug("magic 0x%08x, command %d, size %"FMTSZ"u, port %d, "
+         "srcAddr %"FMTSZ"u, dstAddr %"FMTSZ"u\n",
+         myBp->in.ax.word, myBp->in.bx.halfs.low, myBp->in.size,
+         myBp->in.dx.halfs.low, myBp->in.srcAddr, myBp->in.dstAddr);
+
+#ifndef VM_X86_64
+   Debug("ax %#x, "
+         "bx %#x, "
+         "cx %#x, "
+         "dx %#x, "
+         "si %#x, "
+         "di %#x, "
+         "bp %#x\n",
+         myBp->out.ax.word,
+         myBp->out.bx.word,
+         myBp->out.cx.word,
+         myBp->out.dx.word,
+         myBp->out.si.word,
+         myBp->out.di.word,
+         myBp->out.bp.word);
+#else
+   Debug("ax %#"FMT64"x, "
+         "bx %#"FMT64"x, "
+         "cx %#"FMT64"x, "
+         "dx %#"FMT64"x, "
+         "si %#"FMT64"x, "
+         "di %#"FMT64"x, "
+         "bp %#"FMT64"x\n",
+         myBp->out.ax.quad,
+         myBp->out.bx.quad,
+         myBp->out.cx.quad,
+         myBp->out.dx.quad,
+         myBp->out.si.quad,
+         myBp->out.di.quad,
+         myBp->out.bp.quad);
+#endif
+}
+
+#else
+#   define BACKDOOR_LOG(args)
+#   define BACKDOOR_LOG_PROTO_STRUCT(x)
+#   define BACKDOOR_LOG_HB_PROTO_STRUCT(x)
+#endif
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Backdoor --
+ *
+ *      Send a low-bandwidth basic request (16 bytes) to vmware, and return its
+ *      reply (24 bytes).
+ *
+ * Result:
+ *      None
+ *
+ * Side-effects:
+ *      None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+void
+Backdoor(Backdoor_proto *myBp) // IN/OUT
+{
+   ASSERT(myBp);
+
+   myBp->in.ax.word = BDOOR_MAGIC;
+   myBp->in.dx.halfs.low = BDOOR_PORT;
+
+   BACKDOOR_LOG(("Backdoor: before "));
+   BACKDOOR_LOG_PROTO_STRUCT(myBp);
+
+   Backdoor_InOut(myBp);
+
+   BACKDOOR_LOG(("Backdoor: after "));
+   BACKDOOR_LOG_PROTO_STRUCT(myBp);
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Backdoor_HbOut --
+ *
+ *      Send a high-bandwidth basic request to vmware, and return its
+ *      reply.
+ *
+ * Result:
+ *      The host-side response is returned via the IN/OUT parameter.
+ *
+ * Side-effects:
+ *      Pokes the high-bandwidth backdoor.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+void
+Backdoor_HbOut(Backdoor_proto_hb *myBp) // IN/OUT
+{
+   ASSERT(myBp);
+
+   myBp->in.ax.word = BDOOR_MAGIC;
+   myBp->in.dx.halfs.low = BDOORHB_PORT;
+
+   BACKDOOR_LOG(("Backdoor_HbOut: before "));
+   BACKDOOR_LOG_HB_PROTO_STRUCT(myBp);
+
+   BackdoorHbOut(myBp);
+
+   BACKDOOR_LOG(("Backdoor_HbOut: after "));
+   BACKDOOR_LOG_HB_PROTO_STRUCT(myBp);
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Backdoor_HbIn --
+ *
+ *      Send a basic request to vmware, and return its high-bandwidth
+ *      reply
+ *
+ * Result:
+ *      Host-side response returned via the IN/OUT parameter.
+ *
+ * Side-effects:
+ *      Pokes the high-bandwidth backdoor.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+void
+Backdoor_HbIn(Backdoor_proto_hb *myBp) // IN/OUT
+{
+   ASSERT(myBp);
+
+   myBp->in.ax.word = BDOOR_MAGIC;
+   myBp->in.dx.halfs.low = BDOORHB_PORT;
+
+   BACKDOOR_LOG(("Backdoor_HbIn: before "));
+   BACKDOOR_LOG_HB_PROTO_STRUCT(myBp);
+
+   BackdoorHbIn(myBp);
+
+   BACKDOOR_LOG(("Backdoor_HbIn: after "));
+   BACKDOOR_LOG_HB_PROTO_STRUCT(myBp);
+}
+
+#ifdef __cplusplus
+}
+#endif
--- kernel/linux-2.6.26.3/fs/vmhgfs/backdoor_def.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/backdoor_def.h	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,172 @@
+/*********************************************************
+ * Copyright (C) 1998 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * backdoor_def.h --
+ *
+ * This contains backdoor defines that can be included from
+ * an assembly language file.
+ */
+
+
+
+#ifndef _BACKDOOR_DEF_H_
+#define _BACKDOOR_DEF_H_
+
+#define INCLUDE_ALLOW_MODULE
+#define INCLUDE_ALLOW_USERLEVEL
+#define INCLUDE_ALLOW_VMMEXT
+#define INCLUDE_ALLOW_VMCORE
+#define INCLUDE_ALLOW_VMKERNEL
+#include "includeCheck.h"
+
+/*
+ * If you want to add a new low-level backdoor call for a guest userland
+ * application, please consider using the GuestRpc mechanism instead. --hpreg
+ */
+
+#define BDOOR_MAGIC 0x564D5868
+
+/* Low-bandwidth backdoor port. --hpreg */
+
+#define BDOOR_PORT 0x5658
+
+#define BDOOR_CMD_GETMHZ      		   1
+/*
+ * BDOOR_CMD_APMFUNCTION is used by:
+ *
+ * o The FrobOS code, which instead should either program the virtual chipset
+ *   (like the new BIOS code does, matthias offered to implement that), or not
+ *   use any VM-specific code (which requires that we correctly implement
+ *   "power off on CLI HLT" for SMP VMs, boris offered to implement that)
+ *
+ * o The old BIOS code, which will soon be jettisoned
+ *
+ *  --hpreg
+ */
+#define BDOOR_CMD_APMFUNCTION 		   2
+#define BDOOR_CMD_GETDISKGEO  		   3
+#define BDOOR_CMD_GETPTRLOCATION	      4
+#define BDOOR_CMD_SETPTRLOCATION	      5
+#define BDOOR_CMD_GETSELLENGTH		   6
+#define BDOOR_CMD_GETNEXTPIECE		   7
+#define BDOOR_CMD_SETSELLENGTH		   8
+#define BDOOR_CMD_SETNEXTPIECE		   9
+#define BDOOR_CMD_GETVERSION		      10
+#define BDOOR_CMD_GETDEVICELISTELEMENT	11
+#define BDOOR_CMD_TOGGLEDEVICE		   12
+#define BDOOR_CMD_GETGUIOPTIONS		   13
+#define BDOOR_CMD_SETGUIOPTIONS		   14
+#define BDOOR_CMD_GETSCREENSIZE		   15
+#define BDOOR_CMD_MONITOR_CONTROL       16
+#define BDOOR_CMD_GETHWVERSION          17
+#define BDOOR_CMD_OSNOTFOUND            18
+#define BDOOR_CMD_GETUUID               19
+#define BDOOR_CMD_GETMEMSIZE            20
+#define BDOOR_CMD_HOSTCOPY              21 /* Devel only */
+#define BDOOR_CMD_SERVICE_VM            22 /* prototype only */         
+#define BDOOR_CMD_GETTIME               23 /* Deprecated. Use GETTIMEFULL. */
+#define BDOOR_CMD_STOPCATCHUP           24
+#define BDOOR_CMD_PUTCHR	        25 /* Devel only */
+#define BDOOR_CMD_ENABLE_MSG	        26 /* Devel only */
+#define BDOOR_CMD_GOTO_TCL	        27 /* Devel only */
+#define BDOOR_CMD_INITPCIOPROM		28
+#define BDOOR_CMD_INT13			29
+#define BDOOR_CMD_MESSAGE               30
+#define BDOOR_CMD_RSVD0                 31
+#define BDOOR_CMD_RSVD1                 32
+#define BDOOR_CMD_RSVD2                 33
+#define BDOOR_CMD_ISACPIDISABLED	34
+#define BDOOR_CMD_TOE			35 /* Not in use */
+/* BDOOR_CMD_INITLSIOPROM, 36, was merged with 28. Reuse. */
+#define BDOOR_CMD_PATCH_SMBIOS_STRUCTS  37
+#define BDOOR_CMD_MAPMEM                38 /* Devel only */
+#define BDOOR_CMD_ABSPOINTER_DATA	39
+#define BDOOR_CMD_ABSPOINTER_STATUS	40
+#define BDOOR_CMD_ABSPOINTER_COMMAND	41
+#define BDOOR_CMD_TIMER_SPONGE          42
+#define BDOOR_CMD_PATCH_ACPI_TABLES	43
+/* Catch-all to allow synchronous tests */
+#define BDOOR_CMD_DEVEL_FAKEHARDWARE	44 /* Debug only - needed in beta */
+#define BDOOR_CMD_GETHZ      		45
+#define BDOOR_CMD_GETTIMEFULL           46
+#define BDOOR_CMD_STATELOGGER           47
+#define BDOOR_CMD_CHECKFORCEBIOSSETUP	48
+#define BDOOR_CMD_LAZYTIMEREMULATION    49
+#define BDOOR_CMD_BIOSBBS               50
+#define BDOOR_CMD_VASSERT               51
+#define BDOOR_CMD_ISGOSDARWIN           52
+#define BDOOR_CMD_DEBUGEVENT            53
+#define BDOOR_CMD_OSNOTMACOSXSERVER     54
+#define BDOOR_CMD_MAX                   55
+
+/* 
+ * IMPORTANT NOTE: When modifying the behavior of an existing backdoor command,
+ * you must adhere to the semantics expected by the oldest Tools who use that
+ * command. Specifically, do not alter the way in which the command modifies 
+ * the registers. Otherwise backwards compatibility will suffer.
+ */
+
+/* High-bandwidth backdoor port. --hpreg */
+
+#define BDOORHB_PORT 0x5659
+
+#define BDOORHB_CMD_MESSAGE 0
+#define BDOORHB_CMD_VASSERT 1
+#define BDOORHB_CMD_MAX 2
+
+/*
+ * There is another backdoor which allows access to certain TSC-related
+ * values using otherwise illegal PMC indices when the pseudo_perfctr
+ * control flag is set.
+ */
+
+#define BDOOR_PMC_HW_TSC      0x10000
+#define BDOOR_PMC_REAL_NS     0x10001
+#define BDOOR_PMC_APPARENT_NS 0x10002
+
+#define IS_BDOOR_PMC(index)  (((index) | 3) == 0x10003)
+#define BDOOR_CMD(ecx)       ((ecx) & 0xffff)
+
+
+#ifdef VMM
+/*
+ *----------------------------------------------------------------------
+ *
+ * Backdoor_CmdRequiresFullyValidVCPU --
+ *
+ *    A few backdoor commands require the full VCPU to be valid
+ *    (including GDTR, IDTR, TR and LDTR). The rest get read/write
+ *    access to GPRs and read access to Segment registers (selectors).
+ *
+ * Result:
+ *    True iff VECX contains a command that require the full VCPU to
+ *    be valid.
+ *
+ *----------------------------------------------------------------------
+ */
+static INLINE Bool
+Backdoor_CmdRequiresFullyValidVCPU(unsigned cmd)
+{
+   return cmd == BDOOR_CMD_RSVD0 ||
+          cmd == BDOOR_CMD_RSVD1 ||
+          cmd == BDOOR_CMD_RSVD2;
+}
+#endif
+
+#endif
--- kernel/linux-2.6.26.3/fs/vmhgfs/backdoorGcc32.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/backdoorGcc32.c	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,221 @@
+/*********************************************************
+ * Copyright (C) 2005 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * backdoorGcc32.c --
+ *
+ *      Implements the real work for guest-side backdoor for GCC, 32-bit
+ *      target (supports inline ASM, GAS syntax). The asm sections are marked
+ *      volatile since vmware can change the registers content without the
+ *      compiler knowing it.
+ *
+ *      XXX
+ *      I tried to write this more cleanly, but:
+ *        - There is no way to specify an "ebp" constraint
+ *        - "ebp" is ignored when specified as cloberred register
+ *        - gas barfs when there is more than 10 operands
+ *        - gas 2.7.2.3, depending on the order of the operands, can
+ *          mis-assemble without any warning
+ *      --hpreg
+ *
+ *      Note that the problems with gas noted above might longer be relevant
+ *      now that we've upgraded most of our compiler versions.
+ *      --rrdharan
+ */
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+#include "backdoor.h"
+#include "backdoorInt.h"
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * Backdoor_InOut --
+ *
+ *      Send a low-bandwidth basic request (16 bytes) to vmware, and return its
+ *      reply (24 bytes).
+ *
+ * Results:
+ *      Host-side response returned in bp IN/OUT parameter.
+ *
+ * Side effects:
+ *      Pokes the backdoor.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+void
+Backdoor_InOut(Backdoor_proto *myBp) // IN/OUT
+{
+   uint32 dummy;
+
+   __asm__ __volatile__(
+#ifdef __PIC__
+        "pushl %%ebx"           "\n\t"
+#endif
+        "pushl %%eax"           "\n\t"
+        "movl 20(%%eax), %%edi" "\n\t"
+        "movl 16(%%eax), %%esi" "\n\t"
+        "movl 12(%%eax), %%edx" "\n\t"
+        "movl  8(%%eax), %%ecx" "\n\t"
+        "movl  4(%%eax), %%ebx" "\n\t"
+        "movl   (%%eax), %%eax" "\n\t"
+        "inl %%dx, %%eax"       "\n\t"
+        "xchgl %%eax, (%%esp)"  "\n\t"
+        "movl %%edi, 20(%%eax)" "\n\t"
+        "movl %%esi, 16(%%eax)" "\n\t"
+        "movl %%edx, 12(%%eax)" "\n\t"
+        "movl %%ecx,  8(%%eax)" "\n\t"
+        "movl %%ebx,  4(%%eax)" "\n\t"
+        "popl          (%%eax)" "\n\t"
+#ifdef __PIC__
+        "popl %%ebx"            "\n\t"
+#endif
+      : "=a" (dummy)
+      : "0" (myBp)
+      /*
+       * vmware can modify the whole VM state without the compiler knowing
+       * it. So far it does not modify EFLAGS. --hpreg
+       */
+      :
+#ifndef __PIC__
+        "ebx",
+#endif
+        "ecx", "edx", "esi", "edi", "memory"
+   );
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * BackdoorHbIn  --
+ * BackdoorHbOut --
+ *
+ *      Send a high-bandwidth basic request to vmware, and return its
+ *      reply.
+ *
+ * Results:
+ *      Host-side response returned in bp IN/OUT parameter.
+ *
+ * Side-effects:
+ *      Pokes the high-bandwidth backdoor port.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+void
+BackdoorHbIn(Backdoor_proto_hb *myBp) // IN/OUT
+{
+   uint32 dummy;
+
+   __asm__ __volatile__(
+#ifdef __PIC__
+        "pushl %%ebx"           "\n\t"
+#endif
+        "pushl %%ebp"           "\n\t"
+
+        "pushl %%eax"           "\n\t"
+        "movl 24(%%eax), %%ebp" "\n\t"
+        "movl 20(%%eax), %%edi" "\n\t"
+        "movl 16(%%eax), %%esi" "\n\t"
+        "movl 12(%%eax), %%edx" "\n\t"
+        "movl  8(%%eax), %%ecx" "\n\t"
+        "movl  4(%%eax), %%ebx" "\n\t"
+        "movl   (%%eax), %%eax" "\n\t"
+        "cld"                   "\n\t"
+        "rep; insb"             "\n\t"
+        "xchgl %%eax, (%%esp)"  "\n\t"
+        "movl %%ebp, 24(%%eax)" "\n\t"
+        "movl %%edi, 20(%%eax)" "\n\t"
+        "movl %%esi, 16(%%eax)" "\n\t"
+        "movl %%edx, 12(%%eax)" "\n\t"
+        "movl %%ecx,  8(%%eax)" "\n\t"
+        "movl %%ebx,  4(%%eax)" "\n\t"
+        "popl          (%%eax)" "\n\t"
+
+        "popl %%ebp"            "\n\t"
+#ifdef __PIC__
+        "popl %%ebx"            "\n\t"
+#endif
+      : "=a" (dummy)
+      : "0" (myBp)
+      /*
+       * vmware can modify the whole VM state without the compiler knowing
+       * it. --hpreg
+       */
+      : 
+#ifndef __PIC__
+        "ebx", 
+#endif
+        "ecx", "edx", "esi", "edi", "memory", "cc"
+   );
+}
+
+
+void
+BackdoorHbOut(Backdoor_proto_hb *myBp) // IN/OUT
+{
+   uint32 dummy;
+
+   __asm__ __volatile__(
+#ifdef __PIC__
+        "pushl %%ebx"           "\n\t"
+#endif
+        "pushl %%ebp"           "\n\t"
+
+        "pushl %%eax"           "\n\t"
+        "movl 24(%%eax), %%ebp" "\n\t"
+        "movl 20(%%eax), %%edi" "\n\t"
+        "movl 16(%%eax), %%esi" "\n\t"
+        "movl 12(%%eax), %%edx" "\n\t"
+        "movl  8(%%eax), %%ecx" "\n\t"
+        "movl  4(%%eax), %%ebx" "\n\t"
+        "movl   (%%eax), %%eax" "\n\t"
+        "cld"                   "\n\t"
+        "rep; outsb"            "\n\t"
+        "xchgl %%eax, (%%esp)"  "\n\t"
+        "movl %%ebp, 24(%%eax)" "\n\t"
+        "movl %%edi, 20(%%eax)" "\n\t"
+        "movl %%esi, 16(%%eax)" "\n\t"
+        "movl %%edx, 12(%%eax)" "\n\t"
+        "movl %%ecx,  8(%%eax)" "\n\t"
+        "movl %%ebx,  4(%%eax)" "\n\t"
+        "popl          (%%eax)" "\n\t"
+
+        "popl %%ebp"            "\n\t"
+#ifdef __PIC__
+        "popl %%ebx"            "\n\t"
+#endif
+      : "=a" (dummy)
+      : "0" (myBp)
+      :
+#ifndef __PIC__
+        "ebx",
+#endif
+        "ecx", "edx", "esi", "edi", "memory", "cc"
+   );
+}
+
+#ifdef __cplusplus
+}
+#endif
+
--- kernel/linux-2.6.26.3/fs/vmhgfs/backdoorGcc64.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/backdoorGcc64.c	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,185 @@
+/*********************************************************
+ * Copyright (C) 2005 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * backdoorGcc64.c --
+ *
+ *      Implements the real work for guest-side backdoor for GCC, 64-bit
+ *      target (supports inline ASM, GAS syntax). The asm sections are marked
+ *      volatile since vmware can change the registers content without the
+ *      compiler knowing it.
+ *
+ *      See backdoorGCC32.c (from which this code was mostly copied) for
+ *      details on why the ASM is written this way. Also note that it might be
+ *      possible to write the asm blocks using the symbolic operand specifiers
+ *      in such a way that the same asm would generate correct code for both
+ *      32-bit and 64-bit targets, but I'm too lazy to figure it all out.
+ *      --rrdharan
+ */
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+#include "backdoor.h"
+#include "backdoorInt.h"
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * Backdoor_InOut --
+ *
+ *      Send a low-bandwidth basic request (16 bytes) to vmware, and return its
+ *      reply (24 bytes).
+ *
+ * Results:
+ *      Host-side response returned in bp IN/OUT parameter.
+ *
+ * Side effects:
+ *      Pokes the backdoor.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+void
+Backdoor_InOut(Backdoor_proto *myBp) // IN/OUT
+{
+   uint64 dummy;
+
+   __asm__ __volatile__(
+        "pushq %%rax"           "\n\t"
+        "movq 40(%%rax), %%rdi" "\n\t"
+        "movq 32(%%rax), %%rsi" "\n\t"
+        "movq 24(%%rax), %%rdx" "\n\t"
+        "movq 16(%%rax), %%rcx" "\n\t"
+        "movq  8(%%rax), %%rbx" "\n\t"
+        "movq   (%%rax), %%rax" "\n\t"
+        "inl %%dx, %%eax"       "\n\t"  /* NB: There is no inq instruction */
+        "xchgq %%rax, (%%rsp)"  "\n\t"
+        "movq %%rdi, 40(%%rax)" "\n\t"
+        "movq %%rsi, 32(%%rax)" "\n\t"
+        "movq %%rdx, 24(%%rax)" "\n\t"
+        "movq %%rcx, 16(%%rax)" "\n\t"
+        "movq %%rbx,  8(%%rax)" "\n\t"
+        "popq          (%%rax)"
+      : "=a" (dummy)
+      : "0" (myBp)
+      /*
+       * vmware can modify the whole VM state without the compiler knowing
+       * it. So far it does not modify EFLAGS. --hpreg
+       */
+      : "rbx", "rcx", "rdx", "rsi", "rdi", "memory"
+   );
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * BackdoorHbIn  --
+ * BackdoorHbOut --
+ *
+ *      Send a high-bandwidth basic request to vmware, and return its
+ *      reply.
+ *
+ * Results:
+ *      Host-side response returned in bp IN/OUT parameter.
+ *
+ * Side-effects:
+ *      Pokes the high-bandwidth backdoor port.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+void
+BackdoorHbIn(Backdoor_proto_hb *myBp) // IN/OUT
+{
+   uint32 dummy;
+
+   __asm__ __volatile__(
+        "pushq %%rbp"           "\n\t"
+
+        "pushq %%rax"           "\n\t"
+        "movq 48(%%rax), %%rbp" "\n\t"
+        "movq 40(%%rax), %%rdi" "\n\t"
+        "movq 32(%%rax), %%rsi" "\n\t"
+        "movq 24(%%rax), %%rdx" "\n\t"
+        "movq 16(%%rax), %%rcx" "\n\t"
+        "movq  8(%%rax), %%rbx" "\n\t"
+        "movq   (%%rax), %%rax" "\n\t"
+        "cld"                   "\n\t"
+        "rep; insb"             "\n\t"
+        "xchgq %%rax, (%%rsp)"  "\n\t"
+        "movq %%rbp, 48(%%rax)" "\n\t"
+        "movq %%rdi, 40(%%rax)" "\n\t"
+        "movq %%rsi, 32(%%rax)" "\n\t"
+        "movq %%rdx, 24(%%rax)" "\n\t"
+        "movq %%rcx, 16(%%rax)" "\n\t"
+        "movq %%rbx,  8(%%rax)" "\n\t"
+        "popq          (%%rax)" "\n\t"
+
+        "popq %%rbp"
+      : "=a" (dummy)
+      : "0" (myBp)
+      /*
+       * vmware can modify the whole VM state without the compiler knowing
+       * it. --hpreg
+       */
+      : "rbx", "rcx", "rdx", "rsi", "rdi", "memory", "cc"
+   );
+}
+
+
+void
+BackdoorHbOut(Backdoor_proto_hb *myBp) // IN/OUT
+{
+   uint64 dummy;
+
+   __asm__ __volatile__(
+        "pushq %%rbp"           "\n\t"
+
+        "pushq %%rax"           "\n\t"
+        "movq 48(%%rax), %%rbp" "\n\t"
+        "movq 40(%%rax), %%rdi" "\n\t"
+        "movq 32(%%rax), %%rsi" "\n\t"
+        "movq 24(%%rax), %%rdx" "\n\t"
+        "movq 16(%%rax), %%rcx" "\n\t"
+        "movq  8(%%rax), %%rbx" "\n\t"
+        "movq   (%%rax), %%rax" "\n\t"
+        "cld"                   "\n\t"
+        "rep; outsb"            "\n\t"
+        "xchgq %%rax, (%%rsp)"  "\n\t"
+        "movq %%rbp, 48(%%rax)" "\n\t"
+        "movq %%rdi, 40(%%rax)" "\n\t"
+        "movq %%rsi, 32(%%rax)" "\n\t"
+        "movq %%rdx, 24(%%rax)" "\n\t"
+        "movq %%rcx, 16(%%rax)" "\n\t"
+        "movq %%rbx,  8(%%rax)" "\n\t"
+        "popq          (%%rax)" "\n\t"
+
+        "popq %%rbp"
+      : "=a" (dummy)
+      : "0" (myBp)
+      : "rbx", "rcx", "rdx", "rsi", "rdi", "memory", "cc"
+   );
+}
+
+
+#ifdef __cplusplus
+}
+#endif
--- kernel/linux-2.6.26.3/fs/vmhgfs/backdoor.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/backdoor.h	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,46 @@
+/*********************************************************
+ * Copyright (C) 1999 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * backdoor.h --
+ *
+ *    First layer of the internal communication channel between guest
+ *    applications and vmware
+ */
+
+#ifndef _BACKDOOR_H_
+#define _BACKDOOR_H_
+
+#include "vm_basic_types.h"
+#include "vm_assert.h"
+
+#include "backdoor_types.h"
+
+void
+Backdoor(Backdoor_proto *bp); // IN/OUT
+
+void 
+Backdoor_InOut(Backdoor_proto *bp); // IN/OUT
+
+void
+Backdoor_HbOut(Backdoor_proto_hb *bp); // IN/OUT
+
+void
+Backdoor_HbIn(Backdoor_proto_hb *bp); // IN/OUT
+
+#endif /* _BACKDOOR_H_ */
--- kernel/linux-2.6.26.3/fs/vmhgfs/backdoorInt.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/backdoorInt.h	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,26 @@
+/*********************************************************
+ * Copyright (C) 2005 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * backdoorInt.h --
+ *
+ *      Internal function prototypes for the real backdoor work.
+ */
+
+void BackdoorHbIn(Backdoor_proto_hb *bp);
+void BackdoorHbOut(Backdoor_proto_hb *bp);
--- kernel/linux-2.6.26.3/fs/vmhgfs/backdoor_types.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/backdoor_types.h	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,118 @@
+/*********************************************************
+ * Copyright (C) 1999 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * backdoor_types.h --
+ *
+ *    Type definitions for backdoor interaction code.
+ */
+
+#ifndef _BACKDOOR_TYPES_H_
+#define _BACKDOOR_TYPES_H_
+
+#ifndef VM_I386
+#error The backdoor protocol is only supported on x86 architectures.
+#endif
+
+/*
+ * These #defines are intended for defining register structs as part of
+ * existing named unions. If the union should encapsulate the register
+ * (and nothing else), use DECLARE_REG_NAMED_STRUCT defined below.
+ */
+
+#define DECLARE_REG32_STRUCT \
+   struct { \
+      uint16 low; \
+      uint16 high; \
+   } halfs; \
+   uint32 word
+
+#define DECLARE_REG64_STRUCT \
+   DECLARE_REG32_STRUCT; \
+   struct { \
+      uint32 low; \
+      uint32 high; \
+   } words; \
+   uint64 quad
+
+#ifndef VM_X86_64
+#define DECLARE_REG_STRUCT DECLARE_REG32_STRUCT
+#else
+#define DECLARE_REG_STRUCT DECLARE_REG64_STRUCT
+#endif
+
+#define DECLARE_REG_NAMED_STRUCT(_r) \
+   union { DECLARE_REG_STRUCT; } _r
+
+/*
+ * Some of the registers are expressed by semantic name, because if they were
+ * expressed as register structs declared above, we could only address them
+ * by fixed size (half-word, word, quad, etc.) instead of by varying size
+ * (size_t, uintptr_t).
+ *
+ * To be cleaner, these registers are expressed ONLY by semantic name,
+ * rather than by a union of the semantic name and a register struct.
+ */
+typedef union {
+   struct {
+      DECLARE_REG_NAMED_STRUCT(ax);
+      size_t size; /* Register bx. */
+      DECLARE_REG_NAMED_STRUCT(cx);
+      DECLARE_REG_NAMED_STRUCT(dx);
+      DECLARE_REG_NAMED_STRUCT(si);
+      DECLARE_REG_NAMED_STRUCT(di);
+   } in;
+   struct {
+      DECLARE_REG_NAMED_STRUCT(ax);
+      DECLARE_REG_NAMED_STRUCT(bx);
+      DECLARE_REG_NAMED_STRUCT(cx);
+      DECLARE_REG_NAMED_STRUCT(dx);
+      DECLARE_REG_NAMED_STRUCT(si);
+      DECLARE_REG_NAMED_STRUCT(di);
+   } out;
+} Backdoor_proto;
+
+typedef union {
+   struct {
+      DECLARE_REG_NAMED_STRUCT(ax);
+      DECLARE_REG_NAMED_STRUCT(bx);
+      size_t size; /* Register cx. */
+      DECLARE_REG_NAMED_STRUCT(dx);
+      uintptr_t srcAddr; /* Register si. */
+      uintptr_t dstAddr; /* Register di. */
+      DECLARE_REG_NAMED_STRUCT(bp);
+   } in;
+   struct {
+      DECLARE_REG_NAMED_STRUCT(ax);
+      DECLARE_REG_NAMED_STRUCT(bx);
+      DECLARE_REG_NAMED_STRUCT(cx);
+      DECLARE_REG_NAMED_STRUCT(dx);
+      DECLARE_REG_NAMED_STRUCT(si);
+      DECLARE_REG_NAMED_STRUCT(di);
+      DECLARE_REG_NAMED_STRUCT(bp);
+   } out;
+} Backdoor_proto_hb;
+
+MY_ASSERTS(BACKDOOR_STRUCT_SIZES,
+           ASSERT_ON_COMPILE(sizeof(Backdoor_proto) == 6 * sizeof(uintptr_t));
+           ASSERT_ON_COMPILE(sizeof(Backdoor_proto_hb) == 7 * sizeof(uintptr_t));
+)
+
+#undef DECLARE_REG_STRUCT
+
+#endif /* _BACKDOOR_TYPES_H_ */
--- kernel/linux-2.6.26.3/fs/vmhgfs/bdhandler.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/bdhandler.c	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,311 @@
+/*********************************************************
+ * Copyright (C) 2006 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * bdhandler.c --
+ *
+ * Background thread for handling backdoor requests and replies.
+ */
+
+/* Must come before any kernel header file. */
+#include "driver-config.h"
+
+#include <asm/atomic.h>
+#include <linux/errno.h>
+#include "compat_completion.h"
+#include "compat_kernel.h"
+#include "compat_kthread.h"
+#include "compat_list.h"
+#include "compat_sched.h"
+#include "compat_semaphore.h"
+#include "compat_slab.h"
+#include "compat_spinlock.h"
+#include "compat_version.h"
+
+/* Must be included after semaphore.h. */
+#include <linux/timer.h>
+/* Must be included after sched.h. */
+#include <linux/smp_lock.h>
+
+#include "hgfsBd.h"
+#include "hgfsDevLinux.h"
+#include "hgfsProto.h"
+#include "bdhandler.h"
+#include "module.h"
+#include "request.h"
+#include "vm_assert.h"
+#include "rpcout.h"
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 9)
+int errno;  /* compat_exit() needs global errno variable. */
+#endif
+
+static inline void HgfsWakeWaitingClient(HgfsReq *req);
+static inline void HgfsCompleteReq(HgfsReq *req,
+                                   char const *reply,
+                                   size_t replySize);
+static void HgfsSendUnsentReqs(void);
+
+/*
+ * Private function implementations.
+ */
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * HgfsWakeWaitingClient --
+ *
+ *    Wakes up the client process waiting for the reply to this
+ *    request.
+ *
+ * Results:
+ *    None
+ *
+ * Side effects:
+ *    None
+ *
+ *----------------------------------------------------------------------
+ */
+
+static inline void
+HgfsWakeWaitingClient(HgfsReq *req)  // IN: Request
+{
+   ASSERT(req);
+   wake_up(&req->queue);
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * HgfsCompleteReq --
+ *
+ *    Copies the reply packet into the request structure and wakes up
+ *    the associated client.
+ *
+ * Results:
+ *    None
+ *
+ * Side effects:
+ *    None
+ *
+ *----------------------------------------------------------------------
+ */
+
+static inline void
+HgfsCompleteReq(HgfsReq *req,       // IN: Request
+                char const *reply,  // IN: Reply packet
+                size_t replySize)   // IN: Size of reply packet
+{
+   ASSERT(replySize <= HGFS_PACKET_MAX);
+
+   memcpy(HGFS_REQ_PAYLOAD(req), reply, replySize);
+   req->payloadSize = replySize;
+   req->state = HGFS_REQ_STATE_COMPLETED;
+   list_del_init(&req->list);
+   HgfsWakeWaitingClient(req);
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * HgfsSendUnsentReqs --
+ *
+ *      Process the unsent list and send requests to the backdoor.
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static void
+HgfsSendUnsentReqs(void)
+{
+   char const *replyPacket;
+   struct list_head *cur, *tmp;
+   HgfsReq *req;
+   size_t payloadSize;
+
+   spin_lock(&hgfsBigLock);
+   list_for_each_safe(cur, tmp, &hgfsReqsUnsent) {
+      req = list_entry(cur, HgfsReq, list);
+
+      /*
+       * A big "wtf" from the driver is in order. Perhaps by "wtf" I really
+       * mean BUG_ON().
+       */
+      ASSERT(req->state == HGFS_REQ_STATE_UNSENT);
+      if (req->state != HGFS_REQ_STATE_UNSENT) {
+         LOG(2, (KERN_DEBUG "VMware hgfs: HgfsSendUnsentReqs: Found request "
+                 "on unsent list in the wrong state, ignoring\n"));
+         continue;
+      }
+
+      ASSERT(req->payloadSize <= HGFS_PACKET_MAX);
+      payloadSize = req->payloadSize;
+      LOG(8, (KERN_DEBUG "VMware hgfs: HgfsSendUnsentReqs: Sending packet "
+              "over backdoor\n"));
+
+      /*
+       * We should attempt to reopen the backdoor channel with every request,
+       * because the HGFS server in the host can be enabled or disabled at any
+       * time.
+       */
+      if (!HgfsBd_OpenBackdoor(&hgfsRpcOut)) {
+         req->state = HGFS_REQ_STATE_ERROR;
+         list_del_init(&req->list);
+         printk(KERN_WARNING "VMware hgfs: HGFS is disabled in the host\n");
+         HgfsWakeWaitingClient(req);
+      } else if (HgfsBd_Dispatch(hgfsRpcOut, HGFS_REQ_PAYLOAD(req),
+                                 &payloadSize, &replyPacket) == 0) {
+
+         /* Request sent successfully. Copy the reply and wake the client. */
+         HgfsCompleteReq(req, replyPacket, payloadSize);
+         LOG(8, (KERN_DEBUG "VMware hgfs: HgfsSendUnsentReqs: Backdoor "
+                 "reply received\n"));
+      } else {
+
+         /* Pass the error into the request. */
+         req->state = HGFS_REQ_STATE_ERROR;
+         list_del_init(&req->list);
+         LOG(8, (KERN_DEBUG "VMware hgfs: HgfsSendUnsentReqs: Backdoor "
+                 "error\n"));
+         HgfsWakeWaitingClient(req);
+
+         /*
+          * If the channel was previously open, make sure it's dead and gone
+          * now. We do this because subsequent requests deserve a chance to
+          * reopen it.
+          */
+         HgfsBd_CloseBackdoor(&hgfsRpcOut);
+      }
+   }
+   spin_unlock(&hgfsBigLock);
+}
+
+
+/*
+ * Public function implementations.
+ */
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * HgfsResetOps --
+ *
+ *      Reset ops with more than one opcode back to the desired opcode.
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+void
+HgfsResetOps(void)
+{
+   atomic_set(&hgfsVersionOpen, HGFS_OP_OPEN_V3);
+   atomic_set(&hgfsVersionRead, HGFS_OP_READ_V3);
+   atomic_set(&hgfsVersionWrite, HGFS_OP_WRITE_V3);
+   atomic_set(&hgfsVersionClose, HGFS_OP_CLOSE_V3);
+   atomic_set(&hgfsVersionSearchOpen, HGFS_OP_SEARCH_OPEN_V3);
+   atomic_set(&hgfsVersionSearchRead, HGFS_OP_SEARCH_READ_V3);
+   atomic_set(&hgfsVersionSearchClose, HGFS_OP_SEARCH_CLOSE_V3);
+   atomic_set(&hgfsVersionGetattr, HGFS_OP_GETATTR_V3);
+   atomic_set(&hgfsVersionSetattr, HGFS_OP_SETATTR_V3);
+   atomic_set(&hgfsVersionCreateDir, HGFS_OP_CREATE_DIR_V3);
+   atomic_set(&hgfsVersionDeleteFile, HGFS_OP_DELETE_FILE_V3);
+   atomic_set(&hgfsVersionDeleteDir, HGFS_OP_DELETE_DIR_V3);
+   atomic_set(&hgfsVersionRename, HGFS_OP_RENAME_V3);
+   atomic_set(&hgfsVersionQueryVolumeInfo, HGFS_OP_QUERY_VOLUME_INFO_V3);
+   atomic_set(&hgfsVersionCreateSymlink, HGFS_OP_CREATE_SYMLINK_V3);
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * HgfsBdHandler --
+ *
+ *    Function run in background thread to pick up HGFS requests from
+ *    the filesystem half of the driver, send them over the backdoor,
+ *    get replies, and send them back to the filesystem.
+ *
+ *    Note that this function is called out of the kthread subsystem or, in
+ *    older kernels, a similar abstraction built in compat_kthread.h.
+ *
+ * Results:
+ *    Always returns zero.
+ *
+ * Side effects:
+ *    Processes entries from hgfsReqQ.
+ *
+ *----------------------------------------------------------------------
+ */
+
+int
+HgfsBdHandler(void *data) // Ignored
+{
+   LOG(6, (KERN_DEBUG "VMware hgfs: HgfsBdHandler: Thread starting\n"));
+   compat_set_freezable();
+
+   for (;;) {
+
+      /* Sleep, waiting for a request or exit. */
+      wait_event_interruptible(hgfsReqThreadWait,
+                               test_bit(HGFS_REQ_THREAD_SEND,
+                                        &hgfsReqThreadFlags) ||
+                               compat_kthread_should_stop());
+
+      /*
+       * First, check for suspend. I'm not convinced that this actually
+       * has to come first, but whatever.
+       */
+      if (compat_try_to_freeze()) {
+	 LOG(6, (KERN_DEBUG
+		 "VMware hgfs: HgfsBdHandler: Closing backdoor after resume\n"));
+	 HgfsBd_CloseBackdoor(&hgfsRpcOut);
+      }
+
+      /* Send outgoing requests. */
+      if (test_and_clear_bit(HGFS_REQ_THREAD_SEND, &hgfsReqThreadFlags)) {
+         LOG(8, (KERN_DEBUG "VMware hgfs: HgfsBdHandler: Sending requests\n"));
+         HgfsSendUnsentReqs();
+      }
+
+      /* Kill yourself. */
+      if (compat_kthread_should_stop()) {
+         LOG(6, (KERN_DEBUG "VMware hgfs: HgfsBdHandler: Told to exit\n"));
+         break;
+      }
+   }
+
+   LOG(6, (KERN_DEBUG "VMware hgfs: HgfsBdHandler: Closing backdoor\n"));
+   HgfsBd_CloseBackdoor(&hgfsRpcOut);
+
+   LOG(6, (KERN_DEBUG "VMware hgfs: HgfsBdHandler: Thread exiting\n"));
+   return 0;
+}
--- kernel/linux-2.6.26.3/fs/vmhgfs/bdhandler.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/bdhandler.h	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,32 @@
+/*********************************************************
+ * Copyright (C) 2006 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * bdhandler.h --
+ *
+ * Background thread for handling backdoor requests and replies.
+ */
+
+#ifndef _HGFS_DRIVER_BDHANDLER_H_
+#define _HGFS_DRIVER_BDHANDLER_H_
+
+/* Public functions (with respect to the entire module). */
+void HgfsResetOps(void);
+int HgfsBdHandler(void *data);
+
+#endif // _HGFS_DRIVER_BDHANDLER_H_
--- kernel/linux-2.6.26.3/fs/vmhgfs/compat_completion.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/compat_completion.h	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,175 @@
+/*********************************************************
+ * Copyright (C) 2004 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_COMPLETION_H__
+#   define __COMPAT_COMPLETION_H__
+
+/*
+ * The kernel's completion objects were made available for module use in 2.4.9.
+ * 
+ * Between 2.4.0 and 2.4.9, we implement completions on our own using 
+ * waitqueues and counters. This was done so that we could safely support
+ * functions like complete_all(), which cannot be implemented using semaphores.
+ *
+ * Prior to that, the waitqueue API is substantially different, and since none 
+ * of our modules that are built against older kernels need complete_all(), 
+ * we fallback on a simple semaphore-based implementation. 
+ */
+
+/* 
+ * Native completions.
+ */ 
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 4, 9)
+
+#include <linux/completion.h>
+#define compat_completion struct completion
+#define compat_init_completion(comp) init_completion(comp)
+#define COMPAT_DECLARE_COMPLETION DECLARE_COMPLETION
+#define compat_wait_for_completion(comp) wait_for_completion(comp)
+#define compat_complete(comp) complete(comp)
+
+/* complete_all() was exported in 2.6.6. */
+# if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 6)
+#  include "compat_wait.h"
+#  include "compat_list.h"
+#  include "compat_spinlock.h"
+#  include "compat_sched.h"
+#  define compat_complete_all(x)         \
+      ({                                 \
+          struct list_head *currLinks;   \
+          spin_lock(&(x)->wait.lock);    \
+          (x)->done += UINT_MAX/2;       \
+                                         \
+          list_for_each(currLinks, &(x)->wait.task_list) { \
+             wait_queue_t *currQueue = list_entry(currLinks, wait_queue_t, task_list); \
+             wake_up_process(currQueue->task); \
+          }                              \
+          spin_unlock(&(x)->wait.lock);  \
+      })
+# else
+#  define compat_complete_all complete_all
+# endif
+
+/* 
+ * Completions via waitqueues.
+ */
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(2, 4, 0)
+
+/*
+ * Kernel completions in 2.4.9 and beyond use a counter and a waitqueue, and 
+ * our implementation is quite similar. Because __wake_up_common() is not 
+ * exported, our implementations of compat_complete() and compat_complete_all()
+ * are somewhat racy: the counter is incremented outside of the waitqueue's 
+ * lock. 
+ *
+ * As a result, our completion cannot guarantee in-order wake ups. For example,
+ * suppose thread A is entering compat_complete(), thread B is sleeping inside
+ * compat_wait_for_completion(), and thread C is just now entering
+ * compat_wait_for_completion(). If Thread A is scheduled first and increments 
+ * the counter, then gets swapped out, thread C may get scheduled and will 
+ * quickly go through compat_wait_for_completion() (since done != 0) while 
+ * thread B continues to sleep, even though thread B should have been the one 
+ * to wake up.
+ */
+
+#include <asm/current.h>
+#include "compat_sched.h"
+#include "compat_list.h"
+#include <linux/smp_lock.h> // for lock_kernel()/unlock_kernel()
+#include "compat_wait.h"
+
+typedef struct compat_completion {
+   unsigned int done;
+   wait_queue_head_t wq;
+} compat_completion;
+
+#define compat_init_completion(comp) do { \
+   (comp)->done = 0; \
+   init_waitqueue_head(&(comp)->wq); \
+} while (0)
+#define COMPAT_DECLARE_COMPLETION(comp) \
+   compat_completion comp = { \
+     .done = 0, \
+     .wq = __WAIT_QUEUE_HEAD_INITIALIZER((comp).wq), \
+   }
+
+/*
+ * Locking and unlocking the kernel lock here ensures that the thread
+ * is no longer running in module code: compat_complete_and_exit
+ * performs the sequence { lock_kernel(); up(comp); compat_exit(); }, with
+ * the final unlock_kernel performed implicitly by the resident kernel
+ * in do_exit.
+ */
+#define compat_wait_for_completion(comp) do { \
+   spin_lock_irq(&(comp)->wq.lock); \
+   if (!(comp)->done) { \
+      DECLARE_WAITQUEUE(wait, current); \
+      wait.flags |= WQ_FLAG_EXCLUSIVE; \
+      __add_wait_queue_tail(&(comp)->wq, &wait); \
+      do { \
+         __set_current_state(TASK_UNINTERRUPTIBLE); \
+         spin_unlock_irq(&(comp)->wq.lock); \
+         schedule(); \
+         spin_lock_irq(&(comp)->wq.lock); \
+      } while (!(comp)->done); \
+      __remove_wait_queue(&(comp)->wq, &wait); \
+   } \
+   (comp)->done--; \
+   spin_unlock_irq(&(comp)->wq.lock); \
+   lock_kernel(); \
+   unlock_kernel(); \
+} while (0)
+
+/* XXX: I don't think I need to touch the BKL. */
+#define compat_complete(comp) do { \
+   unsigned long flags; \
+   spin_lock_irqsave(&(comp)->wq.lock, flags); \
+   (comp)->done++; \
+   spin_unlock_irqrestore(&(comp)->wq.lock, flags); \
+   wake_up(&(comp)->wq); \
+} while (0)
+
+#define compat_complete_all(comp) do { \
+   unsigned long flags; \
+   spin_lock_irqsave(&(comp)->wq.lock, flags); \
+   (comp)->done += UINT_MAX / 2; \
+   spin_unlock_irqrestore(&(comp)->wq.lock, flags); \
+   wake_up_all(&(comp)->wq); \
+} while (0)
+
+/*
+ * Completions via semaphores.
+ */ 
+#else
+
+#include "compat_semaphore.h"
+#define compat_completion struct semaphore 
+#define compat_init_completion(comp) init_MUTEX_LOCKED(comp)
+#define COMPAT_DECLARE_COMPLETION(comp) DECLARE_MUTEX_LOCKED(comp) 
+
+#define compat_wait_for_completion(comp) do { \
+   down(comp); \
+   lock_kernel(); \
+   unlock_kernel(); \
+} while (0)
+
+#define compat_complete(comp) up(comp)
+
+#endif
+
+#endif /* __COMPAT_COMPLETION_H__ */
--- kernel/linux-2.6.26.3/fs/vmhgfs/compat_dcache.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/compat_dcache.h	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,51 @@
+/*********************************************************
+ * Copyright (C) 2006 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_DCACHE_H__
+#   define __COMPAT_DCACHE_H__
+
+#include <linux/dcache.h>
+
+/*
+ * per-dentry locking was born in 2.5.62.
+ */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 5, 62)
+#define compat_lock_dentry(dentry) spin_lock(&dentry->d_lock) 
+#define compat_unlock_dentry(dentry) spin_unlock(&dentry->d_lock)
+#else
+#define compat_lock_dentry(dentry) do {} while (0)
+#define compat_unlock_dentry(dentry) do {} while (0)
+#endif
+
+/*
+ * d_alloc_name was born in 2.6.10.
+ */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 10)
+#define compat_d_alloc_name(parent, s) d_alloc_name(parent, s)
+#else
+#define compat_d_alloc_name(parent, s)                                        \
+({                                                                            \
+   struct qstr q;                                                             \
+   q.name = s;                                                                \
+   q.len = strlen(s);                                                         \
+   q.hash = full_name_hash(q.name, q.len);                                    \
+   d_alloc(parent, &q);                                                       \
+})
+#endif
+
+#endif /* __COMPAT_DCACHE_H__ */
--- kernel/linux-2.6.26.3/fs/vmhgfs/compat_file.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/compat_file.h	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,56 @@
+/*********************************************************
+ * Copyright (C) 2002 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_FILE_H__
+#   define __COMPAT_FILE_H__
+
+
+/* The fput() API is modified in 2.2.0 --hpreg */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 2, 0)
+#   define compat_fput(_file) fput(_file)
+#else
+#   define compat_fput(_file) fput(_file, (_file)->f_inode)
+#endif
+
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 4, 0)
+#   define compat_get_file(_file) get_file(_file)
+#   define compat_file_count(_file) file_count(_file)
+#else
+#   define compat_get_file(_file) (_file)->f_count++
+#   define compat_file_count(_file) (_file)->f_count
+#endif
+
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 2, 4)
+#   define compat_filp_close(_file, _files) filp_close(_file, _files)
+#else
+static inline void compat_filp_close(struct file* filp, fl_owner_t files) {
+   if (filp->f_op && filp->f_op->flush) {
+      filp->f_op->flush(filp);
+   }
+   /*
+    * Hopefully there are no locks to release on this filp. 
+    * locks_remove_posix is not exported so we cannot use it...
+    */
+   fput(filp);
+}
+#endif
+
+
+#endif /* __COMPAT_FILE_H__ */
--- kernel/linux-2.6.26.3/fs/vmhgfs/compat_fs.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/compat_fs.h	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,247 @@
+/*********************************************************
+ * Copyright (C) 2006 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_FS_H__
+#   define __COMPAT_FS_H__
+
+#include <linux/fs.h>
+
+/*
+ * 2.6.5+ kernels define FS_BINARY_MOUNTDATA. Since it didn't exist and
+ * wasn't used prior, it's safe to define it to zero.
+ */
+
+#ifndef FS_BINARY_MOUNTDATA
+#define FS_BINARY_MOUNTDATA 0
+#endif
+
+/*
+ * MAX_LFS_FILESIZE wasn't defined until 2.5.4.
+ */
+#ifndef MAX_LFS_FILESIZE
+#   include <linux/pagemap.h>
+#   if BITS_PER_LONG == 32
+#      define MAX_LFS_FILESIZE       (((u64)PAGE_CACHE_SIZE << (BITS_PER_LONG - 1)) - 1)
+#   elif BITS_PER_LONG == 64
+#      define MAX_LFS_FILESIZE       0x7fffffffffffffffUL
+#   endif
+#endif
+
+
+/*
+ * sendfile as a VFS op was born in 2.5.30. Unfortunately, it also changed
+ * signatures, first in 2.5.47, then again in 2.5.70, then again in 2.6.8.
+ * Luckily, the 2.6.8+ signature is the same as the 2.5.47 signature.  And
+ * as of 2.6.23-rc1 sendfile is gone, replaced by splice_read...
+ *
+ * Let's not support sendfile from 2.5.30 to 2.5.47, because the 2.5.30
+ * signature is much different and file_send_actor isn't externed.
+ */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 23)
+#define VMW_SENDFILE_NONE
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 8)
+#define VMW_SENDFILE_NEW
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(2, 5, 70)
+#define VMW_SENDFILE_OLD
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(2, 5, 47)
+#define VMW_SENDFILE_NEW
+#else
+#define VMW_SENDFILE_NONE
+#endif
+
+/*
+ * splice_read is there since 2.6.17, but let's avoid 2.6.17-rcX kernels...
+ * After all nobody is using splice system call until 2.6.23 using it to
+ * implement sendfile.
+ */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 18)
+#define VMW_SPLICE_READ 1
+#endif
+
+/*
+ * Filesystems wishing to use generic page cache read/write routines are
+ * supposed to implement aio_read and aio_write (calling into
+ * generic_file_aio_read() and generic_file_aio_write() if necessary).
+ *
+ * The VFS exports do_sync_read() and do_sync_write() as the "new"
+ * generic_file_read() and generic_file_write(), but filesystems need not
+ * actually implement read and write- the VFS will automatically call
+ * do_sync_write() and do_sync_read() when applications invoke the standard
+ * read() and write() system calls.
+ *
+ * In 2.6.19, generic_file_read() and generic_file_write() were removed,
+ * necessitating this change. AIO dates as far back as 2.5.42, but the API has
+ * changed over time, so for simplicity, we'll only enable it from 2.6.19 and
+ * on.
+ */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 19)
+# define VMW_USE_AIO
+#endif
+
+
+/*
+ * The alloc_inode and destroy_inode VFS ops didn't exist prior to 2.4.21.
+ * Without these functions, file systems can't embed inodes.
+ */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 4, 21)
+# define VMW_EMBED_INODE
+#endif
+
+
+/*
+ * iget() was removed from the VFS as of 2.6.25-rc1. The replacement for iget()
+ * is iget_locked() which was added in 2.5.17.
+ */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 5, 17)
+# define VMW_USE_IGET_LOCKED
+#endif
+
+/*
+ * parent_ino was born in 2.5.5. For older kernels, let's use 2.5.5
+ * implementation. It uses the dcache lock which is OK because per-dentry
+ * locking appeared after 2.5.5.
+ */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 5, 5)
+#define compat_parent_ino(dentry) parent_ino(dentry)
+#else
+#define compat_parent_ino(dentry)                                             \
+({                                                                            \
+   ino_t res;                                                                 \
+   spin_lock(&dcache_lock);                                                   \
+   res = dentry->d_parent->d_inode->i_ino;                                    \
+   spin_unlock(&dcache_lock);                                                 \
+   res;                                                                       \
+})
+#endif
+
+
+/*
+ * putname changed to __putname in 2.6.6.
+ */
+#define compat___getname() __getname()
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 6)
+#define compat___putname(name) putname(name)
+#else
+#define compat___putname(name) __putname(name)
+#endif
+
+
+/*
+ * inc_nlink, drop_nlink, and clear_nlink were added in 2.6.19.
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 19)
+#define compat_inc_nlink(inode) ((inode)->i_nlink++)
+#define compat_drop_nlink(inode) ((inode)->i_nlink--)
+#define compat_clear_nlink(inode) ((inode)->i_nlink = 0)
+#else
+#define compat_inc_nlink(inode) inc_nlink(inode)
+#define compat_drop_nlink(inode) drop_nlink(inode)
+#define compat_clear_nlink(inode) clear_nlink(inode)
+#endif
+
+
+/*
+ * i_size_write and i_size_read were introduced in 2.6.0-test1 
+ * (though we'll look for them as of 2.6.1). They employ slightly different
+ * locking in order to guarantee atomicity, depending on the length of a long,
+ * whether the kernel is SMP, or whether the kernel is preemptible. Prior to
+ * i_size_write and i_size_read, there was no such locking, so that's the
+ * behavior we'll emulate.
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 1)
+#define compat_i_size_read(inode) ((inode)->i_size)
+#define compat_i_size_write(inode, size) ((inode)->i_size = size)
+#else
+#define compat_i_size_read(inode) i_size_read(inode)
+#define compat_i_size_write(inode, size) i_size_write(inode, size)
+#endif
+
+
+/*
+ * filemap_fdatawrite was introduced in 2.5.12. Prior to that, modules used
+ * filemap_fdatasync instead. In 2.4.18, both filemap_fdatawrite and 
+ * filemap_fdatawait began returning status codes. Prior to that, they were 
+ * void functions, so we'll just have them return 0.
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 18)
+#define compat_filemap_fdatawrite(mapping)                                    \
+({                                                                            \
+   int result = 0;                                                            \
+   filemap_fdatasync(mapping);                                                \
+   result;                                                                    \
+})
+#define compat_filemap_fdatawait(mapping)                                     \
+({                                                                            \
+   int result = 0;                                                            \
+   filemap_fdatawait(mapping);                                                \
+   result;                                                                    \
+})
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 12)
+#define compat_filemap_fdatawrite(mapping) filemap_fdatasync(mapping)
+#define compat_filemap_fdatawait(mapping) filemap_fdatawait(mapping)
+#else
+#define compat_filemap_fdatawrite(mapping) filemap_fdatawrite(mapping)
+#define compat_filemap_fdatawait(mapping) filemap_fdatawait(mapping)
+#endif
+
+
+/*
+ * filemap_write_and_wait was introduced in 2.6.6 and exported for module use
+ * in 2.6.16. It's really just a simple wrapper around filemap_fdatawrite and 
+ * and filemap_fdatawait, which initiates a flush of all dirty pages, then 
+ * waits for the pages to flush. The implementation here is a simplified form 
+ * of the one found in 2.6.20-rc3.
+ *
+ * Unfortunately, it just isn't possible to implement this prior to 2.4.5, when
+ * neither filemap_fdatawait nor filemap_fdatasync were exported for module
+ * use. So we'll define it out and hope for the best.
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 5)
+#define compat_filemap_write_and_wait(mapping)
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 16)
+#define compat_filemap_write_and_wait(mapping)                                \
+({                                                                            \
+   int result = 0;                                                            \
+   if (mapping->nrpages) {                                                    \
+      result = compat_filemap_fdatawrite(mapping);                            \
+      if (result != -EIO) {                                                   \
+         int result2 = compat_filemap_fdatawait(mapping);                     \
+         if (!result) {                                                       \
+            result = result2;                                                 \
+         }                                                                    \
+      }                                                                       \
+   }                                                                          \
+   result;                                                                    \
+})
+#else
+#define compat_filemap_write_and_wait(mapping) filemap_write_and_wait(mapping)
+#endif
+
+
+/*
+ * invalidate_remote_inode was introduced in 2.6.0-test5. Prior to that, 
+ * filesystems wishing to invalidate pages belonging to an inode called 
+ * invalidate_inode_pages.
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 0)
+#define compat_invalidate_remote_inode(inode) invalidate_inode_pages(inode)
+#else
+#define compat_invalidate_remote_inode(inode) invalidate_remote_inode(inode)
+#endif
+
+#endif /* __COMPAT_FS_H__ */
--- kernel/linux-2.6.26.3/fs/vmhgfs/compat_highmem.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/compat_highmem.h	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,40 @@
+/*********************************************************
+ * Copyright (C) 2002 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_HIGHMEM_H__
+#   define __COMPAT_HIGHMEM_H__
+
+
+/*
+ *  BIGMEM  (4 GB)         support appeared in 2.3.16: kmap() API added
+ *  HIGHMEM (4 GB + 64 GB) support appeared in 2.3.23: kmap() API modified
+ *  In 2.3.27, kmap() API modified again
+ *
+ *   --hpreg
+ */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 3, 27)
+#   include <linux/highmem.h>
+#else
+/* For page_address --hpreg */
+#   include <linux/pagemap.h>
+
+#   define kmap(_page) (void*)page_address(_page)
+#   define kunmap(_page)
+#endif
+
+#endif /* __COMPAT_HIGHMEM_H__ */
--- kernel/linux-2.6.26.3/fs/vmhgfs/compat_kernel.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/compat_kernel.h	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,83 @@
+/*********************************************************
+ * Copyright (C) 2004 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_KERNEL_H__
+#   define __COMPAT_KERNEL_H__
+
+#include <asm/unistd.h>
+#include <linux/kernel.h>
+
+/*
+ * container_of was introduced in 2.5.28 but it's easier to check like this.
+ */
+#ifndef container_of
+#define container_of(ptr, type, member) ({			\
+        const typeof( ((type *)0)->member ) *__mptr = (ptr);	\
+        (type *)( (char *)__mptr - offsetof(type,member) );})
+#endif
+
+/*
+ * wait_for_completion and friends did not exist before 2.4.9.
+ */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 4, 9)
+
+#define compat_complete_and_exit(comp, status) complete_and_exit(comp, status)
+
+#else
+
+#include "compat_completion.h"
+
+/*
+ * Used by _syscallX macros. Note that this is global variable, so
+ * do not rely on its contents too much. As exit() is only function
+ * we use, and we never check return value from exit(), we have
+ * no problem...
+ */
+extern int errno;
+
+/*
+ * compat_exit() provides an access to the exit() function. It must 
+ * be named compat_exit(), as exit() (with different signature) is 
+ * provided by x86-64, arm and other (but not by i386).
+ */
+#define __NR_compat_exit __NR_exit
+static inline _syscall1(int, compat_exit, int, exit_code);
+
+/*
+ * See compat_wait_for_completion in compat_completion.h.
+ * compat_exit implicitly performs an unlock_kernel, in resident code,
+ * ensuring that the thread is no longer running in module code when the
+ * module is unloaded.
+ */
+#define compat_complete_and_exit(comp, status) do { \
+   lock_kernel(); \
+   compat_complete(comp); \
+   compat_exit(status); \
+} while (0)
+
+#endif
+
+/*
+ * vsnprintf became available in 2.4.10. For older kernels, just fall back on
+ * vsprintf.
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 10)
+#define vsnprintf(str, size, fmt, args) vsprintf(str, fmt, args)
+#endif
+
+#endif /* __COMPAT_KERNEL_H__ */
--- kernel/linux-2.6.26.3/fs/vmhgfs/compat_kthread.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/compat_kthread.h	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,223 @@
+/*********************************************************
+ * Copyright (C) 2008 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_KTHREAD_H__
+#   define __COMPAT_KTHREAD_H__
+
+/*
+ * The kthread interface for managing kernel threads appeared in 2.6.4, but was
+ * only exported for module use in 2.6.7.
+ */
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 7)
+# include <linux/kthread.h>
+
+# define COMPAT_KTHREAD_DECLARE_STOP_INFO()
+# define compat_kthread_stop(_tsk) kthread_stop(_tsk)
+# define compat_kthread_should_stop() kthread_should_stop()
+# define compat_kthread_run(_fn, _data, _namefmt, ...)                         \
+   kthread_run(_fn, _data, _namefmt, ## __VA_ARGS__)
+# define compat_kthread_create(_fn, _data, _namefmt, ...)                      \
+   kthread_create(_fn, _data, _namefmt, ## __VA_ARGS__)
+#else
+
+/*
+ * When the kthread interface isn't available, we do our best to emulate it,
+ * with a few notable exceptions:
+ *
+ * 1: We use semaphores instead of mutexes for locking, because mutexes aren't
+ *    available in kernels where kthread isn't available.
+ * 2: The real kthread interface uses the kthreadd kernel_thread to broker the
+ *    creation of new kernel threads. This makes sense because kthreadd is part
+ *    of the kernel, but doesn't make sense at all in the context of an
+ *    individual module. So in our emulation, thread creation occurs in the
+ *    context of a kthread_create call.
+ * 3: Because kthreadd is responsible for creating kernel threads in the real
+ *    kthread interface, there's no need to explicitly reparent any of them. We
+ *    aren't using kthreadd, so we call daemonize to reparent, which also sets
+ *    the name of the new kernel thread. That's why we don't set the name as
+ *    the real kthread interface does (within kthread_create). Furthermore, to
+ *    get the name to daemonize, we're forced to pass it through the
+ *    kthread_start_info struct.
+ * 4: Since our interface isn't in the kernel proper, we can't make use of
+ *    get_task_struct/put_task_struct so as to acquire references to kernel
+ *    threads that we're managing. To prevent races, we use an extra completion
+ *    when stopping kernel threads. See the comments in compat_kthread_stop for
+ *    more details.
+ *
+ * Like the real kthread interface, ours must be globally available so that we
+ * can emulate functions like kthread_should_stop without using different
+ * signatures.
+ */
+
+# include "compat_completion.h"
+# include "compat_kernel.h"
+# include "compat_sched.h"
+
+struct compat_kthread_start_info {
+   int (*fn)(void *);
+   void *data;
+   compat_completion created;
+   char comm[TASK_COMM_LEN];
+};
+
+struct compat_kthread_stop_info {
+   struct semaphore lock;
+   struct task_struct *task;
+   compat_completion woken;
+   compat_completion stopped;
+   int ret;
+};
+
+extern struct compat_kthread_stop_info compat_kthread_stop_info;
+
+# define COMPAT_KTHREAD_DECLARE_STOP_INFO()                                    \
+   struct compat_kthread_stop_info compat_kthread_stop_info = {                \
+      .lock = __SEMAPHORE_INITIALIZER(compat_kthread_stop_info.lock, 1),       \
+      .task = NULL,                                                            \
+   }
+
+
+static inline int
+compat_kthread_should_stop(void)
+{
+   return (compat_kthread_stop_info.task == current);
+}
+
+
+static inline int
+compat_kthread_stop(struct task_struct *_task)
+{
+   int ret;
+
+   down(&compat_kthread_stop_info.lock);
+
+   /*
+    * We use a write memory barrier to ensure that all CPUs see _task after
+    * the completions have been initialized.
+    *
+    * There's a race between kernel threads managed by kthread and the upcoming
+    * call to wake_up_process. If the kernel thread wakes up after we set task
+    * but before the call to wake_up_process, the thread's call to
+    * compat_kthread_should_stop will return true and the thread will exit. At
+    * that point, the call to wake_up_process will be on a dead task_struct.
+    *
+    * XXX: The real kthread interface protects against this race by grabbing
+    * and releasing a reference to _task. We don't have that luxury, because
+    * there is a range of kernels where put_task_struct isn't exported to
+    * modules. In fact, no other modules call get_task_struct or
+    * put_task_struct, so to do so from this context may be unwise. Instead,
+    * we'll use an extra completion to ensure that the kernel thread only exits
+    * after wake_up_process has been called.
+    */
+   compat_init_completion(&compat_kthread_stop_info.woken);
+   compat_init_completion(&compat_kthread_stop_info.stopped);
+   smp_wmb();
+
+   compat_kthread_stop_info.task = _task;
+   wake_up_process(_task);
+   compat_complete(&compat_kthread_stop_info.woken);
+
+   compat_wait_for_completion(&compat_kthread_stop_info.stopped);
+   compat_kthread_stop_info.task = NULL;
+   ret = compat_kthread_stop_info.ret;
+   up(&compat_kthread_stop_info.lock);
+   return ret;
+}
+
+
+# define compat_kthread_run(_fn, _data, _namefmt, ...)                         \
+({                                                                             \
+   struct task_struct *tsk;                                                    \
+   tsk = compat_kthread_create(_fn, _data, _namefmt, ## __VA_ARGS__);          \
+   if (!IS_ERR(tsk)) {                                                         \
+      wake_up_process(tsk);                                                    \
+   }                                                                           \
+   tsk;                                                                        \
+})
+
+
+static inline int
+compat_kthread(void *_data)
+{
+   int ret = -EINTR;
+   struct compat_kthread_start_info *info;
+   int (*fn)(void *data);
+   void *data;
+
+   info = (struct compat_kthread_start_info *)_data;
+   fn = info->fn;
+   data = info->data;
+
+   compat_daemonize(info->comm);
+   __set_current_state(TASK_UNINTERRUPTIBLE);
+   compat_complete(&info->created);
+   schedule();
+
+   if (!compat_kthread_should_stop()) {
+      ret = fn(data);
+   }
+
+   if (compat_kthread_should_stop()) {
+      compat_wait_for_completion(&compat_kthread_stop_info.woken);
+      compat_kthread_stop_info.ret = ret;
+      compat_complete_and_exit(&compat_kthread_stop_info.stopped, 0);
+      BUG();
+   }
+   return 0;
+}
+
+
+static inline struct task_struct *
+compat_kthread_create(int (*_fn)(void *data),
+                      void *_data,
+                      const char _namefmt[],
+                      ...)
+{
+   pid_t pid;
+   struct task_struct *task = NULL;
+   struct compat_kthread_start_info info;
+   va_list args;
+
+   info.fn = _fn;
+   info.data = _data;
+   compat_init_completion(&info.created);
+   va_start(args, _namefmt);
+   vsnprintf(info.comm, sizeof info.comm, _namefmt, args);
+   va_end(args);
+   pid = kernel_thread(compat_kthread, &info, CLONE_KERNEL);
+   if (pid >= 0) {
+      compat_wait_for_completion(&info.created);
+
+      /*
+       * find_task_by_pid must be called with tasklist_lock held or under
+       * rcu_read_lock. As the latter doesn't exist in old kernels, we use the
+       * former for convenience.
+       */
+      read_lock(&tasklist_lock);
+      task = find_task_by_pid(pid);
+      read_unlock(&tasklist_lock);
+
+      /* XXX: Do we need to get a reference on task? */
+   }
+   return task;
+}
+
+#endif
+
+#endif /* __COMPAT_KTHREAD_H__ */
--- kernel/linux-2.6.26.3/fs/vmhgfs/compat_list.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/compat_list.h	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,55 @@
+/*********************************************************
+ * Copyright (C) 2006 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_LIST_H__
+#   define __COMPAT_LIST_H__
+
+#include <linux/list.h>
+
+/*
+ * list_add_tail is with us since 2.4.0, or something like that.
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 0)
+#define list_add_tail(newe, head) do {  \
+   struct list_head *__h = (head);      \
+   __list_add((newe), __h->prev, __h);  \
+} while (0)
+#endif
+
+/*
+ * list_for_each_safe() showed up in 2.4.10, but it may be backported so we
+ * just check for its existence.
+ */
+#ifndef list_for_each_safe
+# define list_for_each_safe(pos, n, head) \
+         for (pos = (head)->next, n = pos->next; pos != (head); \
+                 pos = n, n = pos->next)
+#endif
+
+/*
+ * list_for_each_entry() showed up in 2.4.20, but it may be backported so we
+ * just check for its existence.
+ */
+#ifndef list_for_each_entry
+# define list_for_each_entry(pos, head, member) \
+         for (pos = list_entry((head)->next, typeof(*pos), member); \
+              &pos->member != (head); \
+              pos = list_entry(pos->member.next, typeof(*pos), member))
+#endif
+
+#endif /* __COMPAT_LIST_H__ */
--- kernel/linux-2.6.26.3/fs/vmhgfs/compat_mm.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/compat_mm.h	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,134 @@
+/*********************************************************
+ * Copyright (C) 2002 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_MM_H__
+#   define __COMPAT_MM_H__
+
+
+#include <linux/mm.h>
+
+
+/* The get_page() API appeared in 2.3.7 --hpreg */
+/* Sometime during development it became function instead of macro --petr */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 0) && !defined(get_page) 
+#   define get_page(_page) atomic_inc(&(_page)->count)
+/* The __free_page() API is exported in 2.1.67 --hpreg */
+#   if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 1, 67)
+#      define put_page __free_page
+#   else
+#      include "compat_page.h"
+
+#      define page_to_phys(_page) (page_to_pfn(_page) << PAGE_SHIFT)
+#      define put_page(_page) free_page(page_to_phys(_page))
+#   endif
+#endif
+
+
+/* page_count() is 2.4.0 invention. Unfortunately unavailable in some RedHat 
+ * kernels (for example 2.4.21-4-RHEL3). */
+/* It is function since 2.6.0, and hopefully RedHat will not play silly games
+ * with mm_inline.h again... */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 0) && !defined(page_count)
+#  define page_count(page) atomic_read(&(page)->count)
+#endif
+
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 0)
+#  define compat_vm_pgoff(vma) ((vma)->vm_offset >> PAGE_SHIFT)
+
+static inline unsigned long compat_do_mmap_pgoff(struct file *file, unsigned long addr,
+   unsigned long len, unsigned long prot,
+   unsigned long flag, unsigned long pgoff)
+{
+   unsigned long ret = -EINVAL;
+
+   if (pgoff < 1 << (32 - PAGE_SHIFT)) {
+      ret = do_mmap(file, addr, len, prot, flag, pgoff << PAGE_SHIFT);
+   }
+   return ret;
+}
+
+#else
+#  define compat_vm_pgoff(vma) (vma)->vm_pgoff
+#  ifdef VMW_SKAS_MMAP
+#    define compat_do_mmap_pgoff(f, a, l, p, g, o) \
+				do_mmap_pgoff(current->mm, f, a, l, p, g, o)
+#  else
+#    define compat_do_mmap_pgoff(f, a, l, p, g, o) \
+				do_mmap_pgoff(f, a, l, p, g, o)
+#  endif
+#endif
+
+
+/* 2.2.x uses 0 instead of some define */
+#ifndef NOPAGE_SIGBUS
+#define NOPAGE_SIGBUS (0)
+#endif
+
+
+/* 2.2.x does not have HIGHMEM support */
+#ifndef GFP_HIGHUSER
+#define GFP_HIGHUSER (GFP_USER)
+#endif
+
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 0)
+
+#include "compat_page.h"
+
+static inline struct page * alloc_pages(unsigned int gfp_mask, unsigned int order)
+{
+   unsigned long addr;
+   
+   addr = __get_free_pages(gfp_mask, order);
+   if (!addr) {
+      return NULL;
+   }
+   return virt_to_page(addr);
+}
+#define alloc_page(gfp_mask) alloc_pages(gfp_mask, 0)
+
+#endif
+
+/*
+ * In 2.4.14, the logic behind the UnlockPage macro was moved to the 
+ * unlock_page() function. Later (in 2.5.12), the UnlockPage macro was removed
+ * altogether, and nowadays everyone uses unlock_page().
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 14)
+#define compat_unlock_page(page) UnlockPage(page)
+#else
+#define compat_unlock_page(page) unlock_page(page)
+#endif
+
+/*
+ * In 2.4.10, vmtruncate was changed from returning void to returning int.
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 10)
+#define compat_vmtruncate(inode, size)                                        \
+({                                                                            \
+   int result = 0;                                                            \
+   vmtruncate(inode, size);                                                   \
+   result;                                                                    \
+})
+#else
+#define compat_vmtruncate(inode, size) vmtruncate(inode, size)
+#endif
+
+
+#endif /* __COMPAT_MM_H__ */
--- kernel/linux-2.6.26.3/fs/vmhgfs/compat_module.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/compat_module.h	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,72 @@
+/*********************************************************
+ * Copyright (C) 2007 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * compat_module.h --
+ */
+
+#ifndef __COMPAT_MODULE_H__
+#   define __COMPAT_MODULE_H__
+
+
+#include <linux/module.h>
+
+
+/*
+ * Modules wishing to use the GPL license are required to include a
+ * MODULE_LICENSE definition in their module source as of 2.4.10.
+ */
+#ifndef MODULE_LICENSE
+#define MODULE_LICENSE(license)
+#endif
+
+/*
+ * To make use of our own home-brewed MODULE_INFO, we need macros to
+ * concatenate two expressions to "__mod_", and and to convert an
+ * expression into a string. I'm sure we've got these in our codebase,
+ * but I'd rather not introduce such a dependency in a compat header.
+ */
+#ifndef __module_cat
+#define __module_cat_1(a, b) __mod_ ## a ## b
+#define __module_cat(a, b) __module_cat_1(a, b)
+#endif
+
+#ifndef __stringify
+#define __stringify_1(x) #x
+#define __stringify(x) __stringify_1(x)
+#endif
+
+/*
+ * MODULE_INFO was born in 2.5.69.
+ */
+#ifndef MODULE_INFO
+#define MODULE_INFO(tag, info)                                                \
+static const char __module_cat(tag, __LINE__)[]                               \
+  __attribute__((section(".modinfo"), unused)) = __stringify(tag) "=" info
+#endif
+
+/*
+ * MODULE_VERSION was born in 2.6.4. The earlier form appends a long "\0xxx"
+ * string to the module's version, but that was removed in 2.6.10, so we'll
+ * ignore it in our wrapper.
+ */
+#ifndef MODULE_VERSION
+#define MODULE_VERSION(_version) MODULE_INFO(version, _version)
+#endif
+
+#endif /* __COMPAT_MODULE_H__ */
--- kernel/linux-2.6.26.3/fs/vmhgfs/compat_namei.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/compat_namei.h	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,57 @@
+/*********************************************************
+ * Copyright (C) 2006 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_NAMEI_H__
+#   define __COMPAT_NAMEI_H__
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 5, 18)
+#include <linux/namei.h>
+#endif
+
+/*
+ * In 2.6.25-rc2, dentry and mount objects were removed from the nameidata
+ * struct. They were both replaced with a struct path.
+ */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 25)
+#define compat_vmw_nd_to_dentry(nd) (nd).path.dentry
+#else
+#define compat_vmw_nd_to_dentry(nd) (nd).dentry
+#endif
+
+/* In 2.6.25-rc2, path_release(&nd) was replaced with path_put(&nd.path). */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 25)
+#define compat_path_release(nd) path_put(&(nd)->path)
+#else
+#define compat_path_release(nd) path_release(nd)
+#endif
+
+/* path_lookup was exported in 2.4.25 */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 4, 25)
+#define compat_path_lookup(path, flags, nd)     path_lookup(path, flags, nd)
+#else
+#define compat_path_lookup(path, flags, nd)     \
+         ({                                     \
+            int ret = 0;                        \
+            if (path_init(path, flags, nd)) {   \
+               ret = path_walk(path, nd);       \
+            }                                   \
+            ret;                                \
+         })
+#endif
+
+#endif /* __COMPAT_NAMEI_H__ */
--- kernel/linux-2.6.26.3/fs/vmhgfs/compat_page-flags.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/compat_page-flags.h	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,66 @@
+/*********************************************************
+ * Copyright (C) 2007 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_PAGE_FLAGS_H__
+#   define __COMPAT_PAGE_FLAGS_H__
+
+/* No page-flags.h prior to 2.5.12. */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 5, 12)
+#   include <linux/page-flags.h>
+#endif
+
+/* 
+ * The pgoff_t type was introduced in 2.5.20, but we'll look for it by 
+ * definition since it's more convenient. Note that we want to avoid a
+ * situation where, in the future, a #define is changed to a typedef, 
+ * so if pgoff_t is not defined in some future kernel, we won't define it.
+ */
+#if !defined(pgoff_t) && LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 19)
+#define pgoff_t unsigned long
+#endif
+
+/*
+ * set_page_writeback() was introduced in 2.6.6. Prior to that, callers were
+ * using the SetPageWriteback() macro directly, so that's what we'll use.
+ * Prior to 2.5.12, the writeback bit didn't exist, so we don't need to do
+ * anything.
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 12)
+#define compat_set_page_writeback(page)
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 6)
+#define compat_set_page_writeback(page) SetPageWriteback(page)
+#else
+#define compat_set_page_writeback(page) set_page_writeback(page)
+#endif
+
+/*
+ * end_page_writeback() was introduced in 2.5.12. Prior to that, it looks like
+ * there was no page writeback bit, and everything the function accomplished
+ * was done by unlock_page(), so we'll define it out.
+ *
+ * Note that we could just #define end_page_writeback to nothing and avoid 
+ * needing the compat_ prefix, but this is more complete with respect to
+ * compat_set_page_writeback. 
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 12)
+#define compat_end_page_writeback(page)
+#else
+#define compat_end_page_writeback(page) end_page_writeback(page)
+#endif
+
+#endif /* __COMPAT_PAGE_FLAGS_H__ */
--- kernel/linux-2.6.26.3/fs/vmhgfs/compat_page.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/compat_page.h	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,75 @@
+/*********************************************************
+ * Copyright (C) 2002 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_PAGE_H__
+#   define __COMPAT_PAGE_H__
+
+
+#include <linux/mm.h>
+#include <asm/page.h>
+
+
+/* The pfn_to_page() API appeared in 2.5.14 and changed to function during 2.6.x */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 0) && !defined(pfn_to_page)
+#   define pfn_to_page(_pfn) (mem_map + (_pfn))
+#   define page_to_pfn(_page) ((_page) - mem_map)
+#endif
+
+
+/* The virt_to_page() API appeared in 2.4.0 --hpreg */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 0) && !defined(virt_to_page)
+#   define virt_to_page(_kvAddr) pfn_to_page(MAP_NR(_kvAddr))
+#endif
+
+
+/*
+ * The get_order() API appeared at some point in 2.3.x, and was then backported
+ * in 2.2.17-21mdk and in the stock 2.2.18. Because we can only detect its
+ * definition through makefile tricks, we provide our own for now --hpreg
+ */
+static inline int
+compat_get_order(unsigned long size) // IN
+{
+   int order;
+
+   size = (size - 1) >> (PAGE_SHIFT - 1);
+   order = -1;
+   do {
+      size >>= 1;
+      order++;
+   } while (size);
+
+   return order;
+}
+
+/* 
+ * BUG() was added to <asm/page.h> in 2.2.18, and was moved to <asm/bug.h>
+ * in 2.5.58.
+ * 
+ * XXX: Technically, this belongs in some sort of "compat_asm_page.h" file, but
+ * since our compatibility wrappers don't distinguish between <asm/xxx.h> and
+ * <linux/xxx.h>, putting it here is reasonable.
+ */
+#ifndef BUG
+#define BUG() do {                                                            \
+   printk("kernel BUG at %s:%d!\n", __FILE__, __LINE__);                      \
+  __asm__ __volatile__(".byte 0x0f,0x0b");                                    \
+} while (0)
+#endif
+
+#endif /* __COMPAT_PAGE_H__ */
--- kernel/linux-2.6.26.3/fs/vmhgfs/compat_sched.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/compat_sched.h	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,291 @@
+/*********************************************************
+ * Copyright (C) 2002 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_SCHED_H__
+#   define __COMPAT_SCHED_H__
+
+
+#include <linux/sched.h>
+
+/* CLONE_KERNEL available in 2.5.35 and higher. */
+#ifndef CLONE_KERNEL
+#define CLONE_KERNEL CLONE_FILES | CLONE_FS | CLONE_SIGHAND
+#endif
+
+/* TASK_COMM_LEN become available in 2.6.11. */
+#ifndef TASK_COMM_LEN
+#define TASK_COMM_LEN 16
+#endif
+
+/* The capable() API appeared in 2.1.92 --hpreg */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 1, 92)
+#   define capable(_capability) suser()
+#endif
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 2, 0)
+#   define need_resched() need_resched
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 3)
+#   define need_resched() (current->need_resched)
+#endif
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 3)
+#   define cond_resched() (need_resched() ? schedule() : (void) 0)
+#endif
+
+/* Oh well.  We need yield...  Happy us! */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 20)
+#   ifdef __x86_64__
+#      define compat_yield() there_is_nothing_like_yield()
+#   else
+#      include <linux/unistd.h>
+#      include <linux/kernel.h>
+
+/*
+ * Used by _syscallX macros. Note that this is global variable, so
+ * do not rely on its contents too much. As exit() is only function
+ * we use, and we never check return value from exit(), we have
+ * no problem...
+ */
+extern int errno;
+
+/*
+ * compat_exit() provides an access to the exit() function. It must 
+ * be named compat_exit(), as exit() (with different signature) is 
+ * provided by x86-64, arm and other (but not by i386).
+ */
+#      define __NR_compat_yield __NR_sched_yield
+static inline _syscall0(int, compat_yield);
+#   endif
+#else
+#   define compat_yield() yield()
+#endif
+
+
+/*
+ * Since 2.5.34 there are two methods to enumerate tasks:
+ * for_each_process(p) { ... } which enumerates only tasks and
+ * do_each_thread(g,t) { ... } while_each_thread(g,t) which enumerates
+ *     also threads even if they share same pid.
+ */
+#ifndef for_each_process
+#   define for_each_process(p) for_each_task(p)
+#endif
+
+#ifndef do_each_thread
+#   define do_each_thread(g, t) for_each_task(g) { t = g; do
+#   define while_each_thread(g, t) while (0) }
+#endif
+
+
+/*
+ * Lock for signal mask is moving target...
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 40) && defined(CLONE_PID)
+/* 2.4.x without NPTL patches or early 2.5.x */
+#define compat_sigmask_lock sigmask_lock
+#define compat_dequeue_signal_current(siginfo_ptr) \
+   dequeue_signal(&current->blocked, (siginfo_ptr))
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 60) && !defined(INIT_SIGHAND)
+/* RedHat's 2.4.x with first version of NPTL support, or 2.5.40 to 2.5.59 */
+#define compat_sigmask_lock sig->siglock
+#define compat_dequeue_signal_current(siginfo_ptr) \
+   dequeue_signal(&current->blocked, (siginfo_ptr))
+#else
+/* RedHat's 2.4.x with second version of NPTL support, or 2.5.60+. */
+#define compat_sigmask_lock sighand->siglock
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 0)
+#define compat_dequeue_signal_current(siginfo_ptr) \
+   dequeue_signal(&current->blocked, (siginfo_ptr))
+#else
+#define compat_dequeue_signal_current(siginfo_ptr) \
+   dequeue_signal(current, &current->blocked, (siginfo_ptr))
+#endif
+#endif
+
+/*
+ * recalc_sigpending() had task argument in the past
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 29) && defined(CLONE_PID)
+/* 2.4.x without NPTL patches or early 2.5.x */
+#define compat_recalc_sigpending() recalc_sigpending(current)
+#else
+/* RedHat's 2.4.x with NPTL support, or 2.5.29+ */
+#define compat_recalc_sigpending() recalc_sigpending()
+#endif
+
+
+/*
+ * reparent_to_init() was introduced in 2.4.8.  In 2.5.38 (or possibly
+ * earlier, but later than 2.5.31) a call to it was added into
+ * daemonize(), so compat_daemonize no longer needs to call it.
+ *
+ * In 2.4.x kernels reparent_to_init() forgets to do correct refcounting
+ * on current->user. It is better to count one too many than one too few...
+ */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 4, 8) && LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 38)
+#define compat_reparent_to_init() do { \
+					reparent_to_init(); \
+					atomic_inc(&current->user->__count); \
+				  } while (0)
+#else
+#define compat_reparent_to_init() do {} while (0)
+#endif
+
+
+/*
+ * daemonize appeared in 2.2.18. Except 2.2.17-4-RH7.0, which has it too.
+ * Fortunately 2.2.17-4-RH7.0 uses versioned symbols, so we can check
+ * its existence with defined().
+ */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2, 2, 18)) && !defined(daemonize)
+static inline void daemonize(void) {
+   struct fs_struct *fs;
+
+   exit_mm(current);
+   current->session = 1;
+   current->pgrp = 1;
+   exit_fs(current);
+   fs = init_task.fs;
+   current->fs = fs;
+   atomic_inc(&fs->count);
+}
+#endif
+
+
+/*
+ * flush_signals acquires sighand->siglock since 2.5.61... Verify RH's kernels!
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 61)
+#define compat_flush_signals(task) do { \
+				      spin_lock_irq(&task->compat_sigmask_lock); \
+				      flush_signals(task); \
+				      spin_unlock_irq(&task->compat_sigmask_lock); \
+				   } while (0)
+#else
+#define compat_flush_signals(task) flush_signals(task)
+#endif
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 61)
+#define compat_allow_signal(signr) do { \
+                                      spin_lock_irq(&current->compat_sigmask_lock); \
+                                      sigdelset(&current->blocked, signr); \
+                                      compat_recalc_sigpending(); \
+                                      spin_unlock_irq(&current->compat_sigmask_lock); \
+                                   } while (0)
+#else
+#define compat_allow_signal(signr) allow_signal(signr)
+#endif
+
+/*
+ * daemonize can set process name since 2.5.61. Prior to 2.5.61, daemonize
+ * didn't block signals on our behalf.
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 61)
+#define compat_daemonize(x...)                                                \
+({                                                                            \
+   /* Beware! No snprintf here, so verify arguments! */                       \
+   sprintf(current->comm, x);                                                 \
+                                                                              \
+   /* Block all signals. */                                                   \
+   spin_lock_irq(&current->compat_sigmask_lock);                              \
+   sigfillset(&current->blocked);                                             \
+   compat_recalc_sigpending();                                                \
+   spin_unlock_irq(&current->compat_sigmask_lock);                            \
+   compat_flush_signals(current);                                             \
+                                                                              \
+   daemonize();                                                               \
+   compat_reparent_to_init();                                                 \
+})
+#else
+#define compat_daemonize(x...) daemonize(x)
+#endif
+
+
+/*
+ * set priority for specified thread. Exists on 2.6.x kernels and some
+ * 2.4.x vendor's kernels.
+ */
+#if defined(VMW_HAVE_SET_USER_NICE)
+#define compat_set_user_nice(task, n) set_user_nice((task), (n))
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 0)
+#define compat_set_user_nice(task, n) do { (task)->priority = 20 - (n); } while (0)
+#elif !defined(VMW_HAVE_SET_USER_NICE)
+#define compat_set_user_nice(task, n) do { (task)->nice = (n); } while (0)
+#endif
+
+/*
+ * try to freeze a process. For kernels 2.6.11 or newer, we know how to choose
+ * the interface. The problem is that the oldest interface, introduced in
+ * 2.5.18, was backported to 2.4.x kernels. So if we're older than 2.6.11,
+ * we'll decide what to do based on whether or not swsusp was configured
+ * for the kernel.  For kernels 2.6.20 and newer, we'll also need to include
+ * freezer.h since the try_to_freeze definition was pulled out of sched.h.
+ */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 20)
+#include <linux/freezer.h>
+#endif
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 13) || defined(VMW_TL10S64_WORKAROUND)
+#define compat_try_to_freeze() try_to_freeze()
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 11)
+#define compat_try_to_freeze() try_to_freeze(PF_FREEZE)
+#elif defined(CONFIG_SOFTWARE_SUSPEND) || defined(CONFIG_SOFTWARE_SUSPEND2)
+#include "compat_mm.h"
+#include <linux/errno.h>
+#include <linux/suspend.h>
+static inline int compat_try_to_freeze(void)  { 
+   if (current->flags & PF_FREEZE) {
+      refrigerator(PF_FREEZE); 
+      return 1;
+   } else {
+      return 0;
+   }
+}
+#else
+static inline int compat_try_to_freeze(void) { return 0; }
+#endif
+
+/*
+ * As of 2.6.23-rc1, kernel threads are no longer freezable by
+ * default. Instead, kernel threads that need to be frozen must opt-in
+ * by calling set_freezable() as soon as the thread is created.
+ */
+
+#if LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 22)
+#define compat_set_freezable() do { set_freezable(); } while (0)
+#else
+#define compat_set_freezable() do {} while (0)
+#endif
+
+/*
+ * Since 2.6.27-rc2 kill_proc() is gone... Replacement (GPL-only!)
+ * API is available since 2.6.19.  Use them from 2.6.27-rc1 up.
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 27)
+typedef int compat_pid;
+#define compat_find_get_pid(pid) (pid)
+#define compat_put_pid(pid) do { } while (0)
+#define compat_kill_pid(pid, sig, flag) kill_proc(pid, sig, flag)
+#else
+typedef struct pid * compat_pid;
+#define compat_find_get_pid(pid) find_get_pid(pid)
+#define compat_put_pid(pid) put_pid(pid)
+#define compat_kill_pid(pid, sig, flag) kill_pid(pid, sig, flag)
+#endif
+
+
+#endif /* __COMPAT_SCHED_H__ */
--- kernel/linux-2.6.26.3/fs/vmhgfs/compat_semaphore.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/compat_semaphore.h	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,49 @@
+/*********************************************************
+ * Copyright (C) 2002 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_SEMAPHORE_H__
+#   define __COMPAT_SEMAPHORE_H__
+
+
+/* <= 2.6.25 have asm only, 2.6.26 has both, and 2.6.27-rc2+ has linux only. */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 27)
+#   include <asm/semaphore.h>
+#else
+#   include <linux/semaphore.h>
+#endif
+
+
+/*
+* The init_MUTEX_LOCKED() API appeared in 2.2.18, and is also in
+* 2.2.17-21mdk --hpreg
+*/
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 2, 18)
+   #ifndef init_MUTEX_LOCKED
+      #define init_MUTEX_LOCKED(_sem) *(_sem) = MUTEX_LOCKED
+   #endif
+   #ifndef DECLARE_MUTEX
+      #define DECLARE_MUTEX(name) struct semaphore name = MUTEX
+   #endif
+   #ifndef DECLARE_MUTEX_LOCKED
+      #define DECLARE_MUTEX_LOCKED(name) struct semaphore name = MUTEX_LOCKED
+   #endif
+#endif
+
+
+#endif /* __COMPAT_SEMAPHORE_H__ */
--- kernel/linux-2.6.26.3/fs/vmhgfs/compat_slab.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/compat_slab.h	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,85 @@
+/*********************************************************
+ * Copyright (C) 2005 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_SLAB_H__
+#   define __COMPAT_SLAB_H__
+
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 2, 0)
+#   include <linux/slab.h>
+#else
+#   include <linux/malloc.h>
+#endif
+
+/*
+ * Before 2.6.20, kmem_cache_t was the accepted way to refer to a kmem_cache
+ * structure.  Prior to 2.6.15, this structure was called kmem_cache_s, and
+ * afterwards it was renamed to kmem_cache.  Here we keep things simple and use
+ * the accepted typedef until it became deprecated, at which point we switch
+ * over to the kmem_cache name.
+ */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 20)
+#   define compat_kmem_cache struct kmem_cache
+#else
+#   define compat_kmem_cache kmem_cache_t
+#endif
+
+/*
+ * Up to 2.6.22 kmem_cache_create has 6 arguments - name, size, alignment, flags,
+ * constructor, and destructor.  Then for some time kernel was asserting that
+ * destructor is NULL, and since 2.6.23-pre1 kmem_cache_create takes only 5
+ * arguments - destructor is gone.
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 22) || defined(VMW_KMEMCR_HAS_DTOR)
+#define compat_kmem_cache_create(name, size, align, flags, ctor) \
+		kmem_cache_create(name, size, align, flags, ctor, NULL)
+#else
+#define compat_kmem_cache_create(name, size, align, flags, ctor) \
+		kmem_cache_create(name, size, align, flags, ctor)
+#endif
+
+/*
+ * Up to 2.6.23 kmem_cache constructor has three arguments - pointer to block to
+ * prepare (aka "this"), from which cache it came, and some unused flags.  After
+ * 2.6.23 flags were removed, and order of "this" and cache parameters was swapped...
+ * Since 2.6.27-rc2 everything is different again, and ctor has only one argument.
+ *
+ * HAS_3_ARGS has precedence over HAS_2_ARGS if both are defined.
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 23) && !defined(VMW_KMEMCR_CTOR_HAS_3_ARGS)
+#  define VMW_KMEMCR_CTOR_HAS_3_ARGS
+#endif
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 26) && !defined(VMW_KMEMCR_CTOR_HAS_2_ARGS)
+#  define VMW_KMEMCR_CTOR_HAS_2_ARGS
+#endif
+
+#if defined(VMW_KMEMCR_CTOR_HAS_3_ARGS)
+typedef void compat_kmem_cache_ctor(void *, compat_kmem_cache *, unsigned long);
+#define COMPAT_KMEM_CACHE_CTOR_ARGS(arg) void *arg, \
+                                         compat_kmem_cache *cache, \
+                                         unsigned long flags
+#elif defined(VMW_KMEMCR_CTOR_HAS_2_ARGS)
+typedef void compat_kmem_cache_ctor(compat_kmem_cache *, void *);
+#define COMPAT_KMEM_CACHE_CTOR_ARGS(arg) compat_kmem_cache *cache, \
+                                         void *arg
+#else
+typedef void compat_kmem_cache_ctor(void *);
+#define COMPAT_KMEM_CACHE_CTOR_ARGS(arg) void *arg
+#endif
+
+#endif /* __COMPAT_SLAB_H__ */
--- kernel/linux-2.6.26.3/fs/vmhgfs/compat_spinlock.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/compat_spinlock.h	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,68 @@
+/*********************************************************
+ * Copyright (C) 2005 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_SPINLOCK_H__
+#   define __COMPAT_SPINLOCK_H__
+
+
+/*
+ * The spin_lock() API appeared in 2.1.25 in asm/smp_lock.h
+ * It moved in 2.1.30 to asm/spinlock.h
+ * It moved again in 2.3.18 to linux/spinlock.h
+ *
+ *   --hpreg
+ */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 3, 18)
+#   include <linux/spinlock.h>
+#else
+#   if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 1, 30)
+#      include <asm/spinlock.h>
+#   else
+typedef struct {} spinlock_t;
+#      define spin_lock_init(lock)
+#      define spin_lock(lock)
+#      define spin_unlock(lock)
+#      define spin_lock_irqsave(lock, flags) do {      \
+                    save_flags(flags);                 \
+                    cli();                             \
+                    spin_lock(lock);                   \
+                 } while (0)
+#      define spin_unlock_irqrestore(lock, flags) do { \
+                    spin_unlock(lock);                 \
+                    restore_flags(flags);              \
+                 } while (0)
+#   endif
+#endif
+
+
+/*
+ * Preempt support was added during 2.5.x development cycle, and later
+ * it was backported to 2.4.x.  In 2.4.x backport these definitions
+ * live in linux/spinlock.h, that's why we put them here (in 2.6.x they
+ * are defined in linux/preempt.h which is included by linux/spinlock.h).
+ */
+#ifdef CONFIG_PREEMPT
+#define compat_preempt_disable() preempt_disable()
+#define compat_preempt_enable()  preempt_enable()
+#else
+#define compat_preempt_disable() do { } while (0)
+#define compat_preempt_enable()  do { } while (0)
+#endif
+
+
+#endif /* __COMPAT_SPINLOCK_H__ */
--- kernel/linux-2.6.26.3/fs/vmhgfs/compat_statfs.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/compat_statfs.h	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,32 @@
+/*********************************************************
+ * Copyright (C) 2006 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_STATFS_H__
+#   define __COMPAT_STATFS_H__
+
+/* vfs.h simply include statfs.h, but it knows what directory statfs.h is in. */
+#include <linux/vfs.h>
+
+/* 2.5.74 renamed struct statfs to kstatfs. */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 5, 74)
+#define compat_kstatfs kstatfs
+#else
+#define compat_kstatfs statfs
+#endif
+
+#endif /* __COMPAT_STATFS_H__ */
--- kernel/linux-2.6.26.3/fs/vmhgfs/compat_string.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/compat_string.h	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,42 @@
+/*********************************************************
+ * Copyright (C) 2007 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_STRING_H__
+#   define __COMPAT_STRING_H__
+
+#include <linux/string.h>
+
+/*
+ * kstrdup was born in 2.6.13. This implementation is almost identical to the
+ * one found there.
+ */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 13)
+#define compat_kstrdup(s, gfp) kstrdup(s, gfp)
+#else
+#define compat_kstrdup(s, gfp)                                                \
+({                                                                            \
+   size_t len;                                                                \
+   char *buf;                                                                 \
+   len = strlen(s) + 1;                                                       \
+   buf = kmalloc(len, gfp);                                                   \
+   memcpy(buf, s, len);                                                       \
+   buf;                                                                       \
+})                                                                            
+#endif
+
+#endif /* __COMPAT_STRING_H__ */
--- kernel/linux-2.6.26.3/fs/vmhgfs/compat_uaccess.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/compat_uaccess.h	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,79 @@
+/*********************************************************
+ * Copyright (C) 2002 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_UACCESS_H__
+#   define __COMPAT_UACCESS_H__
+
+
+/* User space access functions moved in 2.1.7 to asm/uaccess.h --hpreg */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 1, 7)
+#   include <asm/uaccess.h>
+#else
+#   include <asm/segment.h>
+#endif
+
+
+/* get_user() API modified in 2.1.4 to take 2 arguments --hpreg */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 1, 4)
+#   define compat_get_user get_user
+#else
+/*
+ * We assign 0 to the variable in case of failure to prevent "`_var' might be
+ * used uninitialized in this function" compiler warnings. I think it is OK,
+ * because the hardware-based version in newer kernels probably has the same
+ * semantics and does not guarantee that the value of _var will not be
+ * modified, should the access fail --hpreg
+ */
+#   define compat_get_user(_var, _uvAddr) ({                        \
+   int _status;                                                     \
+                                                                    \
+   _status = verify_area(VERIFY_READ, _uvAddr, sizeof(*(_uvAddr))); \
+   if (_status == 0) {                                              \
+      (_var) = get_user(_uvAddr);                                   \
+   } else {                                                         \
+      (_var) = 0;                                                   \
+   }                                                                \
+   _status;                                                         \
+})
+#endif
+
+
+/*
+ * The copy_from_user() API appeared in 2.1.4
+ *
+ * The emulation is not perfect here, but it is conservative: on failure, we
+ * always return the total size, instead of the potentially smaller faulty
+ * size --hpreg
+ *
+ * Since 2.5.55 copy_from_user() is no longer macro.
+ */
+#if !defined(copy_from_user) && LINUX_VERSION_CODE < KERNEL_VERSION(2, 2, 0)
+#   define copy_from_user(_to, _from, _size) ( \
+   verify_area(VERIFY_READ, _from, _size)      \
+       ? (_size)                               \
+       : (memcpy_fromfs(_to, _from, _size), 0) \
+)
+#   define copy_to_user(_to, _from, _size) ( \
+   verify_area(VERIFY_WRITE, _to, _size)     \
+       ? (_size)                             \
+       : (memcpy_tofs(_to, _from, _size), 0) \
+)
+#endif
+
+
+#endif /* __COMPAT_UACCESS_H__ */
--- kernel/linux-2.6.26.3/fs/vmhgfs/compat_version.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/compat_version.h	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,121 @@
+/*********************************************************
+ * Copyright (C) 1998 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_VERSION_H__
+#   define __COMPAT_VERSION_H__
+
+#define INCLUDE_ALLOW_VMMON
+#define INCLUDE_ALLOW_MODULE
+#define INCLUDE_ALLOW_VMCORE
+#define INCLUDE_ALLOW_VMNIXMOD
+#define INCLUDE_ALLOW_DISTRIBUTE
+#include "includeCheck.h"
+
+
+#ifndef __linux__
+#   error "linux-version.h"
+#endif
+
+
+#include <linux/version.h>
+
+/* Appeared in 2.1.90 --hpreg */
+#ifndef KERNEL_VERSION
+#   define KERNEL_VERSION(a, b, c) (((a) << 16) + ((b) << 8) + (c))
+#endif
+
+
+/*
+ * Distinguish relevant classes of Linux kernels.
+ *
+ * The convention is that version X defines all
+ * the KERNEL_Y symbols where Y <= X.
+ *
+ * XXX Do not add more definitions here. This way of doing things does not
+ *     scale, and we are going to phase it out soon --hpreg
+ */
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 1, 0)
+#   define KERNEL_2_1
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 2, 0)
+#   define KERNEL_2_2
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 3, 1)
+#   define KERNEL_2_3_1
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 3, 15)
+/*   new networking */
+#   define KERNEL_2_3_15
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 3, 25)
+/*  new procfs */
+#   define KERNEL_2_3_25
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 3, 29)
+/*  even newer procfs */
+#   define KERNEL_2_3_29
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 3, 43)
+/*  softnet changes */
+#   define KERNEL_2_3_43
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 3, 47)
+/*  more softnet changes */
+#   define KERNEL_2_3_47
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 3, 99)
+/*  name in netdevice struct is array and not pointer */
+#   define KERNEL_2_3_99
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 4, 0)
+/*  New 'owner' member at the beginning of struct file_operations */
+#      define KERNEL_2_4_0
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 4, 8)
+/*  New netif_rx_ni() --hpreg */
+#   define KERNEL_2_4_8
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 4, 22)
+/*  New vmap() */
+#   define KERNEL_2_4_22
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 5, 2)
+/*  New kdev_t, major()/minor() API --hpreg */
+#   define KERNEL_2_5_2
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 5, 5)
+/*  New sk_alloc(), pte_offset_map()/pte_unmap() --hpreg */
+#   define KERNEL_2_5_5
+#endif
+
+
+#endif /* __COMPAT_VERSION_H__ */
--- kernel/linux-2.6.26.3/fs/vmhgfs/compat_wait.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/compat_wait.h	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,225 @@
+/*********************************************************
+ * Copyright (C) 2002 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __COMPAT_WAIT_H__
+#   define __COMPAT_WAIT_H__
+
+
+#include <linux/wait.h>
+#include <linux/poll.h>
+#include <linux/file.h>
+
+#include "compat_file.h"
+
+
+/*
+ * The DECLARE_WAITQUEUE() API appeared in 2.3.1
+ * It was back ported in 2.2.18
+ *
+ *  --hpreg
+ */
+
+#ifndef DECLARE_WAITQUEUE
+
+typedef struct wait_queue *wait_queue_head_t;
+#   define init_waitqueue_head(_headPtr) *(_headPtr) = NULL
+#   define DECLARE_WAITQUEUE(_var, _task) \
+   struct wait_queue _var = {_task, NULL, }
+
+typedef struct wait_queue wait_queue_t;
+#   define init_waitqueue_entry(_wait, _task) ((_wait)->task = (_task))
+
+#endif
+
+/*
+ * The 'struct poll_wqueues' appeared in 2.5.48, when global
+ * /dev/epoll interface was added.  It was backported to the
+ * 2.4.20-wolk4.0s.
+ */
+
+#ifdef VMW_HAVE_EPOLL // {
+#define compat_poll_wqueues struct poll_wqueues
+#else // } {
+#define compat_poll_wqueues poll_table
+#endif // }
+
+#ifdef VMW_HAVE_EPOLL // {
+
+/* If prototype does not match, build will abort here */
+extern void poll_initwait(compat_poll_wqueues *);
+
+#define compat_poll_initwait(wait, table) ( \
+   poll_initwait((table)), \
+   (wait) = &(table)->pt \
+)
+
+#define compat_poll_freewait(wait, table) ( \
+   poll_freewait((table)) \
+)
+
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(2, 4, 0) // {
+
+/* If prototype does not match, build will abort here */
+extern void poll_initwait(compat_poll_wqueues *);
+
+#define compat_poll_initwait(wait, table) ( \
+   (wait) = (table), \
+   poll_initwait(wait) \
+)
+
+#define compat_poll_freewait(wait, table) ( \
+   poll_freewait((table)) \
+)
+
+#else // } {
+
+#define compat_poll_initwait(wait, table) ( \
+   (wait) = (table), /* confuse compiler */ \
+   (wait) = (poll_table *) __get_free_page(GFP_KERNEL), \
+   (wait)->nr = 0, \
+   (wait)->entry = (struct poll_table_entry *)((wait) + 1), \
+   (wait)->next = NULL \
+)
+
+static inline void
+poll_freewait(poll_table *wait)
+{
+   while (wait) {
+      struct poll_table_entry * entry;
+      poll_table *old;
+
+      entry = wait->entry + wait->nr;
+      while (wait->nr > 0) {
+	 wait->nr--;
+	 entry--;
+	 remove_wait_queue(entry->wait_address, &entry->wait);
+	 compat_fput(entry->filp);
+      }
+      old = wait;
+      wait = wait->next;
+      free_page((unsigned long) old);
+   }
+}
+
+#define compat_poll_freewait(wait, table) ( \
+   poll_freewait((wait)) \
+)
+
+#endif // }
+
+/*
+ * The wait_event_interruptible_timeout() interface is not
+ * defined in pre-2.6 kernels.
+ */
+#ifndef wait_event_interruptible_timeout
+#define __wait_event_interruptible_timeout(wq, condition, ret)		\
+do {									\
+   wait_queue_t __wait;						        \
+   init_waitqueue_entry(&__wait, current);				\
+									\
+   add_wait_queue(&wq, &__wait);					\
+   for (;;) {							        \
+      set_current_state(TASK_INTERRUPTIBLE);			        \
+      if (condition)						        \
+	 break;						                \
+      if (!signal_pending(current)) {				        \
+	 ret = schedule_timeout(ret);			                \
+	 if (!ret)					                \
+	    break;					                \
+	 continue;					                \
+      }							                \
+      ret = -ERESTARTSYS;					        \
+      break;							        \
+   }								        \
+   set_current_state(TASK_RUNNING);				        \
+   remove_wait_queue(&wq, &__wait);				        \
+} while (0)
+
+#define wait_event_interruptible_timeout(wq, condition, timeout)	\
+({									\
+   long __ret = timeout;						\
+   if (!(condition))						        \
+      __wait_event_interruptible_timeout(wq, condition, __ret);         \
+   __ret;								\
+})
+#endif
+
+/*
+ * The wait_event_timeout() interface is not
+ * defined in pre-2.6 kernels.
+ */
+#ifndef wait_event_timeout
+#define __wait_event_timeout(wq, condition, ret)        		\
+do {									\
+   wait_queue_t __wait;						        \
+   init_waitqueue_entry(&__wait, current);				\
+									\
+   add_wait_queue(&wq, &__wait);					\
+   for (;;) {							        \
+      set_current_state(TASK_UNINTERRUPTIBLE);        	                \
+      if (condition)						        \
+         break;						                \
+      ret = schedule_timeout(ret);			                \
+      if (!ret)					                        \
+         break;					                        \
+   }								        \
+   set_current_state(TASK_RUNNING);				        \
+   remove_wait_queue(&wq, &__wait);				        \
+} while (0)
+
+#define wait_event_timeout(wq, condition, timeout)	                \
+({									\
+   long __ret = timeout;						\
+   if (!(condition))						        \
+      __wait_event_timeout(wq, condition, __ret);                       \
+   __ret;								\
+})
+#endif
+
+/*
+ * DEFINE_WAIT() and friends were added in 2.5.39 and backported to 2.4.28.
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 28) || \
+   (LINUX_VERSION_CODE >= KERNEL_VERSION(2, 5, 0) && \
+    LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 39))
+# define COMPAT_DEFINE_WAIT(_wait)                              \
+   DECLARE_WAITQUEUE(_wait, current)
+# define compat_init_prepare_to_wait(_sleep, _wait, _state)     \
+   do {                                                         \
+      __set_current_state(_state);                              \
+      add_wait_queue(_sleep, _wait);                            \
+   } while (0)
+# define compat_cont_prepare_to_wait(_sleep, _wait, _state)     \
+   set_current_state(_state)
+# define compat_finish_wait(_sleep, _wait, _state)              \
+   do {                                                         \
+      __set_current_state(_state);                              \
+      remove_wait_queue(_sleep, _wait);                         \
+   } while (0)
+#else
+# define COMPAT_DEFINE_WAIT(_wait)                              \
+   DEFINE_WAIT(_wait)
+# define compat_init_prepare_to_wait(_sleep, _wait, _state)     \
+   prepare_to_wait(_sleep, _wait, _state)
+# define compat_cont_prepare_to_wait(_sleep, _wait, _state)     \
+   prepare_to_wait(_sleep, _wait, _state)
+# define compat_finish_wait(_sleep, _wait, _state)              \
+   finish_wait(_sleep, _wait)
+#endif
+
+#endif /* __COMPAT_WAIT_H__ */
--- kernel/linux-2.6.26.3/fs/vmhgfs/COPYING	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/COPYING	2008-09-03 09:57:35.000000000 -0500
@@ -0,0 +1,339 @@
+		    GNU GENERAL PUBLIC LICENSE
+		       Version 2, June 1991
+
+ Copyright (C) 1989, 1991 Free Software Foundation, Inc.,
+ 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ Everyone is permitted to copy and distribute verbatim copies
+ of this license document, but changing it is not allowed.
+
+			    Preamble
+
+  The licenses for most software are designed to take away your
+freedom to share and change it.  By contrast, the GNU General Public
+License is intended to guarantee your freedom to share and change free
+software--to make sure the software is free for all its users.  This
+General Public License applies to most of the Free Software
+Foundation's software and to any other program whose authors commit to
+using it.  (Some other Free Software Foundation software is covered by
+the GNU Lesser General Public License instead.)  You can apply it to
+your programs, too.
+
+  When we speak of free software, we are referring to freedom, not
+price.  Our General Public Licenses are designed to make sure that you
+have the freedom to distribute copies of free software (and charge for
+this service if you wish), that you receive source code or can get it
+if you want it, that you can change the software or use pieces of it
+in new free programs; and that you know you can do these things.
+
+  To protect your rights, we need to make restrictions that forbid
+anyone to deny you these rights or to ask you to surrender the rights.
+These restrictions translate to certain responsibilities for you if you
+distribute copies of the software, or if you modify it.
+
+  For example, if you distribute copies of such a program, whether
+gratis or for a fee, you must give the recipients all the rights that
+you have.  You must make sure that they, too, receive or can get the
+source code.  And you must show them these terms so they know their
+rights.
+
+  We protect your rights with two steps: (1) copyright the software, and
+(2) offer you this license which gives you legal permission to copy,
+distribute and/or modify the software.
+
+  Also, for each author's protection and ours, we want to make certain
+that everyone understands that there is no warranty for this free
+software.  If the software is modified by someone else and passed on, we
+want its recipients to know that what they have is not the original, so
+that any problems introduced by others will not reflect on the original
+authors' reputations.
+
+  Finally, any free program is threatened constantly by software
+patents.  We wish to avoid the danger that redistributors of a free
+program will individually obtain patent licenses, in effect making the
+program proprietary.  To prevent this, we have made it clear that any
+patent must be licensed for everyone's free use or not licensed at all.
+
+  The precise terms and conditions for copying, distribution and
+modification follow.
+
+		    GNU GENERAL PUBLIC LICENSE
+   TERMS AND CONDITIONS FOR COPYING, DISTRIBUTION AND MODIFICATION
+
+  0. This License applies to any program or other work which contains
+a notice placed by the copyright holder saying it may be distributed
+under the terms of this General Public License.  The "Program", below,
+refers to any such program or work, and a "work based on the Program"
+means either the Program or any derivative work under copyright law:
+that is to say, a work containing the Program or a portion of it,
+either verbatim or with modifications and/or translated into another
+language.  (Hereinafter, translation is included without limitation in
+the term "modification".)  Each licensee is addressed as "you".
+
+Activities other than copying, distribution and modification are not
+covered by this License; they are outside its scope.  The act of
+running the Program is not restricted, and the output from the Program
+is covered only if its contents constitute a work based on the
+Program (independent of having been made by running the Program).
+Whether that is true depends on what the Program does.
+
+  1. You may copy and distribute verbatim copies of the Program's
+source code as you receive it, in any medium, provided that you
+conspicuously and appropriately publish on each copy an appropriate
+copyright notice and disclaimer of warranty; keep intact all the
+notices that refer to this License and to the absence of any warranty;
+and give any other recipients of the Program a copy of this License
+along with the Program.
+
+You may charge a fee for the physical act of transferring a copy, and
+you may at your option offer warranty protection in exchange for a fee.
+
+  2. You may modify your copy or copies of the Program or any portion
+of it, thus forming a work based on the Program, and copy and
+distribute such modifications or work under the terms of Section 1
+above, provided that you also meet all of these conditions:
+
+    a) You must cause the modified files to carry prominent notices
+    stating that you changed the files and the date of any change.
+
+    b) You must cause any work that you distribute or publish, that in
+    whole or in part contains or is derived from the Program or any
+    part thereof, to be licensed as a whole at no charge to all third
+    parties under the terms of this License.
+
+    c) If the modified program normally reads commands interactively
+    when run, you must cause it, when started running for such
+    interactive use in the most ordinary way, to print or display an
+    announcement including an appropriate copyright notice and a
+    notice that there is no warranty (or else, saying that you provide
+    a warranty) and that users may redistribute the program under
+    these conditions, and telling the user how to view a copy of this
+    License.  (Exception: if the Program itself is interactive but
+    does not normally print such an announcement, your work based on
+    the Program is not required to print an announcement.)
+
+These requirements apply to the modified work as a whole.  If
+identifiable sections of that work are not derived from the Program,
+and can be reasonably considered independent and separate works in
+themselves, then this License, and its terms, do not apply to those
+sections when you distribute them as separate works.  But when you
+distribute the same sections as part of a whole which is a work based
+on the Program, the distribution of the whole must be on the terms of
+this License, whose permissions for other licensees extend to the
+entire whole, and thus to each and every part regardless of who wrote it.
+
+Thus, it is not the intent of this section to claim rights or contest
+your rights to work written entirely by you; rather, the intent is to
+exercise the right to control the distribution of derivative or
+collective works based on the Program.
+
+In addition, mere aggregation of another work not based on the Program
+with the Program (or with a work based on the Program) on a volume of
+a storage or distribution medium does not bring the other work under
+the scope of this License.
+
+  3. You may copy and distribute the Program (or a work based on it,
+under Section 2) in object code or executable form under the terms of
+Sections 1 and 2 above provided that you also do one of the following:
+
+    a) Accompany it with the complete corresponding machine-readable
+    source code, which must be distributed under the terms of Sections
+    1 and 2 above on a medium customarily used for software interchange; or,
+
+    b) Accompany it with a written offer, valid for at least three
+    years, to give any third party, for a charge no more than your
+    cost of physically performing source distribution, a complete
+    machine-readable copy of the corresponding source code, to be
+    distributed under the terms of Sections 1 and 2 above on a medium
+    customarily used for software interchange; or,
+
+    c) Accompany it with the information you received as to the offer
+    to distribute corresponding source code.  (This alternative is
+    allowed only for noncommercial distribution and only if you
+    received the program in object code or executable form with such
+    an offer, in accord with Subsection b above.)
+
+The source code for a work means the preferred form of the work for
+making modifications to it.  For an executable work, complete source
+code means all the source code for all modules it contains, plus any
+associated interface definition files, plus the scripts used to
+control compilation and installation of the executable.  However, as a
+special exception, the source code distributed need not include
+anything that is normally distributed (in either source or binary
+form) with the major components (compiler, kernel, and so on) of the
+operating system on which the executable runs, unless that component
+itself accompanies the executable.
+
+If distribution of executable or object code is made by offering
+access to copy from a designated place, then offering equivalent
+access to copy the source code from the same place counts as
+distribution of the source code, even though third parties are not
+compelled to copy the source along with the object code.
+
+  4. You may not copy, modify, sublicense, or distribute the Program
+except as expressly provided under this License.  Any attempt
+otherwise to copy, modify, sublicense or distribute the Program is
+void, and will automatically terminate your rights under this License.
+However, parties who have received copies, or rights, from you under
+this License will not have their licenses terminated so long as such
+parties remain in full compliance.
+
+  5. You are not required to accept this License, since you have not
+signed it.  However, nothing else grants you permission to modify or
+distribute the Program or its derivative works.  These actions are
+prohibited by law if you do not accept this License.  Therefore, by
+modifying or distributing the Program (or any work based on the
+Program), you indicate your acceptance of this License to do so, and
+all its terms and conditions for copying, distributing or modifying
+the Program or works based on it.
+
+  6. Each time you redistribute the Program (or any work based on the
+Program), the recipient automatically receives a license from the
+original licensor to copy, distribute or modify the Program subject to
+these terms and conditions.  You may not impose any further
+restrictions on the recipients' exercise of the rights granted herein.
+You are not responsible for enforcing compliance by third parties to
+this License.
+
+  7. If, as a consequence of a court judgment or allegation of patent
+infringement or for any other reason (not limited to patent issues),
+conditions are imposed on you (whether by court order, agreement or
+otherwise) that contradict the conditions of this License, they do not
+excuse you from the conditions of this License.  If you cannot
+distribute so as to satisfy simultaneously your obligations under this
+License and any other pertinent obligations, then as a consequence you
+may not distribute the Program at all.  For example, if a patent
+license would not permit royalty-free redistribution of the Program by
+all those who receive copies directly or indirectly through you, then
+the only way you could satisfy both it and this License would be to
+refrain entirely from distribution of the Program.
+
+If any portion of this section is held invalid or unenforceable under
+any particular circumstance, the balance of the section is intended to
+apply and the section as a whole is intended to apply in other
+circumstances.
+
+It is not the purpose of this section to induce you to infringe any
+patents or other property right claims or to contest validity of any
+such claims; this section has the sole purpose of protecting the
+integrity of the free software distribution system, which is
+implemented by public license practices.  Many people have made
+generous contributions to the wide range of software distributed
+through that system in reliance on consistent application of that
+system; it is up to the author/donor to decide if he or she is willing
+to distribute software through any other system and a licensee cannot
+impose that choice.
+
+This section is intended to make thoroughly clear what is believed to
+be a consequence of the rest of this License.
+
+  8. If the distribution and/or use of the Program is restricted in
+certain countries either by patents or by copyrighted interfaces, the
+original copyright holder who places the Program under this License
+may add an explicit geographical distribution limitation excluding
+those countries, so that distribution is permitted only in or among
+countries not thus excluded.  In such case, this License incorporates
+the limitation as if written in the body of this License.
+
+  9. The Free Software Foundation may publish revised and/or new versions
+of the General Public License from time to time.  Such new versions will
+be similar in spirit to the present version, but may differ in detail to
+address new problems or concerns.
+
+Each version is given a distinguishing version number.  If the Program
+specifies a version number of this License which applies to it and "any
+later version", you have the option of following the terms and conditions
+either of that version or of any later version published by the Free
+Software Foundation.  If the Program does not specify a version number of
+this License, you may choose any version ever published by the Free Software
+Foundation.
+
+  10. If you wish to incorporate parts of the Program into other free
+programs whose distribution conditions are different, write to the author
+to ask for permission.  For software which is copyrighted by the Free
+Software Foundation, write to the Free Software Foundation; we sometimes
+make exceptions for this.  Our decision will be guided by the two goals
+of preserving the free status of all derivatives of our free software and
+of promoting the sharing and reuse of software generally.
+
+			    NO WARRANTY
+
+  11. BECAUSE THE PROGRAM IS LICENSED FREE OF CHARGE, THERE IS NO WARRANTY
+FOR THE PROGRAM, TO THE EXTENT PERMITTED BY APPLICABLE LAW.  EXCEPT WHEN
+OTHERWISE STATED IN WRITING THE COPYRIGHT HOLDERS AND/OR OTHER PARTIES
+PROVIDE THE PROGRAM "AS IS" WITHOUT WARRANTY OF ANY KIND, EITHER EXPRESSED
+OR IMPLIED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
+MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE.  THE ENTIRE RISK AS
+TO THE QUALITY AND PERFORMANCE OF THE PROGRAM IS WITH YOU.  SHOULD THE
+PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF ALL NECESSARY SERVICING,
+REPAIR OR CORRECTION.
+
+  12. IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING
+WILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MAY MODIFY AND/OR
+REDISTRIBUTE THE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES,
+INCLUDING ANY GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING
+OUT OF THE USE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED
+TO LOSS OF DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY
+YOU OR THIRD PARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER
+PROGRAMS), EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE
+POSSIBILITY OF SUCH DAMAGES.
+
+		     END OF TERMS AND CONDITIONS
+
+	    How to Apply These Terms to Your New Programs
+
+  If you develop a new program, and you want it to be of the greatest
+possible use to the public, the best way to achieve this is to make it
+free software which everyone can redistribute and change under these terms.
+
+  To do so, attach the following notices to the program.  It is safest
+to attach them to the start of each source file to most effectively
+convey the exclusion of warranty; and each file should have at least
+the "copyright" line and a pointer to where the full notice is found.
+
+    <one line to give the program's name and a brief idea of what it does.>
+    Copyright (C) <year>  <name of author>
+
+    This program is free software; you can redistribute it and/or modify
+    it under the terms of the GNU General Public License as published by
+    the Free Software Foundation; either version 2 of the License, or
+    (at your option) any later version.
+
+    This program is distributed in the hope that it will be useful,
+    but WITHOUT ANY WARRANTY; without even the implied warranty of
+    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+    GNU General Public License for more details.
+
+    You should have received a copy of the GNU General Public License along
+    with this program; if not, write to the Free Software Foundation, Inc.,
+    51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA.
+
+Also add information on how to contact you by electronic and paper mail.
+
+If the program is interactive, make it output a short notice like this
+when it starts in an interactive mode:
+
+    Gnomovision version 69, Copyright (C) year name of author
+    Gnomovision comes with ABSOLUTELY NO WARRANTY; for details type `show w'.
+    This is free software, and you are welcome to redistribute it
+    under certain conditions; type `show c' for details.
+
+The hypothetical commands `show w' and `show c' should show the appropriate
+parts of the General Public License.  Of course, the commands you use may
+be called something other than `show w' and `show c'; they could even be
+mouse-clicks or menu items--whatever suits your program.
+
+You should also get your employer (if you work as a programmer) or your
+school, if any, to sign a "copyright disclaimer" for the program, if
+necessary.  Here is a sample; alter the names:
+
+  Yoyodyne, Inc., hereby disclaims all copyright interest in the program
+  `Gnomovision' (which makes passes at compilers) written by James Hacker.
+
+  <signature of Ty Coon>, 1 April 1989
+  Ty Coon, President of Vice
+
+This General Public License does not permit incorporating your program into
+proprietary programs.  If your program is a subroutine library, you may
+consider it more useful to permit linking proprietary applications with the
+library.  If this is what you want to do, use the GNU Lesser General
+Public License instead of this License.
--- kernel/linux-2.6.26.3/fs/vmhgfs/cpName.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/cpName.c	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,433 @@
+/*********************************************************
+ * Copyright (C) 1998 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * cpName.c --
+ *
+ *    Shared portions of cross-platform name conversion routines used
+ *    by hgfs. [bac]
+ *
+ */
+
+#ifdef sun
+#include <string.h>
+#endif
+
+#include "cpName.h"
+#include "cpNameInt.h"
+#include "vm_assert.h"
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * CPName_GetComponentGeneric --
+ *
+ *    Get the next component of the CP name.
+ *
+ *    Returns the length of the component starting with the begin
+ *    pointer, and a pointer to the next component in the buffer, if
+ *    any. The "next" pointer is set to "end" if there is no next
+ *    component.
+ *
+ *    'illegal' is a string of characters that are not allowed to
+ *    be present in the pre-converted CP name.
+ *
+ * Results:
+ *    length (not including NUL termination) >= 0 of next
+ *    component on success.
+ *    error < 0 on failure (invalid component).
+ *
+ * Side effects:
+ *    None
+ *
+ *----------------------------------------------------------------------
+ */
+
+int
+CPName_GetComponentGeneric(char const *begin,   // IN: Beginning of buffer
+                           char const *end,     // IN: End of buffer
+                           char const *illegal, // IN: Illegal characters
+                           char const **next)   // OUT: Start of next component
+{
+   char const *walk;
+   char const *myNext;
+   size_t len;
+
+   ASSERT(begin);
+   ASSERT(end);
+   ASSERT(next);
+   ASSERT(illegal);
+   ASSERT(begin <= end);
+
+   for (walk = begin; ; walk++) {
+      if (walk == end) {
+         /* End of buffer. No NUL was found */
+
+         myNext = end;
+         break;
+      }
+
+      if (*walk == '\0') {
+         /* Found a NUL */
+
+         if (walk == begin) {
+            Log("CPName_GetComponentGeneric: error: first char can't be NUL\n");
+            return -1;
+         }
+
+         myNext = walk + 1;
+         if (myNext == end) {
+            /* Last character in the buffer is not allowed to be NUL */
+            return -1;
+         }
+
+         break;
+      }
+
+      /*
+       * Make sure the input buffer does not contain any illegal
+       * characters. In particular, we want to make sure that there
+       * are no path separator characters in the name. Since the
+       * cross-platform name format by definition does not use path
+       * separators, this is an error condition, and is likely the
+       * sign of an attack. See bug 27926. [bac]
+       *
+       * The test above ensures that *walk != NUL here, so we don't
+       * need to test it again before calling strchr().
+       */
+      if (strchr(illegal, *walk) != NULL) {
+         Log("CPName_GetComponentGeneric: error: Illegal char \"%c\" found in "
+             "input\n", *walk);
+         return -1;
+      }
+   }
+
+   len = walk - begin;
+
+   /* 
+    * We're only interested in looking for dot/dotdot if the illegal character
+    * string isn't empty. These characters are only relevant when the resulting
+    * string is to be passed down to the filesystem. Some callers (such as the
+    * HGFS server, when dealing with actual filenames) do care about this 
+    * validation, but others (like DnD, hgFileCopy, and the HGFS server when
+    * converting share names) just want to convert a CPName down to a 
+    * nul-terminated string. 
+    */
+   if (strcmp(illegal, "") != 0 &&
+       ((len == 1 && memcmp(begin, ".", 1) == 0) ||
+        (len == 2 && memcmp(begin, "..", 2) == 0))) {
+      Log("CPName_GetComponentGeneric: error: found dot/dotdot\n");
+      return -1;
+   }
+
+   *next = myNext;
+   return ((int) len);
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * CPNameConvertFrom --
+ *
+ *    Converts a cross-platform name representation into a string for
+ *    use in the local filesystem. This is a cross-platform
+ *    implementation and takes the path separator argument as an
+ *    argument. The path separator is prepended before each additional
+ *    path component, so this function never adds a trailing path
+ *    separator.
+ *
+ * Results:
+ *    0 on success.
+ *    error < 0 on failure (the converted string did not fit in
+ *    the buffer provided or the input was invalid).
+ *
+ * Side effects:
+ *    None
+ *
+ *----------------------------------------------------------------------
+ */
+
+int
+CPNameConvertFrom(char const **bufIn, // IN/OUT: Input to convert
+                  size_t *inSize,     // IN/OUT: Size of input
+                  size_t *outSize,    // IN/OUT: Size of output buffer
+                  char **bufOut,      // IN/OUT: Output buffer
+                  char pathSep)       // IN: Path separator character
+{
+   char const *in;
+   char const *inEnd;
+   size_t myOutSize;
+   char *out;
+
+   ASSERT(bufIn);
+   ASSERT(inSize);
+   ASSERT(outSize);
+   ASSERT(bufOut);
+
+   in = *bufIn;
+   inEnd = in + *inSize;
+   myOutSize = *outSize;
+   out = *bufOut;
+
+   for (;;) {
+      char const *next;
+      int len;
+      int newLen;
+
+      len = CPName_GetComponent(in, inEnd, &next);
+      if (len < 0) {
+         Log("CPNameConvertFrom: error: get next component failed\n");
+         return len;
+      }
+
+      if (len == 0) {
+         /* No more component */
+         break;
+      }
+
+      newLen = ((int) myOutSize) - len - 1;
+      if (newLen < 0) {
+         Log("CPNameConvertFrom: error: not enough room\n");
+         return -1;
+      }
+      myOutSize = (size_t) newLen;
+
+      *out++ = pathSep;
+      memcpy(out, in, len);
+      out += len;
+
+      in = next;
+   }
+
+   /* NUL terminate */
+   if (myOutSize < 1) {
+      Log("CPNameConvertFrom: error: not enough room\n");
+      return -1;
+   }
+   *out = '\0';
+
+   /* Path name size should not require more than 4 bytes. */
+   ASSERT((in - *bufIn) <= 0xFFFFFFFF);
+
+   /* Update pointers. */
+   *inSize -= (in - *bufIn);
+   *outSize = myOutSize;
+   *bufIn = in;
+   *bufOut = out;
+
+   return 0;
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * CPName_Print --
+ *
+ *    Converts a CPName formatted string to a valid, NUL-terminated string by
+ *    replacing all embedded NUL characters with '|'.
+ *
+ * Results:
+ *    Pointer to a static buffer containing the converted string.
+ *
+ * Side effects:
+ *    None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+char const *
+CPName_Print(char const *in, // IN: Name to print
+             size_t size)    // IN: Size of name
+{
+   /* Static so it does not go on a kernel stack --hpreg */
+   static char out[128];
+   size_t i;
+
+   ASSERT(in);
+
+   ASSERT(sizeof out >= 4);
+   if (size > sizeof out - 1) {
+      size = sizeof out - 4;
+      out[size] = '.';
+      out[size + 1] = '.';
+      out[size + 2] = '.';
+      out[size + 3] = '\0';
+   } else {
+      out[size] = '\0';
+   }
+
+   for (i = 0; i < size; i++) {
+      out[i] = in[i] != '\0' ? in[i] : '|';
+   }
+
+   return out;
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * CPName_LinuxConvertTo --
+ *
+ *    Wrapper function that calls CPNameConvertTo() with the correct arguments
+ *    for Linux path conversions.
+ *
+ *    Makes a cross-platform name representation from the Linux path input
+ *    string and writes it into the output buffer.
+ *
+ * Results:
+ *    On success, returns the number of bytes used in the cross-platform name,
+ *    NOT including the final terminating NUL character.  On failure, returns
+ *    a negative error.
+ *
+ * Side effects:
+ *    None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+int
+CPName_LinuxConvertTo(char const *nameIn, // IN:  Buf to convert
+                      size_t bufOutSize,  // IN:  Size of the output buffer
+                      char *bufOut)       // OUT: Output buffer
+{
+   return CPNameConvertTo(nameIn, bufOutSize, bufOut, '/', NULL);
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * CPName_WindowsConvertTo --
+ *
+ *    Wrapper function that calls CPNameConvertTo() with the correct arguments
+ *    for Windows path conversions.
+ *
+ *    Makes a cross-platform name representation from the Linux path input
+ *    string and writes it into the output buffer.
+ *
+ * Results:
+ *    On success, returns the number of bytes used in the cross-platform name,
+ *    NOT including the final terminating NUL character.  On failure, returns
+ *    a negative error.
+ *
+ * Side effects:
+ *    None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+int
+CPName_WindowsConvertTo(char const *nameIn, // IN:  Buf to convert
+                        size_t bufOutSize,  // IN:  Size of the output buffer
+                        char *bufOut)       // OUT: Output buffer
+{
+   return CPNameConvertTo(nameIn, bufOutSize, bufOut, '\\', ":");
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * CPNameConvertTo --
+ *
+ *    Makes a cross-platform name representation from the input string
+ *    and writes it into the output buffer.
+ *
+ * Results:
+ *    On success, returns the number of bytes used in the
+ *    cross-platform name, NOT including the final terminating NUL
+ *    character. On failure, returns a negative error.
+ *
+ * Side effects:
+ *    None
+ *
+ *----------------------------------------------------------------------
+ */
+
+int
+CPNameConvertTo(char const *nameIn, // IN:  Buf to convert
+                size_t bufOutSize,  // IN:  Size of the output buffer
+                char *bufOut,       // OUT: Output buffer
+                char pathSep,       // IN:  path separator to use
+                char *ignores)      // IN:  chars to not transfer to output
+{
+   char const *origOut = bufOut;
+   char const *endOut = bufOut + bufOutSize;
+   size_t cpNameLength = 0;
+
+   ASSERT(nameIn);
+   ASSERT(bufOut);
+
+   /* Skip any path separators at the beginning of the input string */
+   while (*nameIn == pathSep) {
+      nameIn++;
+   }
+
+   /*
+    * Copy the string to the output buf, converting all path separators into
+    * '\0' and ignoring the specified characters.
+    */
+   for (; *nameIn != '\0' && bufOut < endOut; nameIn++) {
+      if (ignores) {
+         char *currIgnore = ignores;
+         Bool ignore = FALSE;
+
+         while (*currIgnore != '\0') {
+            if (*nameIn == *currIgnore) {
+               ignore = TRUE;
+               break;
+            }
+            currIgnore++;
+         }
+
+         if (!ignore) {
+            *bufOut = (*nameIn == pathSep) ? '\0' : *nameIn;
+            bufOut++;
+         }
+      } else {
+         *bufOut = (*nameIn == pathSep) ? '\0' : *nameIn;
+         bufOut++;
+      }
+   }
+
+   /*
+    * NUL terminate. XXX This should go away.
+    *
+    * When we get rid of NUL termination here, this test should
+    * also change to "if (*nameIn != '\0')".
+    */
+   if (bufOut == endOut) {
+      return -1;
+   }
+   *bufOut = '\0';
+
+   /* Path name size should not require more than 4 bytes. */
+   ASSERT((bufOut - origOut) <= 0xFFFFFFFF);
+
+   /* If there were any trailing path separators, dont count them [krishnan] */
+   cpNameLength = bufOut - origOut;
+   while ((cpNameLength >= 1) && (origOut[cpNameLength - 1] == 0)) {
+      cpNameLength--;
+   }
+
+   /* Return number of bytes used */
+   return (int) cpNameLength;
+}
--- kernel/linux-2.6.26.3/fs/vmhgfs/cpName.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/cpName.h	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,110 @@
+/*********************************************************
+ * Copyright (C) 1998 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * cpName.h --
+ *
+ *    Cross-platform name format used by hgfs.
+ *
+ */
+
+#ifndef __CP_NAME_H__
+#define __CP_NAME_H__
+
+
+#ifdef __KERNEL__
+#  include "driver-config.h"
+#  include <linux/string.h>
+#elif defined(__FreeBSD__)
+#   if defined(_KERNEL)
+#      include <sys/libkern.h>
+#      define strchr(s,c)       index(s,c)
+#   else
+#      include <string.h>
+#   endif
+#elif defined(__APPLE__) && defined(KERNEL)
+#  include <string.h>
+#elif !defined(sun)
+#  include <stdlib.h>
+#  include <string.h>
+#endif
+
+#include "vm_basic_types.h"
+
+
+/* Status codes for processing share names */
+typedef enum {
+   HGFS_NAME_STATUS_COMPLETE,            /* Name is complete */
+   HGFS_NAME_STATUS_FAILURE,             /* Name processing failed */
+   HGFS_NAME_STATUS_INCOMPLETE_BASE,     /* Name is base of namespace */
+   HGFS_NAME_STATUS_INCOMPLETE_ROOT,     /* Name is "root" only */
+   HGFS_NAME_STATUS_INCOMPLETE_DRIVE,    /* Name is "root drive" only */
+   HGFS_NAME_STATUS_INCOMPLETE_UNC,      /* Name is "root unc" only */
+   HGFS_NAME_STATUS_INCOMPLETE_UNC_MACH, /* Name is "root unc <x>" only */
+   HGFS_NAME_STATUS_DOES_NOT_EXIST,      /* Name does not exist */
+   HGFS_NAME_STATUS_ACCESS_DENIED,       /* Desired access to share denied */
+   HGFS_NAME_STATUS_SYMBOLIC_LINK,       /* Name contains a symbolic link */
+   HGFS_NAME_STATUS_OUT_OF_MEMORY,       /* Out of memory while processing */
+   HGFS_NAME_STATUS_TOO_LONG,            /* Name has overly long component */
+} HgfsNameStatus;
+
+
+int
+CPName_ConvertTo(char const *nameIn, // IN:  The buf to convert
+                 size_t bufOutSize,  // IN:  The size of the output buffer
+                 char *bufOut);      // OUT: The output buffer
+
+int
+CPName_LinuxConvertTo(char const *nameIn, // IN:  buf to convert
+                      size_t bufOutSize,  // IN:  size of the output buffer
+                      char *bufOut);      // OUT: output buffer
+
+int
+CPName_WindowsConvertTo(char const *nameIn, // IN:  buf to convert
+                        size_t bufOutSize,  // IN:  size of the output buffer
+                        char *bufOut);      // OUT: output buffer
+
+int
+CPName_ConvertFrom(char const **bufIn, // IN/OUT: Input to convert
+                   size_t *inSize,     // IN/OUT: Size of input buffer
+                   size_t *outSize,    // IN/OUT: Size of output buffer
+                   char **bufOut);     // IN/OUT: Output buffer
+
+HgfsNameStatus
+CPName_ConvertFromRoot(char const **bufIn, // IN/OUT: Input to convert
+                       size_t *inSize,     // IN/OUT: Size of input
+                       size_t *outSize,    // IN/OUT: Size of output buf
+                       char **bufOut);     // IN/OUT: Output buffer
+
+int
+CPName_GetComponentGeneric(char const *begin,  // IN: Beginning of buffer
+                           char const *end,    // IN: End of buffer
+                           char const *illegal, // IN: Illegal characters
+                           char const **next); // OUT: Next component
+
+int
+CPName_GetComponent(char const *begin,  // IN: Beginning of buffer
+                    char const *end,    // IN: End of buffer
+                    char const **next); // OUT: Next component
+
+char const *
+CPName_Print(char const *in, // IN: Name to print
+             size_t size);   // IN: Size of name
+
+
+#endif /* __CP_NAME_H__ */
--- kernel/linux-2.6.26.3/fs/vmhgfs/cpNameInt.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/cpNameInt.h	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,54 @@
+/*********************************************************
+ * Copyright (C) 1998 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * cpNameInt.h --
+ *
+ *    Cross-platform name format used by hgfs.
+ *
+ */
+
+
+#ifndef __CP_NAME_INT_H__
+#define __CP_NAME_INT_H__
+
+
+#include "vm_basic_types.h"
+
+/*
+ * Used by CPName_ConvertFrom
+ */
+int
+CPNameConvertFrom(char const **bufIn, // IN/OUT: Input to convert
+                  size_t *inSize,     // IN/OUT: Size of input
+                  size_t *outSize,    // IN/OUT: Size of output buffer
+                  char **bufOut,      // IN/OUT: Output buffer
+                  char pathSep);      // IN: Path separator character
+
+
+/*
+ * Common code for CPName_ConvertTo
+ */
+int
+CPNameConvertTo(char const *nameIn, // IN:  Buf to convert
+                size_t bufOutSize,  // IN:  Size of the output buffer
+                char *bufOut,       // OUT: Output buffer
+                char pathSep,       // IN:  path separator to use
+                char *ignores);     // IN:  chars to not transfer to output
+
+#endif /* __CP_NAME_INT_H__ */
--- kernel/linux-2.6.26.3/fs/vmhgfs/cpNameLinux.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/cpNameLinux.c	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,209 @@
+/*********************************************************
+ * Copyright (C) 1998 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * cpNameLinux.c --
+ *
+ *    Linux implementation of cross-platform name conversion
+ *    routines used by hgfs. [bac]
+ *
+ */
+
+#if defined(sun) && !defined(SOL9)
+#include <memory.h>
+#endif
+
+#include "cpName.h"
+#include "cpNameInt.h"
+#include "vm_assert.h"
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * CPName_GetComponent --
+ *
+ *    Get the next component of the CP name.
+ *
+ *    Returns the length of the component starting with the begin
+ *    pointer, and a pointer to the next component in the buffer, if
+ *    any. The "next" pointer is set to "end" if there is no next
+ *    component.
+ *
+ * Results:
+ *    length (not including NUL termination) >= 0 of next
+ *    component on success.
+ *    error < 0 on failure (invalid component).
+ *
+ * Side effects:
+ *    None
+ *
+ *----------------------------------------------------------------------
+ */
+
+int
+CPName_GetComponent(char const *begin,  // IN: Beginning of buffer
+                    char const *end,    // IN: End of buffer
+                    char const **next)  // OUT: Start of next component
+{
+   ASSERT(begin);
+   ASSERT(end);
+   ASSERT(next);
+
+   /*
+    * '/' is not a legal character on Linux, since it is a path
+    * separator.
+    */
+   return CPName_GetComponentGeneric(begin, end, "/", next);
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * CPName_ConvertFrom --
+ *
+ *    Converts a cross-platform name representation into a string for
+ *    use in the local filesystem.
+ *
+ * Results:
+ *    Length (not including NUL termination) >= 0 of resulting
+ *    string on success.
+ *    Negative error on failure (the converted string did not fit in
+ *    the buffer provided or the input was invalid).
+ *
+ * Side effects:
+ *    None
+ *
+ *----------------------------------------------------------------------
+ */
+
+int
+CPName_ConvertFrom(char const **bufIn, // IN/OUT: Input to convert
+                   size_t *inSize,     // IN/OUT: Size of input
+                   size_t *outSize,    // IN/OUT: Size of output buffer
+                   char **bufOut)      // IN/OUT: Output buffer
+{
+   ASSERT(bufIn);
+   ASSERT(inSize);
+   ASSERT(outSize);
+   ASSERT(bufOut);
+
+   return CPNameConvertFrom(bufIn, inSize, outSize, bufOut, '/');
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * CPName_ConvertFromRoot --
+ *
+ *    Append the appropriate prefix to the output buffer for accessing
+ *    the root of the local filesystem. CPName_ConvertFrom prepends
+ *    leading path separators before each path component, but only
+ *    when the next component has nonzero length, so we still need to
+ *    special case this for Linux.
+ *
+ *    The pointers and sizes are updated appropriately.
+ *
+ * Results:
+ *    Status of name conversion
+ *
+ * Side effects:
+ *    None
+ *
+ *----------------------------------------------------------------------
+ */
+
+HgfsNameStatus
+CPName_ConvertFromRoot(char const **bufIn, // IN/OUT: Input to convert
+                       size_t *inSize,     // IN/OUT: Size of input
+                       size_t *outSize,    // IN/OUT: Size of output buffer
+                       char **bufOut)      // IN/OUT: Output buffer
+{
+   char const *next;
+   char *out;
+   int len;
+
+   ASSERT(bufIn);
+   ASSERT(inSize);
+   ASSERT(outSize);
+   ASSERT(bufOut);
+
+   out = *bufOut;
+
+   /*
+    * Get first component
+    */
+   len = CPName_GetComponent(*bufIn, *bufIn + *inSize, &next);
+   if (len < 0) {
+      Log("CPName_ConvertFromRoot: get first component failed\n");
+      return HGFS_NAME_STATUS_FAILURE;
+   }
+
+   /* Space for leading '/' plus NUL termination */
+   if (*outSize < len + 2) {
+      return HGFS_NAME_STATUS_FAILURE;
+   }
+
+   /* Put a leading '/' in the output buffer either way */
+   *out++ = '/';
+
+   memcpy(out, *bufIn, len);
+   out += len;
+
+   /* NUL terminate */
+   *out = '\0';
+
+   *inSize -= next - *bufIn;
+   *outSize -= out - *bufOut;
+   *bufIn = next;
+   *bufOut = out;
+
+   return HGFS_NAME_STATUS_COMPLETE;
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * CPName_ConvertTo --
+ *
+ *    Wrapper function that calls the Linux implementation of _ConvertTo().
+ *
+ *    Makes a cross-platform name representation from the Linux path input
+ *    string and writes it into the output buffer.
+ *
+ * Results:
+ *    On success, returns the number of bytes used in the
+ *    cross-platform name, NOT including the final terminating NUL
+ *    character. On failure, returns a negative error.
+ *
+ * Side effects:
+ *    None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+int
+CPName_ConvertTo(char const *nameIn, // IN:  Buf to convert
+                 size_t bufOutSize,  // IN:  Size of the output buffer
+                 char *bufOut)       // OUT: Output buffer
+{
+   return CPName_LinuxConvertTo(nameIn, bufOutSize, bufOut);
+}
--- kernel/linux-2.6.26.3/fs/vmhgfs/cpNameLite.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/cpNameLite.c	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,97 @@
+/*********************************************************
+ * Copyright (C) 2006 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * cpNameLite.c --
+ *
+ *    Shared portions of cross-platform name conversion routines used
+ *    by hgfs. Unlike the real CP name conversion routines, these ones
+ *    just convert path separators to nul characters and vice versa.
+ *
+ */
+
+#include "cpNameLite.h"
+#include "vm_assert.h"
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * CPNameLite_ConvertTo --
+ *
+ *    Makes a cross-platform lite name representation from the input
+ *    string.
+ *
+ * Results:
+ *    None
+ *
+ * Side effects:
+ *    None
+ *
+ *----------------------------------------------------------------------
+ */
+
+void
+CPNameLite_ConvertTo(char *bufIn,      // IN/OUT: Input to convert
+                     size_t inSize,    // IN: Size of input buffer
+                     char pathSep)     // IN: Path separator
+{
+   size_t pos;
+   ASSERT(bufIn);
+
+   for (pos = 0; pos < inSize; pos++) {
+      if (bufIn[pos] == pathSep) {
+         bufIn[pos] = '\0';
+      }
+   }
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * CPNameLite_ConvertFrom --
+ *
+ *    Converts a cross-platform lite name representation into a string for
+ *    use in the local filesystem. This is a cross-platform
+ *    implementation and takes the path separator as an
+ *    argument.
+ *
+ * Results:
+ *    None
+ *
+ * Side effects:
+ *    None
+ *
+ *----------------------------------------------------------------------
+ */
+
+void
+CPNameLite_ConvertFrom(char *bufIn,     // IN/OUT: Input to convert
+                       size_t inSize,   // IN: Size of input buffer
+                       char pathSep)    // IN: Path separator
+
+{
+   size_t pos;
+   ASSERT(bufIn);
+
+   for (pos = 0; pos < inSize; pos++) {
+      if (bufIn[pos] == '\0') {
+         bufIn[pos] = pathSep;
+      }
+   }
+}
--- kernel/linux-2.6.26.3/fs/vmhgfs/cpNameLite.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/cpNameLite.h	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,53 @@
+/*********************************************************
+ * Copyright (C) 2006 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * cpLiteName.h --
+ *
+ *    Cross-platform "lite" name format used by hgfs.
+ *
+ */
+
+#ifndef __CP_NAME_LITE_H__
+#define __CP_NAME_LITE_H__
+
+#if defined(__KERNEL__) && defined(__linux__)
+#  include "driver-config.h"
+#  include <linux/string.h>
+#elif defined(_KERNEL) && defined(__FreeBSD__)
+#  include <sys/libkern.h>
+#  define strchr(s,c)       index(s,c)
+#else
+#  include <string.h>
+#endif
+
+#include "vm_basic_types.h"
+
+void
+CPNameLite_ConvertTo(char *bufIn,      // IN/OUT: Input to convert
+                     size_t inSize,    // IN: Size of input buffer
+                     char pathSep);    // IN: Path separator
+
+void
+CPNameLite_ConvertFrom(char *bufIn,    // IN/OUT: Input to convert
+                       size_t inSize,  // IN: Size of input buffer
+                       char pathSep);  // IN: Path separator
+
+
+
+#endif /* __CP_NAME_LITE_H__ */
--- kernel/linux-2.6.26.3/fs/vmhgfs/dbllnklst.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/dbllnklst.h	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,69 @@
+/*********************************************************
+ * Copyright (C) 1998 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * dbllnklst.h --
+ *
+ *    Double linked lists
+ */
+
+#ifndef _DBLLNKLST_H_
+#define _DBLLNKLST_H_
+
+#include "vm_basic_types.h"
+
+#define INCLUDE_ALLOW_MODULE
+#define INCLUDE_ALLOW_USERLEVEL
+#include "includeCheck.h"
+
+
+#define DblLnkLst_OffsetOf(type, field) ((intptr_t)&((type *)0)->field)
+
+#define DblLnkLst_Container(addr, type, field) \
+   ((type *)((char *)addr - DblLnkLst_OffsetOf(type, field)))
+
+#define DblLnkLst_ForEach(curr, head)                   \
+      for (curr = (head)->next; curr != (head); curr = (curr)->next)
+
+/* Safe from list element removal within loop body. */
+#define DblLnkLst_ForEachSafe(curr, nextElem, head)             \
+      for (curr = (head)->next, nextElem = (curr)->next;        \
+           curr != (head);                                      \
+           curr = nextElem, nextElem = (curr)->next)
+
+typedef struct DblLnkLst_Links {
+   struct DblLnkLst_Links *prev;
+   struct DblLnkLst_Links *next;
+} DblLnkLst_Links;
+
+
+/* Functions for both circular and anchored lists. --hpreg */
+
+void DblLnkLst_Init(DblLnkLst_Links *l);
+void DblLnkLst_Link(DblLnkLst_Links *l1, DblLnkLst_Links *l2);
+void DblLnkLst_Unlink(DblLnkLst_Links *l1, DblLnkLst_Links *l2);
+void DblLnkLst_Unlink1(DblLnkLst_Links *l);
+Bool DblLnkLst_IsLinked(DblLnkLst_Links const *l);
+
+/* Functions specific to anchored lists. --hpreg */
+
+void DblLnkLst_LinkFirst(DblLnkLst_Links *head, DblLnkLst_Links *l);
+void DblLnkLst_LinkLast(DblLnkLst_Links *head, DblLnkLst_Links *l);
+
+
+#endif /* _DBLLNKLST_H_ */
--- kernel/linux-2.6.26.3/fs/vmhgfs/dentry.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/dentry.c	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,101 @@
+/*********************************************************
+ * Copyright (C) 2006 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * dentry.c --
+ *
+ * Dentry operations for the filesystem portion of the vmhgfs driver.
+ */
+
+/* Must come before any kernel header file. */
+#include "driver-config.h"
+
+#include "compat_fs.h"
+#include "compat_kernel.h"
+#include "compat_version.h"
+
+#include "inode.h"
+#include "module.h"
+#include "vm_assert.h"
+
+/* HGFS dentry operations. */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 5, 75)
+static int HgfsDentryRevalidate(struct dentry *dentry,
+                                struct nameidata *nd);
+#else
+static int HgfsDentryRevalidate(struct dentry *dentry,
+                                int flags);
+#endif
+
+/* HGFS dentry operations structure. */
+struct dentry_operations HgfsDentryOperations = {
+   .d_revalidate     = HgfsDentryRevalidate,
+};
+
+/*
+ * HGFS dentry operations.
+ */
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * HgfsDentryRevalidate --
+ *
+ *    Called by namei.c every time a dentry is looked up in the dcache
+ *    to determine if it is still valid.
+ *
+ *    If the entry is found to be invalid, namei calls dput on it and
+ *    returns NULL, which causes a new lookup to be done in the actual
+ *    filesystem, which in our case means that HgfsLookup is called.
+ *
+ * Results:
+ *    Positive value if the entry IS valid.
+ *    Zero if the entry is NOT valid.
+ *
+ * Side effects:
+ *    None
+ *
+ *----------------------------------------------------------------------
+ */
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 5, 75)
+static int
+HgfsDentryRevalidate(struct dentry *dentry,  // IN: Dentry to revalidate
+                     struct nameidata *nd)   // IN: Lookup flags & intent
+#else
+static int
+HgfsDentryRevalidate(struct dentry *dentry,  // IN: Dentry to revalidate
+                     int flags)              // IN: Lookup flags (e.g. LOOKUP_CONTINUE)
+#endif
+{
+   int error;
+   LOG(6, (KERN_DEBUG "VMware hgfs: HgfsDentryRevalidate: calling "
+           "HgfsRevalidate\n"));
+
+   ASSERT(dentry);
+
+   /* Just call HgfsRevaliate, which does the right thing. */
+   error = HgfsRevalidate(dentry);
+   if (error) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsDentryRevalidate: invalid\n"));
+      return 0;
+   }
+
+   LOG(6, (KERN_DEBUG "VMware hgfs: HgfsDentryRevalidate: valid\n"));
+   return 1;
+}
--- kernel/linux-2.6.26.3/fs/vmhgfs/dir.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/dir.c	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,874 @@
+/*********************************************************
+ * Copyright (C) 2006 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * dir.c --
+ *
+ * Directory operations for the filesystem portion of the vmhgfs driver.
+ */
+
+/* Must come before any kernel header file. */
+#include "driver-config.h"
+
+#include <linux/errno.h>
+#include <linux/module.h>
+#include "compat_fs.h"
+#include "compat_kernel.h"
+#include "compat_slab.h"
+
+#include "cpName.h"
+#include "hgfsEscape.h"
+#include "hgfsProto.h"
+#include "hgfsUtil.h"
+#include "module.h"
+#include "request.h"
+#include "fsutil.h"
+#include "vm_assert.h"
+#include "vm_basic_types.h"
+
+/* Private functions. */
+static int HgfsUnpackSearchReadReply(HgfsReq *req,
+                                     HgfsAttrInfo *attr);
+static int HgfsGetNextDirEntry(HgfsSuperInfo *si,
+                               HgfsHandle searchHandle,
+                               uint32 offset,
+                               HgfsAttrInfo *attr,
+                               Bool *done);
+static int HgfsPackDirOpenRequest(struct inode *inode,
+                                  struct file *file,
+				  HgfsOp opUsed,
+                                  HgfsReq *req);
+
+/* HGFS file operations for directories. */
+static int HgfsDirOpen(struct inode *inode,
+                       struct file *file);
+static int HgfsReaddir(struct file *file,
+                       void *dirent,
+                       filldir_t filldir);
+static int HgfsDirRelease(struct inode *inode,
+                          struct file *file);
+
+/* HGFS file operations structure for directories. */
+struct file_operations HgfsDirFileOperations = {
+   .owner       = THIS_MODULE,
+   .open        = HgfsDirOpen,
+   .read        = generic_read_dir,
+   .readdir     = HgfsReaddir,
+   .release     = HgfsDirRelease,
+};
+
+/*
+ * Private function implementations.
+ */
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * HgfsUnpackSearchReadReply --
+ *
+ *    This function abstracts the differences between a SearchReadV1 and
+ *    a SearchReadV2. The caller provides the packet containing the reply
+ *    and we populate the AttrInfo with version-independent information.
+ *
+ *    Note that attr->requestType has already been populated so that we
+ *    know whether to expect a V1 or V2 reply.
+ *
+ * Results:
+ *    0 on success, anything else on failure.
+ *
+ * Side effects:
+ *    None
+ *
+ *----------------------------------------------------------------------
+ */
+static int
+HgfsUnpackSearchReadReply(HgfsReq *req,        // IN: Reply packet
+                          HgfsAttrInfo *attr)  // IN/OUT: Attributes
+{
+   char *fileName;
+   uint32 fileNameLength;
+   uint32 replySize;
+   int result;
+
+   ASSERT(req);
+   ASSERT(attr);
+
+   result = HgfsUnpackCommonAttr(req, attr);
+   if (result != 0) {
+      return result;
+   }
+
+   switch(attr->requestType) {
+   case HGFS_OP_SEARCH_READ_V3: {
+      HgfsReplySearchReadV3 *replyV3;
+      HgfsDirEntry *dirent;
+
+      /* Currently V3 returns only 1 entry. */
+      replyV3 = (HgfsReplySearchReadV3 *)(HGFS_REP_PAYLOAD_V3(req));
+      replyV3->count = 1;
+      replySize = HGFS_REP_PAYLOAD_SIZE_V3(replyV3) + sizeof *dirent;
+      dirent = (HgfsDirEntry *)replyV3->payload;
+      fileName = dirent->fileName.name;
+      fileNameLength = dirent->fileName.length;
+      break;
+   }
+   case HGFS_OP_SEARCH_READ_V2: {
+      HgfsReplySearchReadV2 *replyV2;
+
+      replyV2 = (HgfsReplySearchReadV2 *)(HGFS_REQ_PAYLOAD(req));
+      replySize = sizeof *replyV2;
+      fileName = replyV2->fileName.name;
+      fileNameLength = replyV2->fileName.length;
+      break;
+   }
+   case HGFS_OP_SEARCH_READ: {
+      HgfsReplySearchRead *replyV1;
+
+      replyV1 = (HgfsReplySearchRead *)(HGFS_REQ_PAYLOAD(req));
+      replySize = sizeof *replyV1;
+      fileName = replyV1->fileName.name;
+      fileNameLength = replyV1->fileName.length;
+      break;
+   }
+   default:
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsUnpackSearchReadReply: unexpected "
+              "OP type encountered\n"));
+      return -EPROTO;
+   }
+
+   /*
+    * Make sure name length is legal.
+    */
+   if (fileNameLength > NAME_MAX ||
+       fileNameLength > HGFS_PACKET_MAX - replySize) {
+      return -ENAMETOOLONG;
+   }
+
+   /*
+    * If the size of the name is valid (meaning the end of the directory has
+    * not yet been reached), copy the name to the AttrInfo struct.
+    *
+    * XXX: This operation happens often and the length of the filename is
+    * bounded by NAME_MAX. Perhaps I should just put a statically-sized
+    * array in HgfsAttrInfo and use a slab allocator to allocate the struct.
+    */
+   if (fileNameLength > 0) {
+      /* Sanity check on name length. */
+      if (fileNameLength != strlen(fileName)) {
+         LOG(4, (KERN_DEBUG "VMware hgfs: HgfsUnpackSearchReadReply: name "
+                 "length mismatch %u/%Zu, name \"%s\"\n",
+                 fileNameLength, strlen(fileName), fileName));
+         return -EPROTO;
+      }
+      attr->fileName = kmalloc(fileNameLength + 1, GFP_KERNEL);
+      if (attr->fileName == NULL) {
+         LOG(4, (KERN_DEBUG "VMware hgfs: HgfsUnpackSearchReadReply: out of "
+                 "memory allocating filename, ignoring\n"));
+         return -ENOMEM;
+      }
+      memcpy(attr->fileName, fileName, fileNameLength + 1);
+   } else {
+      attr->fileName = NULL;
+   }
+   return 0;
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * HgfsGetNextDirEntry --
+ *
+ *    Get the directory entry with the given offset from the server.
+ *
+ *    attr->fileName gets allocated and must be freed by the caller.
+ *
+ * Results:
+ *    Returns zero on success, negative error on failure. If the
+ *    dentry's name is too long, -ENAMETOOLONG is returned.
+ *
+ * Side effects:
+ *    None
+ *
+ *----------------------------------------------------------------------
+ */
+
+static int
+HgfsGetNextDirEntry(HgfsSuperInfo *si,       // IN: Superinfo for this SB
+                    HgfsHandle searchHandle, // IN: Handle of dir
+                    uint32 offset,           // IN: Offset of next dentry to get
+                    HgfsAttrInfo *attr,      // OUT: File attributes of dentry
+                    Bool *done)              // OUT: Set true when there are
+                                             // no more dentries
+{
+   HgfsReq *req;
+   HgfsOp opUsed;
+   HgfsStatus replyStatus;
+   int result = 0;
+
+   ASSERT(si);
+   ASSERT(attr);
+   ASSERT(done);
+
+   req = HgfsGetNewRequest();
+   if (!req) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsGetNextDirEntry: out of memory "
+              "while getting new request\n"));
+      return -ENOMEM;
+   }
+
+  retry:
+   opUsed = atomic_read(&hgfsVersionSearchRead);
+   if (opUsed == HGFS_OP_SEARCH_READ_V3) {
+      HgfsRequest *header;
+      HgfsRequestSearchReadV3 *request;
+
+      header = (HgfsRequest *)(HGFS_REQ_PAYLOAD(req));
+      header->op = attr->requestType = opUsed;
+      header->id = req->id;
+
+      request = (HgfsRequestSearchReadV3 *)(HGFS_REQ_PAYLOAD_V3(req));
+      request->search = searchHandle;
+      request->offset = offset;
+      request->flags = 0;
+      request->reserved = 0;
+      req->payloadSize = HGFS_REQ_PAYLOAD_SIZE_V3(request);
+   } else {
+      HgfsRequestSearchRead *request;
+
+      request = (HgfsRequestSearchRead *)(HGFS_REQ_PAYLOAD(req));
+      request->header.op = attr->requestType = opUsed;
+      request->header.id = req->id;
+      request->search = searchHandle;
+      request->offset = offset;
+      req->payloadSize = sizeof *request;
+   }
+
+   /* Send the request and process the reply. */
+   result = HgfsSendRequest(req);
+   if (result == 0) {
+      LOG(6, (KERN_DEBUG "VMware hgfs: HgfsGetNextDirEntry: got reply\n"));
+      replyStatus = HgfsReplyStatus(req);
+      result = HgfsStatusConvertToLinux(replyStatus);
+
+      switch(result) {
+      case 0:
+         result = HgfsUnpackSearchReadReply(req, attr);
+         if (result == 0 && attr->fileName == NULL) {
+            /* We're at the end of the directory. */
+            LOG(6, (KERN_DEBUG "VMware hgfs: HgfsGetNextDirEntry: end of "
+                    "dir\n"));
+            *done = TRUE;
+         }
+         break;
+
+      case -EPROTO:
+         /* Retry with older version(s). Set globally. */
+         if (attr->requestType == HGFS_OP_SEARCH_READ_V3) {
+            LOG(4, (KERN_DEBUG "VMware hgfs: HgfsGetNextDirEntry: Version 3 "
+                    "not supported. Falling back to version 2.\n"));
+            atomic_set(&hgfsVersionSearchRead, HGFS_OP_SEARCH_READ_V2);
+            goto retry;
+         } else if (attr->requestType == HGFS_OP_SEARCH_READ_V2) {
+            LOG(4, (KERN_DEBUG "VMware hgfs: HgfsGetNextDirEntry: Version 2 "
+                    "not supported. Falling back to version 1.\n"));
+            atomic_set(&hgfsVersionSearchRead, HGFS_OP_SEARCH_READ);
+            goto retry;
+         }
+
+         /* Fallthrough. */
+      default:
+         break;
+      }
+   } else if (result == -EIO) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsGetNextDirEntry: timed out\n"));
+   } else if (result == -EPROTO) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsGetNextDirEntry: server "
+              "returned error: %d\n", result));
+   } else {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsGetNextDirEntry: unknown error: "
+              "%d\n", result));
+   }
+
+   HgfsFreeRequest(req);
+   return result;
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * HgfsPackDirOpenRequest --
+ *
+ *    Setup the directory open request, depending on the op version.
+ *
+ * Results:
+ *    Returns zero on success, or negative error on failure.
+ *
+ * Side effects:
+ *    None
+ *
+ *----------------------------------------------------------------------
+ */
+
+static int
+HgfsPackDirOpenRequest(struct inode *inode, // IN: Inode of the file to open
+                       struct file *file,   // IN: File pointer for this open
+                       HgfsOp opUsed,       // IN: Op to be used
+                       HgfsReq *req)        // IN/OUT: Packet to write into
+{
+   char *name;
+   uint32 *nameLength;
+   size_t requestSize;
+   int result;
+
+   ASSERT(inode);
+   ASSERT(file);
+   ASSERT(req);
+
+   switch (opUsed) {
+   case HGFS_OP_SEARCH_OPEN_V3: {
+      HgfsRequest *requestHeader;
+      HgfsRequestSearchOpenV3 *requestV3;
+
+      requestHeader = (HgfsRequest *)(HGFS_REQ_PAYLOAD(req));
+      requestHeader->op = opUsed;
+      requestHeader->id = req->id;
+
+      requestV3 = (HgfsRequestSearchOpenV3 *)HGFS_REQ_PAYLOAD_V3(req);
+
+      /* We'll use these later. */
+      name = requestV3->dirName.name;
+      nameLength = &requestV3->dirName.length;
+      requestV3->dirName.flags = 0;
+      requestV3->dirName.caseType = HGFS_FILE_NAME_CASE_SENSITIVE;
+      requestV3->dirName.fid = HGFS_INVALID_HANDLE;
+      requestV3->reserved = 0;
+      requestSize = HGFS_REQ_PAYLOAD_SIZE_V3(requestV3);
+      break;
+   }
+
+   case HGFS_OP_SEARCH_OPEN: {
+      HgfsRequestSearchOpen *request;
+
+      request = (HgfsRequestSearchOpen *)(HGFS_REQ_PAYLOAD(req));
+      request->header.op = opUsed;
+      request->header.id = req->id;
+
+      /* We'll use these later. */
+      name = request->dirName.name;
+      nameLength = &request->dirName.length;
+      requestSize = sizeof *request;
+      break;
+   }
+
+   default:
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsPackDirOpenRequest: unexpected "
+              "OP type encountered\n"));
+      return -EPROTO;
+   }
+
+   /* Build full name to send to server. */
+   if (HgfsBuildPath(name, HGFS_PACKET_MAX - (requestSize - 1),
+                     file->f_dentry) < 0) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsPackDirOpenRequest: build path failed\n"));
+      return -EINVAL;
+   }
+   LOG(6, (KERN_DEBUG "VMware hgfs: HgfsPackDirOpenRequest: opening \"%s\"\n",
+           name));
+
+   /* Convert to CP name. */
+   result = CPName_ConvertTo(name,
+                             HGFS_PACKET_MAX - (requestSize - 1),
+                             name);
+   if (result < 0) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsPackDirOpenRequest: CP conversion failed\n"));
+      return -EINVAL;
+   }
+
+   /* Unescape the CP name. */
+   result = HgfsEscape_Undo(name, result);
+   *nameLength = (uint32) result;
+   req->payloadSize = requestSize + result;
+
+   return 0;
+}
+
+
+/*
+ * HGFS file operations for directories.
+ */
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * HgfsDirOpen --
+ *
+ *    Called whenever a process opens a directory in our filesystem.
+ *
+ *    We send a "Search Open" request to the server with the name
+ *    stored in this file's inode. If the Open succeeds, we store the
+ *    search handle sent by the server in the file struct so it can be
+ *    accessed by readdir and close.
+ *
+ * Results:
+ *    Returns zero if on success, error on failure.
+ *
+ * Side effects:
+ *    None
+ *
+ *----------------------------------------------------------------------
+ */
+
+static int
+HgfsDirOpen(struct inode *inode,  // IN: Inode of the dir to open
+            struct file *file)    // IN: File pointer for this open
+{
+   HgfsReq *req;
+   int result;
+   HgfsOp opUsed;
+   HgfsStatus replyStatus;
+   HgfsHandle *replySearch;
+
+   ASSERT(inode);
+   ASSERT(inode->i_sb);
+   ASSERT(file);
+
+   req = HgfsGetNewRequest();
+   if (!req) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsDirOpen: out of memory while "
+              "getting new request\n"));
+      result = -ENOMEM;
+      goto out;
+   }
+
+  retry:
+   opUsed = atomic_read(&hgfsVersionSearchOpen);
+   if (opUsed == HGFS_OP_SEARCH_OPEN_V3) {
+      replySearch = &((HgfsReplySearchOpenV3 *)HGFS_REP_PAYLOAD_V3(req))->search;
+   } else {
+      replySearch = &((HgfsReplySearchOpen *)HGFS_REQ_PAYLOAD(req))->search;
+   }
+
+   result = HgfsPackDirOpenRequest(inode, file, opUsed, req);
+   if (result != 0) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsDirOpen: error packing request\n"));
+      goto out;
+   }
+
+   /* Send the request and process the reply. */
+   result = HgfsSendRequest(req);
+   if (result == 0) {
+      /* Get the reply and check return status. */
+      replyStatus = HgfsReplyStatus(req);
+      result = HgfsStatusConvertToLinux(replyStatus);
+
+      switch (result) {
+      case 0:
+         result = HgfsCreateFileInfo(file, *replySearch);
+         if (result) {
+           goto out;
+         }
+         LOG(6, (KERN_DEBUG "VMware hgfs: HgfsDirOpen: set handle to %u\n",
+                    *replySearch));
+         break;
+      case -EPROTO:
+         /* Retry with older version(s). Set globally. */
+         if (opUsed == HGFS_OP_SEARCH_OPEN_V3) {
+            LOG(4, (KERN_DEBUG "VMware hgfs: HgfsDirOpen: Version 3 not "
+                    "supported. Falling back to version 1.\n"));
+            atomic_set(&hgfsVersionSearchOpen, HGFS_OP_SEARCH_OPEN);
+            goto retry;
+         }
+         LOG(4, (KERN_DEBUG "VMware hgfs: HgfsDirOpen: server "
+                 "returned error: %d\n", result));
+         break;
+
+      default:
+         LOG(4, (KERN_DEBUG "VMware hgfs: HgfsDirOpen: server "
+                  "returned error: %d\n", result));
+         break;
+      }
+   } else if (result == -EIO) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsDirOpen: timed out\n"));
+   } else if (result == -EPROTO) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsDirOpen: server "
+              "returned error: %d\n", result));
+   } else {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsDirOpen: unknown error: "
+              "%d\n", result));
+   }
+
+out:
+   HgfsFreeRequest(req);
+   return result;
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * HgfsReaddir --
+ *
+ *    Handle a readdir request. See details below if interested.
+ *
+ *    Readdir is a bit complicated, and is best understood by reading
+ *    the code. For the impatient, here is an overview of the major
+ *    moving parts [bac]:
+ *
+ *     - Getdents syscall calls readdir, which is supposed to call
+ *       filldir some number of times.
+ *     - Each time it's called, filldir updates a struct with the
+ *       number of bytes copied thus far, and sets an error code if
+ *       appropriate.
+ *     - When readdir returns, getdents checks the struct to see if
+ *       any dentries were copied, and if so returns the byte count.
+ *       Otherwise, it returns the error from the struct (which should
+ *       still be zero if filldir was never called).
+ *
+ *       A consequence of this last fact is that if there are no more
+ *       dentries, then readdir should NOT call filldir, and should
+ *       return from readdir with a non-error.
+ *
+ *    Other notes:
+ *
+ *     - Passing an inum of zero to filldir doesn't work. At a minimum,
+ *       you have to make up a bogus inum for each dentry.
+ *     - Passing the correct d_type to filldir seems to be non-critical;
+ *       apparently most programs (such as ls) stat each file if they
+ *       really want to know what type it is. However, passing the
+ *       correct type means that ls doesn't bother calling stat on
+ *       directories, and that saves an entire round trip per dirctory
+ *       dentry.
+ *
+ * Results:
+ *    Returns zero if on success, negative error on failure.
+ *    (According to /fs/readdir.c, any non-negative return value
+ *    means it succeeded).
+ *
+ * Side effects:
+ *    None
+ *
+ *----------------------------------------------------------------------
+ */
+
+static int
+HgfsReaddir(struct file *file, // IN:  Directory to read from
+            void *dirent,      // OUT: Buffer to copy dentries into
+            filldir_t filldir) // IN:  Filler function
+{
+   HgfsSuperInfo *si;
+   HgfsAttrInfo attr;
+   uint32 d_type;    // type of dirent
+   char *escName = NULL; // buf for escaped version of name
+   size_t escNameLength = NAME_MAX + 1;
+   int nameLength = 0;
+   int result = 0;
+   Bool done = FALSE;
+   ino_t ino;
+
+   ASSERT(file);
+   ASSERT(dirent);
+
+   if (!file ||
+      !(file->f_dentry) ||
+      !(file->f_dentry->d_inode)) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsReaddir: null input\n"));
+      return -EFAULT;
+   }
+
+   ASSERT(file->f_dentry->d_inode->i_sb);
+
+   si = HGFS_SB_TO_COMMON(file->f_dentry->d_inode->i_sb);
+
+   LOG(6, (KERN_DEBUG "VMware hgfs: HgfsReaddir: dir with name %s, "
+           "inum %lu, f_pos %Lu\n",
+          file->f_dentry->d_name.name,
+          file->f_dentry->d_inode->i_ino,
+          file->f_pos));
+
+   /*
+    * Some day when we're out of things to do we can move this to a slab
+    * allocator.
+    */
+   escName = kmalloc(escNameLength, GFP_KERNEL);
+   if (!escName) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsReaddir: out of memory allocating "
+              "escaped name buffer\n"));
+      return  -ENOMEM;
+   }
+
+   while (1) {
+      /*
+       * Nonzero result = we failed to get valid reply from server.
+       * Zero result:
+       *     - done == TRUE means we hit the end of the directory
+       *     - Otherwise, attr.fileName has the name of the next dirent
+       *
+       */
+      result = HgfsGetNextDirEntry(si,
+                                   FILE_GET_FI_P(file)->handle,
+                                   (uint32)file->f_pos,
+                                   &attr,
+                                   &done);
+      if (result == -ENAMETOOLONG) {
+         /*
+          * Skip dentry if its name is too long (see below).
+          *
+          * XXX: If a bad server sends us bad packets, we can loop here
+          * forever, as I did while testing *grumble*. Maybe we should error
+          * in that case.
+          */
+         file->f_pos++;
+         continue;
+      } else if (result) {
+         /* Error  */
+         LOG(4, (KERN_DEBUG "VMware hgfs: HgfsReaddir: error "
+                 "getting dentry\n"));
+         kfree(escName);
+         return result;
+      }
+      if (done == TRUE) {
+         LOG(6, (KERN_DEBUG "VMware hgfs: HgfsReaddir: end of dir reached\n"));
+         break;
+      }
+
+      /*
+       * Escape all non-printable characters (which for linux is just
+       * "/").
+       *
+       * Note that normally we would first need to convert from the
+       * CP name format, but that is done implicitely here since we
+       * are guaranteed to have just one path component per dentry.
+       */
+      result = HgfsEscape_Do(attr.fileName,
+			     strlen(attr.fileName),
+			     escNameLength,
+			     escName);
+      kfree(attr.fileName);
+
+      /*
+       * Check the filename length.
+       *
+       * If the name is too long to be represented in linux, we simply
+       * skip it (i.e., that file is not visible to our filesystem) by
+       * incrementing file->f_pos and repeating the loop to get the
+       * next dentry.
+       *
+       * HgfsEscape_Do returns a negative value if the escaped
+       * output didn't fit in the specified output size, so we can
+       * just check its return value.
+       */
+      if (result < 0) {
+         /*
+          * XXX: Another area where a bad server could cause us to loop
+          * forever.
+          */
+         file->f_pos++;
+         continue;
+      }
+
+      nameLength = result;
+
+      /* Assign the correct dentry type. */
+      switch (attr.type) {
+
+      case HGFS_FILE_TYPE_SYMLINK:
+         d_type = DT_LNK;
+         break;
+
+      case HGFS_FILE_TYPE_REGULAR:
+         d_type = DT_REG;
+         break;
+
+      case HGFS_FILE_TYPE_DIRECTORY:
+         d_type = DT_DIR;
+         break;
+
+      default:
+         /*
+          * XXX Should never happen. I'd put NOT_IMPLEMENTED() here
+          * but if the driver ever goes in the host it's probably not
+          * a good idea for an attacker to be able to hang the host
+          * simply by using a bogus file type in a reply. [bac]
+          */
+         d_type = DT_UNKNOWN;
+         break;
+      }
+
+      /*
+       * It is unfortunate, but the HGFS server sends back '.' and ".."
+       * when we do a SearchRead. In an ideal world, these would be faked
+       * on the client, but it would be a real backwards-compatibility
+       * hassle to change the behavior at this point.
+       *
+       * So instead, we'll take the '.' and ".." and modify their inode
+       * numbers so they match what the client expects.
+       */
+      if (!strncmp(escName, ".", sizeof ".")) {
+         ino = file->f_dentry->d_inode->i_ino;
+      } else if (!strncmp(escName, "..", sizeof "..")) {
+         ino = compat_parent_ino(file->f_dentry);
+      } else {
+         if (attr.mask & HGFS_ATTR_VALID_FILEID) {
+            ino = attr.hostFileId;
+         } else {
+            ino = iunique(file->f_dentry->d_inode->i_sb,
+                          HGFS_RESERVED_INO);
+         }
+      }
+
+      /*
+       * Call filldir for this dentry.
+       */
+      LOG(6, (KERN_DEBUG "VMware hgfs: HgfsReaddir: calling filldir "
+              "with \"%s\", %u, %Lu\n", escName, nameLength, file->f_pos));
+      result = filldir(dirent,         /* filldir callback struct */
+                       escName,        /* name of dirent */
+                       nameLength,     /* length of name */
+                       file->f_pos,    /* offset of dirent */
+                       ino,            /* inode number (0 makes it not show) */
+                       d_type);        /* type of dirent */
+      if (result) {
+         /*
+          * This means that filldir ran out of room in the user buffer
+          * it was copying into; we just break out and return, but
+          * don't increment f_pos. So the next time the user calls
+          * getdents, this dentry will be requested again, will get
+          * retrieved again, and get copied properly to the user.
+          */
+         break;
+      }
+      file->f_pos++;
+   }
+
+   LOG(6, (KERN_DEBUG "VMware hgfs: HgfsReaddir: finished\n"));
+   kfree(escName);
+   return 0;
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * HgfsDirRelease --
+ *
+ *    Called when the last reader of a directory closes it, i.e. when
+ *    the directory's file f_count field becomes zero.
+ *
+ * Results:
+ *    Returns zero on success, or an error on failure.
+ *
+ * Side effects:
+ *    None
+ *
+ *----------------------------------------------------------------------
+ */
+
+static int
+HgfsDirRelease(struct inode *inode,  // IN: Inode that the file* points to
+               struct file *file)    // IN: File for the dir getting released
+{
+   HgfsReq *req;
+   HgfsStatus replyStatus;
+   HgfsHandle handle;
+   HgfsOp opUsed;
+   int result = 0;
+
+   ASSERT(inode);
+   ASSERT(file);
+   ASSERT(file->f_dentry);
+   ASSERT(file->f_dentry->d_sb);
+
+   handle = FILE_GET_FI_P(file)->handle;
+   LOG(6, (KERN_DEBUG "VMware hgfs: HgfsDirRelease: close fh %u\n", handle));
+
+   HgfsReleaseFileInfo(file);
+
+   req = HgfsGetNewRequest();
+   if (!req) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsDirRelease: out of memory while "
+              "getting new request\n"));
+      result = -ENOMEM;
+      goto out;
+   }
+
+ retry:
+   opUsed = atomic_read(&hgfsVersionSearchClose);
+   if (opUsed == HGFS_OP_SEARCH_CLOSE_V3) {
+      HgfsRequestSearchCloseV3 *request;
+      HgfsRequest *header;
+
+      header = (HgfsRequest *)(HGFS_REQ_PAYLOAD(req));
+      header->id = req->id;
+      header->op = opUsed;
+
+      request = (HgfsRequestSearchCloseV3 *)(HGFS_REQ_PAYLOAD_V3(req));
+      request->search = handle;
+      request->reserved = 0;
+      req->payloadSize = HGFS_REQ_PAYLOAD_SIZE_V3(request);
+   } else {
+      HgfsRequestSearchClose *request;
+
+      request = (HgfsRequestSearchClose *)(HGFS_REQ_PAYLOAD(req));
+      request->header.id = req->id;
+      request->header.op = opUsed;
+      request->search = handle;
+      req->payloadSize = sizeof *request;
+   }
+
+   /* Send the request and process the reply. */
+   result = HgfsSendRequest(req);
+   if (result == 0) {
+      /* Get the reply. */
+      replyStatus = HgfsReplyStatus(req);
+      result = HgfsStatusConvertToLinux(replyStatus);
+
+      switch (result) {
+      case 0:
+         LOG(4, (KERN_DEBUG "VMware hgfs: HgfsDirRelease: release handle %u\n",
+                 handle));
+         break;
+      case -EPROTO:
+         /* Retry with older version(s). Set globally. */
+         if (opUsed == HGFS_OP_SEARCH_CLOSE_V3) {
+            LOG(4, (KERN_DEBUG "VMware hgfs: HgfsDirRelease: Version 3 not "
+                    "supported. Falling back to version 1.\n"));
+            atomic_set(&hgfsVersionSearchClose, HGFS_OP_SEARCH_CLOSE);
+            goto retry;
+         }
+         break;
+      default:
+         LOG(4, (KERN_DEBUG "VMware hgfs: HgfsDirRelease: failed handle %u\n",
+                 handle));
+         break;
+      }
+   } else if (result == -EIO) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsDirRelease: timed out\n"));
+   } else if (result == -EPROTO) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsDirRelease: server "
+              "returned error: %d\n", result));
+   } else {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsOpen: unknown error: "
+              "%d\n", result));
+   }
+
+out:
+   HgfsFreeRequest(req);
+   return result;
+}
--- kernel/linux-2.6.26.3/fs/vmhgfs/driver-config.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/driver-config.h	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,78 @@
+/*********************************************************
+ * Copyright (C) 1998 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * Sets the proper defines from the Linux header files
+ *
+ * This file must be included before the inclusion of any kernel header file,
+ * with the exception of linux/autoconf.h and linux/version.h --hpreg
+ */
+
+#ifndef __VMX_CONFIG_H__
+#define __VMX_CONFIG_H__
+
+#define INCLUDE_ALLOW_VMCORE
+#define INCLUDE_ALLOW_VMMON
+#define INCLUDE_ALLOW_MODULE
+#define INCLUDE_ALLOW_VMNIXMOD
+#include "includeCheck.h"
+
+#include <linux/autoconf.h>
+#include "compat_version.h"
+
+/*
+ * We rely on Kernel Module support.  Check here.
+ */
+#ifndef CONFIG_MODULES
+#   error "No Module support in this kernel.  Please configure with CONFIG_MODULES"
+#endif
+
+/*
+ * 2.2 kernels still use __SMP__ (derived from CONFIG_SMP
+ * in the main Makefile), so we do it here.
+ */
+
+#ifdef CONFIG_SMP
+#   define __SMP__ 1
+#endif
+
+#if defined(CONFIG_MODVERSIONS) && defined(KERNEL_2_1)
+#   if LINUX_VERSION_CODE < KERNEL_VERSION(2,5,60)
+/*
+ * MODVERSIONS might be already defined when using kernel's Makefiles.
+ */
+#      ifndef MODVERSIONS
+#         define MODVERSIONS
+#      endif
+#      include <linux/modversions.h>
+#   endif
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 24)
+/*
+ * Force the uintptr_t definition to come from linux/types.h instead of vm_basic_types.h.
+ */
+#   include <linux/types.h>
+#   define _STDINT_H 1
+#endif
+
+#ifndef __KERNEL__
+#   define __KERNEL__
+#endif
+
+#endif
--- kernel/linux-2.6.26.3/fs/vmhgfs/escBitvector.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/escBitvector.h	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,142 @@
+/*********************************************************
+ * Copyright (C) 1998 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+
+
+#ifndef _ESC_BITVECTOR_H_
+#define _ESC_BITVECTOR_H_
+
+#define INCLUDE_ALLOW_USERLEVEL
+#define INCLUDE_ALLOW_MODULE
+#define INCLUDE_ALLOW_DISTRIBUTE  // XXX is this true?
+#include "includeCheck.h"
+
+
+#ifdef __KERNEL__
+#include "driver-config.h"
+#include <linux/string.h>
+/* Don't include these if compiling for the Solaris or Apple kernels. */
+#elif !defined(_KERNEL) && !defined(KERNEL)
+#include <stdlib.h>
+#include <string.h>
+#endif
+
+#if defined(_KERNEL) && defined(__FreeBSD__)
+# include <sys/libkern.h>
+#elif defined(KERNEL) && defined(__APPLE__)
+# include <string.h>
+#endif
+
+#include "vm_assert.h"
+
+
+
+#define ESC_BITVECTOR_INDEX(_x)     ((_x)>>5)
+#define ESC_BITVECTOR_MASK(_x)      (1<<((_x)&31))
+
+#define ESC_BITVECTOR_SIZE 256 // hardwired size of the bitvector
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * EscBitVector --
+ *
+ *      Taken from bitvector.h, but hard wired for use with the Escape
+ *      routines, which always need a bitvector of 256 bits, are never
+ *      used in the monitor, and need to work in the linux kernel. [bac]
+ *
+ *
+ *----------------------------------------------------------------------
+ */
+typedef struct EscBitVector {
+   uint32 vector[ESC_BITVECTOR_SIZE/32];
+} EscBitVector;
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * EscBitVector_Init --
+ *
+ *      Clear all the bits in this vector.
+ *
+ * Results:
+ *      All bits are cleared
+ *      
+ *----------------------------------------------------------------------
+ */
+static INLINE void EscBitVector_Init(EscBitVector *bv)
+{
+   memset(bv, 0, sizeof(EscBitVector));
+}
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * EscBitVector_Set, EscBitVector_Clear, EscBitVector_Test --
+ *
+ *      basic operations
+ *
+ * Results:
+ *      insertion/deletion/presence  to/from/in the set
+ *      
+ *      EscBitVector_Test returns non-zero if present, 0 otherwise
+ *
+ *
+ *----------------------------------------------------------------------
+ */
+static INLINE void EscBitVector_Set(EscBitVector *bv,int n)
+{
+   ASSERT(n>=0 && n<ESC_BITVECTOR_SIZE);
+#ifdef __GNUC__
+   __asm__ __volatile ( "btsl %1,%0" : "=m" (bv->vector[0]) :"Ir" (n));
+#else
+   bv->vector[ESC_BITVECTOR_INDEX(n)] |= ESC_BITVECTOR_MASK(n);
+#endif
+}
+
+static INLINE void EscBitVector_Clear(EscBitVector *bv,int n)
+{
+   ASSERT(n>=0 && n<ESC_BITVECTOR_SIZE);
+#ifdef __GNUC__
+   __asm__ __volatile ( "btrl %1,%0" : "=m" (bv->vector[0]) :"Ir" (n));
+#else
+   bv->vector[ESC_BITVECTOR_INDEX(n)] &= ~ESC_BITVECTOR_MASK(n);
+#endif
+}
+
+static INLINE int EscBitVector_Test(EscBitVector const *bv, int n)
+{
+   ASSERT(n>=0 && n<ESC_BITVECTOR_SIZE);
+#ifdef __GNUC__
+   {
+      uint32 tmp;
+   __asm__ __volatile ( "btl %2,%1\n\tsbbl %0,%0" : "=r" (tmp) : "m" (bv->vector[0]),"Ir" (n));
+      return tmp;
+   }
+#else
+   return ((bv->vector[ESC_BITVECTOR_INDEX(n)] & ESC_BITVECTOR_MASK(n)) != 0);
+#endif
+}
+
+
+
+
+#endif  /* _ESC_BITVECTOR_H_ */
+
+
--- kernel/linux-2.6.26.3/fs/vmhgfs/file.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/file.c	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,1218 @@
+/*********************************************************
+ * Copyright (C) 2006 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * file.c --
+ *
+ * File operations for the filesystem portion of the vmhgfs driver.
+ */
+
+/* Must come before any kernel header file. */
+#include "driver-config.h"
+
+#include <linux/errno.h>
+#include <linux/module.h>
+#include <linux/signal.h>
+#include "compat_fs.h"
+#include "compat_kernel.h"
+#include "compat_slab.h"
+
+#include "cpName.h"
+#include "hgfsEscape.h"
+#include "hgfsProto.h"
+#include "module.h"
+#include "request.h"
+#include "hgfsUtil.h"
+#include "fsutil.h"
+#include "vm_assert.h"
+#include "vm_basic_types.h"
+
+/* Private functions. */
+static int HgfsPackOpenRequest(struct inode *inode,
+                               struct file *file,
+			       HgfsOp opUsed,
+                               HgfsReq *req);
+static int HgfsUnpackOpenReply(HgfsReq *req,
+                               HgfsOp opUsed,
+                               HgfsHandle *file,
+                               HgfsServerLock *lock);
+static int HgfsGetOpenFlags(uint32 flags);
+
+/* HGFS file operations for files. */
+static int HgfsOpen(struct inode *inode,
+                    struct file *file);
+#if defined(VMW_USE_AIO)
+static ssize_t HgfsAioRead(struct kiocb *iocb,
+                           const struct iovec *iov,
+                           unsigned long numSegs,
+                           loff_t offset);
+static ssize_t HgfsAioWrite(struct kiocb *iocb,
+                            const struct iovec *iov,
+                            unsigned long numSegs,
+                            loff_t offset);
+#else
+static ssize_t HgfsRead(struct file *file,
+                        char __user *buf,
+                        size_t count,
+                        loff_t *offset);
+static ssize_t HgfsWrite(struct file *file,
+                         const char __user *buf,
+                         size_t count,
+                         loff_t *offset);
+#endif
+static int HgfsFsync(struct file *file,
+                     struct dentry *dentry,
+                     int datasync);
+static int HgfsMmap(struct file *file,
+                    struct vm_area_struct *vma);
+static int HgfsRelease(struct inode *inode,
+                       struct file *file);
+
+#ifndef VMW_SENDFILE_NONE
+#if defined(VMW_SENDFILE_OLD)
+static ssize_t HgfsSendfile(struct file *file,
+                            loff_t *offset,
+                            size_t count,
+                            read_actor_t actor,
+                            void __user *target);
+#else /* defined(VMW_SENDFILE_NEW) */
+static ssize_t HgfsSendfile(struct file *file,
+                            loff_t *offset,
+                            size_t count,
+                            read_actor_t actor,
+                            void *target);
+#endif
+#endif
+#ifdef VMW_SPLICE_READ
+static ssize_t HgfsSpliceRead(struct file *file,
+                              loff_t *offset,
+                              struct pipe_inode_info *pipe,
+                              size_t len,
+                              unsigned int flags);
+#endif
+
+/* HGFS file operations structure for files. */
+struct file_operations HgfsFileFileOperations = {
+   .owner      = THIS_MODULE,
+   .open       = HgfsOpen,
+#if defined(VMW_USE_AIO)
+   .aio_read   = HgfsAioRead,
+   .aio_write  = HgfsAioWrite,
+#else
+   .read       = HgfsRead,
+   .write      = HgfsWrite,
+#endif
+   .fsync      = HgfsFsync,
+   .mmap       = HgfsMmap,
+   .release    = HgfsRelease,
+#ifndef VMW_SENDFILE_NONE
+   .sendfile   = HgfsSendfile,
+#endif
+#ifdef VMW_SPLICE_READ
+   .splice_read = HgfsSpliceRead,
+#endif
+};
+
+/* File open mask. */
+#define HGFS_FILE_OPEN_MASK (HGFS_OPEN_VALID_MODE | \
+                             HGFS_OPEN_VALID_FLAGS | \
+                             HGFS_OPEN_VALID_SPECIAL_PERMS | \
+			     HGFS_OPEN_VALID_OWNER_PERMS | \
+			     HGFS_OPEN_VALID_GROUP_PERMS | \
+			     HGFS_OPEN_VALID_OTHER_PERMS | \
+			     HGFS_OPEN_VALID_FILE_NAME | \
+			     HGFS_OPEN_VALID_SERVER_LOCK)
+
+
+/*
+ * Private functions.
+ */
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * HgfsPackOpenRequest --
+ *
+ *    Setup the Open request, depending on the op version.
+ *
+ * Results:
+ *    Returns zero on success, or negative error on failure.
+ *
+ * Side effects:
+ *    None
+ *
+ *----------------------------------------------------------------------
+ */
+
+static int
+HgfsPackOpenRequest(struct inode *inode, // IN: Inode of the file to open
+                    struct file *file,   // IN: File pointer for this open
+		    HgfsOp opUsed,       // IN: Op to use
+                    HgfsReq *req)        // IN/OUT: Packet to write into
+{
+   char *name;
+   uint32 *nameLength;
+   size_t requestSize;
+   int result;
+
+   ASSERT(inode);
+   ASSERT(file);
+   ASSERT(req);
+
+   switch (opUsed) {
+    case HGFS_OP_OPEN_V3: {
+      HgfsRequest *requestHeader;
+      HgfsRequestOpenV3 *requestV3;
+
+      requestHeader = (HgfsRequest *)HGFS_REQ_PAYLOAD(req);
+      requestHeader->op = opUsed;
+      requestHeader->id = req->id;
+
+      requestV3 = (HgfsRequestOpenV3 *)HGFS_REQ_PAYLOAD_V3(req);
+      requestSize = HGFS_REQ_PAYLOAD_SIZE_V3(requestV3);
+
+      /* We'll use these later. */
+      name = requestV3->fileName.name;
+      nameLength = &requestV3->fileName.length;
+
+      requestV3->mask = HGFS_FILE_OPEN_MASK;
+
+      /* Linux clients need case-sensitive lookups. */
+      requestV3->fileName.flags = 0;
+      requestV3->fileName.caseType = HGFS_FILE_NAME_CASE_SENSITIVE;
+      requestV3->fileName.fid = HGFS_INVALID_HANDLE;
+
+      /* Set mode. */
+      result = HgfsGetOpenMode(file->f_flags);
+      if (result < 0) {
+         LOG(4, (KERN_DEBUG "VMware hgfs: HgfsPackOpenRequest: failed to get "
+                 "open mode\n"));
+         return -EINVAL;
+      }
+      requestV3->mode = result;
+
+      /* Set flags. */
+      result = HgfsGetOpenFlags(file->f_flags);
+      if (result < 0) {
+         LOG(4, (KERN_DEBUG "VMware hgfs: HgfsPackOpenRequest: failed to get "
+                 "open flags\n"));
+         return -EINVAL;
+      }
+      requestV3->flags = result;
+
+      /* Set permissions. */
+      requestV3->specialPerms = (inode->i_mode & (S_ISUID | S_ISGID | S_ISVTX))
+                                >> 9;
+      requestV3->ownerPerms = (inode->i_mode & S_IRWXU) >> 6;
+      requestV3->groupPerms = (inode->i_mode & S_IRWXG) >> 3;
+      requestV3->otherPerms = (inode->i_mode & S_IRWXO);
+
+      /* XXX: Request no lock for now. */
+      requestV3->desiredLock = HGFS_LOCK_NONE;
+
+      requestV3->reserved1 = 0;
+      requestV3->reserved2 = 0;
+      break;
+   }
+
+   case HGFS_OP_OPEN_V2: {
+      HgfsRequestOpenV2 *requestV2;
+
+      requestV2 = (HgfsRequestOpenV2 *)(HGFS_REQ_PAYLOAD(req));
+      requestV2->header.op = opUsed;
+      requestV2->header.id = req->id;
+
+      /* We'll use these later. */
+      name = requestV2->fileName.name;
+      nameLength = &requestV2->fileName.length;
+      requestSize = sizeof *requestV2;
+
+      requestV2->mask = HGFS_FILE_OPEN_MASK;
+
+      /* Set mode. */
+      result = HgfsGetOpenMode(file->f_flags);
+      if (result < 0) {
+         LOG(4, (KERN_DEBUG "VMware hgfs: HgfsPackOpenRequest: failed to get "
+                 "open mode\n"));
+         return -EINVAL;
+      }
+      requestV2->mode = result;
+
+      /* Set flags. */
+      result = HgfsGetOpenFlags(file->f_flags);
+      if (result < 0) {
+         LOG(4, (KERN_DEBUG "VMware hgfs: HgfsPackOpenRequest: failed to get "
+                 "open flags\n"));
+         return -EINVAL;
+      }
+      requestV2->flags = result;
+
+      /* Set permissions. */
+      requestV2->specialPerms = (inode->i_mode & (S_ISUID | S_ISGID | S_ISVTX))
+                                >> 9;
+      requestV2->ownerPerms = (inode->i_mode & S_IRWXU) >> 6;
+      requestV2->groupPerms = (inode->i_mode & S_IRWXG) >> 3;
+      requestV2->otherPerms = (inode->i_mode & S_IRWXO);
+
+      /* XXX: Request no lock for now. */
+      requestV2->desiredLock = HGFS_LOCK_NONE;
+      break;
+   }
+   case HGFS_OP_OPEN: {
+      HgfsRequestOpen *request;
+
+      request = (HgfsRequestOpen *)(HGFS_REQ_PAYLOAD(req));
+      request->header.op = opUsed;
+      request->header.id = req->id;
+
+      /* We'll use these later. */
+      name = request->fileName.name;
+      nameLength = &request->fileName.length;
+      requestSize = sizeof *request;
+
+      /* Set mode. */
+      result = HgfsGetOpenMode(file->f_flags);
+      if (result < 0) {
+         LOG(4, (KERN_DEBUG "VMware hgfs: HgfsPackOpenRequest: failed to get "
+                 "open mode\n"));
+         return -EINVAL;
+      }
+      request->mode = result;
+
+      /* Set flags. */
+      result = HgfsGetOpenFlags(file->f_flags);
+      if (result < 0) {
+         LOG(4, (KERN_DEBUG "VMware hgfs: HgfsPackOpenRequest: failed to get "
+                 "open flags\n"));
+         return -EINVAL;
+      }
+      request->flags = result;
+
+      /* Set permissions. */
+      request->permissions = (inode->i_mode & S_IRWXU) >> 6;
+      break;
+   }
+   default:
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsPackOpenRequest: unexpected "
+              "OP type encountered\n"));
+      return -EPROTO;
+   }
+
+   /* Build full name to send to server. */
+   if (HgfsBuildPath(name,
+                     HGFS_PACKET_MAX - (requestSize - 1),
+                     file->f_dentry) < 0) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsPackOpenRequest: build path "
+              "failed\n"));
+      return -EINVAL;
+   }
+   LOG(6, (KERN_DEBUG "VMware hgfs: HgfsPackOpenRequest: opening \"%s\", "
+           "flags %o, create perms %o\n", name,
+           file->f_flags, file->f_mode));
+
+   /* Convert to CP name. */
+   result = CPName_ConvertTo(name,
+                             HGFS_PACKET_MAX - (requestSize - 1),
+                             name);
+   if (result < 0) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsPackOpenRequest: CP conversion "
+              "failed\n"));
+      return -EINVAL;
+   }
+
+   /* Unescape the CP name. */
+   result = HgfsEscape_Undo(name, result);
+   *nameLength = (uint32) result;
+   req->payloadSize = requestSize + result;
+
+   return 0;
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * HgfsUnpackOpenReply --
+ *
+ *    Get interesting fields out of the Open reply, depending on the op
+ *    version.
+ *
+ * Results:
+ *    Returns zero on success, or negative error on failure.
+ *
+ * Side effects:
+ *    None
+ *
+ *----------------------------------------------------------------------
+ */
+
+static int
+HgfsUnpackOpenReply(HgfsReq *req,          // IN: Packet with reply inside
+                    HgfsOp opUsed,         // IN: What request op did we send
+                    HgfsHandle *file,      // OUT: Handle in reply packet
+                    HgfsServerLock *lock)  // OUT: The server lock we got
+{
+   HgfsReplyOpenV3 *replyV3;
+   HgfsReplyOpenV2 *replyV2;
+   HgfsReplyOpen *replyV1;
+   size_t replySize;
+
+   ASSERT(req);
+   ASSERT(file);
+   ASSERT(lock);
+
+   switch (opUsed) {
+   case HGFS_OP_OPEN_V3:
+      replyV3 = (HgfsReplyOpenV3 *)HGFS_REP_PAYLOAD_V3(req);
+      replySize = HGFS_REP_PAYLOAD_SIZE_V3(replyV3);
+      *file = replyV3->file;
+      *lock = replyV3->acquiredLock;
+      break;
+   case HGFS_OP_OPEN_V2:
+      replyV2 = (HgfsReplyOpenV2 *)(HGFS_REQ_PAYLOAD(req));
+      replySize = sizeof *replyV2;
+      *file = replyV2->file;
+      *lock = replyV2->acquiredLock;
+      break;
+   case HGFS_OP_OPEN:
+      replyV1 = (HgfsReplyOpen *)(HGFS_REQ_PAYLOAD(req));
+      replySize = sizeof *replyV1;
+      *file = replyV1->file;
+      *lock = HGFS_LOCK_NONE;
+      break;
+   default:
+
+      /* This really shouldn't happen since we set opUsed ourselves. */
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsUnpackOpenReply: unexpected "
+              "OP type encountered\n"));
+      ASSERT(FALSE);
+      return -EPROTO;
+   }
+
+   if (req->payloadSize != replySize) {
+      /*
+       * The reply to Open is a fixed size. So the size of the payload
+       * really ought to match the expected size of an HgfsReplyOpen[V2].
+       */
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsUnpackOpenReply: wrong packet "
+              "size\n"));
+      return -EPROTO;
+   }
+   return 0;
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * HgfsGetOpenFlags --
+ *
+ *    Based on the flags requested by the process making the open()
+ *    syscall, determine which flags to send to the server to open the
+ *    file.
+ *
+ * Results:
+ *    Returns the correct HgfsOpenFlags enumeration to send to the
+ *    server, or -1 on failure.
+ *
+ * Side effects:
+ *    None
+ *
+ *----------------------------------------------------------------------
+ */
+
+static int
+HgfsGetOpenFlags(uint32 flags) // IN: Open flags
+{
+   uint32 mask = O_CREAT | O_TRUNC | O_EXCL;
+   int result = -1;
+
+   LOG(6, (KERN_DEBUG "VMware hgfs: HgfsGetOpenFlags: entered\n"));
+
+   /*
+    * Mask the flags to only look at O_CREAT, O_EXCL, and O_TRUNC.
+    */
+
+   flags &= mask;
+
+   /* O_EXCL has no meaning if O_CREAT is not set. */
+   if (!(flags & O_CREAT)) {
+      flags &= ~O_EXCL;
+   }
+
+   /* Pick the right HgfsOpenFlags. */
+   switch (flags) {
+
+   case 0:
+      /* Regular open; fails if file nonexistant. */
+      result = HGFS_OPEN;
+      break;
+
+   case O_CREAT:
+      /* Create file; if it exists already just open it. */
+      result = HGFS_OPEN_CREATE;
+      break;
+
+   case O_TRUNC:
+      /* Truncate existing file; fails if nonexistant. */
+      result = HGFS_OPEN_EMPTY;
+      break;
+
+   case (O_CREAT | O_EXCL):
+      /* Create file; fail if it exists already. */
+      result = HGFS_OPEN_CREATE_SAFE;
+      break;
+
+   case (O_CREAT | O_TRUNC):
+      /* Create file; if it exists already, truncate it. */
+      result = HGFS_OPEN_CREATE_EMPTY;
+      break;
+
+   default:
+      /*
+       * This can only happen if all three flags are set, which
+       * conceptually makes no sense because O_EXCL and O_TRUNC are
+       * mutually exclusive if O_CREAT is set.
+       *
+       * However, the open(2) man page doesn't say you can't set all
+       * three flags, and certain apps (*cough* Nautilus *cough*) do
+       * so. To be friendly to those apps, we just silenty drop the
+       * O_TRUNC flag on the assumption that it's safer to honor
+       * O_EXCL.
+       */
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsGetOpenFlags: invalid open "
+              "flags %o. Ignoring the O_TRUNC flag.\n", flags));
+      result = HGFS_OPEN_CREATE_SAFE;
+      break;
+   }
+
+   return result;
+}
+
+
+/*
+ * HGFS file operations for files.
+ */
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * HgfsOpen --
+ *
+ *    Called whenever a process opens a file in our filesystem.
+ *
+ *    We send an "Open" request to the server with the name stored in
+ *    this file's inode. If the Open succeeds, we store the filehandle
+ *    sent by the server in the file struct so it can be accessed by
+ *    read/write/close.
+ *
+ * Results:
+ *    Returns zero if on success, error on failure.
+ *
+ * Side effects:
+ *    None
+ *
+ *----------------------------------------------------------------------
+ */
+
+static int
+HgfsOpen(struct inode *inode,  // IN: Inode of the file to open
+         struct file *file)    // IN: File pointer for this open
+{
+   HgfsSuperInfo *si;
+   HgfsReq *req;
+   HgfsOp opUsed;
+   HgfsStatus replyStatus;
+   HgfsHandle replyFile;
+   HgfsServerLock replyLock;
+   HgfsInodeInfo *iinfo;
+   int result = 0;
+
+   ASSERT(inode);
+   ASSERT(inode->i_sb);
+   ASSERT(file);
+   ASSERT(file->f_dentry);
+   ASSERT(file->f_dentry->d_inode);
+
+   si = HGFS_SB_TO_COMMON(inode->i_sb);
+   iinfo = INODE_GET_II_P(inode);
+
+   req = HgfsGetNewRequest();
+   if (!req) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsOpen: out of memory while "
+              "getting new request\n"));
+      result = -ENOMEM;
+      goto out;
+   }
+
+  retry:
+   /*
+    * Set up pointers using the proper struct This lets us check the
+    * version exactly once and use the pointers later.
+    */
+
+   opUsed = atomic_read(&hgfsVersionOpen);
+   result = HgfsPackOpenRequest(inode, file, opUsed, req);
+   if (result != 0) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsOpen: error packing request\n"));
+      goto out;
+   }
+
+   /* Send the request and process the reply. */
+   result = HgfsSendRequest(req);
+   if (result == 0) {
+      /* Get the reply and check return status. */
+      replyStatus = HgfsReplyStatus(req);
+      result = HgfsStatusConvertToLinux(replyStatus);
+
+      switch (result) {
+      case 0:
+         iinfo->createdAndUnopened = FALSE;
+         result = HgfsUnpackOpenReply(req, opUsed, &replyFile, &replyLock);
+         if (result != 0) {
+            break;
+         }
+         result = HgfsCreateFileInfo(file, replyFile);
+         if (result != 0) {
+            break;
+         }
+         LOG(6, (KERN_DEBUG "VMware hgfs: HgfsOpen: set handle to %u\n",
+                 replyFile));
+
+         /*
+          * HgfsCreate faked all of the inode's attributes, so by the time
+          * we're done in HgfsOpen, we need to make sure that the attributes
+          * in the inode are real. The following is only necessary when
+          * O_CREAT is set, otherwise we got here after HgfsLookup (which sent
+          * a getattr to the server and got the real attributes).
+          *
+          * In particular, we'd like to at least try and set the inode's
+          * uid/gid to match the caller's. We don't expect this to work,
+          * because Windows servers will ignore it, and Linux servers running
+          * as non-root won't be able to change it, but we're forward thinking
+          * people.
+          *
+          * Either way, we force a revalidate following the setattr so that
+          * we'll get the actual uid/gid from the server.
+          */
+         if (file->f_flags & O_CREAT) {
+            struct dentry *dparent;
+            struct inode *iparent;
+
+            /*
+             * This is not the root of our file system so there should always
+             * be a parent.
+             */
+            ASSERT(file->f_dentry->d_parent);
+
+            /*
+             * Here we obtain a reference on the parent to make sure it doesn't
+             * go away.  This might not be necessary, since the existence of
+             * a child (which we hold a reference to in this call) should
+             * account for a reference in the parent, but it's safe to do so.
+             * Overly cautious and safe is better than risky and broken.
+             *
+             * XXX Note that this and a handful of other hacks wouldn't be
+             * necessary if we actually created the file in our create
+             * implementation (where references and locks are properly held).
+             * We could do this if we were willing to give up support for
+             * O_EXCL on 2.4 kernels.
+             */
+            dparent = dget(file->f_dentry->d_parent);
+            iparent = dparent->d_inode;
+
+            HgfsSetUidGid(iparent, file->f_dentry,
+                          current->fsuid, current->fsgid);
+
+            dput(dparent);
+         }
+         break;
+
+      case -EPROTO:
+         /* Retry with older version(s). Set globally. */
+         if (opUsed == HGFS_OP_OPEN_V3) {
+            LOG(4, (KERN_DEBUG "VMware hgfs: HgfsOpen: Version 3 not "
+                    "supported. Falling back to version 2.\n"));
+            atomic_set(&hgfsVersionOpen, HGFS_OP_OPEN_V2);
+            goto retry;
+         }
+
+         /* Retry with Version 1 of Open. Set globally. */
+         if (opUsed == HGFS_OP_OPEN_V2) {
+            LOG(4, (KERN_DEBUG "VMware hgfs: HgfsOpen: Version 2 not "
+                    "supported. Falling back to version 1.\n"));
+            atomic_set(&hgfsVersionOpen, HGFS_OP_OPEN);
+            goto retry;
+         }
+
+         /* Fallthrough. */
+      default:
+         break;
+      }
+   } else if (result == -EIO) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsOpen: timed out\n"));
+   } else if (result == -EPROTO) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsOpen: server "
+              "returned error: %d\n", result));
+   } else {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsOpen: unknown error: "
+              "%d\n", result));
+   }
+out:
+   HgfsFreeRequest(req);
+
+   /*
+    * If the open failed (for any reason) and we tried to open a newly created
+    * file, we must ensure that the next operation on this inode triggers a
+    * revalidate to the server. This is because the file wasn't created on the
+    * server, yet we currently believe that it was, because we created a fake
+    * inode with a hashed dentry for it in HgfsCreate. We will continue to
+    * believe this until the dentry's ttl expires, which will cause a
+    * revalidate to the server that will reveal the truth. So in order to find
+    * the truth as soon as possible, we'll reset the dentry's last revalidate
+    * time now to force a revalidate the next time someone uses the dentry.
+    *
+    * We're using our own flag to track this case because using O_CREAT isn't
+    * good enough: HgfsOpen will be called with O_CREAT even if the file exists
+    * on the server, and if that's the case, there's no need to revalidate.
+    *
+    * XXX: Note that this will need to be reworked if/when we support hard
+    * links, because multiple dentries will point to the same inode, and
+    * forcing a revalidate on one will not force it on any others.
+    */
+   if (result != 0 && iinfo->createdAndUnopened == TRUE) {
+      HgfsDentryAgeForce(file->f_dentry);
+   }
+   return result;
+}
+
+
+#if defined(VMW_USE_AIO)
+/*
+ *----------------------------------------------------------------------
+ *
+ * HgfsAioRead --
+ *
+ *    Called when the kernel initiates an asynchronous read to a file in
+ *    our filesystem. Our function is just a thin wrapper around
+ *    generic_file_aio_read() that tries to validate the dentry first.
+ *
+ * Results:
+ *    Returns the number of bytes read on success, or an error on
+ *    failure.
+ *
+ * Side effects:
+ *    None
+ *
+ *----------------------------------------------------------------------
+ */
+
+static ssize_t
+HgfsAioRead(struct kiocb *iocb,      // IN:  I/O control block
+            const struct iovec *iov, // OUT: Array of I/O buffers
+            unsigned long numSegs,   // IN:  Number of buffers
+            loff_t offset)           // IN:  Offset at which to read
+{
+   int result;
+
+   ASSERT(iocb);
+   ASSERT(iocb->ki_filp);
+   ASSERT(iocb->ki_filp->f_dentry);
+   ASSERT(iov);
+
+   LOG(6, (KERN_DEBUG "VMware hgfs: HgfsAioRead: was called\n"));
+
+   result = HgfsRevalidate(iocb->ki_filp->f_dentry);
+   if (result) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsAioRead: invalid dentry\n"));
+      goto out;
+   }
+
+   result = generic_file_aio_read(iocb, iov, numSegs, offset);
+  out:
+   return result;
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * HgfsAioWrite --
+ *
+ *    Called when the kernel initiates an asynchronous write to a file in
+ *    our filesystem. Our function is just a thin wrapper around
+ *    generic_file_aio_write() that tries to validate the dentry first.
+ *
+ *    Note that files opened with O_SYNC (or superblocks mounted with
+ *    "sync") are synchronously written to by the VFS.
+ *
+ * Results:
+ *    Returns the number of bytes written on success, or an error on
+ *    failure.
+ *
+ * Side effects:
+ *    None
+ *
+ *----------------------------------------------------------------------
+ */
+
+static ssize_t
+HgfsAioWrite(struct kiocb *iocb,      // IN:  I/O control block
+             const struct iovec *iov, // IN:  Array of I/O buffers
+             unsigned long numSegs,   // IN:  Number of buffers
+             loff_t offset)           // IN:  Offset at which to read
+{
+   int result;
+
+   ASSERT(iocb);
+   ASSERT(iocb->ki_filp);
+   ASSERT(iocb->ki_filp->f_dentry);
+   ASSERT(iov);
+
+   LOG(6, (KERN_DEBUG "VMware hgfs: HgfsAioWrite: was called\n"));
+
+   result = HgfsRevalidate(iocb->ki_filp->f_dentry);
+   if (result) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsAioWrite: invalid dentry\n"));
+      goto out;
+   }
+
+   result = generic_file_aio_write(iocb, iov, numSegs, offset);
+  out:
+   return result;
+}
+
+
+#else
+/*
+ *----------------------------------------------------------------------
+ *
+ * HgfsRead --
+ *
+ *    Called whenever a process reads from a file in our filesystem. Our
+ *    function is just a thin wrapper around generic_read_file() that
+ *    tries to validate the dentry first.
+ *
+ * Results:
+ *    Returns the number of bytes read on success, or an error on
+ *    failure.
+ *
+ * Side effects:
+ *    None
+ *
+ *----------------------------------------------------------------------
+ */
+
+static ssize_t
+HgfsRead(struct file *file,  // IN:  File to read from
+         char __user *buf,   // OUT: User buffer to copy data into
+         size_t count,       // IN:  Number of bytes to read
+         loff_t *offset)     // IN:  Offset at which to read
+{
+   int result;
+
+   ASSERT(file);
+   ASSERT(file->f_dentry);
+   ASSERT(buf);
+   ASSERT(offset);
+
+   LOG(6, (KERN_DEBUG "VMware hgfs: HgfsRead: read %Zu bytes from fh %u "
+           "at offset %Lu\n", count, FILE_GET_FI_P(file)->handle, *offset));
+
+   result = HgfsRevalidate(file->f_dentry);
+   if (result) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsRead: invalid dentry\n"));
+      goto out;
+   }
+
+   result = generic_file_read(file, buf, count, offset);
+  out:
+   return result;
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * HgfsWrite --
+ *
+ *    Called whenever a process writes to a file in our filesystem. Our
+ *    function is just a thin wrapper around generic_write_file() that
+ *    tries to validate the dentry first.
+ *
+ *    Note that files opened with O_SYNC (or superblocks mounted with
+ *    "sync") are synchronously written to by the VFS.
+ *
+ * Results:
+ *    Returns the number of bytes written on success, or an error on
+ *    failure.
+ *
+ * Side effects:
+ *    None
+ *
+ *----------------------------------------------------------------------
+ */
+
+static ssize_t
+HgfsWrite(struct file *file,      // IN: File to write to
+          const char __user *buf, // IN: User buffer where the data is
+          size_t count,           // IN: Number of bytes to write
+          loff_t *offset)         // IN: Offset to begin writing at
+{
+   int result;
+
+   ASSERT(file);
+   ASSERT(file->f_dentry);
+   ASSERT(file->f_dentry->d_inode);
+   ASSERT(buf);
+   ASSERT(offset);
+
+   LOG(6, (KERN_DEBUG "VMware hgfs: HgfsWrite: write %Zu bytes to fh %u "
+           "at offset %Lu\n", count, FILE_GET_FI_P(file)->handle, *offset));
+
+   result = HgfsRevalidate(file->f_dentry);
+   if (result) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsWrite: invalid dentry\n"));
+      goto out;
+   }
+
+   result = generic_file_write(file, buf, count, offset);
+  out:
+   return result;
+}
+#endif
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * HgfsFsync --
+ *
+ *    Called when user process calls fsync() on hgfs file.
+ *
+ *    The hgfs protocol doesn't support fsync yet, so for now, we punt
+ *    and just return success. This is a little less sketchy than it
+ *    might sound, because hgfs skips the buffer cache in the guest
+ *    anyway (we always write to the host immediately).
+ *
+ *    In the future we might want to try harder though, since
+ *    presumably the intent of an app calling fsync() is to get the
+ *    data onto persistent storage, and as things stand now we're at
+ *    the whim of the hgfs server code running on the host to fsync or
+ *    not if and when it pleases.
+ *
+ *    Note that do_fsync will call filemap_fdatawrite() before us and
+ *    filemap_fdatawait() after us, so there's no need to do anything
+ *    here w.r.t. writing out dirty pages.
+ *
+ * Results:
+ *    Returns zero on success. (Currently always succeeds).
+ *
+ * Side effects:
+ *    None.
+ *
+ *----------------------------------------------------------------------
+ */
+
+static int
+HgfsFsync(struct file *file,		// IN: File we operate on
+          struct dentry *dentry,        // IN: Dentry for this file
+          int datasync)	                // IN: fdatasync or fsync
+{
+   LOG(6, (KERN_DEBUG "VMware hgfs: HgfsFsync: was called\n"));
+
+   return 0;
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * HgfsMmap --
+ *
+ *    Called when user process calls mmap() on hgfs file. This is a very
+ *    thin wrapper function- we simply attempt to revalidate the
+ *    dentry prior to calling generic_file_mmap().
+ *
+ * Results:
+ *    Returns zero on success.
+ *    Returns negative error value on failure
+ *
+ * Side effects:
+ *    None.
+ *
+ *----------------------------------------------------------------------
+ */
+
+static int
+HgfsMmap(struct file *file,		// IN: File we operate on
+         struct vm_area_struct *vma)	// IN/OUT: VM area information
+{
+   int result;
+
+   ASSERT(file);
+   ASSERT(vma);
+   ASSERT(file->f_dentry);
+
+   LOG(6, (KERN_DEBUG "VMware hgfs: HgfsMmap: was called\n"));
+
+   result = HgfsRevalidate(file->f_dentry);
+   if (result) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsMmap: invalid dentry\n"));
+      goto out;
+   }
+
+   result = generic_file_mmap(file, vma);
+  out:
+   return result;
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * HgfsRelease --
+ *
+ *    Called when the last user of a file closes it, i.e. when the
+ *    file's f_count becomes zero.
+ *
+ * Results:
+ *    Returns zero on success, or an error on failure.
+ *
+ * Side effects:
+ *    None
+ *
+ *----------------------------------------------------------------------
+ */
+
+static int
+HgfsRelease(struct inode *inode,  // IN: Inode that this file points to
+            struct file *file)    // IN: File that is getting released
+{
+   HgfsSuperInfo *si;
+   HgfsReq *req;
+   HgfsHandle handle;
+   HgfsOp opUsed;
+   HgfsStatus replyStatus;
+   int result = 0;
+
+   ASSERT(inode);
+   ASSERT(file);
+   ASSERT(file->f_dentry);
+   ASSERT(file->f_dentry->d_sb);
+
+   handle = FILE_GET_FI_P(file)->handle;
+   LOG(6, (KERN_DEBUG "VMware hgfs: HgfsRelease: close fh %u\n", handle));
+
+   /*
+    * This may be our last open handle to an inode, so we should flush our
+    * dirty pages before closing it.
+    */
+   compat_filemap_write_and_wait(inode->i_mapping);
+
+   HgfsReleaseFileInfo(file);
+   si = HGFS_SB_TO_COMMON(file->f_dentry->d_sb);
+
+   req = HgfsGetNewRequest();
+   if (!req) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsRelease: out of memory while "
+              "getting new request\n"));
+      result = -ENOMEM;
+      goto out;
+   }
+
+ retry:
+   opUsed = atomic_read(&hgfsVersionClose);
+   if (opUsed == HGFS_OP_CLOSE_V3) {
+      HgfsRequest *header;
+      HgfsRequestCloseV3 *request;
+
+      header = (HgfsRequest *)(HGFS_REQ_PAYLOAD(req));
+      header->id = req->id;
+      header->op = opUsed;
+
+      request = (HgfsRequestCloseV3 *)(HGFS_REQ_PAYLOAD_V3(req));
+      request->file = handle;
+      request->reserved = 0;
+      req->payloadSize = HGFS_REQ_PAYLOAD_SIZE_V3(request);
+   } else {
+      HgfsRequestClose *request;
+
+      request = (HgfsRequestClose *)(HGFS_REQ_PAYLOAD(req));
+      request->header.id = req->id;
+      request->header.op = opUsed;
+      request->file = handle;
+      req->payloadSize = sizeof *request;
+   }
+
+   /* Send the request and process the reply. */
+   result = HgfsSendRequest(req);
+   if (result == 0) {
+      /* Get the reply. */
+      replyStatus = HgfsReplyStatus(req);
+      result = HgfsStatusConvertToLinux(replyStatus);
+
+      switch (result) {
+      case 0:
+         LOG(4, (KERN_DEBUG "VMware hgfs: HgfsRelease: released handle %u\n",
+                 handle));
+         break;
+      case -EPROTO:
+         /* Retry with older version(s). Set globally. */
+         if (opUsed == HGFS_OP_CLOSE_V3) {
+            LOG(4, (KERN_DEBUG "VMware hgfs: HgfsRelease: Version 3 not "
+                    "supported. Falling back to version 1.\n"));
+            atomic_set(&hgfsVersionClose, HGFS_OP_CLOSE);
+            goto retry;
+         }
+         break;
+      default:
+         LOG(4, (KERN_DEBUG "VMware hgfs: HgfsRelease: failed handle %u\n",
+                 handle));
+         break;
+      }
+   } else if (result == -EIO) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsRelease: timed out\n"));
+   } else if (result == -EPROTO) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsRelease: server "
+              "returned error: %d\n", result));
+   } else {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsRelease: unknown error: "
+              "%d\n", result));
+   }
+
+out:
+   HgfsFreeRequest(req);
+   return result;
+}
+
+
+#ifndef VMW_SENDFILE_NONE
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * HgfsSendfile --
+ *
+ *    sendfile() wrapper for HGFS. Note that this is for sending a file
+ *    from HGFS to another filesystem (or socket). To use HGFS as the
+ *    destination file in a call to sendfile(), we must implement sendpage()
+ *    as well.
+ *
+ *    Like mmap(), we're just interested in validating the dentry and then
+ *    calling into generic_file_sendfile().
+ *
+ * Results:
+ *    Returns number of bytes written on success, or an error on failure.
+ *
+ * Side effects:
+ *    None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+#if defined(VMW_SENDFILE_OLD)
+static ssize_t
+HgfsSendfile(struct file *file,    // IN: File to read from
+             loff_t *offset,       // IN/OUT: Where to start reading
+             size_t count,         // IN: How much to read
+             read_actor_t actor,   // IN: Routine to send a page of data
+             void __user *target)  // IN: Destination file/socket
+#elif defined(VMW_SENDFILE_NEW)
+static ssize_t
+HgfsSendfile(struct file *file,    // IN: File to read from
+             loff_t *offset,       // IN/OUT: Where to start reading
+             size_t count,         // IN: How much to read
+             read_actor_t actor,   // IN: Routine to send a page of data
+             void *target)         // IN: Destination file/socket
+#endif
+{
+   ssize_t result;
+
+   ASSERT(file);
+   ASSERT(file->f_dentry);
+   ASSERT(target);
+   ASSERT(offset);
+   ASSERT(actor);
+
+   LOG(6, (KERN_DEBUG "VMware hgfs: HgfsSendfile: was called\n"));
+
+   result = HgfsRevalidate(file->f_dentry);
+   if (result) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsSendfile: invalid dentry\n"));
+      goto out;
+   }
+
+   result = generic_file_sendfile (file, offset, count, actor, target);
+  out:
+   return result;
+
+}
+#endif
+
+
+#ifdef VMW_SPLICE_READ
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * HgfsSpliceRead --
+ *
+ *    splice_read() wrapper for HGFS. Note that this is for sending a file
+ *    from HGFS to another filesystem (or socket). To use HGFS as the
+ *    destination file in a call to splice, we must implement splice_write()
+ *    as well.
+ *
+ *    Like mmap(), we're just interested in validating the dentry and then
+ *    calling into generic_file_splice_read().
+ *
+ * Results:
+ *    Returns number of bytes written on success, or an error on failure.
+ *
+ * Side effects:
+ *    None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static ssize_t
+HgfsSpliceRead(struct file *file,            // IN: File to read from
+               loff_t *offset,               // IN/OUT: Where to start reading
+               struct pipe_inode_info *pipe, // IN: Pipe where to write data
+               size_t len,                   // IN: How much to read
+               unsigned int flags)           // IN: Various flags
+{
+   ssize_t result;
+
+   ASSERT(file);
+   ASSERT(file->f_dentry);
+
+   LOG(6, (KERN_DEBUG "VMware hgfs: HgfsSpliceRead: was called\n"));
+
+   result = HgfsRevalidate(file->f_dentry);
+   if (result) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsSpliceRead: invalid dentry\n"));
+      goto out;
+   }
+
+   result = generic_file_splice_read(file, offset, pipe, len, flags);
+  out:
+   return result;
+
+}
+#endif
+
+
--- kernel/linux-2.6.26.3/fs/vmhgfs/filesystem.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/filesystem.c	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,706 @@
+/*********************************************************
+ * Copyright (C) 2006 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * filesystem.c --
+ *
+ * High-level filesystem operations for the filesystem portion of
+ * the vmhgfs driver.
+ */
+
+/* Must come before any kernel header file. */
+#include "driver-config.h"
+
+#include <asm/atomic.h>
+#include <linux/errno.h>
+#include <linux/list.h>
+#include <linux/module.h>
+#include <linux/pagemap.h>
+#include "compat_completion.h"
+#include "compat_dcache.h"
+#include "compat_fs.h"
+#include "compat_kernel.h"
+#include "compat_kthread.h"
+#include "compat_sched.h"
+#include "compat_semaphore.h"
+#include "compat_slab.h"
+#include "compat_spinlock.h"
+#include "compat_string.h"
+#include "compat_uaccess.h"
+#include "compat_version.h"
+
+/* Must be included after sched.h. */
+#include <linux/smp_lock.h>
+
+#include "bdhandler.h"
+#include "filesystem.h"
+#include "hgfsDevLinux.h"
+#include "hgfsProto.h"
+#include "hgfsUtil.h"
+#include "module.h"
+#include "request.h"
+#include "fsutil.h"
+#include "vm_assert.h"
+#include "vm_basic_types.h"
+#include "rpcout.h"
+#include "hgfs.h"
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 25)
+#define KERNEL_25_FS 0
+#else
+#define KERNEL_25_FS 1
+#endif
+
+#define HGFS_BD_THREAD_NAME "VMware hgfs backdoor handler"
+
+/* Synchronization primitives. */
+spinlock_t hgfsBigLock = SPIN_LOCK_UNLOCKED;
+long hgfsReqThreadFlags;
+wait_queue_head_t hgfsReqThreadWait;
+struct task_struct *hgfsReqThread;
+COMPAT_KTHREAD_DECLARE_STOP_INFO();
+
+/* Other variables. */
+compat_kmem_cache *hgfsReqCache = NULL;
+compat_kmem_cache *hgfsInodeCache = NULL;
+RpcOut *hgfsRpcOut = NULL;
+unsigned int hgfsIdCounter = 0;
+struct list_head hgfsReqsUnsent;
+
+/* Global protocol version switch. */
+atomic_t hgfsVersionOpen;
+atomic_t hgfsVersionRead;
+atomic_t hgfsVersionWrite;
+atomic_t hgfsVersionClose;
+atomic_t hgfsVersionSearchOpen;
+atomic_t hgfsVersionSearchRead;
+atomic_t hgfsVersionSearchClose;
+atomic_t hgfsVersionGetattr;
+atomic_t hgfsVersionSetattr;
+atomic_t hgfsVersionCreateDir;
+atomic_t hgfsVersionDeleteFile;
+atomic_t hgfsVersionDeleteDir;
+atomic_t hgfsVersionRename;
+atomic_t hgfsVersionQueryVolumeInfo;
+atomic_t hgfsVersionCreateSymlink;
+
+/* Private functions. */
+static inline unsigned long HgfsComputeBlockBits(unsigned long blockSize);
+static compat_kmem_cache_ctor HgfsInodeCacheCtor;
+static HgfsSuperInfo *HgfsInitSuperInfo(HgfsMountInfo *mountInfo);
+static int HgfsReadSuper(struct super_block *sb,
+                         void *rawData,
+                         int flags);
+
+
+/* HGFS filesystem high-level operations. */
+#if KERNEL_25_FS /* { */
+#   if defined(VMW_GETSB_2618)
+static int HgfsGetSb(struct file_system_type *fs_type,
+                     int flags,
+                     const char *dev_name,
+                     void *rawData,
+                     struct vfsmount *mnt);
+#   elif LINUX_VERSION_CODE >= KERNEL_VERSION(2, 5, 70)
+static struct super_block *HgfsGetSb(struct file_system_type *fs_type,
+                                     int flags,
+                                     const char *dev_name,
+                                     void *rawData);
+#   else
+static struct super_block *HgfsGetSb(struct file_system_type *fs_type,
+                                     int flags,
+                                     char *dev_name,
+                                     void *rawData);
+#   endif
+#else /* } { */
+static struct super_block *HgfsReadSuper24(struct super_block *sb,
+                                           void *rawData,
+                                           int flags);
+#endif /* } */
+
+/* HGFS filesystem type structure. */
+static struct file_system_type hgfsType = {
+   .owner        = THIS_MODULE,
+   .name         = HGFS_NAME,
+
+   .fs_flags     = FS_BINARY_MOUNTDATA,
+#if KERNEL_25_FS
+   .get_sb       = HgfsGetSb,
+   .kill_sb      = kill_anon_super,
+#else
+   .read_super   = HgfsReadSuper24,
+#endif
+};
+
+
+/*
+ * Private functions implementations.
+ */
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * HgfsComputeBlockBits --
+ *
+ *      Given a block size, returns the number of bits in the block, rounded
+ *      down. This approach of computing the number of bits per block and
+ *      saving it for later use is the same used in NFS.
+ *
+ * Results:
+ *      The number of bits in the block.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static inline unsigned long
+HgfsComputeBlockBits(unsigned long blockSize)
+{
+   uint8 numBits;
+
+   for (numBits = 31; numBits && !(blockSize & (1 << numBits)); numBits--);
+   return numBits;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * HgfsInodeCacheCtor --
+ *
+ *      Constructor for HGFS inode structures that runs once at slab
+ *      allocation. It is called once for each piece of memory that
+ *      is used to satisfy HGFS inode allocations; it should only be
+ *      used to initialize items that will naturally return to their
+ *      initialized state before deallocation (such as locks, list_heads).
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static void
+HgfsInodeCacheCtor(COMPAT_KMEM_CACHE_CTOR_ARGS(slabElem)) // IN: slab item to initialize
+{
+#ifdef VMW_EMBED_INODE
+   HgfsInodeInfo *iinfo = (HgfsInodeInfo *)slabElem;
+
+   /*
+    * VFS usually calls this as part of allocating inodes for us, but since
+    * we're doing the allocation now, we need to call it. It'll set up
+    * much of the VFS inode members.
+    */
+   inode_init_once(&iinfo->inode);
+#endif
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * HgfsInitSuperInfo --
+ *
+ *    Allocate and initialize a new HgfsSuperInfo object
+ *
+ * Results:
+ *    Returns a new HgfsSuperInfo object with all its fields initialized,
+ *    or an error code cast as a pointer.
+ *
+ * Side effects:
+ *    None
+ *
+ *----------------------------------------------------------------------
+ */
+
+static HgfsSuperInfo *
+HgfsInitSuperInfo(HgfsMountInfo *mountInfo) // IN: Passed down from the user
+{
+   HgfsSuperInfo *si = NULL;
+   int result = 0;
+   int len;
+   char *tmpName;
+   Bool hostValid;
+
+   si = kmalloc(sizeof *si, GFP_KERNEL);
+   if (!si) {
+      result = -ENOMEM;
+      goto out2;
+   }
+
+   /*
+    * If the mounter specified a uid or gid, we will prefer them over any uid
+    * or gid given to us by the server.
+    */
+   si->uidSet = mountInfo->uidSet;
+   if (si->uidSet) {
+      si->uid = mountInfo->uid;
+   } else {
+      si->uid = current->uid;
+   }
+   si->gidSet = mountInfo->gidSet;
+   if (si->gidSet) {
+      si->gid = mountInfo->gid;
+   } else {
+      si->gid = current->gid;
+   }
+   si->fmask = mountInfo->fmask;
+   si->dmask = mountInfo->dmask;
+   si->ttl = mountInfo->ttl * HZ; // in ticks
+
+   /*
+    * We don't actually care about this field (though we may care in the
+    * future). For now, just make sure it is set to ".host" as a sanity check.
+    *
+    * We can't call getname() directly because on certain kernels we can't call
+    * putname() directly.  For more details, see the change description of
+    * change 464782 or the second comment in bug 159623, which fixed the same
+    * problem for vmblock.
+    */
+   tmpName = compat___getname();
+   if (!tmpName) {
+      LOG(6, (KERN_DEBUG "VMware hgfs: HgfsInitSuperInfo: could not obtain "
+              "memory for filename\n"));
+      result = -ENOMEM;
+      goto out2;
+   }
+
+   len = strncpy_from_user(tmpName, mountInfo->shareNameHost, PATH_MAX);
+   if (len < 0 || len >= PATH_MAX) {
+      LOG(6, (KERN_DEBUG "VMware hgfs: HgfsInitSuperInfo: strncpy_from_user "
+              "on host string failed\n"));
+      result = len < 0 ? len : -ENAMETOOLONG;
+      goto out;
+   }
+
+   hostValid = strcmp(tmpName, ".host") == 0;
+   if (!hostValid) {
+      LOG(6, (KERN_DEBUG "VMware hgfs: HgfsInitSuperInfo: host string is "
+              "invalid\n"));
+      result = -EINVAL;
+      goto out;
+   }
+
+   /*
+    * Perform a simple sanity check on the directory portion: it must begin
+    * with forward slash.
+    */
+   len = strncpy_from_user(tmpName, mountInfo->shareNameDir, PATH_MAX);
+   if (len < 0 || len >= PATH_MAX) {
+      LOG(6, (KERN_DEBUG "VMware hgfs: HgfsInitSuperInfo: strncpy_from_user "
+              "on dir string failed\n"));
+      result = len < 0 ? len : -ENAMETOOLONG;
+      goto out;
+   }
+
+   if (*tmpName != '/') {
+      LOG(6, (KERN_DEBUG "VMware hgfs: HgfsInitSuperInfo: dir string is "
+              "invalid\n"));
+      result = -EINVAL;
+      goto out;
+   }
+
+   /*
+    * The SELinux audit subsystem will delay the putname() of a string until
+    * the end of a system call so that it may be audited at any point. At that
+    * time, it also unconditionally calls putname() on every string allocated
+    * by getname().
+    *
+    * This means we can't safely retain strings allocated by getname() beyond
+    * the syscall boundary. So after getting the string, use kstrdup() to
+    * duplicate it, and store that (audit-safe) result in the SuperInfo struct.
+    */
+   si->shareName = compat_kstrdup(tmpName, GFP_KERNEL);
+   if (si->shareName == NULL) {
+      LOG(6, (KERN_DEBUG "VMware hgfs: HgfsInitSuperInfo: kstrdup on "
+              "dir string failed\n"));
+      result = -ENOMEM;
+      goto out;
+   }
+   si->shareNameLen = strlen(si->shareName);
+
+  out:
+   compat___putname(tmpName);
+  out2:
+   if (result) {
+      /* If we failed, si->shareName couldn't have been allocated. */
+      kfree(si);
+      si = ERR_PTR(result);
+   }
+   return si;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * HgfsReadSuper --
+ *
+ *    The main entry point of the filesystem side of the driver. Called when
+ *    a userland process does a mount(2) of an hgfs filesystem. This makes the
+ *    whole driver transition from its initial state to state 1. Fill the
+ *    content of the uninitialized superblock provided by the kernel.
+ *
+ *    'rawData' is a pointer (that can be NULL) to a kernel buffer (whose
+ *    size is <= PAGE_SIZE) that corresponds to the filesystem-specific 'data'
+ *    argument passed to mount(2).
+ *
+ * Results:
+ *    zero and initialized superblock on success
+ *    negative value on failure
+ *
+ * Side effects:
+ *    None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static int
+HgfsReadSuper(struct super_block *sb, // OUT: Superblock object
+              void *rawData,          // IN: Fs-specific mount data
+              int flags)              // IN: Mount flags
+{
+   int result;
+   HgfsSuperInfo *si;
+   HgfsMountInfo *mountInfo;
+   struct dentry *rootDentry;
+
+   ASSERT(sb);
+
+   LOG(6, (KERN_DEBUG "VMware hgfs: HgfsReadSuper: entered\n"));
+
+   /* Sanity check the incoming user data. */
+   mountInfo = (HgfsMountInfo *)rawData;
+   if (!mountInfo ||
+       mountInfo->magicNumber != HGFS_SUPER_MAGIC ||
+       mountInfo->version != HGFS_PROTOCOL_VERSION) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsReadSuper: bad mount data passed "
+              "in by user, failing!\n"));
+      return -EINVAL;
+   }
+
+   /* Setup both our superblock and the VFS superblock. */
+   si = HgfsInitSuperInfo(mountInfo);
+   if (IS_ERR(si)) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsReadSuper: superinfo "
+              "init failed\n"));
+      return PTR_ERR(si);
+   }
+   HGFS_SET_SB_TO_COMMON(sb, si);
+   sb->s_magic = HGFS_SUPER_MAGIC;
+   sb->s_op = &HgfsSuperOperations;
+
+   /*
+    * If s_maxbytes isn't initialized, the generic write path may fail. In
+    * most kernels, s_maxbytes is initialized by the kernel's superblock
+    * allocation routines, but in some, it's up to the filesystem to initialize
+    * it. Note that we'll initialize it anyway, because the default value is
+    * MAX_NON_LFS, which caps our filesize at 2^32 bytes.
+    */
+#ifdef VMW_SB_HAS_MAXBYTES
+   sb->s_maxbytes = MAX_LFS_FILESIZE;
+#endif
+
+   /*
+    * These two operations will make sure that our block size and the bits
+    * per block match up, no matter what HGFS_BLOCKSIZE may be. Granted,
+    * HGFS_BLOCKSIZE will always be a power of two, but you never know!
+    */
+   sb->s_blocksize_bits = HgfsComputeBlockBits(HGFS_BLOCKSIZE);
+   sb->s_blocksize = 1 << sb->s_blocksize_bits;
+
+   /*
+    * We can't use d_alloc_root() here directly because it requires a valid
+    * inode, which only HgfsInstantiate will create. So instead, we'll do the
+    * work in pieces. First we'll allocate the dentry and setup its parent
+    * and superblock. Then HgfsInstantiate will do the rest, issuing a getattr,
+    * getting the inode, and instantiating the dentry with it.
+    */
+   rootDentry = compat_d_alloc_name(NULL, "/");
+   if (rootDentry == NULL) {
+      LOG(4, (KERN_WARNING "VMware hgfs: HgfsReadSuper: Could not allocate "
+              "root dentry\n"));
+      result = -ENOMEM;
+      goto exit;
+   }
+   rootDentry->d_parent = rootDentry;
+   rootDentry->d_sb = sb;
+   result = HgfsInstantiate(rootDentry, HGFS_ROOT_INO, NULL);
+   if (result) {
+      LOG(4, (KERN_WARNING "VMware hgfs: HgfsReadSuper: Could not instantiate "
+              "root dentry\n"));
+      goto exit;
+   }
+   sb->s_root = rootDentry;
+
+   LOG(6, (KERN_DEBUG "VMware hgfs: HgfsReadSuper: finished %s\n", si->shareName));
+
+  exit:
+   if (result) {
+      dput(rootDentry);
+      kfree(si->shareName);
+      kfree(si);
+   }
+   return result;
+}
+
+
+/*
+ * HGFS filesystem high-level operations.
+ */
+
+#if KERNEL_25_FS
+#if defined(VMW_GETSB_2618)
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * HgfsGetSb --
+ *
+ *    Invokes generic kernel code to prepare superblock for
+ *    deviceless filesystem.
+ *
+ * Results:
+ *    0 on success
+ *    non-zero on failure
+ *
+ * Side effects:
+ *    None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static int
+HgfsGetSb(struct file_system_type *fs_type,
+	  int flags,
+	  const char *dev_name,
+	  void *rawData,
+          struct vfsmount *mnt)
+{
+   return get_sb_nodev(fs_type, flags, rawData, HgfsReadSuper, mnt);
+}
+#else
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * HgfsGetSb --
+ *
+ *    Invokes generic kernel code to prepare superblock for
+ *    deviceless filesystem.
+ *
+ * Results:
+ *    The initialized superblock on success
+ *    NULL on failure
+ *
+ * Side effects:
+ *    None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 5, 70)
+static struct super_block *
+HgfsGetSb(struct file_system_type *fs_type,
+	  int flags,
+	  const char *dev_name,
+	  void *rawData)
+#else
+static struct super_block *
+HgfsGetSb(struct file_system_type *fs_type,
+	  int flags,
+	  char *dev_name,
+	  void *rawData)
+#endif
+{
+   return get_sb_nodev(fs_type, flags, rawData, HgfsReadSuper);
+}
+#endif
+#else
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * HgfsReadSuper24 --
+ *
+ *    Compatibility wrapper for 2.4.x kernels read_super.
+ *    Converts success to sb, and failure to NULL.
+ *
+ * Results:
+ *    The initialized superblock on success
+ *    NULL on failure
+ *
+ * Side effects:
+ *    None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static struct super_block *
+HgfsReadSuper24(struct super_block *sb,
+		void *rawData,
+		int flags) {
+   return HgfsReadSuper(sb, rawData, flags) ? NULL : sb;
+}
+#endif
+
+/*
+ * Public function implementations.
+ */
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * HgfsInitFileSystem --
+ *
+ *      Initializes the file system and registers it with the kernel.
+ *
+ * Results:
+ *      TRUE on success, FALSE on failure.
+ *
+ * Side effects:
+ *      None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+Bool
+HgfsInitFileSystem(void)
+{
+   Bool success = FALSE;
+
+   /* Initialize primitives. */
+   INIT_LIST_HEAD(&hgfsReqsUnsent);
+   init_waitqueue_head(&hgfsReqThreadWait);
+   hgfsReqThread = NULL;
+   hgfsReqThreadFlags = 0;
+   HgfsResetOps();
+
+   /* Setup the request slab allocator. */
+   hgfsReqCache = compat_kmem_cache_create("hgfsReqCache",
+                                           sizeof (HgfsReq),
+                                           0,
+                                           SLAB_HWCACHE_ALIGN,
+                                           NULL);
+   if (hgfsReqCache == NULL) {
+      printk(KERN_WARNING "VMware hgfs: failed to create request allocator\n");
+      goto exit;
+   }
+
+   /* Setup the inode slab allocator. */
+   hgfsInodeCache = compat_kmem_cache_create("hgfsInodeCache",
+                                             sizeof (HgfsInodeInfo),
+                                             0,
+                                             SLAB_HWCACHE_ALIGN,
+                                             HgfsInodeCacheCtor);
+   if (hgfsInodeCache == NULL) {
+      printk(KERN_WARNING "VMware hgfs: failed to create inode allocator\n");
+      goto exit;
+   }
+
+   /* Create backdoor handler. */
+   hgfsReqThread = compat_kthread_run(HgfsBdHandler, NULL, HGFS_NAME);
+   if (IS_ERR(hgfsReqThread)) {
+      printk(KERN_WARNING "VMware hgfs: failed to create kernel thread\n");
+      goto exit;
+   }
+
+   /*
+    * Register the filesystem. This should be the last thing we do
+    * in init_module.
+    */
+   if (register_filesystem(&hgfsType)) {
+      printk(KERN_WARNING "VMware hgfs: failed to register filesystem\n");
+      goto exit;
+   }
+   LOG(4, (KERN_DEBUG "VMware hgfs: Module Loaded\n"));
+#ifdef HGFS_ENABLE_WRITEBACK
+   LOG(4, (KERN_DEBUG "VMware hgfs: writeback cache enabled\n"));
+#endif
+   success = TRUE;
+
+  exit:
+
+   /* Cleanup if an error occurred. */
+   if (success == FALSE) {
+      if (!IS_ERR(hgfsReqThread)) {
+         compat_kthread_stop(hgfsReqThread);
+      }
+      if (hgfsInodeCache != NULL) {
+         kmem_cache_destroy(hgfsInodeCache);
+      }
+      if (hgfsReqCache != NULL) {
+         kmem_cache_destroy(hgfsReqCache);
+      }
+   }
+   return success;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * HgfsCleanupFileSystem --
+ *
+ *      Cleans up file system and unregisters it with the kernel.
+ *
+ * Results:
+ *      TRUE on success, FALSE on failure.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+Bool
+HgfsCleanupFileSystem(void)
+{
+   Bool success = TRUE;
+
+/* FIXME: Check actual kernel version when RR's modules went in */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 45)
+   if (MOD_IN_USE) {
+      printk(KERN_WARNING "VMware hgfs: filesystem in use, removal failed\n");
+      success = FALSE;
+   }
+#endif
+
+  /*
+   * Unregister the filesystem. This should be the first thing we do in
+   * the module cleanup code.
+   */
+   if (unregister_filesystem(&hgfsType)) {
+      printk(KERN_WARNING "VMware hgfs: failed to unregister filesystem\n");
+      success = FALSE;
+   }
+
+   /* Kill the backdoor handler thread. */
+   compat_kthread_stop(hgfsReqThread);
+
+   /* Destroy the inode and request slabs. */
+   kmem_cache_destroy(hgfsInodeCache);
+   kmem_cache_destroy(hgfsReqCache);
+
+   LOG(4, (KERN_DEBUG "VMware hgfs: Module Unloaded\n"));
+   return success;
+}
--- kernel/linux-2.6.26.3/fs/vmhgfs/filesystem.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/filesystem.h	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,35 @@
+/*********************************************************
+ * Copyright (C) 2006 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * filesystem.h --
+ *
+ * High-level filesystem operations for the filesystem portion of
+ * the vmhgfs driver.
+ */
+
+#ifndef _HGFS_DRIVER_FILESYSTEM_H_
+#define _HGFS_DRIVER_FILESYSTEM_H_
+
+#include "vm_basic_types.h"
+
+/* Public functions (with respect to the entire module). */
+Bool HgfsInitFileSystem(void);
+Bool HgfsCleanupFileSystem(void);
+
+#endif // _HGFS_DRIVER_FILESYSTEM_H_
--- kernel/linux-2.6.26.3/fs/vmhgfs/fsutil.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/fsutil.c	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,1761 @@
+/*********************************************************
+ * Copyright (C) 2006 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * fsutil.c --
+ *
+ * Functions used in more than one type of filesystem operation will be
+ * exported from this file.
+ */
+
+/* Must come before any kernel header file. */
+#include "driver-config.h"
+
+#include <linux/signal.h>
+
+/* Must come before compat_dcache. */
+#include "compat_fs.h"
+
+#include "compat_dcache.h"
+#include "compat_kernel.h"
+#include "compat_sched.h"
+#include "compat_slab.h"
+#include "compat_spinlock.h"
+
+#include "vm_assert.h"
+#include "hgfsEscape.h"
+#include "cpName.h"
+#include "cpNameLite.h"
+#include "hgfsUtil.h"
+#include "module.h"
+#include "request.h"
+#include "fsutil.h"
+#include "hgfsProto.h"
+#include "vm_basic_types.h"
+
+static struct inode *HgfsInodeLookup(struct super_block *sb,
+                                     ino_t ino);
+static void HgfsSetFileType(struct inode *inode,
+                            HgfsAttrInfo const *attr);
+static int HgfsUnpackGetattrReply(HgfsReq *req,
+                                  HgfsAttrInfo *attr);
+static int HgfsPackGetattrRequest(HgfsReq *req,
+                                  struct dentry *dentry,
+                                  Bool allowHandleReuse,
+				  HgfsOp opUsed,
+                                  HgfsAttrInfo *attr);
+
+/*
+ * Private function implementations.
+ */
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * HgfsInodeLookup --
+ *
+ *    The equivalent of ilookup() in the Linux kernel. We have an HGFS
+ *    specific implementation in order to hack around the lack of
+ *    ilookup() on older kernels.
+ *
+ * Results:
+ *    Pointer to the VFS inode using the current inode number if it
+ *    already exists in the inode cache, NULL otherwise.
+ *
+ * Side effects:
+ *    None
+ *
+ *----------------------------------------------------------------------
+ */
+
+static struct inode *
+HgfsInodeLookup(struct super_block *sb,  // IN: Superblock of this fs
+                ino_t ino)               // IN: Inode number to look up
+{
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 5, 42)
+   return ilookup(sb, ino);
+#else
+   struct inode *inode;
+   HgfsInodeInfo *iinfo;
+
+   /*
+    * Note that returning NULL in both of these cases will make the
+    * caller think that no such inode exists, which is correct. In the first
+    * case, we failed to allocate an inode inside iget(), meaning the inode
+    * number didn't already exist in the inode cache. In the second case, the
+    * inode got marked bad inside read_inode, also indicative of a new inode
+    * allocation.
+    */
+   inode = HgfsGetInode(sb, ino);
+   if (inode == NULL) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsInodeLookup: iget ran out of "
+              "memory and returned NULL\n"));
+      return NULL;
+   }
+   if (is_bad_inode(inode)) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsInodeLookup: inode marked bad\n"));
+      goto iput_and_exit;
+   }
+
+   /*
+    * Our read_inode function should guarantee that if we're here, iinfo should
+    * have been allocated already.
+    */
+   iinfo = INODE_GET_II_P(inode);
+   ASSERT(iinfo);
+   if (iinfo == NULL) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsInodeLookup: found corrupt inode, "
+              "bailing out\n"));
+      goto iput_and_exit;
+   }
+
+   /*
+    * It's HGFS's job to make sure this is set to TRUE in all inodes on which
+    * we hold a reference. If it is set to TRUE, we return the inode, just as
+    * ilookup() does.
+    *
+    * XXX: Note that there exists a race here and in HgfsIget (between the time
+    * that the inode is unlocked and isReferencedInode is set), but I'm hoping
+    * that it doesn't matter because anyone executing this code can't posibly
+    * be "CONFIG_PREEMPT=y".
+    */
+   if (iinfo->isReferencedInode) {
+      goto exit;
+   }
+
+  iput_and_exit:
+   iput(inode);
+   inode = NULL;
+
+  exit:
+   return inode;
+#endif
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * HgfsSetFileType --
+ *
+ *    Set file type in inode according to the hgfs attributes.
+ *
+ * Results:
+ *    None
+ *
+ * Side effects:
+ *    None
+ *
+ *----------------------------------------------------------------------
+ */
+
+static void
+HgfsSetFileType(struct inode *inode,          // IN/OUT: Inode to update
+                HgfsAttrInfo const *attr)     // IN: Attrs to use to update
+{
+   ASSERT(inode);
+   ASSERT(attr);
+
+   switch (attr->type) {
+   case HGFS_FILE_TYPE_DIRECTORY:
+      inode->i_mode = S_IFDIR;
+      inode->i_op = &HgfsDirInodeOperations;
+      inode->i_fop = &HgfsDirFileOperations;
+      break;
+
+   case HGFS_FILE_TYPE_SYMLINK:
+      inode->i_mode = S_IFLNK;
+      inode->i_op = &HgfsLinkInodeOperations;
+      break;
+
+   case HGFS_FILE_TYPE_REGULAR:
+      inode->i_mode = S_IFREG;
+      inode->i_op = &HgfsFileInodeOperations;
+      inode->i_fop = &HgfsFileFileOperations;
+      inode->i_data.a_ops = &HgfsAddressSpaceOperations;
+      break;
+
+   default:
+      /*
+       * XXX Should never happen. I'd put NOT_IMPLEMENTED() here
+       * but if the driver ever goes in the host it's probably not
+       * a good idea for an attacker to be able to hang the host
+       * simply by using a bogus file type in a reply. [bac]
+       */
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsSetFileType: UNSUPPORTED "
+              "inode type\n"));
+      inode->i_mode = 0;
+//      NOT_IMPLEMENTED();
+      break;
+   }
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * HgfsUnpackGetattrReply --
+ *
+ *    This function abstracts the differences between a GetattrV1 and
+ *    a GetattrV2. The caller provides the packet containing the reply
+ *    and we populate the AttrInfo with version-independent information.
+ *
+ *    Note that attr->requestType has already been populated so that we
+ *    know whether to expect a V1 or V2 reply.
+ *
+ * Results:
+ *    0 on success, anything else on failure.
+ *
+ * Side effects:
+ *    None
+ *
+ *----------------------------------------------------------------------
+ */
+static int
+HgfsUnpackGetattrReply(HgfsReq *req,        // IN: Reply packet
+                       HgfsAttrInfo *attr)  // IN/OUT: Attributes
+{
+   int result;
+   char *name = NULL;
+   uint32 length = 0;
+
+   ASSERT(req);
+   ASSERT(attr);
+
+   result = HgfsUnpackCommonAttr(req, attr);
+   if (result != 0) {
+      return result;
+   }
+
+   /* GetattrV2+ also wants a symlink target if it exists. */
+   if (attr->requestType == HGFS_OP_GETATTR_V3) {
+      HgfsReplyGetattrV3 *replyV3 = (HgfsReplyGetattrV3 *)(HGFS_REP_PAYLOAD_V3(req));
+      name = replyV3->symlinkTarget.name;
+      length = replyV3->symlinkTarget.length;
+
+      /* Skip the symlinkTarget if it's too long. */
+      if (length > HGFS_NAME_BUFFER_SIZET(sizeof *replyV3 + sizeof(HgfsReply))) {
+         LOG(4, (KERN_DEBUG "VMware hgfs: HgfsUnpackGetattrReply: symlink "
+                 "target name too long, ignoring\n"));
+         return -ENAMETOOLONG;
+      }
+   } else if (attr->requestType == HGFS_OP_GETATTR_V2) {
+      HgfsReplyGetattrV2 *replyV2 = (HgfsReplyGetattrV2 *)
+         (HGFS_REQ_PAYLOAD(req));
+      name = replyV2->symlinkTarget.name;
+      length = replyV2->symlinkTarget.length;
+
+      /* Skip the symlinkTarget if it's too long. */
+      if (length > HGFS_NAME_BUFFER_SIZE(replyV2)) {
+         LOG(4, (KERN_DEBUG "VMware hgfs: HgfsUnpackGetattrReply: symlink "
+                 "target name too long, ignoring\n"));
+         return -ENAMETOOLONG;
+      }
+   }
+
+   if (length != 0) {
+
+      attr->fileName = kmalloc(length + 1, GFP_KERNEL);
+      if (attr->fileName == NULL) {
+         LOG(4, (KERN_DEBUG "VMware hgfs: HgfsUnpackGetattrReply: out of "
+                 "memory allocating symlink target name, ignoring\n"));
+         return -ENOMEM;
+      }
+
+      /* Copy and convert. From now on, the symlink target is in UTF8. */
+      memcpy(attr->fileName, name, length);
+      CPNameLite_ConvertFrom(attr->fileName, length, '/');
+      attr->fileName[length] = '\0';
+   }
+
+   return 0;
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * HgfsPackGetattrRequest --
+ *
+ *    Setup the getattr request, depending on the op version. When possible,
+ *    we will issue the getattr using an existing open HGFS handle.
+ *
+ * Results:
+ *    Returns zero on success, or negative error on failure.
+ *
+ * Side effects:
+ *    None
+ *
+ *----------------------------------------------------------------------
+ */
+
+static int
+HgfsPackGetattrRequest(HgfsReq *req,            // IN/OUT: Request buffer
+                       struct dentry *dentry,   // IN: Dentry containing name
+                       Bool allowHandleReuse,   // IN: Can we use a handle?
+                       HgfsOp opUsed,           // IN: Op to be used
+                       HgfsAttrInfo *attr)      // OUT: Attrs to update
+{
+   size_t reqBufferSize;
+   size_t reqSize;
+   int result = 0;
+   HgfsHandle handle;
+   char *fileName = NULL;
+   uint32 *fileNameLength = NULL;
+
+   ASSERT(attr);
+   ASSERT(dentry);
+   ASSERT(req);
+
+   attr->requestType = opUsed;
+
+   switch (opUsed) {
+   case HGFS_OP_GETATTR_V3: {
+      HgfsRequest *requestHeader;
+      HgfsRequestGetattrV3 *requestV3;
+
+      /* Fill out the request packet. */
+      requestHeader = (HgfsRequest *)(HGFS_REQ_PAYLOAD(req));
+      requestHeader->op = opUsed;
+      requestHeader->id = req->id;
+
+      requestV3 = (HgfsRequestGetattrV3 *)HGFS_REQ_PAYLOAD_V3(req);
+
+      /*
+       * When possible, issue a getattr using an existing handle. This will
+       * give us slightly better performance on a Windows server, and is more
+       * correct regardless. If we don't find a handle, fall back on getattr
+       * by name.
+       */
+      requestV3->hints = 0;
+      if (allowHandleReuse && HgfsGetHandle(dentry->d_inode,
+                                            0,
+                                            &handle) == 0) {
+         requestV3->fileName.flags = HGFS_FILE_NAME_USE_FILE_DESC;
+         requestV3->fileName.fid = handle;
+         requestV3->fileName.length = 0;
+         requestV3->fileName.caseType = HGFS_FILE_NAME_DEFAULT_CASE;
+         fileName = NULL;
+      } else {
+         fileName = requestV3->fileName.name;
+         fileNameLength = &requestV3->fileName.length;
+         requestV3->fileName.flags = 0;
+         requestV3->fileName.fid = HGFS_INVALID_HANDLE;
+         requestV3->fileName.caseType = HGFS_FILE_NAME_CASE_SENSITIVE;
+      }
+      requestV3->reserved = 0;
+      reqSize = HGFS_REQ_PAYLOAD_SIZE_V3(requestV3);
+      reqBufferSize = HGFS_NAME_BUFFER_SIZET(reqSize);
+      break;
+   }
+
+   case HGFS_OP_GETATTR_V2: {
+      HgfsRequestGetattrV2 *requestV2;
+
+      requestV2 = (HgfsRequestGetattrV2 *)(HGFS_REQ_PAYLOAD(req));
+      requestV2->header.op = opUsed;
+      requestV2->header.id = req->id;
+
+      /*
+       * When possible, issue a getattr using an existing handle. This will
+       * give us slightly better performance on a Windows server, and is more
+       * correct regardless. If we don't find a handle, fall back on getattr
+       * by name.
+       */
+      if (allowHandleReuse && HgfsGetHandle(dentry->d_inode,
+                                            0,
+                                            &handle) == 0) {
+         requestV2->hints = HGFS_ATTR_HINT_USE_FILE_DESC;
+         requestV2->file = handle;
+         fileName = NULL;
+      } else {
+         requestV2->hints = 0;
+         fileName = requestV2->fileName.name;
+         fileNameLength = &requestV2->fileName.length;
+      }
+      reqSize = sizeof *requestV2;
+      reqBufferSize = HGFS_NAME_BUFFER_SIZE(requestV2);
+      break;
+   }
+
+   case HGFS_OP_GETATTR: {
+      HgfsRequestGetattr *requestV1;
+
+      requestV1 = (HgfsRequestGetattr *)(HGFS_REQ_PAYLOAD(req));
+      requestV1->header.op = opUsed;
+      requestV1->header.id = req->id;
+
+      fileName = requestV1->fileName.name;
+      fileNameLength = &requestV1->fileName.length;
+      reqSize = sizeof *requestV1;
+      reqBufferSize = HGFS_NAME_BUFFER_SIZE(requestV1);
+      break;
+   }
+
+   default:
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsPackGetattrRequest: unexpected "
+              "OP type encountered\n"));
+      result = -EPROTO;
+      goto out;
+   }
+
+   /* Avoid all this extra work when we're doing a getattr by handle. */
+   if (fileName != NULL) {
+
+      /* Build full name to send to server. */
+      if (HgfsBuildPath(fileName, reqBufferSize,
+                        dentry) < 0) {
+         LOG(4, (KERN_DEBUG "VMware hgfs: HgfsPackGetattrRequest: build path "
+                 "failed\n"));
+         result = -EINVAL;
+         goto out;
+      }
+      LOG(6, (KERN_DEBUG "VMware hgfs: HgfsPackGetattrRequest: getting attrs "
+              "for \"%s\"\n", fileName));
+
+      /* Convert to CP name. */
+      result = CPName_ConvertTo(fileName,
+                                reqBufferSize,
+                                fileName);
+      if (result < 0) {
+         LOG(4, (KERN_DEBUG "VMware hgfs: HgfsPackGetattrRequest: CP "
+                 "conversion failed\n"));
+         result = -EINVAL;
+         goto out;
+      }
+
+      /* Unescape the CP name. */
+      result = HgfsEscape_Undo(fileName, result);
+      *fileNameLength = result;
+   }
+   req->payloadSize = reqSize + result;
+   result = 0;
+out:
+   return result;
+}
+
+/*
+ * Public function implementations.
+ */
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * HgfsUnpackCommonAttr --
+ *
+ *    This function abstracts the HgfsAttr struct behind HgfsAttrInfo.
+ *    Callers can pass one of four replies into it and receive back the
+ *    attributes for those replies.
+ *
+ *    Callers must populate attr->requestType so that we know whether to
+ *    expect a V1 or V2 Attr struct.
+ *
+ * Results:
+ *    Zero on success, non-zero otherwise.
+ *
+ * Side effects:
+ *    None
+ *
+ *----------------------------------------------------------------------
+ */
+int
+HgfsUnpackCommonAttr(HgfsReq *req,            // IN: Reply packet
+                     HgfsAttrInfo *attrInfo)  // OUT: Attributes
+{
+   HgfsReplyGetattrV3 *getattrReplyV3;
+   HgfsReplyGetattrV2 *getattrReplyV2;
+   HgfsReplyGetattr *getattrReplyV1;
+   HgfsReplySearchReadV3 *searchReadReplyV3;
+   HgfsReplySearchReadV2 *searchReadReplyV2;
+   HgfsReplySearchRead *searchReadReplyV1;
+   HgfsDirEntry *dirent;
+   HgfsAttrV2 *attrV2 = NULL;
+   HgfsAttr *attrV1 = NULL;
+
+   ASSERT(req);
+   ASSERT(attrInfo);
+
+   switch (attrInfo->requestType) {
+   case HGFS_OP_GETATTR_V3:
+      getattrReplyV3 = (HgfsReplyGetattrV3 *)(HGFS_REP_PAYLOAD_V3(req));
+      attrV2 = &getattrReplyV3->attr;
+      break;
+   case HGFS_OP_GETATTR_V2:
+      getattrReplyV2 = (HgfsReplyGetattrV2 *)(HGFS_REQ_PAYLOAD(req));
+      attrV2 = &getattrReplyV2->attr;
+      break;
+   case HGFS_OP_GETATTR:
+      getattrReplyV1 = (HgfsReplyGetattr *)(HGFS_REQ_PAYLOAD(req));
+      attrV1 = &getattrReplyV1->attr;
+      break;
+   case HGFS_OP_SEARCH_READ_V3:
+      searchReadReplyV3 = (HgfsReplySearchReadV3 *)(HGFS_REP_PAYLOAD_V3(req));
+      dirent = (HgfsDirEntry *)searchReadReplyV3->payload;
+      attrV2 = &dirent->attr;
+      break;
+   case HGFS_OP_SEARCH_READ_V2:
+      searchReadReplyV2 = (HgfsReplySearchReadV2 *)(HGFS_REQ_PAYLOAD(req));
+      attrV2 = &searchReadReplyV2->attr;
+      break;
+   case HGFS_OP_SEARCH_READ:
+      searchReadReplyV1 = (HgfsReplySearchRead *)(HGFS_REQ_PAYLOAD(req));
+      attrV1 = &searchReadReplyV1->attr;
+      break;
+   default:
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsUnpackCommonAttr: unexpected op "
+              "in reply packet\n"));
+      return -EPROTO;
+   }
+
+   if (attrV2 != NULL) {
+      attrInfo->mask = 0;
+
+      if (attrV2->mask & HGFS_ATTR_VALID_TYPE) {
+         attrInfo->type = attrV2->type;
+         attrInfo->mask |= HGFS_ATTR_VALID_TYPE;
+      }
+      if (attrV2->mask & HGFS_ATTR_VALID_SIZE) {
+         attrInfo->size = attrV2->size;
+         attrInfo->mask |= HGFS_ATTR_VALID_SIZE;
+      }
+      if (attrV2->mask & HGFS_ATTR_VALID_ACCESS_TIME) {
+         attrInfo->accessTime = attrV2->accessTime;
+         attrInfo->mask |= HGFS_ATTR_VALID_ACCESS_TIME;
+      }
+      if (attrV2->mask & HGFS_ATTR_VALID_WRITE_TIME) {
+         attrInfo->writeTime = attrV2->writeTime;
+         attrInfo->mask |= HGFS_ATTR_VALID_WRITE_TIME;
+      }
+      if (attrV2->mask & HGFS_ATTR_VALID_CHANGE_TIME) {
+         attrInfo->attrChangeTime = attrV2->attrChangeTime;
+         attrInfo->mask |= HGFS_ATTR_VALID_CHANGE_TIME;
+      }
+      if (attrV2->mask & HGFS_ATTR_VALID_SPECIAL_PERMS) {
+         attrInfo->specialPerms = attrV2->specialPerms;
+         attrInfo->mask |= HGFS_ATTR_VALID_SPECIAL_PERMS;
+      }
+      if (attrV2->mask & HGFS_ATTR_VALID_OWNER_PERMS) {
+         attrInfo->ownerPerms = attrV2->ownerPerms;
+         attrInfo->mask |= HGFS_ATTR_VALID_OWNER_PERMS;
+      }
+      if (attrV2->mask & HGFS_ATTR_VALID_GROUP_PERMS) {
+         attrInfo->groupPerms = attrV2->groupPerms;
+         attrInfo->mask |= HGFS_ATTR_VALID_GROUP_PERMS;
+      }
+      if (attrV2->mask & HGFS_ATTR_VALID_OTHER_PERMS) {
+         attrInfo->otherPerms = attrV2->otherPerms;
+         attrInfo->mask |= HGFS_ATTR_VALID_OTHER_PERMS;
+      }
+      if (attrV2->mask & HGFS_ATTR_VALID_USERID) {
+         attrInfo->userId = attrV2->userId;
+         attrInfo->mask |= HGFS_ATTR_VALID_USERID;
+      }
+      if (attrV2->mask & HGFS_ATTR_VALID_GROUPID) {
+         attrInfo->groupId = attrV2->groupId;
+         attrInfo->mask |= HGFS_ATTR_VALID_GROUPID;
+      }
+      if (attrV2->mask & HGFS_ATTR_VALID_FILEID) {
+         attrInfo->hostFileId = attrV2->hostFileId;
+         attrInfo->mask |= HGFS_ATTR_VALID_FILEID;
+      }
+   } else if (attrV1 != NULL) {
+      /* Implicit mask for a Version 1 attr. */
+      attrInfo->mask = HGFS_ATTR_VALID_TYPE |
+         HGFS_ATTR_VALID_SIZE |
+         HGFS_ATTR_VALID_ACCESS_TIME |
+         HGFS_ATTR_VALID_WRITE_TIME |
+         HGFS_ATTR_VALID_CHANGE_TIME |
+         HGFS_ATTR_VALID_OWNER_PERMS;
+
+      attrInfo->type = attrV1->type;
+      attrInfo->size = attrV1->size;
+      attrInfo->accessTime = attrV1->accessTime;
+      attrInfo->writeTime = attrV1->writeTime;
+      attrInfo->attrChangeTime = attrV1->attrChangeTime;
+      attrInfo->ownerPerms = attrV1->permissions;
+   }
+
+   return 0;
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * HgfsChangeFileAttributes --
+ *
+ *    Update an inode's attributes to match those of the HgfsAttr. May
+ *    cause dirty pages to be flushed, and may invalidate cached pages,
+ *    if there was a change in the file size or modification time in
+ *    the server.
+ *
+ * Results:
+ *    None
+ *
+ * Side effects:
+ *    None
+ *
+ *----------------------------------------------------------------------
+ */
+
+void
+HgfsChangeFileAttributes(struct inode *inode,          // IN/OUT: Inode
+                         HgfsAttrInfo const *attr)     // IN: New attrs
+{
+   HgfsSuperInfo *si;
+   Bool needInvalidate = FALSE;
+
+   ASSERT(inode);
+   ASSERT(inode->i_sb);
+   ASSERT(attr);
+
+   si = HGFS_SB_TO_COMMON(inode->i_sb);
+
+   LOG(6, (KERN_DEBUG "VMware hgfs: HgfsChangeFileAttributes: entered\n"));
+   HgfsSetFileType(inode, attr);
+
+   /*
+    * Set the access mode. For hosts that don't give us group or other
+    * bits (Windows), we use the owner bits in their stead.
+    */
+   inode->i_mode &= ~S_IALLUGO;
+   if (attr->mask & HGFS_ATTR_VALID_SPECIAL_PERMS) {
+      inode->i_mode |= (attr->specialPerms << 9);
+   }
+   if (attr->mask & HGFS_ATTR_VALID_OWNER_PERMS) {
+      inode->i_mode |= (attr->ownerPerms << 6);
+   }
+   if (attr->mask & HGFS_ATTR_VALID_GROUP_PERMS) {
+      inode->i_mode |= (attr->groupPerms << 3);
+   } else {
+      inode->i_mode |= ((inode->i_mode & S_IRWXU) >> 3);
+   }
+   if (attr->mask & HGFS_ATTR_VALID_OTHER_PERMS) {
+      inode->i_mode |= (attr->otherPerms);
+   } else {
+      inode->i_mode |= ((inode->i_mode & S_IRWXU) >> 6);
+   }
+
+   /* Mask the access mode. */
+   switch (attr->type) {
+   case HGFS_FILE_TYPE_REGULAR:
+      inode->i_mode &= ~si->fmask;
+      break;
+   case HGFS_FILE_TYPE_DIRECTORY:
+      inode->i_mode &= ~si->dmask;
+      break;
+   default:
+      /* Nothing else gets masked. */
+      break;
+   }
+
+   /*
+    * This field is used to represent the number of hard links. If the file is
+    * really a file, this is easy; our filesystem doesn't support hard-linking,
+    * so we just set it to 1. If the field is a directory, the number of links
+    * represents the number of subdirectories, including '.' and "..".
+    *
+    * In either case, what we're doing isn't ideal. We've carefully tracked the
+    * number of links through calls to HgfsMkdir and HgfsDelete, and now some
+    * revalidate will make us trample on the number of links. But we have no
+    * choice: someone on the server may have made our local view of the number
+    * of links inconsistent (by, say, removing a directory) , and without the
+    * ability to retrieve nlink via getattr, we have no way of knowing that.
+    *
+    * XXX: So in the future, adding nlink to getattr would be nice. At that
+    * point we may as well just implement hard links anyway. Note that user
+    * programs seem to have issues with a link count greater than 1 that isn't
+    * accurate. I experimented with setting nlink to 2 for directories (to
+    * account for '.' and ".."), and find printed a hard link error. So until
+    * we have getattr support for nlink, everyone gets 1.
+    */
+   inode->i_nlink = 1;
+
+   /*
+    * Use the stored uid and gid if we were given them at mount-time, or if
+    * the server didn't give us a uid or gid.
+    */
+   if (si->uidSet || (attr->mask & HGFS_ATTR_VALID_USERID) == 0) {
+      inode->i_uid = si->uid;
+   } else {
+      inode->i_uid = attr->userId;
+   }
+   if (si->gidSet || (attr->mask & HGFS_ATTR_VALID_GROUPID) == 0) {
+      inode->i_gid = si->gid;
+   } else {
+      inode->i_gid = attr->groupId;
+   }
+
+   inode->i_rdev = 0;  /* Device nodes are not supported */
+#if !defined(VMW_INODE_2618)
+   inode->i_blksize = HGFS_BLOCKSIZE;
+#endif
+
+   /*
+    * Invalidate cached pages if we didn't receive the file size, or if it has
+    * changed on the server.
+    */
+   if (attr->mask & HGFS_ATTR_VALID_SIZE) {
+      loff_t oldSize = compat_i_size_read(inode);
+      inode->i_blocks = (attr->size + HGFS_BLOCKSIZE - 1) / HGFS_BLOCKSIZE;
+      if (oldSize != attr->size) {
+         LOG(4, (KERN_DEBUG "VMware hgfs: HgfsChangeFileAttributes: new file "
+                 "size: %"FMT64"u, old file size: %Lu\n", attr->size, oldSize));
+         needInvalidate = TRUE;
+      }
+      compat_i_size_write(inode, attr->size);
+   } else {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsChangeFileAttributes: did not "
+              "get file size\n"));
+      needInvalidate = TRUE;
+   }
+
+   if (attr->mask & HGFS_ATTR_VALID_ACCESS_TIME) {
+      HGFS_SET_TIME(inode->i_atime, attr->accessTime);
+   } else {
+      HGFS_SET_TIME(inode->i_atime, HGFS_GET_CURRENT_TIME());
+   }
+
+   /*
+    * Invalidate cached pages if we didn't receive the modification time, or if
+    * it has changed on the server.
+    */
+   if (attr->mask & HGFS_ATTR_VALID_WRITE_TIME) {
+      HGFS_DECLARE_TIME(newTime);
+      HGFS_SET_TIME(newTime, attr->writeTime);
+      if (!HGFS_EQUAL_TIME(newTime, inode->i_mtime)) {
+         LOG(4, (KERN_DEBUG "VMware hgfs: HgfsChangeFileAttributes: new mod "
+                 "time: %ld:%lu, old mod time: %ld:%lu\n",
+                 HGFS_PRINT_TIME(newTime), HGFS_PRINT_TIME(inode->i_mtime)));
+         needInvalidate = TRUE;
+      }
+      HGFS_SET_TIME(inode->i_mtime, attr->writeTime);
+   } else {
+      needInvalidate = TRUE;
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsChangeFileAttributes: did not "
+              "get mod time\n"));
+      HGFS_SET_TIME(inode->i_mtime, HGFS_GET_CURRENT_TIME());
+   }
+
+   /*
+    * Windows doesn't know about ctime, and might send us something
+    * bogus; if the ctime is invalid, use the mtime instead.
+    */
+   if (attr->mask & HGFS_ATTR_VALID_CHANGE_TIME) {
+      if (HGFS_SET_TIME(inode->i_ctime, attr->attrChangeTime)) {
+         inode->i_ctime = inode->i_mtime;
+      }
+   } else {
+      HGFS_SET_TIME(inode->i_ctime, HGFS_GET_CURRENT_TIME());
+   }
+
+   /*
+    * Compare old size and write time with new size and write time. If there's
+    * a difference (or if we didn't get a new size or write time), the file
+    * must have been written to, and we need to invalidate our cached pages.
+    */
+   if (S_ISREG(inode->i_mode) && needInvalidate) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsChangeFileAttributes: file has "
+              "changed on the server, invalidating pages.\n"));
+      compat_filemap_write_and_wait(inode->i_mapping);
+      compat_invalidate_remote_inode(inode);
+   }
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * HgfsPrivateGetattr --
+ *
+ *    Internal getattr routine. Send a getattr request to the server
+ *    for the indicated remote name, and if it succeeds copy the
+ *    results of the getattr into the provided HgfsAttrInfo.
+ *
+ *    attr->fileName will be allocated on success if the file is a
+ *    symlink; it's the caller's duty to free it.
+ *
+ * Results:
+ *    Returns zero on success, or a negative error on failure.
+ *
+ * Side effects:
+ *    None
+ *
+ *----------------------------------------------------------------------
+ */
+
+int
+HgfsPrivateGetattr(struct dentry *dentry,  // IN: Dentry containing name
+                   HgfsAttrInfo *attr)     // OUT: Attr to copy into
+{
+   struct HgfsSuperInfo *si;
+   HgfsReq *req;
+   HgfsStatus replyStatus;
+   HgfsOp opUsed;
+   int result = 0;
+   HgfsRequest *requestHeader;
+   Bool allowHandleReuse = TRUE;
+
+   ASSERT(dentry);
+   ASSERT(dentry->d_sb);
+   ASSERT(attr);
+
+   si = HGFS_SB_TO_COMMON(dentry->d_sb);
+
+   req = HgfsGetNewRequest();
+   if (!req) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsPrivateGetattr: out of memory "
+              "while getting new request\n"));
+      result = -ENOMEM;
+      goto out;
+   }
+   requestHeader = (HgfsRequest *)(HGFS_REQ_PAYLOAD(req));
+
+  retry:
+
+   opUsed = atomic_read(&hgfsVersionGetattr);
+   result = HgfsPackGetattrRequest(req, dentry, allowHandleReuse, opUsed, attr);
+   if (result != 0) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsPrivateGetattr: no attrs\n"));
+      goto out;
+   }
+
+   result = HgfsSendRequest(req);
+   if (result == 0) {
+      LOG(6, (KERN_DEBUG "VMware hgfs: HgfsPrivateGetattr: got reply\n"));
+      replyStatus = HgfsReplyStatus(req);
+      result = HgfsStatusConvertToLinux(replyStatus);
+
+      /*
+       * If the getattr succeeded on the server, copy the stats
+       * into the HgfsAttrInfo, otherwise return an error.
+       */
+      switch (result) {
+      case 0:
+         result = HgfsUnpackGetattrReply(req, attr);
+         break;
+      case -EBADF:
+         /*
+          * This can happen if we attempted a getattr by handle and the handle
+          * was closed. Because we have no control over the backdoor, it's
+          * possible that an attacker closed our handle, in which case the
+          * driver still thinks the handle is open. So a straight-up
+          * "goto retry" would cause an infinite loop. Instead, let's retry
+          * with a getattr by name.
+          */
+         if (allowHandleReuse) {
+            allowHandleReuse = FALSE;
+            goto retry;
+         }
+
+         /*
+          * There's no reason why the server should have sent us this error
+          * when we haven't used a handle. But to prevent an infinite loop in
+          * the driver, let's make sure that we don't retry again.
+          */
+         break;
+
+      case -EPROTO:
+         /* Retry with older version(s). Set globally. */
+         if (attr->requestType == HGFS_OP_GETATTR_V3) {
+            LOG(4, (KERN_DEBUG "VMware hgfs: HgfsPrivateGetattr: Version 3 "
+                    "not supported. Falling back to version 2.\n"));
+            atomic_set(&hgfsVersionGetattr, HGFS_OP_GETATTR_V2);
+            goto retry;
+         } else if (attr->requestType == HGFS_OP_GETATTR_V2) {
+            LOG(4, (KERN_DEBUG "VMware hgfs: HgfsPrivateGetattr: Version 2 "
+                    "not supported. Falling back to version 1.\n"));
+            atomic_set(&hgfsVersionGetattr, HGFS_OP_GETATTR);
+            goto retry;
+         }
+
+         /* Fallthrough. */
+      default:
+         break;
+      }
+   } else if (result == -EIO) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsPrivateGetattr: timed out\n"));
+   } else if (result == -EPROTO) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsPrivateGetattr: server "
+              "returned error: %d\n", result));
+   } else {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsPrivateGetattr: unknown error: "
+              "%d\n", result));
+   }
+
+out:
+   HgfsFreeRequest(req);
+   return result;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * HgfsIget --
+ *
+ *    Lookup or create an inode with the given attributes and remote filename.
+ *
+ *    If an inode number of zero is specified, we'll extract an inode number
+ *    either from the attributes, or from calling iunique().
+ *
+ * Results:
+ *    The inode on success
+ *    NULL on failure
+ *
+ * Side effects:
+ *    None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+struct inode *
+HgfsIget(struct super_block *sb,         // IN: Superblock of this fs
+         ino_t ino,                      // IN: Inode number (optional)
+         HgfsAttrInfo const *attr)       // IN: Attributes to create with
+{
+   HgfsInodeInfo *iinfo;
+   struct inode *inode;
+   Bool isFakeInodeNumber = FALSE;
+
+   ASSERT(sb);
+   ASSERT(attr);
+
+   LOG(6, (KERN_DEBUG "VMware hgfs: HgfsIget: entered\n"));
+
+   /* No inode number? Use what's in the attributes, or call iunique(). */
+   if (ino == 0) {
+      /*
+       * Let's find out if the inode number the server gave us is already
+       * in use. It's kind of lame that we have to do this, but that's what
+       * we get when certain files have valid inode numbers and certain ones
+       * don't.
+       *
+       * XXX: Is this worth the value? We're mixing server-provided inode
+       * numbers with our own randomly chosen inode numbers.
+       *
+       * XXX: This logic is also racy. After our call to HgfsInodeLookup(), it's
+       * possible another caller came in and grabbed that inode number, which
+       * will cause us to collide in iget() and step on their inode.
+       */
+      if (attr->mask & HGFS_ATTR_VALID_FILEID) {
+         struct inode *oldInode;
+
+         oldInode = HgfsInodeLookup(sb, attr->hostFileId);
+         if (oldInode) {
+
+            /*
+             * If this inode's inode number was generated via iunique(), we
+             * have a collision and cannot use the server's inode number.
+             * Otherwise, we should reuse this inode.
+             */
+            iinfo = INODE_GET_II_P(oldInode);
+            if (iinfo->isFakeInodeNumber) {
+               LOG(6, (KERN_DEBUG "VMware hgfs: HgfsIget: found existing "
+                       "iuniqued inode %"FMT64"d, generating new one\n",
+                       attr->hostFileId));
+               ino = iunique(sb, HGFS_RESERVED_INO);
+               isFakeInodeNumber = TRUE;
+            } else {
+               LOG(6, (KERN_DEBUG "VMware hgfs: HgfsIget: found existing "
+                       "inode %"FMT64"d, reusing\n", attr->hostFileId));
+               ino = attr->hostFileId;
+            }
+            iput(oldInode);
+         } else {
+            ino = attr->hostFileId;
+         }
+      } else {
+         /*
+          * Get the next available inode number. There is a bit of a problem
+          * with using iunique() in cases where HgfsIget was called to
+          * instantiate an inode that's already in memory to a new dentry. In
+          * such cases, we would like to get the old inode. But if we're
+          * generating inode numbers with iunique(), we'll always have a new
+          * inode number, thus we'll never get the old inode. This is
+          * especially unfortunate when the old inode has some cached pages
+          * attached to it that we won't be able to reuse.
+          *
+          * To mitigate this problem, whenever we use iunique() to generate an
+          * inode number, we keep track of that fact in the inode. Then, when
+          * we use ilookup() above to retrieve an inode, we only consider the
+          * result a "collision" if the retrieved inode's inode number was set
+          * via iunique(). Otherwise, we assume that we're reusing an inode
+          * whose inode number was given to us by the server.
+          */
+         ino = iunique(sb, HGFS_RESERVED_INO);
+         isFakeInodeNumber = TRUE;
+      }
+   }
+
+   LOG(6, (KERN_DEBUG "VMware hgfs: HgfsIget: calling iget on inode number "
+           "%lu\n", ino));
+
+
+   /* Now we have a good inode number, get the inode itself. */
+   inode = HgfsGetInode(sb, ino);
+   if (inode) {
+
+      /*
+       * On an allocation failure in read_super, the inode will have been
+       * marked "bad". If it was, we certainly don't want to start playing with
+       * the HgfsInodeInfo. So quietly put the inode back and fail.
+       */
+      if (is_bad_inode(inode)) {
+         LOG(6, (KERN_DEBUG "VMware hgfs: HgfsIget: encountered bad inode\n"));
+         iput(inode);
+         return NULL;
+      }
+
+      iinfo = INODE_GET_II_P(inode);
+      iinfo->isFakeInodeNumber = isFakeInodeNumber;
+      iinfo->isReferencedInode = TRUE;
+      HgfsChangeFileAttributes(inode, attr);
+   }
+
+   LOG(6, (KERN_DEBUG "VMware hgfs: HgfsIget: done\n"));
+   return inode;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * HgfsInstantiate --
+ *
+ *    Tie a dentry to a looked up or created inode. Callers may choose to
+ *    supply their own attributes, or may leave attr NULL in which case the
+ *    attributes will be queried from the server. Likewise, an inode number
+ *    of zero may be specified, in which case HgfsIget will get one from the
+ *    server or, barring that, from iunique().
+ *
+ * Results:
+ *    Zero on success, negative error otherwise.
+ *
+ * Side effects:
+ *    None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+int
+HgfsInstantiate(struct dentry *dentry,    // IN: Dentry to use
+                ino_t ino,                // IN: Inode number (optional)
+                HgfsAttrInfo const *attr) // IN: Attributes to use (optional)
+{
+   struct inode *inode;
+   HgfsAttrInfo newAttr;
+
+   ASSERT(dentry);
+
+   LOG(8, (KERN_DEBUG "VMware hgfs: HgfsInstantiate: entered\n"));
+
+   /* If no specified attributes, get them from the server. */
+   if (attr == NULL) {
+      int error;
+
+      LOG(6, (KERN_DEBUG "VMware hgfs: HgfsInstantiate: issuing getattr\n"));
+      newAttr.fileName = NULL;
+      error = HgfsPrivateGetattr(dentry, &newAttr);
+      if (error) {
+         return error;
+      }
+      kfree(newAttr.fileName);
+      attr = &newAttr;
+   }
+
+   /*
+    * Get the inode with this inode number and the attrs we got from
+    * the server.
+    */
+   inode = HgfsIget(dentry->d_sb, ino, attr);
+   if (!inode) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsInstantiate: out of memory "
+              "getting inode\n"));
+      return -ENOMEM;
+   }
+
+   /* Everything worked out, instantiate the dentry. */
+   LOG(8, (KERN_DEBUG "VMware hgfs: HgfsInstantiate: instantiating dentry\n"));
+   HgfsDentryAgeReset(dentry);
+   dentry->d_op = &HgfsDentryOperations;
+   d_instantiate(dentry, inode);
+   return 0;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * HgfsBuildPath --
+ *
+ *    Constructs the full path given a dentry by walking the dentry and its
+ *    parents back to the root. Adapted from d_path(), smb_build_path(), and
+ *    build_path_from_dentry() implementations in Linux 2.6.16.
+ *
+ * Results:
+ *    If non-negative, the length of the buffer written.
+ *    Otherwise, an error code.
+ *
+ * Side effects:
+ *    None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+int
+HgfsBuildPath(unsigned char *buffer,  // IN/OUT: Buffer to write into
+              size_t bufferLen,       // IN: Size of buffer
+              struct dentry *dentry)  // IN: First dentry to walk
+{
+   int retval = 0;
+   size_t shortestNameLength;
+   HgfsSuperInfo *si;
+   char *originalBuffer;
+
+   ASSERT(buffer);
+   ASSERT(dentry);
+   ASSERT(dentry->d_sb);
+
+   si = HGFS_SB_TO_COMMON(dentry->d_sb);
+   originalBuffer = buffer;
+
+   /*
+    * Buffer must hold at least the share name (which is already prefixed with
+    * a forward slash), and nul.
+    */
+   shortestNameLength = si->shareNameLen + 1;
+   if (bufferLen < shortestNameLength) {
+      return -ENAMETOOLONG;
+   }
+   memcpy(buffer, si->shareName, shortestNameLength);
+
+   /* Short-circuit if we're at the root already. */
+   if (IS_ROOT(dentry)) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsBuildPath: Sending root \"%s\"\n",
+              buffer));
+      return shortestNameLength;
+   }
+
+   /* Skip the share name, but overwrite our previous nul. */
+   buffer += shortestNameLength - 1;
+   bufferLen -= shortestNameLength - 1;
+
+   /*
+    * Build the path string walking the tree backward from end to ROOT
+    * and store it in reversed order.
+    */
+   dget(dentry);
+   compat_lock_dentry(dentry);
+   while (!IS_ROOT(dentry)) {
+      struct dentry *parent;
+      size_t nameLen;
+
+      nameLen = dentry->d_name.len;
+      bufferLen -= nameLen + 1;
+      if (bufferLen < 0) {
+         compat_unlock_dentry(dentry);
+         dput(dentry);
+	 LOG(4, (KERN_DEBUG "VMware hgfs: HgfsBuildPath: Ran out of space "
+	         "while writing dentry name\n"));
+         return -ENAMETOOLONG;
+      }
+      buffer[bufferLen] = '/';
+      memcpy(buffer + bufferLen + 1, dentry->d_name.name, nameLen);
+      retval += nameLen + 1;
+
+      parent = dentry->d_parent;
+      dget(parent);
+      compat_unlock_dentry(dentry);
+      dput(dentry);
+      dentry = parent;
+      compat_lock_dentry(dentry);
+   }
+   compat_unlock_dentry(dentry);
+   dput(dentry);
+
+   if (bufferLen == 0) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsBuildPath: Ran out of space while "
+              "writing nul\n"));
+      return -ENAMETOOLONG;
+   }
+
+   /* Shift the constructed string down to just past the share name. */
+   memmove(buffer, buffer + bufferLen, retval);
+   buffer[retval] = '\0';
+
+   /* Don't forget the share name length (which also accounts for the nul). */
+   retval += shortestNameLength;
+   LOG(4, (KERN_DEBUG "VMware hgfs: HgfsBuildPath: Built \"%s\"\n",
+   	   originalBuffer));
+
+   return retval;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * HgfsDentryAgeReset --
+ *
+ *    Reset the age of this dentry by setting d_time to now.
+ *
+ *    XXX: smb_renew_times from smbfs claims it is safe to reset the time of
+ *    all the parent dentries too, but how is that possible? If I stat a file
+ *    using a relative path, only that relative path will be validated. Sure,
+ *    it means that the parents still /exist/, but that doesn't mean their
+ *    attributes are up to date.
+ *
+ * Results:
+ *    None.
+ *
+ * Side effects:
+ *    None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+void
+HgfsDentryAgeReset(struct dentry *dentry) // IN: Dentry whose age to reset
+{
+   ASSERT(dentry);
+
+   LOG(8, (KERN_DEBUG "VMware hgfs: HgfsDentryAgeReset: entered\n"));
+   dget(dentry);
+   compat_lock_dentry(dentry);
+   dentry->d_time = jiffies;
+   compat_unlock_dentry(dentry);
+   dput(dentry);
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * HgfsDentryAgeReset --
+ *
+ *    Set the dentry's time to 0. This makes the dentry's age "too old" and
+ *    forces subsequent HgfsRevalidates to go to the server for attributes.
+ *
+ * Results:
+ *    None.
+ *
+ * Side effects:
+ *    Subsequent HgfsRevalidate will not use cached attributes.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+void
+HgfsDentryAgeForce(struct dentry *dentry) // IN: Dentry we want to force
+{
+   ASSERT(dentry);
+
+   LOG(8, (KERN_DEBUG "VMware hgfs: HgfsDentryAgeForce: entered\n"));
+   dget(dentry);
+   compat_lock_dentry(dentry);
+   dentry->d_time = 0;
+   compat_unlock_dentry(dentry);
+   dput(dentry);
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * HgfsGetOpenMode --
+ *
+ *    Based on the flags requested by the process making the open()
+ *    syscall, determine which open mode (access type) to request from
+ *    the server.
+ *
+ * Results:
+ *    Returns the correct HgfsOpenMode enumeration to send to the
+ *    server, or -1 on failure.
+ *
+ * Side effects:
+ *    None
+ *
+ *----------------------------------------------------------------------
+ */
+
+int
+HgfsGetOpenMode(uint32 flags) // IN: Open flags
+{
+   uint32 mask = O_RDONLY|O_WRONLY|O_RDWR;
+   int result = -1;
+
+   LOG(6, (KERN_DEBUG "VMware hgfs: HgfsGetOpenMode: entered\n"));
+
+
+   /*
+    * Mask the flags to only look at the access type.
+    */
+   flags &= mask;
+
+   /* Pick the correct HgfsOpenMode. */
+   switch (flags) {
+
+   case O_RDONLY:
+      result = HGFS_OPEN_MODE_READ_ONLY;
+      break;
+
+   case O_WRONLY:
+      result = HGFS_OPEN_MODE_WRITE_ONLY;
+      break;
+
+   case O_RDWR:
+      result = HGFS_OPEN_MODE_READ_WRITE;
+      break;
+
+   default:
+      /*
+       * This should never happen, but it could if a userlevel program
+       * is behaving poorly.
+       */
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsGetOpenMode: invalid "
+              "open flags %o\n", flags));
+      result = -1;
+      break;
+   }
+
+   return result;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * HgfsCreateFileInfo --
+ *
+ *    Create the HGFS-specific file information struct and store a pointer to
+ *    it in the VFS file pointer. Also, link the file information struct in the
+ *    inode's file list, so that we may find it when all we have is an inode
+ *    (such as in writepage()).
+ *
+ * Results:
+ *    Zero if success, non-zero if error.
+ *
+ * Side effects:
+ *    None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+int
+HgfsCreateFileInfo(struct file *file,  // IN: File pointer to attach to
+                   HgfsHandle handle)  // IN: Handle returned from server
+{
+   HgfsFileInfo *fileInfo;
+   HgfsInodeInfo *inodeInfo;
+   int mode;
+
+   ASSERT(file);
+
+   inodeInfo = INODE_GET_II_P(file->f_dentry->d_inode);
+   ASSERT(inodeInfo);
+
+   /* Get the mode of the opened file. */
+   mode = HgfsGetOpenMode(file->f_flags);
+   if (mode < 0) {
+      return -EINVAL;
+   }
+
+   /*
+    * Store the file information for this open() in the file*.  This needs
+    * to be freed on a close(). Note that we trim all flags from the open
+    * mode and increment it so that it is guaranteed to be non-zero, because
+    * callers of HgfsGetHandle may pass in zero as the desired mode if they
+    * don't care about the mode of the opened handle.
+    *
+    * XXX: Move this into a slab allocator once HgfsFileInfo is large. One day
+    * soon, the kernel will allow us to embed the vfs file into our file info,
+    * like we currently do for inodes.
+    */
+   fileInfo = kmalloc(sizeof *fileInfo, GFP_KERNEL);
+   if (!fileInfo) {
+      return -ENOMEM;
+   }
+   fileInfo->handle = handle;
+   fileInfo->mode = HGFS_OPEN_MODE_ACCMODE(mode) + 1;
+   FILE_SET_FI_P(file, fileInfo);
+
+   /*
+    * I don't think we need any VFS locks since we're only touching the HGFS
+    * specific state. But we should still acquire our own lock.
+    *
+    * XXX: Better granularity on locks, etc.
+    */
+   spin_lock(&hgfsBigLock);
+   list_add_tail(&fileInfo->list, &inodeInfo->files);
+   spin_unlock(&hgfsBigLock);
+
+   return 0;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * HgfsReleaseFileInfo --
+ *
+ *    Release HGFS-specific file information struct created in
+ *    HgfsCreateFileInfo.
+ *
+ * Results:
+ *    None
+ *
+ * Side effects:
+ *    None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+void
+HgfsReleaseFileInfo(struct file *file) // IN: File pointer to detach from
+{
+   HgfsFileInfo *fileInfo;
+   ASSERT(file);
+
+   fileInfo = FILE_GET_FI_P(file);
+   ASSERT(fileInfo);
+
+   spin_lock(&hgfsBigLock);
+   list_del_init(&fileInfo->list);
+   spin_unlock(&hgfsBigLock);
+
+   kfree(fileInfo);
+   FILE_SET_FI_P(file, NULL);
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * HgfsGetHandle --
+ *
+ *    Retrieve an existing HGFS handle for this inode, assuming one exists.
+ *    The handle retrieved satisfies the mode desired by the client.
+ *
+ *    The desired mode does not correspond directly to HgfsOpenMode. Callers
+ *    should either increment the desired HgfsOpenMode, or, if any mode will
+ *    do, pass zero instead. This is in line with the Linux kernel's behavior
+ *    (see do_filp_open() and open_namei() for details).
+ *
+ * Results:
+ *    Zero on success, non-zero on error.
+ *
+ * Side effects:
+ *    None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+int
+HgfsGetHandle(struct inode *inode,   // IN: Inode to search for handles
+              HgfsOpenMode mode,     // IN: Mode to satisfy
+              HgfsHandle *handle)    // OUT: Retrieved HGFS handle
+{
+   HgfsInodeInfo *iinfo;
+   struct list_head *cur;
+   Bool found = FALSE;
+
+   ASSERT(handle);
+
+   LOG(6, (KERN_DEBUG "VMware hgfs: HgfsGetHandle: desired mode %u\n", mode));
+
+   /*
+    * We may have been called from a dentry without an associated inode.
+    * HgfsReadSuper is one such caller. No inode means no open files, so
+    * return an error.
+    */
+   if (inode == NULL) {
+      LOG(8, (KERN_DEBUG "VMware hgfs: HgfsGetHandle: NULL input\n"));
+      return -EINVAL;
+   }
+   iinfo = INODE_GET_II_P(inode);
+
+   /*
+    * Unfortunately, we can't reuse handles belonging to directories. These
+    * handles were created by a SearchOpen request, but the server itself
+    * backed them with an artificial list of dentries populated via scandir. So
+    * it can't actually use the handles for Getattr or Setattr requests, only
+    * for subsequent SearchRead or SearchClose requests.
+    */
+   if (S_ISDIR(inode->i_mode)) {
+      LOG(8, (KERN_DEBUG "VMware hgfs: HgfsGetHandle: Called on directory\n"));
+      return -EINVAL;
+   }
+
+   /*
+    * Iterate over the open handles for this inode, and find one that allows
+    * the given mode. A desired mode of zero means "any mode will do".
+    * Otherwise return an error;
+    */
+   spin_lock(&hgfsBigLock);
+   list_for_each(cur, &iinfo->files) {
+      HgfsFileInfo *finfo = list_entry(cur, HgfsFileInfo, list);
+
+      if (mode == 0 || finfo->mode & mode) {
+         *handle = finfo->handle;
+         found = TRUE;
+         break;
+      }
+   }
+   spin_unlock(&hgfsBigLock);
+
+   if (found) {
+      LOG(6, (KERN_DEBUG "VMware hgfs: HgfsGetHandle: Returning handle %d\n",
+              *handle));
+      return 0;
+   } else {
+      LOG(6, (KERN_DEBUG "VMware hgfs: HgfsGetHandle: Could not find matching "
+              "handle\n"));
+      return -ENOENT;
+   }
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * HgfsStatusConvertToLinux --
+ *
+ *    Convert a cross-platform HGFS status code to its Linux-kernel specific
+ *    counterpart.
+ *
+ *    Rather than encapsulate the status codes within an array indexed by the
+ *    various HGFS status codes, we explicitly enumerate them in a switch
+ *    statement, saving the reader some time when matching HGFS status codes
+ *    against Linux status codes.
+ *
+ * Results:
+ *    Zero if the converted status code represents success, negative error
+ *    otherwise. Unknown status codes are converted to the more generic
+ *    "protocol error" status code to maintain forwards compatibility.
+ *
+ * Side effects:
+ *    None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+int
+HgfsStatusConvertToLinux(HgfsStatus hgfsStatus) // IN: Status code to convert
+{
+   switch (hgfsStatus) {
+   case HGFS_STATUS_SUCCESS:
+      return 0;
+
+   case HGFS_STATUS_NO_SUCH_FILE_OR_DIR:
+   case HGFS_STATUS_INVALID_NAME:
+      return -ENOENT;
+
+   case HGFS_STATUS_INVALID_HANDLE:
+      return -EBADF;
+
+   case HGFS_STATUS_OPERATION_NOT_PERMITTED:
+      return -EPERM;
+
+   case HGFS_STATUS_FILE_EXISTS:
+      return -EEXIST;
+
+   case HGFS_STATUS_NOT_DIRECTORY:
+      return -ENOTDIR;
+
+   case HGFS_STATUS_DIR_NOT_EMPTY:
+      return -ENOTEMPTY;
+
+   case HGFS_STATUS_PROTOCOL_ERROR:
+      return -EPROTO;
+
+   case HGFS_STATUS_ACCESS_DENIED:
+   case HGFS_STATUS_SHARING_VIOLATION:
+      return -EACCES;
+
+   case HGFS_STATUS_NO_SPACE:
+      return -ENOSPC;
+
+   case HGFS_STATUS_OPERATION_NOT_SUPPORTED:
+      return -EOPNOTSUPP;
+
+   case HGFS_STATUS_NAME_TOO_LONG:
+      return -ENAMETOOLONG;
+
+   case HGFS_STATUS_GENERIC_ERROR:
+      return -EIO;
+
+   default:
+      LOG(10, (KERN_DEBUG "VMware hgfs: HgfsStatusConvertToLinux: unknown "
+               "error: %u\n", hgfsStatus));
+      return -EIO;
+   }
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * HgfsSetUidGid --
+ *
+ *    Sets the uid and gid of the host file represented by the provided
+ *    dentry.
+ *
+ *    Note that this function assumes it is being called for a file that has
+ *    been created on the host with the correct gid if the sgid bit is set for
+ *    the parent directory.  That is, we treat the presence of the sgid bit in
+ *    the parent direcory's mode as an indication not to set the gid manually
+ *    ourselves here.  If we did, we would clobber the gid that the host file
+ *    system chose for us automatically when the file was created.
+ *
+ *    Also note that the sgid bit itself would have been propagated to the new
+ *    file by the host file system as well.
+ *
+ * Results:
+ *    None.
+ *
+ * Side effects:
+ *    The host file's uid and gid are modified if the hgfs server has
+ *    permission to do so.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+void
+HgfsSetUidGid(struct inode *parent,     // IN: parent inode
+              struct dentry *dentry,    // IN: dentry of file to update
+              uid_t uid,                // IN: uid to set
+              gid_t gid)                // IN: gid to set
+{
+   struct iattr setUidGid;
+
+   setUidGid.ia_valid = ATTR_UID;
+   setUidGid.ia_uid = uid;
+
+   /*
+    * Only set the gid if the host file system wouldn't have for us.  See the
+    * comment in the function header.
+    */
+   if (!parent || !(parent->i_mode & S_ISGID)) {
+      setUidGid.ia_valid |= ATTR_GID;
+      setUidGid.ia_gid = gid;
+   }
+
+   /*
+    * After the setattr, we desperately want a revalidate so we can
+    * get the true attributes from the server. However, the setattr
+    * may have done that for us. To prevent a spurious revalidate,
+    * reset the dentry's time before the setattr. That way, if setattr
+    * ends up revalidating the dentry, the subsequent call to
+    * revalidate will do nothing.
+    */
+   HgfsDentryAgeForce(dentry);
+   HgfsSetattr(dentry, &setUidGid);
+   HgfsRevalidate(dentry);
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * HgfsGetInode --
+ *
+ *    This function replaces iget() and should be called instead of it. In newer
+ *    kernels that have removed the iget() interface,  GetInode() obtains an inode
+ *    and if it is a new one, then initializes the inode by calling
+ *    HgfsDoReadInode(). In older kernels that support the iget() interface,
+ *    HgfsDoReadInode() is called by iget() internally.
+ *
+ * Results:
+ *    A new inode object on success, NULL on error.
+ *
+ * Side effects:
+ *    None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+struct inode *
+HgfsGetInode(struct super_block *sb, // IN: file system superblock object
+	     ino_t ino)              // IN: inode number to assign to new inode
+{
+#ifdef VMW_USE_IGET_LOCKED
+   struct inode *inode;
+
+   inode = iget_locked(sb, ino);
+   if (inode && (inode->i_state & I_NEW)) {
+      HgfsDoReadInode(inode);
+      unlock_new_inode(inode);
+   }
+   return inode;
+#else
+   return iget(sb, ino);
+#endif
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ *  HgfsDoReadInode --
+ *
+ *    A filesystem wide function that is called to initialize a new inode.
+ *    This is called from two different places depending on the kernel version.
+ *    In older kernels that provide the iget() interface, this function is
+ *    called by the kernel as part of inode initialization (from
+ *    HgfsDoReadInode). In newer kernels that call iget_locked(), this
+ *    function is called by filesystem code to initialize the new inode.
+ *
+ * Results:
+ *    None.
+ *
+ * Side effects:
+ *    None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+void
+HgfsDoReadInode(struct inode *inode)  // IN: Inode to initialize
+{
+   HgfsInodeInfo *iinfo = INODE_GET_II_P(inode);
+
+   /*
+    * If the vfs inode is not embedded within the HgfsInodeInfo, then we
+    * haven't yet allocated the HgfsInodeInfo. Do so now.
+    *
+    * XXX: We could allocate with GFP_ATOMIC. But instead, we'll do a standard
+    * allocation and mark the inode "bad" if the allocation fails. This'll
+    * make all subsequent operations on the inode fail, which is what we want.
+    */
+#ifndef VMW_EMBED_INODE
+   iinfo = kmem_cache_alloc(hgfsInodeCache, GFP_KERNEL);
+   if (!iinfo) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsDoReadInode: no memory for "
+              "iinfo!\n"));
+      make_bad_inode(inode);
+      return;
+   }
+#endif
+   INODE_SET_II_P(inode, iinfo);
+   INIT_LIST_HEAD(&iinfo->files);
+   iinfo->isReferencedInode = FALSE;
+   iinfo->isFakeInodeNumber = FALSE;
+   iinfo->createdAndUnopened = FALSE;
+
+}
--- kernel/linux-2.6.26.3/fs/vmhgfs/fsutil.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/fsutil.h	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,98 @@
+/*********************************************************
+ * Copyright (C) 2006 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * fsutil.h --
+ *
+ * Functions used in more than one type of filesystem operation will be
+ * exported from this file.
+ */
+
+#ifndef _HGFS_DRIVER_FSUTIL_H_
+#define _HGFS_DRIVER_FSUTIL_H_
+
+/* Must come before any kernel header file. */
+#include "driver-config.h"
+
+#include <linux/signal.h>
+#include "compat_fs.h"
+
+#include "inode.h"
+#include "request.h"
+#include "vm_basic_types.h"
+#include "hgfsProto.h"
+
+/*
+ * Struct used to pass around attributes that Linux cares about.
+ * These aren't just the attributes seen in HgfsAttr[V2]; we add a filename
+ * pointer for convenience (used by SearchRead and Getattr).
+ */
+typedef struct HgfsAttrInfo {
+   HgfsOp requestType;
+   HgfsAttrValid mask;
+   HgfsFileType type;            /* File type */
+   uint64 size;                  /* File size (in bytes) */
+   uint64 accessTime;            /* Time of last access */
+   uint64 writeTime;             /* Time of last write */
+   uint64 attrChangeTime;        /* Time file attributes were last changed */
+   HgfsPermissions specialPerms; /* Special permissions bits */
+   HgfsPermissions ownerPerms;   /* Owner permissions bits */
+   HgfsPermissions groupPerms;   /* Group permissions bits */
+   HgfsPermissions otherPerms;   /* Other permissions bits */
+   uint32 userId;                /* UID */
+   uint32 groupId;               /* GID */
+   uint64 hostFileId;            /* Inode number */
+   char *fileName;               /* Either symlink target or filename */
+} HgfsAttrInfo;
+
+
+/* Public functions (with respect to the entire module). */
+int HgfsUnpackCommonAttr(HgfsReq *req,
+                         HgfsAttrInfo *attr);
+void HgfsChangeFileAttributes(struct inode *inode,
+                              HgfsAttrInfo const *attr);
+int HgfsPrivateGetattr(struct dentry *dentry,
+                       HgfsAttrInfo *attr);
+struct inode *HgfsIget(struct super_block *sb,
+                       ino_t ino,
+                       HgfsAttrInfo const *attr);
+int HgfsInstantiate(struct dentry *dentry,
+                    ino_t ino,
+                    HgfsAttrInfo const *attr);
+int HgfsBuildPath(unsigned char *buffer,
+                  size_t bufferLen,
+                  struct dentry *dentry);
+void HgfsDentryAgeReset(struct dentry *dentry);
+void HgfsDentryAgeForce(struct dentry *dentry);
+int HgfsGetOpenMode(uint32 flags);
+int HgfsCreateFileInfo(struct file *file,
+                       HgfsHandle handle);
+void HgfsReleaseFileInfo(struct file *file);
+int HgfsGetHandle(struct inode *inode,
+                  HgfsOpenMode mode,
+                  HgfsHandle *handle);
+int HgfsStatusConvertToLinux(HgfsStatus hgfsStatus);
+void HgfsSetUidGid(struct inode *parent,
+                   struct dentry *dentry,
+                   uid_t uid,
+                   gid_t gid);
+struct inode *HgfsGetInode(struct super_block *sb, ino_t ino);
+void HgfsDoReadInode(struct inode *inode);
+
+
+#endif // _HGFS_DRIVER_FSUTIL_H_
--- kernel/linux-2.6.26.3/fs/vmhgfs/guest_msg_def.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/guest_msg_def.h	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,92 @@
+/*********************************************************
+ * Copyright (C) 1998 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * guest_msg_def.h --
+ *
+ *    Second layer of the internal communication channel between guest
+ *    applications and vmware
+ *
+ */
+
+#ifndef _GUEST_MSG_DEF_H_
+#define _GUEST_MSG_DEF_H_
+
+#define INCLUDE_ALLOW_MODULE
+#define INCLUDE_ALLOW_USERLEVEL
+#define INCLUDE_ALLOW_VMMEXT
+#include "includeCheck.h"
+
+
+/* Basic request types */
+typedef enum {
+   MESSAGE_TYPE_OPEN,
+   MESSAGE_TYPE_SENDSIZE,
+   MESSAGE_TYPE_SENDPAYLOAD,
+   MESSAGE_TYPE_RECVSIZE,
+   MESSAGE_TYPE_RECVPAYLOAD,
+   MESSAGE_TYPE_RECVSTATUS,
+   MESSAGE_TYPE_CLOSE,
+} MessageType;
+
+
+/* Reply statuses */
+/*  The basic request succeeded */
+#define MESSAGE_STATUS_SUCCESS  0x0001
+/*  vmware has a message available for its party */
+#define MESSAGE_STATUS_DORECV   0x0002
+/*  The channel has been closed */
+#define MESSAGE_STATUS_CLOSED   0x0004
+/*  vmware removed the message before the party fetched it */
+#define MESSAGE_STATUS_UNSENT   0x0008
+/*  A checkpoint occurred */
+#define MESSAGE_STATUS_CPT      0x0010
+/*  An underlying device is powering off */
+#define MESSAGE_STATUS_POWEROFF 0x0020
+/*  vmware has detected a timeout on the channel */
+#define MESSAGE_STATUS_TIMEOUT  0x0040
+/*  vmware supports high-bandwidth for sending and receiving the payload */
+#define MESSAGE_STATUS_HB       0x0080
+
+/*
+ * This mask defines the status bits that the guest is allowed to set;
+ * we use this to mask out all other bits when receiving the status
+ * from the guest. Otherwise, the guest can manipulate VMX state by
+ * setting status bits that are only supposed to be changed by the
+ * VMX. See bug 45385.
+ */
+#define MESSAGE_STATUS_GUEST_MASK    MESSAGE_STATUS_SUCCESS
+
+/*
+ * Max number of channels.
+ * Unfortunately this has to be public because the monitor part
+ * of the backdoor needs it for its trivial-case optimization. [greg]
+ */
+#define GUESTMSG_MAX_CHANNEL 8
+
+/* Flags to open a channel. --hpreg */
+#define GUESTMSG_FLAG_COOKIE 0x80000000
+#define GUESTMSG_FLAG_ALL GUESTMSG_FLAG_COOKIE
+
+/*
+ * Maximum size of incoming message. This is to prevent denial of host service
+ * attacks from guest applications.
+ */
+#define GUESTMSG_MAX_IN_SIZE (64 * 1024)
+
+#endif /* _GUEST_MSG_DEF_H_ */
--- kernel/linux-2.6.26.3/fs/vmhgfs/hgfsBd.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/hgfsBd.c	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,412 @@
+/*********************************************************
+ * Copyright (C) 1998 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * hgfsBd.c --
+ *
+ *    Backdoor calls used by hgfs pserver. [bac]
+ */
+
+#if defined(__KERNEL__) || defined(_KERNEL) || defined(KERNEL)
+#   include "kernelStubs.h"
+#else
+#   include <stdio.h>
+#   include <stdlib.h>
+#   include <string.h>
+#   include <errno.h>
+#   include "str.h"      // for Str_Strcpy
+#   include "debug.h"
+#endif
+
+#include "vm_assert.h"
+#include "rpcout.h"
+#include "hgfs.h"     // for common HGFS definitions
+#include "hgfsBd.h"
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * HgfsBdGetBufInt --
+ *
+ *    Allocates a buffer to send a hgfs request in. This can be either a
+ *    HGFS_PACKET_MAX or HGFS_LARGE_PACKET_MAX size buffer depending on the
+ *    external funciton called.
+ *
+ * Results:
+ *    Pointer to a buffer that has the correct backdoor command prefix for 
+ *    sending hgfs requests over the backdoor.
+ *    NULL on failure (not enough memory).
+ *
+ * Side effects:
+ *    None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static char *
+HgfsBdGetBufInt(size_t bufSize)
+{
+   /* 
+    * Allocate a buffer that is large enough for an HGFS packet and the 
+    * synchronous HGFS command, write the command, and return a pointer that 
+    * points into the buffer, after the command.
+    */
+   size_t len = bufSize + HGFS_SYNC_REQREP_CLIENT_CMD_LEN;
+   char *buf = (char*) calloc(sizeof(char), len);
+
+   if (!buf) {
+      Debug("HgfsBd_GetBuf: Failed to allocate a bd buffer\n");
+      return NULL;
+   }
+
+   Str_Strcpy(buf, HGFS_SYNC_REQREP_CLIENT_CMD, len);
+
+   return buf + HGFS_SYNC_REQREP_CLIENT_CMD_LEN;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * HgfsBd_GetBuf --
+ *
+ *    Get a buffer of size HGFS_PACKET_MAX to send hgfs requests in.
+ *
+ * Results:
+ *    See HgfsBdGetBufInt.
+ *
+ * Side effects:
+ *    Allocates memory that must be freed with a call to HgfsBd_PutBuf.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+char *
+HgfsBd_GetBuf(void)
+{
+   return HgfsBdGetBufInt(HGFS_PACKET_MAX);
+}
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * HgfsBd_GetLargeBuf --
+ *
+ *    Get a buffer of size HGFS_LARGE_PACKET_MAX to send hgfs requests in.
+ *
+ * Results:
+ *    See HgfsBdGetBufInt.
+ *
+ * Side effects:
+ *    Allocates memory that must be freed with a call to HgfsBd_PutBuf.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+char *
+HgfsBd_GetLargeBuf(void)
+{
+   return HgfsBdGetBufInt(HGFS_LARGE_PACKET_MAX);
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * HgfsBd_PutBuf --
+ *
+ *    Release a buffer obtained with HgfsBd_GetBuf.
+ *
+ * Results:
+ *    None
+ *
+ * Side effects:
+ *    None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+void
+HgfsBd_PutBuf(char *buf) // IN
+{
+   ASSERT(buf);
+
+   free(buf - HGFS_SYNC_REQREP_CLIENT_CMD_LEN);
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * HgfsBd_GetChannel --
+ *
+ *    Allocate a new RpcOut channel, and try to open the connection.
+ *
+ * Results:
+ *    Pointer to the allocated, opened channel on success.
+ *    NULL on failure (not enough memory, or failed to open the connection).
+ *
+ * Side effects:
+ *    None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+RpcOut *
+HgfsBd_GetChannel(void)
+{
+   RpcOut *out = RpcOut_Construct();
+   Bool status;
+
+   if (!out) {
+      Debug("HgfsBd_GetChannel: Failed to allocate an RpcOut\n");
+      return NULL;
+   }
+
+   status = RpcOut_start(out);
+   if (status == FALSE) {
+      RpcOut_Destruct(out);
+      return NULL;
+   }
+
+   return out;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * HgfsBd_CloseChannel --
+ *
+ *    Close the channel and free the RpcOut object.
+ *
+ * Results:
+ *    TRUE if closing the channel succeeded, FALSE if it failed.
+ *
+ * Side effects:
+ *    None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+Bool
+HgfsBd_CloseChannel(RpcOut *out) // IN: Channel to close and free
+{
+   Bool success; 
+
+   ASSERT(out);
+
+   success = RpcOut_stop(out);
+   if (success == TRUE) {
+      RpcOut_Destruct(out);
+   }
+
+   return success;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * HgfsBd_Dispatch --
+ *
+ *    Get a reply to an hgfs request. We call RpcOut_Sent, which
+ *    returns a buffer with the reply in it, and we pass this back to
+ *    the caller.
+ *
+ * Results:
+ *    On success, returns zero. On failure, returns a negative error.
+ *
+ * Side effects:
+ *    None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+int
+HgfsBd_Dispatch(RpcOut *out,            // IN: Channel to send on
+                char *packetIn,         // IN: Buf containing request packet
+                size_t *packetSize,     // IN/OUT: Size of packet in/out
+                char const **packetOut) // OUT: Buf containing reply packet
+{
+   Bool success;
+   char const *reply;
+   size_t replyLen;
+
+   ASSERT(out);
+   ASSERT(packetIn);
+   ASSERT(packetSize);
+   ASSERT(packetOut);
+
+   success = RpcOut_send(out, packetIn - HGFS_CLIENT_CMD_LEN, 
+                         *packetSize + HGFS_CLIENT_CMD_LEN, 
+                         &reply, &replyLen);
+   if (success == FALSE) {
+      Debug("HgfsBd_Dispatch: RpcOut_send returned failure\n");
+      return -1;
+   }
+
+   ASSERT(replyLen <= HGFS_LARGE_PACKET_MAX);
+   *packetOut = reply;
+   *packetSize = replyLen;
+
+   return 0;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * HgfsBd_Enabled --
+ *
+ *    Test to see if hgfs is enabled on the host.
+ *
+ * Results:
+ *    TRUE if hgfs is enabled.
+ *    FALSE if hgfs is disabled.
+ *
+ * Side effects:
+ *    None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+Bool
+HgfsBd_Enabled(RpcOut *out,         // IN: RPCI Channel
+               char *requestPacket) // IN: Buffer (obtained from HgfsBd_GetBuf)
+{
+   char const *replyPacket; // Buffer returned by HgfsBd_Dispatch
+   size_t packetSize;
+   int error;
+
+   /*
+    * Send a bogus (empty) request to the VMX. If hgfs is disabled on
+    * the host side then the request will fail (because the RPCI call
+    * itself will fail). If hgfs is enabled, we will get a packet back
+    * (it will be an error packet because our request was malformed,
+    * but we just discard it anyway).
+    */
+   packetSize = 0;
+   error = HgfsBd_Dispatch(out,
+                           requestPacket,
+                           &packetSize,
+                           &replyPacket);
+   if (error < 0) {
+      return FALSE;
+   }
+
+   return TRUE;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * HgfsBd_OpenBackdoor --
+ *
+ *      Check if the HGFS channel is open, and, if not, open it. This is a
+ *      one-stop convenience wrapper around HgfsBd_Enabled, HgfsBd_GetBuf, and
+ *      HgfsBd_GetChannel.
+ *
+ * Results:
+ *      TRUE if the backdoor is now open, regardless of its previous state.
+ *      FALSE if the backdoor could not be opened.
+ *
+ * Side effects:
+ *      May open a channel to the host.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+Bool
+HgfsBd_OpenBackdoor(RpcOut **out) // IN/OUT: RPCI Channel
+{
+   char *packetBuffer = NULL;
+   Bool success = FALSE;
+
+   ASSERT(out);
+
+   /* Short-circuit: backdoor is already open. */
+   if (*out != NULL) {
+      return TRUE;
+   }
+
+   /* Open the channel. */   
+   *out = HgfsBd_GetChannel();
+   if (*out == NULL) {
+      return FALSE;
+   }
+
+   /* Allocate a buffer for use in pinging the HGFS server. */
+   packetBuffer = HgfsBd_GetBuf();
+   if (packetBuffer == NULL) {
+      goto out;
+   }
+
+   /* Ping the HGFS server. */
+   if (!HgfsBd_Enabled(*out, packetBuffer)) {
+      goto out;
+   }
+   success = TRUE;
+
+  out:
+   if (packetBuffer != NULL) {
+      HgfsBd_PutBuf(packetBuffer);
+   }
+   if (!success && *out != NULL) {
+      HgfsBd_CloseChannel(*out);
+      *out = NULL;
+   }
+   return success;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * HgfsBd_CloseBackdoor --
+ *
+ *      Closes the backdoor channel, if it's open.
+ *
+ * Results:
+ *      TRUE if the channel is now closed, regardless of its previous state.
+ *      FALSE if we could not close the channel.
+ *
+ * Side effects:
+ *      May close the channel to the host.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+Bool
+HgfsBd_CloseBackdoor(RpcOut **out) // IN/OUT: RPCI Channel
+{
+   Bool success = TRUE;
+
+   ASSERT(out);
+
+   if (*out != NULL) {
+      if (!HgfsBd_CloseChannel(*out)) {
+         success = FALSE;
+      }
+      *out = NULL;
+   }
+
+   return success;
+}
--- kernel/linux-2.6.26.3/fs/vmhgfs/hgfsBd.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/hgfsBd.h	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,52 @@
+/*********************************************************
+ * Copyright (C) 1998 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef _HGFS_BD_H_
+# define _HGFS_BD_H_
+
+/*
+ * hgfsBd.h --
+ *
+ *    Backdoor calls used by hgfs clients.
+ */
+
+#include "rpcout.h"
+
+char *HgfsBd_GetBuf(void);
+
+char *HgfsBd_GetLargeBuf(void);
+
+void HgfsBd_PutBuf(char *);
+
+RpcOut *HgfsBd_GetChannel(void);
+
+Bool HgfsBd_CloseChannel(RpcOut *out);
+
+int HgfsBd_Dispatch(RpcOut *out,
+                    char *packetIn,
+                    size_t *packetSize,
+                    char const **packetOut);
+
+Bool HgfsBd_Enabled(RpcOut *out,
+                    char *requestPacket);
+
+Bool HgfsBd_OpenBackdoor(RpcOut **out);
+
+Bool HgfsBd_CloseBackdoor(RpcOut **out);
+
+#endif // _HGFS_BD_H_
--- kernel/linux-2.6.26.3/fs/vmhgfs/hgfsDevLinux.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/hgfsDevLinux.h	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,63 @@
+/*********************************************************
+ * Copyright (C) 1998 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * hgfsDev.h --
+ * 
+ *    Header for code shared between the hgfs linux kernel module driver
+ *    and the pserver.
+ */
+
+#ifndef _HGFS_DEV_H_
+#define _HGFS_DEV_H_
+
+#include "vm_basic_types.h"
+#include "hgfs.h"
+
+#define HGFS_NAME "vmhgfs"              // Name of FS (e.g. "mount -t vmhgfs")
+#define HGFS_DEVICE_NAME "dev"          // Name of our device under /proc/fs/HGFS_NAME/
+#define HGFS_SUPER_MAGIC 0xbacbacbc     // Superblock magic number
+#define HGFS_PROTOCOL_VERSION 1         // Incremented when something changes
+#define HGFS_DEFAULT_TTL 1              // Default TTL for dentries
+
+/* 
+ * Mount information, passed from pserver process to kernel
+ * at mount time.
+ *
+ * XXX: I'm hijacking this struct. In the future, when the Solaris HGFS driver
+ * loses its pserver, the struct will be used by /sbin/mount.vmhgfs solely.
+ * As is, it is also used by the Solaris pserver.
+ */
+typedef struct HgfsMountInfo {
+   uint32 magicNumber;        // hgfs magic number
+   uint32 version;            // protocol version
+   uint32 fd;                 // file descriptor of client file
+#ifndef sun
+   uid_t uid;                 // desired owner of files
+   Bool uidSet;               // is the owner actually set?
+   gid_t gid;                 // desired group of files
+   Bool gidSet;               // is the group actually set?
+   unsigned short fmask;      // desired file mask
+   unsigned short dmask;      // desired directory mask
+   uint32 ttl;                // number of seconds before revalidating dentries
+   const char *shareNameHost; // must be ".host"
+   const char *shareNameDir;  // desired share name for mounting
+#endif
+} HgfsMountInfo;
+
+#endif //ifndef _HGFS_DEV_H_
--- kernel/linux-2.6.26.3/fs/vmhgfs/hgfsEscape.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/hgfsEscape.h	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,50 @@
+/*********************************************************
+ * Copyright (C) 2008 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * hgfsEscape.h --
+ *
+ *    Escape and unescape filenames that are not legal on a particular
+ *    platform.
+ *
+ */
+
+#ifndef __HGFS_ESCAPE_H__
+#define __HGFS_ESCAPE_H__
+
+#if defined(WIN32)
+int HgfsEscape_DoW(wchar_t const *bufIn, // IN
+		   uint32 sizeIn,        // IN (chars)
+		   uint32 sizeBufOut,    // IN (bytes)
+		   wchar_t *bufOut);     // OUT
+
+int HgfsEscape_UndoWToA(char *bufIn,    // IN
+		                  uint32 sizeIn); // IN
+
+int HgfsEscape_UndoW(wchar_t *bufIn,   // IN
+                     uint32 sizeIn);   // IN
+#else
+int HgfsEscape_Do(char const *bufIn,   // IN
+		  uint32 sizeIn,       // IN (chars)
+		  uint32 sizeBufOut,   // IN (bytes)
+		  char *bufOut);       // OUT
+
+int HgfsEscape_Undo(char *bufIn,    // IN
+		    uint32 sizeIn); // IN
+#endif // defined(WIN32)
+#endif // __HGFS_ESCAPE_H__
--- kernel/linux-2.6.26.3/fs/vmhgfs/hgfsEscapeLinux.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/hgfsEscapeLinux.c	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,117 @@
+/*********************************************************
+ * Copyright (C) 2008 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * hgfsEscapeLinux.c --
+ *
+ *    Escape and unescape filenames that are not legal on linux.
+ *
+ */
+
+#include "staticEscape.h"
+#include "vmware.h"
+#include "hgfsEscape.h"
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * HgfsEscape_Do --
+ *
+ *    Escape any characters that are not legal in a linux filename,
+ *    which is just the character "/". We also of course have to
+ *    escape the escape character, which is "%".
+ *
+ *    sizeBufOut must account for the NUL terminator.
+ *
+ *    XXX: See the comments in staticEscape.c and staticEscapeW.c to understand
+ *    why this interface sucks.
+ *
+ * Results:
+ *    On success, the size (excluding the NUL terminator) of the
+ *    escaped, NUL terminated buffer.
+ *    On failure (bufOut not big enough to hold result), negative value.
+ *
+ * Side effects:
+ *    None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+int
+HgfsEscape_Do(char const *bufIn, // IN:  Buffer with unescaped input
+	      uint32 sizeIn,     // IN:  Size of input buffer (chars)
+	      uint32 sizeBufOut, // IN:  Size of output buffer (bytes)
+	      char *bufOut)      // OUT: Buffer for escaped output
+{
+   /*
+    * This is just a wrapper around the more general escape
+    * routine; we pass it the correct bitvector and the
+    * buffer to escape. [bac]
+    */
+   EscBitVector bytesToEsc;
+
+   ASSERT(bufIn);
+   ASSERT(bufOut);
+
+   /* Set up the bitvector for "/" and "%" */
+   EscBitVector_Init(&bytesToEsc);
+   EscBitVector_Set(&bytesToEsc, (unsigned char)'%');
+   EscBitVector_Set(&bytesToEsc, (unsigned char)'/');
+
+   return StaticEscape_Do('%',
+                          &bytesToEsc,
+                          bufIn,
+                          sizeIn,
+                          sizeBufOut,
+                          bufOut);
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * HgfsEscape_Undo --
+ *
+ *    Unescape a buffer that was escaped using HgfsEscapeBuffer.
+ *
+ *    The unescaping is done in place in the input buffer, and
+ *    can not fail.
+ *
+ * Results:
+ *    The size (excluding the NUL terminator) of the unescaped, NUL
+ *    terminated buffer.
+ *
+ * Side effects:
+ *    None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+int
+HgfsEscape_Undo(char *bufIn,   // IN: Buffer to be unescaped
+		uint32 sizeIn) // IN: Size of input buffer
+{
+   /*
+    * This is just a wrapper around the more general unescape
+    * routine; we pass it the correct escape character and the
+    * buffer to unescape. [bac]
+    */
+   ASSERT(bufIn);
+   return StaticEscape_Undo('%', bufIn, sizeIn);
+}
--- kernel/linux-2.6.26.3/fs/vmhgfs/hgfs.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/hgfs.h	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,204 @@
+/*********************************************************
+ * Copyright (C) 1998 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+
+
+/*
+ * hgfs.h --
+ *
+ * Header file for public common data types used in the VMware
+ * Host/Guest File System (hgfs).
+ *
+ * This file is included by hgfsProto.h, which defines message formats
+ * used in the hgfs protocol, and by hgfsDev.h, which defines the
+ * interface between the kernel and the hgfs pserver. [bac]
+ */
+
+
+#ifndef _HGFS_H_
+# define _HGFS_H_
+
+#define INCLUDE_ALLOW_USERLEVEL
+#define INCLUDE_ALLOW_MODULE
+#define INCLUDE_ALLOW_DISTRIBUTE
+#include "includeCheck.h"
+#include "vm_assert.h"
+
+/*
+ * Maximum number of pages to transfer to/from the HGFS server for V3 protocol
+ * operations that support large requests/replies, e.g. reads and writes.
+ */
+#define HGFS_LARGE_IO_MAX_PAGES  15
+
+/*
+ * Maximum allowed packet size in bytes. All hgfs code should be made
+ * safe with respect to this limit.
+ */
+#define HGFS_PACKET_MAX 6144
+
+/*
+ * The HGFS_LARGE_PACKET_MAX size is used to allow guests to make
+ * read / write requests of sizes larger than HGFS_PACKET_MAX. The larger size
+ * can only be used with server operations that are specified to be large packet
+ * capable in hgfsProto.h.
+ */
+#define HGFS_LARGE_PACKET_MAX ((4096 * HGFS_LARGE_IO_MAX_PAGES) + 2048)
+
+/* Maximum number of bytes to read or write to a hgfs server in a single packet. */
+#define HGFS_IO_MAX 4096
+
+/* Maximum number of bytes to read or write to a V3 server in a single hgfs packet. */
+#define HGFS_LARGE_IO_MAX (HGFS_LARGE_IO_MAX_PAGES * 4096)
+
+/*
+ * Open mode
+ *
+ * These are equivalent to the O_RDONLY, O_WRONLY, O_RDWR open flags
+ * in Unix; they specify which type of access is being requested.  These three
+ * modes are mutually exclusive and one is required; all other flags are
+ * modifiers to the mode and must come afterwards as a bitmask.  Beware that
+ * HGFS_OPEN_MODE_READ_ONLY contains the value 0 so simply masking another
+ * variable with it to detect its presence is not safe.  The _ACCMODES entry in
+ * the enum serves as a bitmask for the others.
+ *
+ * Changing the order of this enum will break stuff.
+ *
+ * This definition is used in some places that don't include
+ * hgfsProto.h, which is why it is here instead of there.
+ */
+typedef enum {
+   HGFS_OPEN_MODE_READ_ONLY,
+   HGFS_OPEN_MODE_WRITE_ONLY,
+   HGFS_OPEN_MODE_READ_WRITE,
+   HGFS_OPEN_MODE_ACCMODES,
+   /* You cannot add anything else here.  Really. */
+} HgfsOpenMode;
+
+/*
+ * Open flags.
+ *
+ * Each should be shifted left by HGFS_OPEN_MODE_READ_WRITE plus whatever flag
+ * number they are, starting with zero.
+ *
+ * The sequential flag indicates that reads and writes on this handle should
+ * not seek on each operation; instead, the system's file pointer will be used
+ * so each operation is performed where the last one finished.  This flag is
+ * necessary when reading from or writing to non-seekable files (such as procfs
+ * nodes on Linux) but can also lead to inconsistent results if a client shares
+ * a handle amongst several of its callers.  This flag should only be used when
+ * the client knows the file is non-seekable and the burden of ensuring file
+ * handles aren't shared falls upon the hgfs client, not the server.
+ */
+#define HGFS_OPEN_SEQUENTIAL    (1 << HGFS_OPEN_MODE_READ_WRITE)
+
+/* Masking helpers. */
+#define HGFS_OPEN_MODE_ACCMODE(mode)    (mode & HGFS_OPEN_MODE_ACCMODES)
+#define HGFS_OPEN_MODE_FLAGS(mode)      (mode & ~HGFS_OPEN_MODE_ACCMODES)
+
+#define HGFS_OPEN_MODE_IS_VALID_MODE(mode)      \
+   (HGFS_OPEN_MODE_ACCMODE(mode) == HGFS_OPEN_MODE_READ_ONLY  ||   \
+    HGFS_OPEN_MODE_ACCMODE(mode) == HGFS_OPEN_MODE_WRITE_ONLY ||   \
+    HGFS_OPEN_MODE_ACCMODE(mode) == HGFS_OPEN_MODE_READ_WRITE)
+
+
+/*
+ * Return status for replies from the server.
+ *
+ * Changing the order of this enum will break the protocol; new status
+ * types should be added at the end.
+ *
+ * This definition is used in some places that don't include
+ * hgfsProto.h, which is why it is here instead of there.
+ *
+ * XXX: So we have a problem here. At some point, HGFS_STATUS_INVALID_NAME was
+ * added to the list of errors. Later, HGFS_STATUS_GENERIC_ERROR was added, but
+ * it was added /before/ HGFS_STATUS_INVALID_NAME. Nobody noticed because the
+ * error codes travelled from hgfsProto.h to hgfs.h in that same change. Worse,
+ * we GA'ed a product (Server 1.0) this way.
+ *
+ * XXX: I've reversed the order because otherwise new HGFS clients working
+ * against WS55-era HGFS servers will think they got HGFS_STATUS_GENERIC_ERROR
+ * when the server sent them HGFS_STATUS_INVALID_NAME. This was a problem
+ * the Linux client converts HGFS_STATUS_GENERIC_ERROR to -EIO, which causes
+ * HgfsLookup to fail unexpectedly (normally HGFS_STATUS_INVALID_NAME is
+ * converted to -ENOENT, an expected result in HgfsLookup).
+ */
+typedef enum {
+   HGFS_STATUS_SUCCESS,
+   HGFS_STATUS_NO_SUCH_FILE_OR_DIR,
+   HGFS_STATUS_INVALID_HANDLE,
+   HGFS_STATUS_OPERATION_NOT_PERMITTED,
+   HGFS_STATUS_FILE_EXISTS,
+   HGFS_STATUS_NOT_DIRECTORY,
+   HGFS_STATUS_DIR_NOT_EMPTY,
+   HGFS_STATUS_PROTOCOL_ERROR,
+   HGFS_STATUS_ACCESS_DENIED,
+   HGFS_STATUS_INVALID_NAME,
+   HGFS_STATUS_GENERIC_ERROR,
+   HGFS_STATUS_SHARING_VIOLATION,
+   HGFS_STATUS_NO_SPACE,
+   HGFS_STATUS_OPERATION_NOT_SUPPORTED,
+   HGFS_STATUS_NAME_TOO_LONG,
+   HGFS_STATUS_INVALID_PARAMETER,
+} HgfsStatus;
+
+/*
+ * HGFS RPC commands
+ *
+ * HGFS servers can run in a variety of places across several different
+ * transport layers. These definitions constitute all known RPC commands.
+ *
+ * For each definition, there is both the server string (the command itself)
+ * as well as a client "prefix", which is the command followed by a space.
+ * This is provided for convenience, since clients will need to copy both
+ * the command and the space into some buffer that is then sent over the
+ * backdoor.
+ *
+ * In Host --> Guest RPC traffic, the host endpoint is TCLO and the guest
+ * endpoint is RpcIn. TCLO is a particularly confusing name choice which dates
+ * back to when the host was to send raw TCL code to the guest (TCL Out ==
+ * TCLO).
+ *
+ * In Guest --> Host RPC traffic, the guest endpoint is RpcOut and the host
+ * endpoint is RPCI.
+ */
+
+/*
+ * When an RPCI listener registers for this command, HGFS requests are expected
+ * to be synchronously sent from the guest and replies are expected to be
+ * synchronously returned.
+ *
+ * When an RpcIn listener registers for this command, requests are expected to
+ * be asynchronously sent from the host and synchronously returned from the
+ * guest.
+ *
+ * In short, an endpoint sending this command is sending a request whose reply
+ * should be returned synchronously.
+ */
+#define HGFS_SYNC_REQREP_CMD "f"
+#define HGFS_SYNC_REQREP_CLIENT_CMD HGFS_SYNC_REQREP_CMD " "
+#define HGFS_SYNC_REQREP_CLIENT_CMD_LEN (sizeof HGFS_SYNC_REQREP_CLIENT_CMD - 1)
+
+/*
+ * This is just for the sake of macro naming. Since we are guaranteed
+ * equal command lengths, defining command length via a generalized macro name
+ * will prevent confusion.
+ */
+#define HGFS_CLIENT_CMD_LEN HGFS_SYNC_REQREP_CLIENT_CMD_LEN
+
+#endif // _HGFS_H_
--- kernel/linux-2.6.26.3/fs/vmhgfs/hgfsProto.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/hgfsProto.h	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,1470 @@
+/*********************************************************
+ * Copyright (C) 1998 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+
+/*
+ * hgfsProto.h --
+ *
+ * Header file for data types and message formats used in the
+ * Host/Guest File System (hgfs) protocol.
+ */
+
+
+#ifndef _HGFS_PROTO_H_
+# define _HGFS_PROTO_H_
+
+#define INCLUDE_ALLOW_USERLEVEL
+#define INCLUDE_ALLOW_MODULE
+#define INCLUDE_ALLOW_DISTRIBUTE
+#include "includeCheck.h"
+
+#include "vm_basic_types.h"
+#include "hgfs.h"
+
+/*
+ * Handle used by the server to identify files and searches. Used
+ * by the driver to match server replies with pending requests.
+ */
+
+typedef uint32 HgfsHandle;
+#define HGFS_INVALID_HANDLE         ((HgfsHandle)~((HgfsHandle)0))
+
+/*
+ * Opcodes for server operations.
+ *
+ * Changing the ordering of this enum will break the protocol; new ops
+ * should be added at the end (but before HGFS_OP_MAX).
+ */
+
+typedef enum {
+   HGFS_OP_OPEN,               /* Open file */
+   HGFS_OP_READ,               /* Read from file */
+   HGFS_OP_WRITE,              /* Write to file */
+   HGFS_OP_CLOSE,              /* Close file */
+   HGFS_OP_SEARCH_OPEN,        /* Start new search */
+   HGFS_OP_SEARCH_READ,        /* Get next search response */
+   HGFS_OP_SEARCH_CLOSE,       /* End a search */
+   HGFS_OP_GETATTR,            /* Get file attributes */
+   HGFS_OP_SETATTR,            /* Set file attributes */
+   HGFS_OP_CREATE_DIR,         /* Create new directory */
+   HGFS_OP_DELETE_FILE,        /* Delete a file */
+   HGFS_OP_DELETE_DIR,         /* Delete a directory */
+   HGFS_OP_RENAME,             /* Rename a file or directory */
+   HGFS_OP_QUERY_VOLUME_INFO,  /* Query volume information */
+
+   /*
+    * The following operations are only available in version 2 of the hgfs
+    * protocol. The corresponding version 1 opcodes above are deprecated.
+    */
+
+   HGFS_OP_OPEN_V2,            /* Open file */
+   HGFS_OP_GETATTR_V2,         /* Get file attributes */
+   HGFS_OP_SETATTR_V2,         /* Set file attributes */
+   HGFS_OP_SEARCH_READ_V2,     /* Get next search response */
+   HGFS_OP_CREATE_SYMLINK,     /* Create a symlink */
+   HGFS_OP_SERVER_LOCK_CHANGE, /* Change the oplock on a file */
+   HGFS_OP_CREATE_DIR_V2,      /* Create a directory */
+   HGFS_OP_DELETE_FILE_V2,     /* Delete a file */
+   HGFS_OP_DELETE_DIR_V2,      /* Delete a directory */
+   HGFS_OP_RENAME_V2,          /* Rename a file or directory */
+
+   /*
+    * Operations for version 3, deprecating version 2 operations.
+    */
+
+   HGFS_OP_OPEN_V3,               /* Open file */
+   HGFS_OP_READ_V3,               /* Read from file */
+   HGFS_OP_WRITE_V3,              /* Write to file */
+   HGFS_OP_CLOSE_V3,              /* Close file */
+   HGFS_OP_SEARCH_OPEN_V3,        /* Start new search */
+   HGFS_OP_SEARCH_READ_V3,        /* Start new search */
+   HGFS_OP_SEARCH_CLOSE_V3,       /* End a search */
+   HGFS_OP_GETATTR_V3,            /* Get file attributes */
+   HGFS_OP_SETATTR_V3,            /* Set file attributes */
+   HGFS_OP_CREATE_DIR_V3,         /* Create new directory */
+   HGFS_OP_DELETE_FILE_V3,        /* Delete a file */
+   HGFS_OP_DELETE_DIR_V3,         /* Delete a directory */
+   HGFS_OP_RENAME_V3,             /* Rename a file or directory */
+   HGFS_OP_QUERY_VOLUME_INFO_V3,  /* Query volume information */
+   HGFS_OP_CREATE_SYMLINK_V3,     /* Create a symlink */
+   HGFS_OP_SERVER_LOCK_CHANGE_V3, /* Change the oplock on a file */
+
+   HGFS_OP_MAX,                   /* Dummy op, must be last in enum */
+} HgfsOp;
+
+
+/* HGFS protocol versions. */
+#define HGFS_VERSION_OLD           (1 << 0)
+#define HGFS_VERSION_3             (1 << 1)
+
+/* XXX: Needs change when VMCI is supported. */
+#define HGFS_REQ_PAYLOAD_SIZE_V3(hgfsReq) (sizeof *hgfsReq + sizeof(HgfsRequest))
+#define HGFS_REP_PAYLOAD_SIZE_V3(hgfsRep) (sizeof *hgfsRep + sizeof(HgfsReply))
+
+/* XXX: Needs change when VMCI is supported. */
+#define HGFS_REQ_GET_PAYLOAD_V3(hgfsReq) ((char *)(hgfsReq) + sizeof(HgfsRequest))
+#define HGFS_REP_GET_PAYLOAD_V3(hgfsRep) ((char *)(hgfsRep) + sizeof(HgfsReply))
+
+
+/*
+ * File types, used in HgfsAttr. We support regular files,
+ * directories, and symlinks.
+ *
+ * Changing the order of this enum will break the protocol; new types
+ * should be added at the end.
+ */
+
+typedef enum {
+   HGFS_FILE_TYPE_REGULAR,
+   HGFS_FILE_TYPE_DIRECTORY,
+   HGFS_FILE_TYPE_SYMLINK,
+} HgfsFileType;
+
+
+/*
+ * Open flags.
+ *
+ * Changing the order of this enum will break stuff.  Do not add any flags to
+ * this enum: it has been frozen and all new flags should be added to
+ * HgfsOpenMode.  This was done because HgfsOpenMode could still be converted
+ * to a bitmask (so that it's easier to add flags to) whereas this enum was
+ * already too large.
+ */
+
+typedef enum {             //  File doesn't exist   File exists
+   HGFS_OPEN,              //  error
+   HGFS_OPEN_EMPTY,        //  error               size = 0
+   HGFS_OPEN_CREATE,       //  create
+   HGFS_OPEN_CREATE_SAFE,  //  create              error
+   HGFS_OPEN_CREATE_EMPTY, //  create              size = 0
+} HgfsOpenFlags;
+
+
+/*
+ * Write flags.
+ */
+
+typedef uint8 HgfsWriteFlags;
+
+#define HGFS_WRITE_APPEND 1
+
+
+/*
+ * Permissions bits.
+ *
+ * These are intentionally similar to Unix permissions bits, and we
+ * convert to/from Unix permissions using simple shift operations, so
+ * don't change these or you will break things.
+ */
+
+typedef uint8 HgfsPermissions;
+
+#define HGFS_PERM_READ  4
+#define HGFS_PERM_WRITE 2
+#define HGFS_PERM_EXEC  1
+
+
+/*
+ * Server-side locking (oplocks and leases).
+ *
+ * The client can ask the server to acquire opportunistic locking/leasing
+ * from the host FS on its behalf. This is communicated as part of an open request.
+ *
+ * HGFS_LOCK_OPPORTUNISTIC means that the client trusts the server
+ * to decide what kind of locking to request from the host FS.
+ * All other values tell the server explicitly the type of lock to
+ * request.
+ *
+ * The server will attempt to acquire the desired lock and will notify the client
+ * which type of lock was acquired as part of the reply to the open request.
+ * Note that HGFS_LOCK_OPPORTUNISTIC should not be specified as the type of
+ * lock acquired by the server, since HGFS_LOCK_OPPORTUNISTIC is not an
+ * actual lock.
+ */
+
+typedef enum {
+   HGFS_LOCK_NONE,
+   HGFS_LOCK_OPPORTUNISTIC,
+   HGFS_LOCK_EXCLUSIVE,
+   HGFS_LOCK_SHARED,
+} HgfsServerLock;
+
+
+/*
+ * Flags to indicate in a setattr request which fields should be
+ * updated. Deprecated.
+ */
+
+typedef uint8 HgfsAttrChanges;
+
+#define HGFS_ATTR_SIZE                  (1 << 0)
+#define HGFS_ATTR_CREATE_TIME           (1 << 1)
+#define HGFS_ATTR_ACCESS_TIME           (1 << 2)
+#define HGFS_ATTR_WRITE_TIME            (1 << 3)
+#define HGFS_ATTR_CHANGE_TIME           (1 << 4)
+#define HGFS_ATTR_PERMISSIONS           (1 << 5)
+#define HGFS_ATTR_ACCESS_TIME_SET       (1 << 6)
+#define HGFS_ATTR_WRITE_TIME_SET        (1 << 7)
+
+
+/*
+ * Hints to indicate in a getattr or setattr which attributes
+ * are valid for the request.
+ * For setattr only, attributes should be set by host even if
+ * no valid values are specified by the guest.
+ */
+
+typedef uint64 HgfsAttrHint;
+
+#define HGFS_ATTR_HINT_SET_ACCESS_TIME   (1 << 0)
+#define HGFS_ATTR_HINT_SET_WRITE_TIME    (1 << 1)
+#define HGFS_ATTR_HINT_USE_FILE_DESC     (1 << 2)
+
+/*
+ * Hint to determine using a name or a handle to determine
+ * what to delete.
+ */
+
+typedef uint64 HgfsDeleteHint;
+
+#define HGFS_DELETE_HINT_USE_FILE_DESC   (1 << 0)
+
+/*
+ * Hint to determine using a name or a handle to determine
+ * what to renames.
+ */
+
+typedef uint64 HgfsRenameHint;
+
+#define HGFS_RENAME_HINT_USE_SRCFILE_DESC       (1 << 0)
+#define HGFS_RENAME_HINT_USE_TARGETFILE_DESC    (1 << 1)
+#define HGFS_RENAME_HINT_NO_REPLACE_EXISTING    (1 << 2)
+#define HGFS_RENAME_HINT_NO_COPY_ALLOWED        (1 << 3)
+
+/*
+ * File attributes.
+ *
+ * The four time fields below are in Windows NT format, which is in
+ * units of 100ns since Jan 1, 1601, UTC.
+ */
+
+/*
+ * Version 1 attributes. Deprecated.
+ * Version 2 should be using HgfsAttrV2.
+ */
+
+typedef
+#include "vmware_pack_begin.h"
+struct HgfsAttr {
+   HgfsFileType type;            /* File type */
+   uint64 size;                  /* File size (in bytes) */
+   uint64 creationTime;          /* Creation time. Ignored by POSIX */
+   uint64 accessTime;            /* Time of last access */
+   uint64 writeTime;             /* Time of last write */
+   uint64 attrChangeTime;        /* Time file attributess were last
+                                  * changed. Ignored by Windows */
+   HgfsPermissions permissions;  /* Permissions bits */
+}
+#include "vmware_pack_end.h"
+HgfsAttr;
+
+
+/* Various flags and Windows attributes. */
+
+typedef uint64 HgfsAttrFlags;
+
+#define HGFS_ATTR_HIDDEN      (1 << 0)
+#define HGFS_ATTR_SYSTEM      (1 << 1)
+#define HGFS_ATTR_ARCHIVE     (1 << 2)
+#define HGFS_ATTR_HIDDEN_FORCED (1 << 3)
+
+
+/*
+ * Specifies which open request fields contain
+ * valid values.
+ */
+
+typedef uint64 HgfsOpenValid;
+
+#define HGFS_OPEN_VALID_NONE              0
+#define HGFS_OPEN_VALID_MODE              (1 << 0)
+#define HGFS_OPEN_VALID_FLAGS             (1 << 1)
+#define HGFS_OPEN_VALID_SPECIAL_PERMS     (1 << 2)
+#define HGFS_OPEN_VALID_OWNER_PERMS       (1 << 3)
+#define HGFS_OPEN_VALID_GROUP_PERMS       (1 << 4)
+#define HGFS_OPEN_VALID_OTHER_PERMS       (1 << 5)
+#define HGFS_OPEN_VALID_FILE_ATTR         (1 << 6)
+#define HGFS_OPEN_VALID_ALLOCATION_SIZE   (1 << 7)
+#define HGFS_OPEN_VALID_DESIRED_ACCESS    (1 << 8)
+#define HGFS_OPEN_VALID_SHARE_ACCESS      (1 << 9)
+#define HGFS_OPEN_VALID_SERVER_LOCK       (1 << 10)
+#define HGFS_OPEN_VALID_FILE_NAME         (1 << 11)
+
+
+/*
+ * Specifies which attribute fields contain
+ * valid values.
+ */
+
+typedef uint64 HgfsAttrValid;
+
+#define HGFS_ATTR_VALID_NONE              0
+#define HGFS_ATTR_VALID_TYPE              (1 << 0)
+#define HGFS_ATTR_VALID_SIZE              (1 << 1)
+#define HGFS_ATTR_VALID_CREATE_TIME       (1 << 2)
+#define HGFS_ATTR_VALID_ACCESS_TIME       (1 << 3)
+#define HGFS_ATTR_VALID_WRITE_TIME        (1 << 4)
+#define HGFS_ATTR_VALID_CHANGE_TIME       (1 << 5)
+#define HGFS_ATTR_VALID_SPECIAL_PERMS     (1 << 6)
+#define HGFS_ATTR_VALID_OWNER_PERMS       (1 << 7)
+#define HGFS_ATTR_VALID_GROUP_PERMS       (1 << 8)
+#define HGFS_ATTR_VALID_OTHER_PERMS       (1 << 9)
+#define HGFS_ATTR_VALID_FLAGS             (1 << 10)
+#define HGFS_ATTR_VALID_ALLOCATION_SIZE   (1 << 11)
+#define HGFS_ATTR_VALID_USERID            (1 << 12)
+#define HGFS_ATTR_VALID_GROUPID           (1 << 13)
+#define HGFS_ATTR_VALID_FILEID            (1 << 14)
+
+
+/*
+ * Specifies which create dir request fields contain
+ * valid values.
+ */
+
+typedef uint64 HgfsCreateDirValid;
+
+#define HGFS_CREATE_DIR_VALID_NONE              0
+#define HGFS_CREATE_DIR_VALID_SPECIAL_PERMS     (1 << 0)
+#define HGFS_CREATE_DIR_VALID_OWNER_PERMS       (1 << 1)
+#define HGFS_CREATE_DIR_VALID_GROUP_PERMS       (1 << 2)
+#define HGFS_CREATE_DIR_VALID_OTHER_PERMS       (1 << 3)
+#define HGFS_CREATE_DIR_VALID_FILE_NAME         (1 << 4)
+
+/*
+ *  Version 2 of HgfsAttr
+ */
+
+typedef
+#include "vmware_pack_begin.h"
+struct HgfsAttrV2 {
+   HgfsAttrValid mask;           /* A bit mask to determine valid attribute fields */
+   HgfsFileType type;            /* File type */
+   uint64 size;                  /* File size (in bytes) */
+   uint64 creationTime;          /* Creation time. Ignored by POSIX */
+   uint64 accessTime;            /* Time of last access */
+   uint64 writeTime;             /* Time of last write */
+   uint64 attrChangeTime;        /* Time file attributes were last
+                                  * changed. Ignored by Windows */
+   HgfsPermissions specialPerms; /* Special permissions bits (suid, etc.).
+                                  * Ignored by Windows */
+   HgfsPermissions ownerPerms;   /* Owner permissions bits */
+   HgfsPermissions groupPerms;   /* Group permissions bits. Ignored by
+                                  * Windows */
+   HgfsPermissions otherPerms;   /* Other permissions bits. Ignored by
+                                  * Windows */
+   HgfsAttrFlags flags;          /* Various flags and Windows 'attributes' */
+   uint64 allocationSize;        /* Actual size of file on disk */
+   uint32 userId;                /* User identifier, ignored by Windows */
+   uint32 groupId;               /* group identifier, ignored by Windows */
+   uint64 hostFileId;            /* File Id of the file on host: inode_t on Linux */
+   uint64 reserved1;             /* Reserved for future use */
+   uint64 reserved2;             /* Reserved for future use */
+}
+#include "vmware_pack_end.h"
+HgfsAttrV2;
+
+
+/*
+ * Cross-platform filename representation
+ *
+ * Cross-platform (CP) names are represented by a string with each
+ * path component separated by NULs, and terminated with a final NUL,
+ * but with no leading path separator.
+ *
+ * For example, the representations of a POSIX and Windows name
+ * are as follows, with "0" meaning NUL.
+ *
+ * Original name             Cross-platform name
+ * -----------------------------------------------------
+ * "/home/bac/temp"    ->    "home0bac0temp0"
+ * "C:\temp\file.txt"  ->    "C0temp0file.txt0"
+ *
+ * Note that as in the example above, Windows should strip the colon
+ * off of drive letters as part of the conversion. Aside from that,
+ * all characters in each path component should be left unescaped and
+ * unmodified. Each OS is responsible for escaping any characters that
+ * are not legal in its filenames when converting FROM the CP name
+ * format, and unescaping them when converting TO the CP name format.
+ *
+ * In some requests (OPEN, GETATTR, SETATTR, DELETE, CREATE_DIR) the
+ * CP name is used to represent a particular file, but it is also used
+ * to represent a search pattern for looking up files using
+ * SEARCH_OPEN.
+ *
+ * In the current HGFS server implementation, each request has a minimum packet
+ * size that must be met for it to be considered valid. This minimum is simply
+ * the sizeof the particular request, which includes the solitary byte from the
+ * HgfsFileName struct. For these particular requests, clients add an extra
+ * byte to their payload size, without that byte being present anywhere.
+ *
+ * It isn't clear that this behavior is correct, but the end result is that
+ * neither end malfunctions, as an extra byte gets sent by the client and is
+ * ignored by the server. Unfortunately, it cannot be easily fixed. The
+ * server's minimum packet size can be changed, but the client should continue
+ * to send an extra byte, otherwise older servers with a slightly longer
+ * minimum packet size may consider the new client's packets to be too short.
+ *
+ * UTF-8 representation
+ * --------------------
+ * XXX: It is expected that file names in the HGFS protocol will be a valid UTF-8
+ * encoding.
+ * See RFC 3629 (http://tools.ietf.org/html/rfc3629)
+ *
+ * Unicode Format
+ * --------------
+ * HGFS protocol requests that contain file names as in the structure below,
+ * should contain unicode normal form C (precomposed see explanation below)
+ * characters therefore hosts such as Mac OS X which
+ * use HFS+ and unicode form D should convert names before
+ * processing or sending HGFS requests.
+ *
+ * Precomposed (normal form C) versus Decomposed (normal form D)
+ * -------------------------------------------------------------
+ * Certain Unicode characters can be encoded in more than one way.
+ * For example, an (A acute) can be encoded either precomposed,
+ * as U+00C1 (LATIN CAPITAL LETTER A WITH ACUTE), or decomposed,
+ * as U+0041 U+0301 (LATIN CAPITAL LETTER A followed by a COMBINING ACUTE ACCENT).
+ * Precomposed characters are more common in the Windows world,
+ * whereas decomposed characters are more common on the Mac.
+ *
+ * See UAX 15 (http://unicode.org/reports/tr15/)
+ */
+
+typedef
+#include "vmware_pack_begin.h"
+struct HgfsFileName {
+   uint32 length; /* Does NOT include terminating NUL */
+   char name[1];
+}
+#include "vmware_pack_end.h"
+HgfsFileName;
+
+
+/*
+ * Case-sensitiviy flags are only used when any lookup is
+ * involved on the server side.
+ */
+
+typedef enum {
+   HGFS_FILE_NAME_DEFAULT_CASE,
+   HGFS_FILE_NAME_CASE_SENSITIVE,
+   HGFS_FILE_NAME_CASE_INSENSITIVE,
+} HgfsCaseType;
+
+
+/*
+ * HgfsFileNameV3 - new header to incorporate case-sensitivity flags along with
+ * Hgfs file handle.
+ */
+
+typedef
+#include "vmware_pack_begin.h"
+struct HgfsFileNameV3 {
+   uint32 length;           /* Does NOT include terminating NUL */
+   uint32 flags;            /* Flags described below. */
+   HgfsCaseType caseType;   /* Case-sensitivity type. */
+   HgfsHandle fid;
+   char name[1];
+}
+#include "vmware_pack_end.h"
+HgfsFileNameV3;
+
+
+/*
+ * HgfsFileNameV3 flags. Case-sensitiviy flags are only used when any lookup is
+ * involved on the server side.
+ */
+#define HGFS_FILE_NAME_USE_FILE_DESC     (1 << 0)  /* Case type ignored if set. */
+
+
+/*
+ * Request/reply structs. These are the first members of all
+ * operation request and reply messages, respectively.
+ */
+
+typedef
+#include "vmware_pack_begin.h"
+struct HgfsRequest {
+   HgfsHandle id;        /* Opaque request ID used by the requestor */
+   HgfsOp op;
+}
+#include "vmware_pack_end.h"
+HgfsRequest;
+
+
+typedef
+#include "vmware_pack_begin.h"
+struct HgfsReply {
+   HgfsHandle id;        /* Opaque request ID used by the requestor */
+   HgfsStatus status;
+}
+#include "vmware_pack_end.h"
+HgfsReply;
+
+
+/*
+ * Messages for our file operations.
+ */
+
+/* Deprecated */
+
+typedef
+#include "vmware_pack_begin.h"
+struct HgfsRequestOpen {
+   HgfsRequest header;
+   HgfsOpenMode mode;            /* Which type of access is requested */
+   HgfsOpenFlags flags;          /* Which flags to open the file with */
+   HgfsPermissions permissions;  /* Which permissions to *create* a new file with */
+   HgfsFileName fileName;
+}
+#include "vmware_pack_end.h"
+HgfsRequestOpen;
+
+
+/* Version 2 of HgfsRequestOpen */
+
+typedef
+#include "vmware_pack_begin.h"
+struct HgfsRequestOpenV2 {
+   HgfsRequest header;
+   HgfsOpenValid mask;           /* Bitmask that specified which fields are valid. */
+   HgfsOpenMode mode;            /* Which type of access requested. See desiredAccess */
+   HgfsOpenFlags flags;          /* Which flags to open the file with */
+   HgfsPermissions specialPerms; /* Desired 'special' permissions for file creation */
+   HgfsPermissions ownerPerms;   /* Desired 'owner' permissions for file creation */
+   HgfsPermissions groupPerms;   /* Desired 'group' permissions for file creation */
+   HgfsPermissions otherPerms;   /* Desired 'other' permissions for file creation */
+   HgfsAttrFlags attr;           /* Attributes, if any, for file creation */
+   uint64 allocationSize;        /* How much space to pre-allocate during creation */
+   uint32 desiredAccess;         /* Extended support for windows access modes */
+   uint32 shareAccess;           /* Windows only, share access modes */
+   HgfsServerLock desiredLock;   /* The type of lock desired by the client */
+   uint64 reserved1;             /* Reserved for future use */
+   uint64 reserved2;             /* Reserved for future use */
+   HgfsFileName fileName;
+}
+#include "vmware_pack_end.h"
+HgfsRequestOpenV2;
+
+
+/* Version 3 of HgfsRequestOpen */
+
+typedef
+#include "vmware_pack_begin.h"
+struct HgfsRequestOpenV3 {
+   HgfsOpenValid mask;           /* Bitmask that specified which fields are valid. */
+   HgfsOpenMode mode;            /* Which type of access requested. See desiredAccess */
+   HgfsOpenFlags flags;          /* Which flags to open the file with */
+   HgfsPermissions specialPerms; /* Desired 'special' permissions for file creation */
+   HgfsPermissions ownerPerms;   /* Desired 'owner' permissions for file creation */
+   HgfsPermissions groupPerms;   /* Desired 'group' permissions for file creation */
+   HgfsPermissions otherPerms;   /* Desired 'other' permissions for file creation */
+   HgfsAttrFlags attr;           /* Attributes, if any, for file creation */
+   uint64 allocationSize;        /* How much space to pre-allocate during creation */
+   uint32 desiredAccess;         /* Extended support for windows access modes */
+   uint32 shareAccess;           /* Windows only, share access modes */
+   HgfsServerLock desiredLock;   /* The type of lock desired by the client */
+   uint64 reserved1;             /* Reserved for future use */
+   uint64 reserved2;             /* Reserved for future use */
+   HgfsFileNameV3 fileName;
+}
+#include "vmware_pack_end.h"
+HgfsRequestOpenV3;
+
+
+/* Deprecated */
+
+typedef
+#include "vmware_pack_begin.h"
+struct HgfsReplyOpen {
+   HgfsReply header;
+   HgfsHandle file;      /* Opaque file ID used by the server */
+}
+#include "vmware_pack_end.h"
+HgfsReplyOpen;
+
+
+/* Version 2 of HgfsReplyOpen */
+
+typedef
+#include "vmware_pack_begin.h"
+struct HgfsReplyOpenV2 {
+   HgfsReply header;
+   HgfsHandle file;                  /* Opaque file ID used by the server */
+   HgfsServerLock acquiredLock;      /* The type of lock acquired by the server */
+}
+#include "vmware_pack_end.h"
+HgfsReplyOpenV2;
+
+
+/* Version 3 of HgfsReplyOpen */
+
+typedef
+#include "vmware_pack_begin.h"
+struct HgfsReplyOpenV3 {
+   HgfsHandle file;                  /* Opaque file ID used by the server */
+   HgfsServerLock acquiredLock;      /* The type of lock acquired by the server */
+   uint64 reserved;                  /* Reserved for future use */
+}
+#include "vmware_pack_end.h"
+HgfsReplyOpenV3;
+
+
+/* Deprecated */
+
+typedef
+#include "vmware_pack_begin.h"
+struct HgfsRequestRead {
+   HgfsRequest header;
+   HgfsHandle file;      /* Opaque file ID used by the server */
+   uint64 offset;
+   uint32 requiredSize;
+}
+#include "vmware_pack_end.h"
+HgfsRequestRead;
+
+/* Deprecated */
+
+typedef
+#include "vmware_pack_begin.h"
+struct HgfsReplyRead {
+   HgfsReply header;
+   uint32 actualSize;
+   char payload[1];
+}
+#include "vmware_pack_end.h"
+HgfsReplyRead;
+
+
+/*
+ * Version 3 of HgfsRequestRead.
+ * Server must support HGFS_LARGE_PACKET_MAX to implement this op.
+ */
+
+typedef
+#include "vmware_pack_begin.h"
+struct HgfsRequestReadV3 {
+   HgfsHandle file;      /* Opaque file ID used by the server */
+   uint64 offset;
+   uint32 requiredSize;
+   uint64 reserved;      /* Reserved for future use */
+}
+#include "vmware_pack_end.h"
+HgfsRequestReadV3;
+
+typedef
+#include "vmware_pack_begin.h"
+struct HgfsReplyReadV3 {
+   uint32 actualSize;
+   uint64 reserved;      /* Reserved for future use */
+   char payload[1];
+}
+#include "vmware_pack_end.h"
+HgfsReplyReadV3;
+
+
+/* Deprecated */
+
+typedef
+#include "vmware_pack_begin.h"
+struct HgfsRequestWrite {
+   HgfsRequest header;
+   HgfsHandle file;      /* Opaque file ID used by the server */
+   HgfsWriteFlags flags;
+   uint64 offset;
+   uint32 requiredSize;
+   char payload[1];
+}
+#include "vmware_pack_end.h"
+HgfsRequestWrite;
+
+
+/* Deprecated */
+
+typedef
+#include "vmware_pack_begin.h"
+struct HgfsReplyWrite {
+   HgfsReply header;
+   uint32 actualSize;
+}
+#include "vmware_pack_end.h"
+HgfsReplyWrite;
+
+/*
+ * Version 3 of HgfsRequestWrite.
+ * Server must support HGFS_LARGE_PACKET_MAX to implement this op.
+ */
+
+typedef
+#include "vmware_pack_begin.h"
+struct HgfsRequestWriteV3 {
+   HgfsHandle file;      /* Opaque file ID used by the server */
+   HgfsWriteFlags flags;
+   uint64 offset;
+   uint32 requiredSize;
+   uint64 reserved;      /* Reserved for future use */
+   char payload[1];
+}
+#include "vmware_pack_end.h"
+HgfsRequestWriteV3;
+
+
+typedef
+#include "vmware_pack_begin.h"
+struct HgfsReplyWriteV3 {
+   uint32 actualSize;
+   uint64 reserved;      /* Reserved for future use */
+}
+#include "vmware_pack_end.h"
+HgfsReplyWriteV3;
+
+
+/* Deprecated */
+
+typedef
+#include "vmware_pack_begin.h"
+struct HgfsRequestClose {
+   HgfsRequest header;
+   HgfsHandle file;      /* Opaque file ID used by the server */
+}
+#include "vmware_pack_end.h"
+HgfsRequestClose;
+
+
+/* Deprecated */
+
+typedef
+#include "vmware_pack_begin.h"
+struct HgfsReplyClose {
+   HgfsReply header;
+}
+#include "vmware_pack_end.h"
+HgfsReplyClose;
+
+
+typedef
+#include "vmware_pack_begin.h"
+struct HgfsRequestCloseV3 {
+   HgfsHandle file;      /* Opaque file ID used by the server */
+   uint64 reserved;      /* Reserved for future use */
+}
+#include "vmware_pack_end.h"
+HgfsRequestCloseV3;
+
+
+typedef
+#include "vmware_pack_begin.h"
+struct HgfsReplyCloseV3 {
+   uint64 reserved;
+}
+#include "vmware_pack_end.h"
+HgfsReplyCloseV3;
+
+
+/* Deprecated */
+
+typedef
+#include "vmware_pack_begin.h"
+struct HgfsRequestSearchOpen {
+   HgfsRequest header;
+   HgfsFileName dirName;
+}
+#include "vmware_pack_end.h"
+HgfsRequestSearchOpen;
+
+
+typedef
+#include "vmware_pack_begin.h"
+struct HgfsRequestSearchOpenV3 {
+   uint64 reserved;      /* Reserved for future use */
+   HgfsFileNameV3 dirName;
+}
+#include "vmware_pack_end.h"
+HgfsRequestSearchOpenV3;
+
+
+/* Deprecated */
+
+typedef
+#include "vmware_pack_begin.h"
+struct HgfsReplySearchOpen {
+   HgfsReply header;
+   HgfsHandle search;    /* Opaque search ID used by the server */
+}
+#include "vmware_pack_end.h"
+HgfsReplySearchOpen;
+
+
+typedef
+#include "vmware_pack_begin.h"
+struct HgfsReplySearchOpenV3 {
+   HgfsHandle search;    /* Opaque search ID used by the server */
+   uint64 reserved;      /* Reserved for future use */
+}
+#include "vmware_pack_end.h"
+HgfsReplySearchOpenV3;
+
+
+/* Deprecated */
+
+typedef
+#include "vmware_pack_begin.h"
+struct HgfsRequestSearchRead {
+   HgfsRequest header;
+   HgfsHandle search;    /* Opaque search ID used by the server */
+   uint32 offset;        /* The first result is offset 0 */
+}
+#include "vmware_pack_end.h"
+HgfsRequestSearchRead;
+
+
+/* Version 2 of HgfsRequestSearchRead */
+
+typedef
+#include "vmware_pack_begin.h"
+struct HgfsRequestSearchReadV2 {
+   HgfsRequest header;
+   HgfsHandle search;    /* Opaque search ID used by the server */
+   uint32 offset;        /* The first result is offset 0 */
+}
+#include "vmware_pack_end.h"
+HgfsRequestSearchReadV2;
+
+typedef
+#include "vmware_pack_begin.h"
+struct HgfsRequestSearchReadV3 {
+   HgfsHandle search;    /* Opaque search ID used by the server */
+   uint32 offset;        /* The first result is offset 0 */
+   uint32 flags;         /* Reserved for reading multiple directory entries. */
+   uint64 reserved;      /* Reserved for future use */
+}
+#include "vmware_pack_end.h"
+HgfsRequestSearchReadV3;
+
+
+/* Deprecated */
+
+typedef
+#include "vmware_pack_begin.h"
+struct HgfsReplySearchRead {
+   HgfsReply header;
+   HgfsAttr attr;
+   HgfsFileName fileName;
+   /* fileName.length = 0 means "no entry at this offset" */
+}
+#include "vmware_pack_end.h"
+HgfsReplySearchRead;
+
+
+/* Version 2 of HgfsReplySearchRead */
+
+typedef
+#include "vmware_pack_begin.h"
+struct HgfsReplySearchReadV2 {
+   HgfsReply header;
+   HgfsAttrV2 attr;
+
+   /*
+    * fileName.length = 0 means "no entry at this offset"
+    * If the file is a symlink (as specified in attr)
+    * this name is the name of the symlink, not the target.
+    */
+   HgfsFileName fileName;
+}
+#include "vmware_pack_end.h"
+HgfsReplySearchReadV2;
+
+
+/* Directory entry structure. */
+
+typedef struct HgfsDirEntry {
+   uint32 nextEntry;
+   HgfsAttrV2 attr;
+
+   /*
+    * fileName.length = 0 means "no entry at this offset"
+    * If the file is a symlink (as specified in attr)
+    * this name is the name of the symlink, not the target.
+    */
+   HgfsFileNameV3 fileName;
+} HgfsDirEntry;
+
+typedef
+#include "vmware_pack_begin.h"
+struct HgfsReplySearchReadV3 {
+   uint64 count;         /* Number of directory entries. */
+   uint64 reserved;      /* Reserved for future use. */
+   char payload[1];      /* Directory entries. */
+}
+#include "vmware_pack_end.h"
+HgfsReplySearchReadV3;
+
+
+/* Deprecated */
+
+typedef
+#include "vmware_pack_begin.h"
+struct HgfsRequestSearchClose {
+   HgfsRequest header;
+   HgfsHandle search;    /* Opaque search ID used by the server */
+}
+#include "vmware_pack_end.h"
+HgfsRequestSearchClose;
+
+
+/* Deprecated */
+
+typedef
+#include "vmware_pack_begin.h"
+struct HgfsReplySearchClose {
+   HgfsReply header;
+}
+#include "vmware_pack_end.h"
+HgfsReplySearchClose;
+
+
+typedef
+#include "vmware_pack_begin.h"
+struct HgfsRequestSearchCloseV3 {
+   HgfsHandle search;    /* Opaque search ID used by the server */
+   uint64 reserved;      /* Reserved for future use */
+}
+#include "vmware_pack_end.h"
+HgfsRequestSearchCloseV3;
+
+
+typedef
+#include "vmware_pack_begin.h"
+struct HgfsReplySearchCloseV3 {
+   uint64 reserved;      /* Reserved for future use */
+}
+#include "vmware_pack_end.h"
+HgfsReplySearchCloseV3;
+
+
+/* Deprecated */
+
+typedef
+#include "vmware_pack_begin.h"
+struct HgfsRequestGetattr {
+   HgfsRequest header;
+   HgfsFileName fileName;
+}
+#include "vmware_pack_end.h"
+HgfsRequestGetattr;
+
+
+/* Version 2 of HgfsRequestGetattr */
+
+typedef
+#include "vmware_pack_begin.h"
+struct HgfsRequestGetattrV2 {
+   HgfsRequest header;
+   HgfsAttrHint hints;     /* Flags for file handle valid. */
+   HgfsHandle file;        /* Opaque file ID used by the server. */
+   HgfsFileName fileName;  /* Filename used when file handle invalid. */
+}
+#include "vmware_pack_end.h"
+HgfsRequestGetattrV2;
+
+
+typedef
+#include "vmware_pack_begin.h"
+struct HgfsRequestGetattrV3 {
+   HgfsAttrHint hints;       /* Flags for file handle valid. */
+   uint64 reserved;          /* Reserved for future use */
+   HgfsFileNameV3 fileName;  /* Filename used when file handle invalid. */
+}
+#include "vmware_pack_end.h"
+HgfsRequestGetattrV3;
+
+
+/* Deprecated */
+
+typedef
+#include "vmware_pack_begin.h"
+struct HgfsReplyGetattr {
+   HgfsReply header;
+   HgfsAttr attr;
+}
+#include "vmware_pack_end.h"
+HgfsReplyGetattr;
+
+
+/* Version 2 of HgfsReplyGetattr */
+
+typedef
+#include "vmware_pack_begin.h"
+struct HgfsReplyGetattrV2 {
+   HgfsReply header;
+   HgfsAttrV2 attr;
+
+   /*
+    * If the file is a symlink, as specified in attr.type, then this is
+    * the target for the symlink. If the file is not a symlink, this should
+    * be ignored.
+    *
+    * This filename is in "CPNameLite" format. See CPNameLite.c for details.
+    */
+   HgfsFileName symlinkTarget;
+}
+#include "vmware_pack_end.h"
+HgfsReplyGetattrV2;
+
+
+typedef
+#include "vmware_pack_begin.h"
+struct HgfsReplyGetattrV3 {
+   HgfsAttrV2 attr;
+
+   /*
+    * If the file is a symlink, as specified in attr.type, then this is
+    * the target for the symlink. If the file is not a symlink, this should
+    * be ignored.
+    *
+    * This filename is in "CPNameLite" format. See CPNameLite.c for details.
+    */
+   uint64 reserved;          /* Reserved for future use */
+   HgfsFileNameV3 symlinkTarget;
+}
+#include "vmware_pack_end.h"
+HgfsReplyGetattrV3;
+
+
+/* Deprecated */
+
+typedef
+#include "vmware_pack_begin.h"
+struct HgfsRequestSetattr {
+   HgfsRequest header;
+   HgfsAttrChanges update;  /* Which fields need to be updated */
+   HgfsAttr attr;
+   HgfsFileName fileName;
+}
+#include "vmware_pack_end.h"
+HgfsRequestSetattr;
+
+
+/* Version 2 of HgfsRequestSetattr */
+
+typedef
+#include "vmware_pack_begin.h"
+struct HgfsRequestSetattrV2 {
+   HgfsRequest header;
+   HgfsAttrHint hints;
+   HgfsAttrV2 attr;
+   HgfsHandle file;        /* Opaque file ID used by the server. */
+   HgfsFileName fileName;  /* Filename used when file handle invalid. */
+}
+#include "vmware_pack_end.h"
+HgfsRequestSetattrV2;
+
+
+typedef
+#include "vmware_pack_begin.h"
+struct HgfsRequestSetattrV3 {
+   HgfsAttrHint hints;
+   HgfsAttrV2 attr;
+   uint64 reserved;          /* Reserved for future use */
+   HgfsFileNameV3 fileName;  /* Filename used when file handle invalid. */
+}
+#include "vmware_pack_end.h"
+HgfsRequestSetattrV3;
+
+/* Deprecated */
+
+typedef
+#include "vmware_pack_begin.h"
+struct HgfsReplySetattr {
+   HgfsReply header;
+}
+#include "vmware_pack_end.h"
+HgfsReplySetattr;
+
+
+/* Version 2 of HgfsReplySetattr */
+
+typedef
+#include "vmware_pack_begin.h"
+struct HgfsReplySetattrV2 {
+   HgfsReply header;
+}
+#include "vmware_pack_end.h"
+HgfsReplySetattrV2;
+
+typedef
+#include "vmware_pack_begin.h"
+struct HgfsReplySetattrV3 {
+   uint64 reserved;          /* Reserved for future use */
+}
+#include "vmware_pack_end.h"
+HgfsReplySetattrV3;
+
+
+/* Deprecated */
+
+typedef
+#include "vmware_pack_begin.h"
+struct HgfsRequestCreateDir {
+   HgfsRequest header;
+   HgfsPermissions permissions;
+   HgfsFileName fileName;
+}
+#include "vmware_pack_end.h"
+HgfsRequestCreateDir;
+
+
+/* Version 2 of HgfsRequestCreateDir */
+
+typedef
+#include "vmware_pack_begin.h"
+struct HgfsRequestCreateDirV2 {
+   HgfsRequest header;
+   HgfsCreateDirValid mask;
+   HgfsPermissions specialPerms;
+   HgfsPermissions ownerPerms;
+   HgfsPermissions groupPerms;
+   HgfsPermissions otherPerms;
+   HgfsFileName fileName;
+}
+#include "vmware_pack_end.h"
+HgfsRequestCreateDirV2;
+
+
+/* Version 3 of HgfsRequestCreateDir */
+
+typedef
+#include "vmware_pack_begin.h"
+struct HgfsRequestCreateDirV3 {
+   HgfsCreateDirValid mask;
+   HgfsPermissions specialPerms;
+   HgfsPermissions ownerPerms;
+   HgfsPermissions groupPerms;
+   HgfsPermissions otherPerms;
+   uint64 reserved;              /* Reserved for future use */
+   HgfsFileNameV3 fileName;
+}
+#include "vmware_pack_end.h"
+HgfsRequestCreateDirV3;
+
+
+/* Deprecated */
+
+typedef
+#include "vmware_pack_begin.h"
+struct HgfsReplyCreateDir {
+   HgfsReply header;
+}
+#include "vmware_pack_end.h"
+HgfsReplyCreateDir;
+
+
+/* Version 2 of HgfsReplyCreateDir */
+
+typedef
+#include "vmware_pack_begin.h"
+struct HgfsReplyCreateDirV2 {
+   HgfsReply header;
+}
+#include "vmware_pack_end.h"
+HgfsReplyCreateDirV2;
+
+
+/* Version 3 of HgfsReplyCreateDir */
+
+typedef
+#include "vmware_pack_begin.h"
+struct HgfsReplyCreateDirV3 {
+   uint64 reserved;              /* Reserved for future use */
+}
+#include "vmware_pack_end.h"
+HgfsReplyCreateDirV3;
+
+
+/* Deprecated */
+
+typedef
+#include "vmware_pack_begin.h"
+struct HgfsRequestDelete {
+   HgfsRequest header;
+   HgfsFileName fileName;
+}
+#include "vmware_pack_end.h"
+HgfsRequestDelete;
+
+
+/* Version 2 of HgfsRequestDelete */
+
+typedef
+#include "vmware_pack_begin.h"
+struct HgfsRequestDeleteV2 {
+   HgfsRequest header;
+   HgfsDeleteHint hints;
+   HgfsHandle file;        /* Opaque file ID used by the server. */
+   HgfsFileName fileName;  /* Name used if the file is HGFS_HANDLE_INVALID */
+}
+#include "vmware_pack_end.h"
+HgfsRequestDeleteV2;
+
+
+/* Version 3 of HgfsRequestDelete */
+
+typedef
+#include "vmware_pack_begin.h"
+struct HgfsRequestDeleteV3 {
+   HgfsDeleteHint hints;
+   uint64 reserved;              /* Reserved for future use */
+   HgfsFileNameV3 fileName;      /* Name used if the file is HGFS_HANDLE_INVALID */
+}
+#include "vmware_pack_end.h"
+HgfsRequestDeleteV3;
+
+
+/* Deprecated */
+
+typedef
+#include "vmware_pack_begin.h"
+struct HgfsReplyDelete {
+   HgfsReply header;
+}
+#include "vmware_pack_end.h"
+HgfsReplyDelete;
+
+/* Version 2 of HgfsReplyDelete */
+
+typedef
+#include "vmware_pack_begin.h"
+struct HgfsReplyDeleteV2 {
+   HgfsReply header;
+}
+#include "vmware_pack_end.h"
+HgfsReplyDeleteV2;
+
+
+/* Version 2 of HgfsReplyDelete */
+
+typedef
+#include "vmware_pack_begin.h"
+struct HgfsReplyDeleteV3 {
+   uint64 reserved;              /* Reserved for future use */
+}
+#include "vmware_pack_end.h"
+HgfsReplyDeleteV3;
+
+
+/*
+ * The size of the HgfsFileName struct is variable depending on the
+ * length of the name, so you can't use request->newName to get the
+ * actual address of the new name, because where it starts is
+ * dependant on how long the oldName is. To get the address of
+ * newName, use this:
+ *
+ *          &oldName + sizeof(HgfsFileName) + oldName.length
+ */
+
+typedef
+#include "vmware_pack_begin.h"
+struct HgfsRequestRename {
+   HgfsRequest header;
+   HgfsFileName oldName;
+   HgfsFileName newName;
+}
+#include "vmware_pack_end.h"
+HgfsRequestRename;
+
+
+typedef
+#include "vmware_pack_begin.h"
+struct HgfsReplyRename {
+   HgfsReply header;
+}
+#include "vmware_pack_end.h"
+HgfsReplyRename;
+
+
+typedef
+#include "vmware_pack_begin.h"
+struct HgfsRequestRenameV2 {
+   HgfsRequest header;
+   HgfsRenameHint hints;
+   HgfsHandle srcFile;           /* Opaque file ID to "old name" used by the server. */
+   HgfsHandle targetFile;        /* Opaque file ID to "old name" used by the server. */
+   HgfsFileName oldName;
+   HgfsFileName newName;
+}
+#include "vmware_pack_end.h"
+HgfsRequestRenameV2;
+
+
+typedef
+#include "vmware_pack_begin.h"
+struct HgfsReplyRenameV2 {
+   HgfsReply header;
+}
+#include "vmware_pack_end.h"
+HgfsReplyRenameV2;
+
+
+/* HgfsRequestRename and HgfsReplyRename for v3. */
+
+typedef
+#include "vmware_pack_begin.h"
+struct HgfsRequestRenameV3 {
+   HgfsRenameHint hints;
+   uint64 reserved;              /* Reserved for future use */
+   HgfsFileNameV3 oldName;
+   HgfsFileNameV3 newName;
+}
+#include "vmware_pack_end.h"
+HgfsRequestRenameV3;
+
+
+typedef
+#include "vmware_pack_begin.h"
+struct HgfsReplyRenameV3 {
+   uint64 reserved;              /* Reserved for future use */
+}
+#include "vmware_pack_end.h"
+HgfsReplyRenameV3;
+
+
+typedef
+#include "vmware_pack_begin.h"
+struct HgfsRequestQueryVolume {
+   HgfsRequest header;
+   HgfsFileName fileName;
+}
+#include "vmware_pack_end.h"
+HgfsRequestQueryVolume;
+
+
+typedef
+#include "vmware_pack_begin.h"
+struct HgfsReplyQueryVolume {
+   HgfsReply header;
+   uint64 freeBytes;
+   uint64 totalBytes;
+}
+#include "vmware_pack_end.h"
+HgfsReplyQueryVolume;
+
+
+/* HgfsRequestQueryVolume and HgfsReplyQueryVolume for v3. */
+
+typedef
+#include "vmware_pack_begin.h"
+struct HgfsRequestQueryVolumeV3 {
+   uint64 reserved;              /* Reserved for future use */
+   HgfsFileNameV3 fileName;
+}
+#include "vmware_pack_end.h"
+HgfsRequestQueryVolumeV3;
+
+
+typedef
+#include "vmware_pack_begin.h"
+struct HgfsReplyQueryVolumeV3 {
+   uint64 freeBytes;
+   uint64 totalBytes;
+   uint64 reserved;              /* Reserved for future use */
+}
+#include "vmware_pack_end.h"
+HgfsReplyQueryVolumeV3;
+
+
+
+/* New operations for Version 2 */
+
+typedef
+#include "vmware_pack_begin.h"
+struct HgfsRequestServerLockChange {
+   HgfsRequest header;
+   HgfsHandle file;
+   HgfsServerLock newServerLock;
+}
+#include "vmware_pack_end.h"
+HgfsRequestServerLockChange;
+
+
+typedef
+#include "vmware_pack_begin.h"
+struct HgfsReplyServerLockChange {
+   HgfsReply header;
+   HgfsServerLock serverLock;
+}
+#include "vmware_pack_end.h"
+HgfsReplyServerLockChange;
+
+
+typedef
+#include "vmware_pack_begin.h"
+struct HgfsRequestSymlinkCreate {
+   HgfsRequest header;
+   HgfsFileName symlinkName;
+
+   /* This filename is in "CPNameLite" format. See CPNameLite.c for details. */
+   HgfsFileName targetName;
+}
+#include "vmware_pack_end.h"
+HgfsRequestSymlinkCreate;
+
+
+typedef
+#include "vmware_pack_begin.h"
+struct HgfsReplySymlinkCreate {
+   HgfsReply header;
+}
+#include "vmware_pack_end.h"
+HgfsReplySymlinkCreate;
+
+
+/* HgfsRequestSymlinkCreate and HgfsReplySymlinkCreate for v3. */
+
+typedef
+#include "vmware_pack_begin.h"
+struct HgfsRequestSymlinkCreateV3 {
+   uint64 reserved;              /* Reserved for future use */
+   HgfsFileNameV3 symlinkName;
+
+   /* This filename is in "CPNameLite" format. See CPNameLite.c for details. */
+   HgfsFileNameV3 targetName;
+}
+#include "vmware_pack_end.h"
+HgfsRequestSymlinkCreateV3;
+
+
+typedef
+#include "vmware_pack_begin.h"
+struct HgfsReplySymlinkCreateV3 {
+   uint64 reserved;              /* Reserved for future use */
+}
+#include "vmware_pack_end.h"
+HgfsReplySymlinkCreateV3;
+
+
+#endif /* _HGFS_PROTO_H_ */
--- kernel/linux-2.6.26.3/fs/vmhgfs/hgfsUtil.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/hgfsUtil.c	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,265 @@
+/*********************************************************
+ * Copyright (C) 1998 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * hgfsUtil.c --
+ *
+ *    Utility routines used by both HGFS servers and clients, such as
+ *    conversion routines between Unix time and Windows NT time.
+ *    The former is in units of seconds since midnight 1/1/1970, while the
+ *    latter is in units of 100 nanoseconds since midnight 1/1/1601.
+ */
+
+/*
+ * hgfsUtil.h must be included before vm_basic_asm.h, as hgfsUtil.h
+ * includes kernel headers on Linux.  That is, vmware.h must come after
+ * hgfsUtil.h.
+ */
+#include "hgfsUtil.h"
+#include "vmware.h"
+#include "vm_basic_asm.h"
+
+#ifndef _WIN32
+/*
+ * NT time of the Unix epoch:
+ * midnight January 1, 1970 UTC
+ */
+#define UNIX_EPOCH ((((uint64)369 * 365) + 89) * 24 * 3600 * 10000000)
+
+/*
+ * NT time of the Unix 32 bit signed time_t wraparound:
+ * 03:14:07 January 19, 2038 UTC
+ */
+#define UNIX_S32_MAX (UNIX_EPOCH + (uint64)0x80000000 * 10000000)
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * HgfsConvertToNtTime --
+ *
+ *    Convert from Unix time to Windows NT time.
+ *
+ * Results:
+ *    The time in Windows NT format.
+ *
+ * Side effects:
+ *    None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+uint64
+HgfsConvertToNtTime(time_t unixTime, // IN: Time in Unix format (seconds)
+		    long   nsec)     // IN: nanoseconds
+{
+   return (uint64)unixTime * 10000000 + nsec / 100 + UNIX_EPOCH;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * HgfsConvertFromNtTimeNsec --
+ *
+ *    Convert from Windows NT time to Unix time. If NT time is outside of
+ *    UNIX time range (1970-2038), returned time is nearest time valid in
+ *    UNIX.
+ *
+ * Results:
+ *    0        on success
+ *    non-zero if NT time is outside of valid range for UNIX
+ *
+ * Side effects:
+ *    None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+int
+HgfsConvertFromNtTimeNsec(struct timespec *unixTime, // OUT: Time in UNIX format
+			  uint64 ntTime) // IN: Time in Windows NT format
+{
+#ifndef VM_X86_64
+   uint32 sec;
+   uint32 nsec;
+
+   ASSERT(unixTime);
+   /* We assume that time_t is 32bit */
+   ASSERT_ON_COMPILE(sizeof (unixTime->tv_sec) == 4);
+
+   /* Cap NT time values that are outside of Unix time's range */
+
+   if (ntTime >= UNIX_S32_MAX) {
+      unixTime->tv_sec = 0x7FFFFFFF;
+      unixTime->tv_nsec = 0;
+      return 1;
+   }
+#else
+   ASSERT(unixTime);
+#endif
+
+   if (ntTime < UNIX_EPOCH) {
+      unixTime->tv_sec = 0;
+      unixTime->tv_nsec = 0;
+      return -1;
+   }
+
+#ifndef VM_X86_64
+   Div643232(ntTime - UNIX_EPOCH, 10000000, &sec, &nsec);
+   unixTime->tv_sec = sec;
+   unixTime->tv_nsec = nsec * 100;
+#else
+   unixTime->tv_sec = (ntTime - UNIX_EPOCH) / 10000000;
+   unixTime->tv_nsec = ((ntTime - UNIX_EPOCH) % 10000000) * 100;
+#endif
+
+   return 0;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * HgfsConvertFromNtTime --
+ *
+ *    Convert from Windows NT time to Unix time.
+ *
+ * Results:
+ *    0       on success
+ *    nonzero if time is not representable on UNIX
+ *
+ * Side effects:
+ *    None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+int
+HgfsConvertFromNtTime(time_t *unixTime, // OUT: Time in UNIX format
+		      uint64 ntTime) // IN: Time in Windows NT format
+{
+   struct timespec tm;
+   int ret;
+
+   ret = HgfsConvertFromNtTimeNsec(&tm, ntTime);
+   *unixTime = tm.tv_sec;
+   return ret;
+}
+#endif /* !def(_WIN32) */
+
+
+#undef UNIX_EPOCH
+#undef UNIX_S32_MAX
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * HgfsConvertFromInternalStatus --
+ *
+ *    This function converts between a platform-specific status code and a
+ *    cross-platform status code to be sent down the wire.
+ *
+ * Results:
+ *    Converted status code.
+ *
+ * Side effects:
+ *    None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+#ifdef _WIN32
+HgfsStatus
+HgfsConvertFromInternalStatus(HgfsInternalStatus status) // IN
+{
+   switch(status) {
+   case ERROR_SUCCESS:
+      return HGFS_STATUS_SUCCESS;
+   case ERROR_FILE_NOT_FOUND:
+   case ERROR_PATH_NOT_FOUND:
+      return HGFS_STATUS_NO_SUCH_FILE_OR_DIR;
+   case ERROR_INVALID_HANDLE:
+      return HGFS_STATUS_INVALID_HANDLE;
+   case ERROR_ALREADY_EXISTS:
+   case ERROR_FILE_EXISTS:
+      return HGFS_STATUS_FILE_EXISTS;
+   case ERROR_DIR_NOT_EMPTY:
+      return HGFS_STATUS_DIR_NOT_EMPTY;
+   case RPC_S_PROTOCOL_ERROR:
+      return HGFS_STATUS_PROTOCOL_ERROR;
+   case ERROR_ACCESS_DENIED:
+      return HGFS_STATUS_ACCESS_DENIED;
+   case ERROR_INVALID_NAME:
+      return HGFS_STATUS_INVALID_NAME;
+   case ERROR_SHARING_VIOLATION:
+      return HGFS_STATUS_SHARING_VIOLATION;
+   case ERROR_DISK_FULL:
+   case ERROR_HANDLE_DISK_FULL:
+      return HGFS_STATUS_NO_SPACE;
+   case ERROR_NOT_SUPPORTED:
+      return HGFS_STATUS_OPERATION_NOT_SUPPORTED;
+   case ERROR_INVALID_PARAMETER:
+      return HGFS_STATUS_INVALID_PARAMETER;
+   case HGFS_INTERNAL_STATUS_ERROR:
+   default:
+      return HGFS_STATUS_GENERIC_ERROR;
+   }
+}
+
+#else /* Win32 */
+
+HgfsStatus
+HgfsConvertFromInternalStatus(HgfsInternalStatus status) // IN
+{
+   switch(status) {
+   case 0:
+      return HGFS_STATUS_SUCCESS;
+   case ENOENT:
+      return HGFS_STATUS_NO_SUCH_FILE_OR_DIR;
+   case EBADF:
+      return HGFS_STATUS_INVALID_HANDLE;
+   case EPERM:
+      return HGFS_STATUS_OPERATION_NOT_PERMITTED;
+   case EEXIST:
+      return HGFS_STATUS_FILE_EXISTS;
+   case ENOTDIR:
+      return HGFS_STATUS_NOT_DIRECTORY;
+   case ENOTEMPTY:
+      return HGFS_STATUS_DIR_NOT_EMPTY;
+   case EPROTO:
+      return HGFS_STATUS_PROTOCOL_ERROR;
+   case EACCES:
+      return HGFS_STATUS_ACCESS_DENIED;
+   case EINVAL:
+      return HGFS_STATUS_INVALID_NAME;
+   case ENOSPC:
+      return HGFS_STATUS_NO_SPACE;
+   case EOPNOTSUPP:
+      return HGFS_STATUS_OPERATION_NOT_SUPPORTED;
+   case ENAMETOOLONG:
+      return HGFS_STATUS_NAME_TOO_LONG;
+   case EPARAMETERNOTSUPPORTED:
+      return HGFS_STATUS_INVALID_PARAMETER;
+   case HGFS_INTERNAL_STATUS_ERROR:
+   default:
+      return HGFS_STATUS_GENERIC_ERROR;
+   }
+}
+#endif
--- kernel/linux-2.6.26.3/fs/vmhgfs/hgfsUtil.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/hgfsUtil.h	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,130 @@
+/*********************************************************
+ * Copyright (C) 1998 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+
+/*
+ * hgfsUtil.h --
+ *
+ *    Utility functions and macros used by hgfs.
+ */
+
+
+#ifndef _HGFSUTIL_H_
+#   define _HGFSUTIL_H_
+
+#   if defined(__linux__) && defined(__KERNEL__)
+#      include "driver-config.h"
+#      include <linux/time.h> // for time_t and timespec
+    /* Include time.h in userspace code, but not in Solaris kernel code. */
+#   elif defined(__FreeBSD__) && defined(_KERNEL)
+    /* Do nothing. */
+#   elif defined(__APPLE__) && defined(KERNEL)
+#      include <sys/time.h>
+#   else
+#      include <time.h>
+#   endif
+#   include "vm_basic_types.h"
+#   if !defined(_STRUCT_TIMESPEC) &&   \
+       !defined(_TIMESPEC_DECLARED) && \
+       !defined(__timespec_defined) && \
+       !defined(sun) && \
+       !defined(__FreeBSD__) && \
+       !__APPLE__ && \
+       !defined(_WIN32)
+struct timespec {
+   time_t tv_sec;
+   long   tv_nsec;
+};
+#   endif
+
+#   include "hgfs.h"
+
+/* Cross-platform representation of a platform-specific error code. */
+#ifndef _WIN32
+#   if defined(__KERNEL__) || defined(_KERNEL) || defined(KERNEL)
+#      if defined(__linux__)
+#         include <linux/errno.h>
+#      elif defined(sun) || defined(__FreeBSD__) || defined(__APPLE__)
+#         include <sys/errno.h>
+#      endif
+#   else
+#      include <errno.h>
+#   endif
+    typedef int HgfsInternalStatus;
+#else
+#   include <windows.h>
+    typedef DWORD HgfsInternalStatus;
+#endif
+
+/*
+ * Unfortunately, we need a catch-all "generic error" to use with
+ * HgfsInternalStatus, because there are times when cross-platform code needs
+ * to return its own errors along with errors from platform specific code.
+ *
+ * Using -1 should be safe because we expect our platforms to use zero as
+ * success and a positive range of numbers as error values.
+ */
+#define HGFS_INTERNAL_STATUS_ERROR (-1)
+
+#ifndef _WIN32
+/*
+ * This error code is used to notify the client that some of the parameters passed
+ * (e.g. file handles) are not supported. Clients are expected to correct
+ * the parameter (e.g. pass file name instead) and retry.
+ *
+ * Note that this error code is artificially made up and in future may conflict
+ * with an "official" error code when added.
+ */
+#define EPARAMETERNOTSUPPORTED  (MAX_INT32 - 1)
+#endif
+
+/*
+ * FreeBSD (pre-6.0) does not define EPROTO, so we'll define our own error code.
+ */
+#if defined(__FreeBSD__) && !defined(EPROTO)
+#define EPROTO (ELAST + 1)
+#endif
+
+#define HGFS_NAME_BUFFER_SIZE(request) (HGFS_PACKET_MAX - (sizeof *request - 1))
+#define HGFS_NAME_BUFFER_SIZET(sizet) (HGFS_PACKET_MAX - ((sizet) - 1))
+
+#ifndef _WIN32
+/*
+ * Routines for converting between Win NT and unix time formats. The
+ * hgfs attributes use the NT time formats, so the linux driver and
+ * server have to convert back and forth. [bac]
+ */
+
+uint64 HgfsConvertToNtTime(time_t unixTime, // IN
+			   long   nsec);    // IN
+static INLINE uint64
+HgfsConvertTimeSpecToNtTime(const struct timespec *unixTime) // IN
+{
+   return HgfsConvertToNtTime(unixTime->tv_sec, unixTime->tv_nsec);
+}
+
+int HgfsConvertFromNtTime(time_t * unixTime, // OUT
+			  uint64 ntTime);    // IN
+int HgfsConvertFromNtTimeNsec(struct timespec *unixTime, // OUT
+                              uint64 ntTime);            // IN
+#endif /* !def(_WIN32) */
+
+HgfsStatus HgfsConvertFromInternalStatus(HgfsInternalStatus status); // IN
+
+#endif /* _HGFSUTIL_H_ */
+
--- kernel/linux-2.6.26.3/fs/vmhgfs/includeCheck.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/includeCheck.h	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,132 @@
+/*********************************************************
+ * Copyright (C) 1998 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * includeCheck.h --
+ *
+ *	Restrict include file use.
+ *
+ * In every .h file, define one or more of these
+ *
+ *	INCLUDE_ALLOW_VMX 
+ *	INCLUDE_ALLOW_USERLEVEL 
+ *	INCLUDE_ALLOW_VMMEXT
+ *	INCLUDE_ALLOW_VMCORE
+ *	INCLUDE_ALLOW_MODULE
+ *      INCLUDE_ALLOW_VMNIXMOD 
+ *	INCLUDE_ALLOW_VMKERNEL 
+ *	INCLUDE_ALLOW_DISTRIBUTE
+ *	INCLUDE_ALLOW_VMK_MODULE
+ *      INCLUDE_ALLOW_VMKDRIVERS
+ *      INCLUDE_ALLOW_VMIROM
+ *
+ * Then include this file.
+ *
+ * Any file that has INCLUDE_ALLOW_DISTRIBUTE defined will potentially
+ * be distributed in source form along with GPLed code.  Ensure
+ * that this is acceptable.
+ */
+
+
+/*
+ * Declare a VMCORE-only variable to help classify object
+ * files.  The variable goes in the common block and does
+ * not create multiple definition link-time conflicts.
+ */
+
+#if defined VMCORE && defined VMX86_DEVEL && defined VMX86_DEBUG && \
+    defined linux && !defined MODULE && \
+    !defined COMPILED_WITH_VMCORE
+#define COMPILED_WITH_VMCORE compiled_with_vmcore
+#ifdef ASM
+        .comm   compiled_with_vmcore, 0
+#else
+        asm(".comm compiled_with_vmcore, 0");
+#endif /* ASM */
+#endif
+
+
+#if defined VMCORE && \
+    !(defined VMX86_VMX || defined VMM || \
+      defined MONITOR_APP || defined VMMON)
+#error "Makefile problem: VMCORE without VMX86_VMX or \
+        VMM or MONITOR_APP or MODULE."
+#endif
+
+#if defined VMCORE && !defined INCLUDE_ALLOW_VMCORE
+#error "The surrounding include file is not allowed in vmcore."
+#endif
+#undef INCLUDE_ALLOW_VMCORE
+
+#if defined VMX86_VMX && !defined VMCORE && \
+    !(defined INCLUDE_ALLOW_VMX || defined INCLUDE_ALLOW_USERLEVEL)
+#error "The surrounding include file is not allowed in the VMX."
+#endif
+#undef INCLUDE_ALLOW_VMX
+
+#if defined USERLEVEL && !defined VMX86_VMX && !defined VMCORE && \
+    !defined INCLUDE_ALLOW_USERLEVEL
+#error "The surrounding include file is not allowed at userlevel."
+#endif
+#undef INCLUDE_ALLOW_USERLEVEL
+
+#if defined VMM && !defined VMCORE && \
+    !defined INCLUDE_ALLOW_VMMEXT
+#error "The surrounding include file is not allowed in the monitor."
+#endif
+#undef INCLUDE_ALLOW_VMMEXT
+
+#if defined MODULE && !defined VMKERNEL_MODULE && !defined VMNIXMOD && \
+    !defined VMMON && !defined INCLUDE_ALLOW_MODULE
+#error "The surrounding include file is not allowed in driver modules."
+#endif
+#undef INCLUDE_ALLOW_MODULE
+
+#if defined VMMON && !defined INCLUDE_ALLOW_VMMON
+#error "The surrounding include file is not allowed in vmmon."
+#endif
+#undef INCLUDE_ALLOW_VMMON
+
+#if defined VMKERNEL && !defined INCLUDE_ALLOW_VMKERNEL
+#error "The surrounding include file is not allowed in the vmkernel."
+#endif
+#undef INCLUDE_ALLOW_VMKERNEL
+
+#if defined GPLED_CODE && !defined INCLUDE_ALLOW_DISTRIBUTE
+#error "The surrounding include file is not allowed in GPL code."
+#endif
+#undef INCLUDE_ALLOW_DISTRIBUTE
+
+#if defined VMKERNEL_MODULE && !defined VMKERNEL && \
+    !defined INCLUDE_ALLOW_VMK_MODULE && !defined INCLUDE_ALLOW_VMKDRIVERS
+#error "The surrounding include file is not allowed in vmkernel modules."
+#endif
+#undef INCLUDE_ALLOW_VMK_MODULE
+#undef INCLUDE_ALLOW_VMKDRIVERS
+
+#if defined VMNIXMOD && !defined INCLUDE_ALLOW_VMNIXMOD
+#ifndef VMNIXMOD_VM
+#error "The surrounding include file is not allowed in vmnixmod."
+#endif
+#endif
+#undef INCLUDE_ALLOW_VMNIXMOD
+
+#if defined VMIROM && ! defined INCLUDE_ALLOW_VMIROM
+#error "The surrounding include file is not allowed in vmirom."
+#endif
+#undef INCLUDE_ALLOW_VMIROM
--- kernel/linux-2.6.26.3/fs/vmhgfs/inode.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/inode.c	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,2001 @@
+/*********************************************************
+ * Copyright (C) 2006 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * inode.c --
+ *
+ * Inode operations for the filesystem portion of the vmhgfs driver.
+ */
+
+/* Must come before any kernel header file. */
+#include "driver-config.h"
+
+#include <linux/errno.h>
+#include <linux/pagemap.h>
+
+#include "compat_fs.h"
+#include "compat_highmem.h"
+#include "compat_kernel.h"
+#include "compat_mm.h"
+#include "compat_page-flags.h"
+#include "compat_spinlock.h"
+#include "compat_version.h"
+
+#include "cpName.h"
+#include "cpNameLite.h"
+#include "hgfsEscape.h"
+#include "hgfsProto.h"
+#include "hgfsUtil.h"
+#include "inode.h"
+#include "module.h"
+#include "request.h"
+#include "fsutil.h"
+#include "vm_assert.h"
+
+/*
+ * The inode_operations structure changed in 2.5.18:
+ * before:
+ * . 'getattr' was defined but unused
+ * . 'revalidate' was defined and used
+ * after:
+ * 1) 'getattr' changed and became used
+ * 2) 'revalidate' was removed
+ *
+ * Note: Mandrake backported 1) but not 2) starting with 2.4.8-26mdk
+ *
+ *   --hpreg
+ */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 5, 18)
+#   define HGFS_GETATTR_ONLY 1
+#else
+#   undef HGFS_GETATTR_ONLY
+#endif
+
+
+/* Private functions. */
+static int HgfsDelete(struct inode *dir,
+                      struct dentry *dentry,
+                      HgfsOp op);
+static int HgfsPackSetattrRequest(struct iattr *iattr,
+                                  struct dentry *dentry,
+                                  Bool allowHandleReuse,
+                                  HgfsOp opUsed,
+                                  HgfsReq *req,
+                                  Bool *changed);
+static int HgfsPackCreateDirRequest(struct dentry *dentry,
+                                    int mode,
+				    HgfsOp opUsed,
+                                    HgfsReq *req);
+static int HgfsTruncatePages(struct inode *inode,
+                             loff_t newSize);
+static int HgfsPackSymlinkCreateRequest(struct dentry *dentry,
+                                        const char *symname,
+                                        HgfsOp opUsed,
+                                        HgfsReq *req);
+
+/* HGFS inode operations. */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 5, 75)
+static int HgfsCreate(struct inode *dir,
+                      struct dentry *dentry,
+                      int mode,
+                      struct nameidata *nd);
+static struct dentry *HgfsLookup(struct inode *dir,
+                                 struct dentry *dentry,
+                                 struct nameidata *nd);
+#else
+static int HgfsCreate(struct inode *dir,
+                      struct dentry *dentry,
+                      int mode);
+static struct dentry *HgfsLookup(struct inode *dir,
+                                 struct dentry *dentry);
+#endif
+static int HgfsMkdir(struct inode *dir,
+                     struct dentry *dentry,
+                     int mode);
+static int HgfsRmdir(struct inode *dir,
+                     struct dentry *dentry);
+static int HgfsUnlink(struct inode *dir,
+                      struct dentry *dentry);
+static int HgfsRename(struct inode *oldDir,
+                      struct dentry *oldDentry,
+                      struct inode *newDir,
+                      struct dentry *newDentry);
+static int HgfsSymlink(struct inode *dir,
+                       struct dentry *dentry,
+                       const char *symname);
+#ifdef HGFS_GETATTR_ONLY
+static int HgfsGetattr(struct vfsmount *mnt,
+                       struct dentry *dentry,
+                       struct kstat *stat);
+#endif
+
+#define HGFS_CREATE_DIR_MASK (HGFS_CREATE_DIR_VALID_FILE_NAME | \
+                              HGFS_CREATE_DIR_VALID_SPECIAL_PERMS | \
+                              HGFS_CREATE_DIR_VALID_OWNER_PERMS | \
+                              HGFS_CREATE_DIR_VALID_GROUP_PERMS | \
+                              HGFS_CREATE_DIR_VALID_OTHER_PERMS)
+
+/* HGFS inode operations structure for directories. */
+struct inode_operations HgfsDirInodeOperations = {
+   /* Optional */
+   .create      = HgfsCreate,
+
+   /* Optional */
+   .mkdir       = HgfsMkdir,
+
+   .lookup      = HgfsLookup,
+   .rmdir       = HgfsRmdir,
+   .unlink      = HgfsUnlink,
+   .rename      = HgfsRename,
+   .symlink     = HgfsSymlink,
+   .setattr     = HgfsSetattr,
+
+#ifdef HGFS_GETATTR_ONLY
+   /* Optional */
+   .getattr     = HgfsGetattr,
+#else
+   /* Optional */
+   .revalidate  = HgfsRevalidate,
+#endif
+};
+
+/* HGFS inode operations structure for files. */
+struct inode_operations HgfsFileInodeOperations = {
+   .setattr     = HgfsSetattr,
+
+#ifdef HGFS_GETATTR_ONLY
+   /* Optional */
+   .getattr     = HgfsGetattr,
+#else
+   /* Optional */
+   .revalidate  = HgfsRevalidate,
+#endif
+};
+
+/*
+ * Private functions implementations.
+ */
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * HgfsDelete --
+ *
+ *    Handle both unlink and rmdir requests.
+ *
+ * Results:
+ *    Returns zero on success, or a negative error on failure.
+ *
+ * Side effects:
+ *    None
+ *
+ *----------------------------------------------------------------------
+ */
+
+static int
+HgfsDelete(struct inode *dir,      // IN: Parent dir of file/dir to delete
+           struct dentry *dentry,  // IN: Dentry of file/dir to delete
+           HgfsOp op)              // IN: Opcode for file type (file or dir)
+{
+   HgfsReq *req = NULL;
+   int result = 0;
+   Bool secondAttempt = FALSE;
+   HgfsStatus replyStatus;
+   char *fileName = NULL;
+   uint32 *fileNameLength;
+   uint32 reqSize;
+   HgfsOp opUsed;
+
+   ASSERT(dir);
+   ASSERT(dir->i_sb);
+   ASSERT(dentry);
+   ASSERT(dentry->d_inode);
+
+   if (!dir || !dentry) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsDelete: NULL input\n"));
+      result = -EFAULT;
+      goto out;
+   }
+
+   if ((op != HGFS_OP_DELETE_FILE) &&
+       (op != HGFS_OP_DELETE_DIR)) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsDelete: Invalid opcode\n"));
+      result = -EINVAL;
+      goto out;
+   }
+
+   req = HgfsGetNewRequest();
+   if (!req) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsDelete: out of memory while "
+              "getting new request\n"));
+      result = -ENOMEM;
+      goto out;
+   }
+
+  retry:
+   if (op == HGFS_OP_DELETE_FILE) {
+      opUsed = atomic_read(&hgfsVersionDeleteFile);
+   } else {
+      opUsed = atomic_read(&hgfsVersionDeleteDir);
+   }
+
+   if (opUsed == HGFS_OP_DELETE_FILE_V3 ||
+       opUsed == HGFS_OP_DELETE_DIR_V3) {
+      HgfsRequestDeleteV3 *request;
+      HgfsRequest *header;
+
+      header = (HgfsRequest *)(HGFS_REQ_PAYLOAD(req));
+      header->id = req->id;
+      header->op = opUsed;
+
+      request = (HgfsRequestDeleteV3 *)(HGFS_REQ_PAYLOAD_V3(req));
+      request->hints = 0;
+      fileName = request->fileName.name;
+      fileNameLength = &request->fileName.length;
+      request->fileName.fid = HGFS_INVALID_HANDLE;
+      request->fileName.flags = 0;
+      request->fileName.caseType = HGFS_FILE_NAME_DEFAULT_CASE;
+      request->reserved = 0;
+      reqSize = HGFS_REQ_PAYLOAD_SIZE_V3(request);
+   } else {
+      HgfsRequestDelete *request;
+
+      request = (HgfsRequestDelete *)(HGFS_REQ_PAYLOAD(req));
+      /* Fill out the request packet. */
+      request->header.id = req->id;
+      request->header.op = opUsed;
+      fileName = request->fileName.name;
+      fileNameLength = &request->fileName.length;
+      reqSize = sizeof *request;
+   }
+
+   /* Build full name to send to server. */
+   if (HgfsBuildPath(fileName, HGFS_NAME_BUFFER_SIZET(reqSize),
+                     dentry) < 0) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsDelete: build path failed\n"));
+      result = -EINVAL;
+      goto out;
+   }
+   LOG(4, (KERN_DEBUG "VMware hgfs: HgfsDelete: deleting \"%s\", opUsed %u\n",
+           fileName, opUsed));
+
+   /* Convert to CP name. */
+   result = CPName_ConvertTo(fileName,
+                             HGFS_NAME_BUFFER_SIZET(reqSize),
+                             fileName);
+   if (result < 0) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsDelete: CP conversion failed\n"));
+      result = -EINVAL;
+      goto out;
+   }
+
+   /* Unescape the CP name. */
+   result = HgfsEscape_Undo(fileName, result);
+   *fileNameLength = result;
+   req->payloadSize = reqSize + result;
+
+   result = HgfsSendRequest(req);
+   if (result == 0) {
+      LOG(6, (KERN_DEBUG "VMware hgfs: HgfsDelete: got reply\n"));
+      replyStatus = HgfsReplyStatus(req);
+      result = HgfsStatusConvertToLinux(replyStatus);
+
+      switch (result) {
+      case 0:
+         /*
+          * Since we deleted the file, decrement its hard link count. As
+          * we don't support hard links, this has the effect of making the
+          * link count 0, which means that when the last reference to the
+          * inode is dropped, the inode will be freed instead of moved to
+          * the unused list.
+          *
+          * Also update the mtime/ctime of the parent directory, and the
+          * ctime of the deleted file.
+          */
+         compat_drop_nlink(dentry->d_inode);
+         dentry->d_inode->i_ctime = dir->i_ctime = dir->i_mtime =
+            CURRENT_TIME;
+         break;
+
+      case -EACCES:
+      case -EPERM:
+         /*
+          * It's possible that we're talking to a Windows server with
+          * a file marked read-only. Let's try again, after removing
+          * the read-only bit from the file.
+          *
+          * XXX: I think old servers will send -EPERM here. Is this entirely
+          * safe?
+          */
+         if (!secondAttempt) {
+            struct iattr enableWrite;
+            secondAttempt = TRUE;
+
+            LOG(4, (KERN_DEBUG "VMware hgfs: HgfsDelete: access denied, "
+                    "attempting to work around read-only bit\n"));
+            enableWrite.ia_mode = (dentry->d_inode->i_mode | S_IWUSR);
+            enableWrite.ia_valid = ATTR_MODE;
+            result = HgfsSetattr(dentry, &enableWrite);
+            if (result == 0) {
+               LOG(4, (KERN_DEBUG "VMware hgfs: HgfsDelete: file is no "
+                       "longer read-only, retrying delete\n"));
+               goto retry;
+            }
+            LOG(4, (KERN_DEBUG "VMware hgfs: HgfsDelete: failed to remove "
+                    "read-only property\n"));
+         } else {
+            LOG(4, (KERN_DEBUG "VMware hgfs: HgfsDelete: second attempt at "
+                    "delete failed\n"));
+         }
+         break;
+      case -EPROTO:
+         /* Retry with older version(s). Set globally. */
+         if (opUsed == HGFS_OP_DELETE_DIR_V3) {
+            LOG(4, (KERN_DEBUG "VMware hgfs: HgfsDelete: Version 3 not "
+                    "supported. Falling back to version 1.\n"));
+            atomic_set(&hgfsVersionDeleteDir, HGFS_OP_DELETE_DIR);
+            goto retry;
+         } else if (opUsed == HGFS_OP_DELETE_FILE_V3) {
+            LOG(4, (KERN_DEBUG "VMware hgfs: HgfsDelete: Version 3 not "
+                    "supported. Falling back to version 1.\n"));
+            atomic_set(&hgfsVersionDeleteFile, HGFS_OP_DELETE_FILE);
+            goto retry;
+         }
+
+         LOG(4, (KERN_DEBUG "VMware hgfs: HgfsDelete: server "
+                 "returned error: %d\n", result));
+         break;
+      default:
+         break;
+      }
+   } else if (result == -EIO) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsDelete: timed out\n"));
+   } else if (result == -EPROTO) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsDelete: server "
+              "returned error: %d\n", result));
+   } else {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsDelete: unknown error: "
+              "%d\n", result));
+   }
+
+out:
+   HgfsFreeRequest(req);
+   return result;
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * HgfsPackSetattrRequest --
+ *
+ *    Setup the Setattr request, depending on the op version. When possible,
+ *    we will issue the setattr request using an existing open HGFS handle.
+ *
+ * Results:
+ *    Returns zero on success, or negative error on failure.
+ *
+ *    On success, the changed argument is set indicating whether the
+ *    attributes have actually changed.
+ *
+ * Side effects:
+ *    None
+ *
+ *----------------------------------------------------------------------
+ */
+
+static int
+HgfsPackSetattrRequest(struct iattr *iattr,   // IN: Inode attrs to update from
+                       struct dentry *dentry, // IN: File to set attributes of
+                       Bool allowHandleReuse, // IN: Can we use a handle?
+                       HgfsOp opUsed,         // IN: Op to be used
+		       HgfsReq *req,          // IN/OUT: Packet to write into
+                       Bool *changed)         // OUT: Have the attrs changed?
+{
+   HgfsAttrV2 *attrV2;
+   HgfsAttr *attr;
+   HgfsAttrHint *hints;
+   HgfsAttrChanges *update;
+   HgfsHandle handle;
+   char *fileName = NULL;
+   uint32 *fileNameLength = NULL;
+   unsigned int valid;
+   size_t reqBufferSize;
+   size_t reqSize;
+   int result = 0;
+
+   ASSERT(iattr);
+   ASSERT(dentry);
+   ASSERT(req);
+   ASSERT(changed);
+
+   valid = iattr->ia_valid;
+
+   switch (opUsed) {
+   case HGFS_OP_SETATTR_V3: {
+      HgfsRequest *requestHeader;
+      HgfsRequestSetattrV3 *requestV3;
+
+      requestHeader = (HgfsRequest *)(HGFS_REQ_PAYLOAD(req));
+      requestHeader->op = opUsed;
+      requestHeader->id = req->id;
+
+      requestV3 = (HgfsRequestSetattrV3 *)HGFS_REQ_PAYLOAD_V3(req);
+      attrV2 = &requestV3->attr;
+      hints = &requestV3->hints;
+
+      /*
+       * Clear attributes, mask, and hints before touching them.
+       * We can't rely on GetNewRequest() to zero our structures, so
+       * make sure to zero them all here.
+       */
+      memset(attrV2, 0, sizeof *attrV2);
+      memset(hints, 0, sizeof *hints);
+
+      /*
+       * When possible, issue a setattr using an existing handle. This will
+       * give us slightly better performance on a Windows server, and is more
+       * correct regardless. If we don't find a handle, fall back on setattr
+       * by name.
+       *
+       * Changing the size (via truncate) requires write permissions. Changing
+       * the times also requires write permissions on Windows, so we require it
+       * here too. Otherwise, any handle will do.
+       */
+      if (allowHandleReuse && HgfsGetHandle(dentry->d_inode,
+                                            (valid & ATTR_SIZE) ||
+                                            (valid & ATTR_ATIME) ||
+                                            (valid & ATTR_MTIME) ?
+                                            HGFS_OPEN_MODE_WRITE_ONLY + 1 : 0,
+                                            &handle) == 0) {
+         requestV3->fileName.fid = handle;
+         requestV3->fileName.flags = HGFS_FILE_NAME_USE_FILE_DESC;
+         requestV3->fileName.caseType = HGFS_FILE_NAME_DEFAULT_CASE;
+         requestV3->fileName.length = 0;
+         LOG(6, (KERN_DEBUG "VMware hgfs: HgfsPackSetattrRequest: setting "
+                 "attributes of handle %u\n", handle));
+      } else {
+         fileName = requestV3->fileName.name;
+         fileNameLength = &requestV3->fileName.length;
+         requestV3->fileName.caseType = HGFS_FILE_NAME_CASE_SENSITIVE;
+         requestV3->fileName.fid = HGFS_INVALID_HANDLE;
+         requestV3->fileName.flags = 0;
+      }
+      requestV3->reserved = 0;
+      reqSize = HGFS_REQ_PAYLOAD_SIZE_V3(requestV3);
+      reqBufferSize = HGFS_NAME_BUFFER_SIZET(reqSize);
+
+      /*
+       * We only support changing these attributes:
+       * - all mode bits (i.e. all permissions)
+       * - uid/gid
+       * - size
+       * - access/write times
+       */
+
+      if (valid & ATTR_MODE) {
+         attrV2->mask |= HGFS_ATTR_VALID_SPECIAL_PERMS |
+            HGFS_ATTR_VALID_OWNER_PERMS | HGFS_ATTR_VALID_GROUP_PERMS |
+            HGFS_ATTR_VALID_OTHER_PERMS;
+         attrV2->specialPerms = ((iattr->ia_mode &
+                                  (S_ISUID | S_ISGID | S_ISVTX)) >> 9);
+         attrV2->ownerPerms = ((iattr->ia_mode & S_IRWXU) >> 6);
+         attrV2->groupPerms = ((iattr->ia_mode & S_IRWXG) >> 3);
+         attrV2->otherPerms = (iattr->ia_mode & S_IRWXO);
+         *changed = TRUE;
+      }
+
+      if (valid & ATTR_UID) {
+         attrV2->mask |= HGFS_ATTR_VALID_USERID;
+         attrV2->userId = iattr->ia_uid;
+         *changed = TRUE;
+      }
+
+      if (valid & ATTR_GID) {
+         attrV2->mask |= HGFS_ATTR_VALID_GROUPID;
+         attrV2->groupId = iattr->ia_gid;
+         *changed = TRUE;
+      }
+
+      if (valid & ATTR_SIZE) {
+         attrV2->mask |= HGFS_ATTR_VALID_SIZE;
+         attrV2->size = iattr->ia_size;
+         *changed = TRUE;
+      }
+
+      if (valid & ATTR_ATIME) {
+         attrV2->mask |= HGFS_ATTR_VALID_ACCESS_TIME;
+         attrV2->accessTime = HGFS_GET_TIME(iattr->ia_atime);
+         if (valid & ATTR_ATIME_SET) {
+            *hints |= HGFS_ATTR_HINT_SET_ACCESS_TIME;
+         }
+         *changed = TRUE;
+      }
+
+      if (valid & ATTR_MTIME) {
+         attrV2->mask |= HGFS_ATTR_VALID_WRITE_TIME;
+         attrV2->writeTime = HGFS_GET_TIME(iattr->ia_mtime);
+         if (valid & ATTR_MTIME_SET) {
+            *hints |= HGFS_ATTR_HINT_SET_WRITE_TIME;
+         }
+         *changed = TRUE;
+      }
+      break;
+   }
+
+   case HGFS_OP_SETATTR_V2: {
+      HgfsRequestSetattrV2 *requestV2;
+
+      requestV2 = (HgfsRequestSetattrV2 *)(HGFS_REQ_PAYLOAD(req));
+      requestV2->header.op = opUsed;
+      requestV2->header.id = req->id;
+
+      attrV2 = &requestV2->attr;
+      hints = &requestV2->hints;
+
+      /*
+       * Clear attributes, mask, and hints before touching them.
+       * We can't rely on GetNewRequest() to zero our structures, so
+       * make sure to zero them all here.
+       */
+      memset(attrV2, 0, sizeof *attrV2);
+      memset(hints, 0, sizeof *hints);
+
+      /*
+       * When possible, issue a setattr using an existing handle. This will
+       * give us slightly better performance on a Windows server, and is more
+       * correct regardless. If we don't find a handle, fall back on setattr
+       * by name.
+       *
+       * Changing the size (via truncate) requires write permissions. Changing
+       * the times also requires write permissions on Windows, so we require it
+       * here too. Otherwise, any handle will do.
+       */
+      if (allowHandleReuse && HgfsGetHandle(dentry->d_inode,
+                                            (valid & ATTR_SIZE) ||
+                                            (valid & ATTR_ATIME) ||
+                                            (valid & ATTR_MTIME) ?
+                                            HGFS_OPEN_MODE_WRITE_ONLY + 1 : 0,
+                                            &handle) == 0) {
+         *hints = HGFS_ATTR_HINT_USE_FILE_DESC;
+         requestV2->file = handle;
+         LOG(6, (KERN_DEBUG "VMware hgfs: HgfsPackSetattrRequest: setting "
+                 "attributes of handle %u\n", handle));
+      } else {
+         fileName = requestV2->fileName.name;
+	 fileNameLength = &requestV2->fileName.length;
+      }
+      reqSize = sizeof *requestV2;
+      reqBufferSize = HGFS_NAME_BUFFER_SIZE(requestV2);
+
+      /*
+       * We only support changing these attributes:
+       * - all mode bits (i.e. all permissions)
+       * - uid/gid
+       * - size
+       * - access/write times
+       */
+
+      if (valid & ATTR_MODE) {
+         attrV2->mask |= HGFS_ATTR_VALID_SPECIAL_PERMS |
+            HGFS_ATTR_VALID_OWNER_PERMS | HGFS_ATTR_VALID_GROUP_PERMS |
+            HGFS_ATTR_VALID_OTHER_PERMS;
+         attrV2->specialPerms = ((iattr->ia_mode &
+                                  (S_ISUID | S_ISGID | S_ISVTX)) >> 9);
+         attrV2->ownerPerms = ((iattr->ia_mode & S_IRWXU) >> 6);
+         attrV2->groupPerms = ((iattr->ia_mode & S_IRWXG) >> 3);
+         attrV2->otherPerms = (iattr->ia_mode & S_IRWXO);
+         *changed = TRUE;
+      }
+
+      if (valid & ATTR_UID) {
+         attrV2->mask |= HGFS_ATTR_VALID_USERID;
+         attrV2->userId = iattr->ia_uid;
+         *changed = TRUE;
+      }
+
+      if (valid & ATTR_GID) {
+         attrV2->mask |= HGFS_ATTR_VALID_GROUPID;
+         attrV2->groupId = iattr->ia_gid;
+         *changed = TRUE;
+      }
+
+      if (valid & ATTR_SIZE) {
+         attrV2->mask |= HGFS_ATTR_VALID_SIZE;
+         attrV2->size = iattr->ia_size;
+         *changed = TRUE;
+      }
+
+      if (valid & ATTR_ATIME) {
+         attrV2->mask |= HGFS_ATTR_VALID_ACCESS_TIME;
+         attrV2->accessTime = HGFS_GET_TIME(iattr->ia_atime);
+         if (valid & ATTR_ATIME_SET) {
+            *hints |= HGFS_ATTR_HINT_SET_ACCESS_TIME;
+         }
+         *changed = TRUE;
+      }
+
+      if (valid & ATTR_MTIME) {
+         attrV2->mask |= HGFS_ATTR_VALID_WRITE_TIME;
+         attrV2->writeTime = HGFS_GET_TIME(iattr->ia_mtime);
+         if (valid & ATTR_MTIME_SET) {
+            *hints |= HGFS_ATTR_HINT_SET_WRITE_TIME;
+         }
+         *changed = TRUE;
+      }
+      break;
+   }
+
+   case HGFS_OP_SETATTR: {
+      HgfsRequestSetattr *request;
+
+      request = (HgfsRequestSetattr *)(HGFS_REQ_PAYLOAD(req));
+      request->header.op = opUsed;
+      request->header.id = req->id;
+
+      attr = &request->attr;
+      update = &request->update;
+
+      /* We'll use these later. */
+      fileName = request->fileName.name;
+      fileNameLength = &request->fileName.length;
+      reqSize = sizeof *request;
+      reqBufferSize = HGFS_NAME_BUFFER_SIZE(request);
+
+
+      /*
+       * Clear attributes before touching them.
+       * We can't rely on GetNewRequest() to zero our structures, so
+       * make sure to zero them all here.
+       */
+      memset(attr, 0, sizeof *attr);
+      memset(update, 0, sizeof *update);
+
+      /*
+       * We only support changing these attributes:
+       * - owner mode bits (i.e. owner permissions)
+       * - size
+       * - access/write times
+       */
+
+      if (valid & ATTR_MODE) {
+         *update |= HGFS_ATTR_PERMISSIONS;
+         attr->permissions = ((iattr->ia_mode & S_IRWXU) >> 6);
+         *changed = TRUE;
+      }
+
+      if (valid & ATTR_SIZE) {
+         *update |= HGFS_ATTR_SIZE;
+         attr->size = iattr->ia_size;
+         *changed = TRUE;
+      }
+
+      if (valid & ATTR_ATIME) {
+         *update |= HGFS_ATTR_ACCESS_TIME |
+            ((valid & ATTR_ATIME_SET) ? HGFS_ATTR_ACCESS_TIME_SET : 0);
+         attr->accessTime = HGFS_GET_TIME(iattr->ia_atime);
+         *changed = TRUE;
+      }
+
+      if (valid & ATTR_MTIME) {
+         *update |= HGFS_ATTR_WRITE_TIME |
+            ((valid & ATTR_MTIME_SET) ? HGFS_ATTR_WRITE_TIME_SET : 0);
+         attr->writeTime = HGFS_GET_TIME(iattr->ia_mtime);
+         *changed = TRUE;
+      }
+      break;
+   }
+
+   default:
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsPackSetattrRequest: unexpected "
+              "OP type encountered\n"));
+      return -EPROTO;
+   }
+
+   /* Avoid all this extra work when we're doing a setattr by handle. */
+   if (fileName != NULL) {
+
+      /* Build full name to send to server. */
+      if (HgfsBuildPath(fileName, reqBufferSize, dentry) < 0) {
+         LOG(4, (KERN_DEBUG "VMware hgfs: HgfsPackSetattrRequest: build path "
+                 "failed\n"));
+         return -EINVAL;
+      }
+      LOG(6, (KERN_DEBUG "VMware hgfs: HgfsPackSetattrRequest: setting "
+              "attributes of \"%s\"\n", fileName));
+
+      /* Convert to CP name. */
+      result = CPName_ConvertTo(fileName,
+                                reqBufferSize,
+                                fileName);
+      if (result < 0) {
+         LOG(4, (KERN_DEBUG "VMware hgfs: HgfsPackSetattrRequest: CP "
+                 "conversion failed\n"));
+         return -EINVAL;
+      }
+
+      /* Unescape the CP name. */
+      result = HgfsEscape_Undo(fileName, result);
+      *fileNameLength = result;
+   }
+   req->payloadSize = reqSize + result;
+   return 0;
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * HgfsPackCreateDirRequest --
+ *
+ *    Setup the CreateDir request, depending on the op version.
+ *
+ * Results:
+ *    Returns zero on success, or negative error on failure.
+ *
+ * Side effects:
+ *    None
+ *
+ *----------------------------------------------------------------------
+ */
+
+static int
+HgfsPackCreateDirRequest(struct dentry *dentry, // IN: Directory to create
+                         int mode,              // IN: Mode to assign dir
+                         HgfsOp opUsed,         // IN: Op to be used.
+                         HgfsReq *req)          // IN/OUT: Packet to write into
+{
+   char *fileName = NULL;
+   uint32 *fileNameLength;
+   size_t requestSize;
+   int result;
+
+   ASSERT(dentry);
+   ASSERT(req);
+
+   switch (opUsed) {
+   case HGFS_OP_CREATE_DIR_V3: {
+      HgfsRequest *requestHeader;
+      HgfsRequestCreateDirV3 *requestV3;
+
+      requestHeader = (HgfsRequest *)(HGFS_REQ_PAYLOAD(req));
+      requestHeader->op = opUsed;
+      requestHeader->id = req->id;
+
+      requestV3 = (HgfsRequestCreateDirV3 *)(HGFS_REQ_PAYLOAD_V3(req));
+
+      /* We'll use these later. */
+      fileName = requestV3->fileName.name;
+      fileNameLength = &requestV3->fileName.length;
+      requestV3->fileName.flags = 0;
+      requestV3->fileName.fid = HGFS_INVALID_HANDLE;
+      requestV3->fileName.caseType = HGFS_FILE_NAME_CASE_SENSITIVE;
+
+      requestSize = HGFS_REQ_PAYLOAD_SIZE_V3(requestV3);
+
+      requestV3->mask = HGFS_CREATE_DIR_MASK;
+
+      /* Set permissions. */
+      requestV3->specialPerms = (mode & (S_ISUID | S_ISGID | S_ISVTX)) >> 9;
+      requestV3->ownerPerms = (mode & S_IRWXU) >> 6;
+      requestV3->groupPerms = (mode & S_IRWXG) >> 3;
+      requestV3->otherPerms = (mode & S_IRWXO);
+      requestV3->reserved = 0;
+      break;
+   }
+   case HGFS_OP_CREATE_DIR_V2: {
+      HgfsRequestCreateDirV2 *requestV2;
+
+      requestV2 = (HgfsRequestCreateDirV2 *)(HGFS_REQ_PAYLOAD(req));
+      requestV2->header.op = opUsed;
+      requestV2->header.id = req->id;
+
+      /* We'll use these later. */
+      fileName = requestV2->fileName.name;
+      fileNameLength = &requestV2->fileName.length;
+      requestSize = sizeof *requestV2;
+
+      requestV2->mask = HGFS_CREATE_DIR_MASK;
+
+      /* Set permissions. */
+      requestV2->specialPerms = (mode & (S_ISUID | S_ISGID | S_ISVTX)) >> 9;
+      requestV2->ownerPerms = (mode & S_IRWXU) >> 6;
+      requestV2->groupPerms = (mode & S_IRWXG) >> 3;
+      requestV2->otherPerms = (mode & S_IRWXO);
+      break;
+   }
+   case HGFS_OP_CREATE_DIR: {
+      HgfsRequestCreateDir *request;
+
+      request = (HgfsRequestCreateDir *)(HGFS_REQ_PAYLOAD(req));
+
+      /* We'll use these later. */
+      fileName = request->fileName.name;
+      fileNameLength = &request->fileName.length;
+      requestSize = sizeof *request;
+      requestSize = sizeof *request;
+
+      /* Set permissions. */
+      request->permissions = (mode & S_IRWXU) >> 6;
+      break;
+   }
+   default:
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsPackCreateDirRequest: unexpected "
+              "OP type encountered\n"));
+      return -EPROTO;
+   }
+
+   /* Build full name to send to server. */
+   if (HgfsBuildPath(fileName,
+                     HGFS_PACKET_MAX - (requestSize - 1),
+                     dentry) < 0) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsPackCreateDirRequest: build path "
+              "failed\n"));
+      return -EINVAL;
+   }
+   LOG(6, (KERN_DEBUG "VMware hgfs: HgfsPackCreateDirRequest: create dir "
+           "\"%s\", perms %o\n", fileName, mode));
+
+   /* Convert to CP name. */
+   result = CPName_ConvertTo(fileName,
+                             HGFS_PACKET_MAX - (requestSize - 1),
+                             fileName);
+   if (result < 0) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsPackCreateDirRequest: CP "
+              "conversion failed\n"));
+      return -EINVAL;
+   }
+
+   /* Unescape the CP name. */
+   result = HgfsEscape_Undo(fileName, result);
+   *fileNameLength = result;
+   req->payloadSize = requestSize + result;
+
+   return 0;
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * HgfsTruncatePages --
+ *
+ *    Following a truncate operation on the server, we must update the
+ *    page cache's view of the file by truncating some pages. This is a
+ *    two step procedure. First we call vmtruncate() to truncate all
+ *    whole pages. Then we get the boundary page from the page cache
+ *    ourselves, compute where the truncation began, and memset() the
+ *    rest of the page to zero.
+ *
+ * Results:
+ *    Returns zero on success, or negative error on failure.
+ *
+ * Side effects:
+ *    None
+ *
+ *----------------------------------------------------------------------
+ */
+
+static int
+HgfsTruncatePages(struct inode *inode, // IN: Inode whose page to truncate
+                  loff_t newSize)      // IN: New size of the file
+{
+   int result;
+   pgoff_t pageIndex = newSize >> PAGE_CACHE_SHIFT;
+   unsigned pageOffset = newSize & (PAGE_CACHE_SIZE - 1);
+   struct page *page;
+   char *buffer;
+
+   ASSERT(inode);
+
+   LOG(4, (KERN_DEBUG "VMware hgfs: HgfsTruncatePages: entered\n"));
+   result = compat_vmtruncate(inode, newSize);
+   if (result) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsTruncatePages: vmtruncate failed "
+              "with error code %d\n", result));
+      return result;
+   }
+
+   /*
+    * This is a bit complicated, so it merits an explanation. grab_cache_page()
+    * will give us back the page with the specified index, after having locked
+    * and incremented its reference count. We must first map it into memory so
+    * we can modify it. After we're done modifying the page, we flush its data
+    * from the data cache, unmap it, release our reference, and unlock it.
+    */
+   page = grab_cache_page(inode->i_mapping, pageIndex);
+   if (page == NULL) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsTruncatePages: could not get page "
+             "with index %lu from page cache\n", pageIndex));
+      return -ENOMEM;
+   }
+   buffer = kmap(page);
+   memset(buffer + pageOffset, 0, PAGE_CACHE_SIZE - pageOffset);
+   flush_dcache_page(page);
+   kunmap(page);
+   page_cache_release(page);
+   compat_unlock_page(page);
+   return 0;
+}
+
+
+/*
+ * HGFS inode operations.
+ */
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * HgfsCreate --
+ *
+ *    Create inode for a new file. Called directly by vfs_create,
+ *    which is called by open_namei (both in fs/namei.c), as a result
+ *    of someone doing a creat(2) or an open(2) with O_CREAT.
+ *
+ *    This gets called BEFORE f_op->open is called, so the file on the
+ *    remote end has not been created yet when we get here. So, we
+ *    just cheat and create a reasonable looking inode and instantiate
+ *    it. When this returns, our open routine will get called, which
+ *    will create the actual file on the server. If that fails for
+ *    some reason, dentry_open (which calls f_op->open) will cleanup
+ *    things and fput the dentry.
+ *
+ *    XXX: Now that we do care about having valid inode numbers, it is
+ *    unfortunate but necessary that we "cheat" here. The problem is that
+ *    without the "intent" field from the nameidata struct (which we don't
+ *    get prior to 2.5.75), we have no way of knowing whether the file was
+ *    opened with O_EXCL or O_TRUNC. Knowing about O_TRUNC isn't crucial
+ *    because we can always create the file now and truncate it later, in
+ *    HgfsOpen. But without knowing about O_EXCL, we can't "fail if the file
+ *    exists on the server", which is the desired behavior for O_EXCL. The
+ *    source code for NFSv3 in 2.4.2 describes this shortcoming. The only
+ *    solution, barring massive architectural differences between the 2.4 and
+ *    2.6 HGFS drivers, is to ignore O_EXCL, but we've supported it up until
+ *    now...
+ *
+ * Results:
+ *    Returns zero on success, negative error on failure.
+ *
+ * Side effects:
+ *    None
+ *
+ *----------------------------------------------------------------------
+ */
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 5, 75)
+static int
+HgfsCreate(struct inode *dir,     // IN: Parent dir to create in
+           struct dentry *dentry, // IN: Dentry containing name to create
+           int mode,              // IN: Mode of file to be created
+	   struct nameidata *nd)  // IN: Intent, vfsmount, ...
+#else
+static int
+HgfsCreate(struct inode *dir,     // IN: Parent dir to create in
+           struct dentry *dentry, // IN: Dentry containing name to create
+           int mode)              // IN: Mode of file to be created
+#endif
+{
+   HgfsAttrInfo attr;
+   int result;
+
+   ASSERT(dir);
+   ASSERT(dentry);
+
+   /*
+    * We can call HgfsBuildPath and make the full path to this new entry,
+    * but why bother if it's only for logging.
+    */
+   LOG(6, (KERN_DEBUG "VMware hgfs: HgfsCreate: new entry \"%s\"\n",
+           dentry->d_name.name));
+
+   /* Create appropriate attrs for this file. */
+   attr.type = HGFS_FILE_TYPE_REGULAR;
+   attr.size = 0; /* just to be explicit */
+   attr.specialPerms = ((mode & (S_ISUID | S_ISGID | S_ISVTX)) >> 9);
+   attr.ownerPerms = (mode & S_IRWXU) >> 6;
+   attr.groupPerms = (mode & S_IRWXG) >> 3;
+   attr.otherPerms = mode & S_IRWXO;
+   attr.mask = HGFS_ATTR_VALID_TYPE | HGFS_ATTR_VALID_SIZE |
+      HGFS_ATTR_VALID_SPECIAL_PERMS | HGFS_ATTR_VALID_OWNER_PERMS |
+      HGFS_ATTR_VALID_GROUP_PERMS | HGFS_ATTR_VALID_OTHER_PERMS;
+
+   result = HgfsInstantiate(dentry, 0, &attr);
+
+   /*
+    * Mark the inode as recently created but not yet opened so that if we do
+    * fail to create the actual file in HgfsOpen, we know to force a
+    * revalidate so that the next operation on this inode will fail.
+    */
+   if (result == 0) {
+      HgfsInodeInfo *iinfo = INODE_GET_II_P(dentry->d_inode);
+      iinfo->createdAndUnopened = TRUE;
+   }
+   return result;
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * HgfsLookup --
+ *
+ *    Lookup a file in a directory.
+ *
+ *    We do a getattr to see if the file exists on the server, and if
+ *    so we create a new inode and fill in the fields appropriately by
+ *    calling HgfsIget with the results of the getattr, and then
+ *    call d_add with the new dentry.
+ *
+ *    For the curious, the way lookup in linux works (see fs/namei.c)
+ *    is roughly as follows: first a d_lookup is done to see if there
+ *    is an appropriate entry in the dcache already. If there is, it
+ *    is revalidated by calling d_op->d_revalidate, which calls our
+ *    HgfsDentryRevalidate (see above). If there is no dentry in the
+ *    cache or if the dentry is no longer valid, then namei calls
+ *    i_op->lookup, which calls HgfsLookup.
+ *
+ * Results:
+ *    Returns NULL on success, negative error on failure.
+ *
+ * Side effects:
+ *    None
+ *
+ *----------------------------------------------------------------------
+ */
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 5, 75)
+static struct dentry *
+HgfsLookup(struct inode *dir,      // IN: Inode of parent directory
+           struct dentry *dentry,  // IN: Dentry containing name to look up
+	   struct nameidata *nd)   // IN: Intent, vfsmount, ...
+#else
+static struct dentry *
+HgfsLookup(struct inode *dir,      // IN: Inode of parent directory
+           struct dentry *dentry)  // IN: Dentry containing name to look up
+#endif
+{
+   HgfsAttrInfo attr;
+   struct inode *inode;
+   int error = 0;
+
+   ASSERT(dir);
+   ASSERT(dentry);
+
+   if (!dir || !dentry) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsLookup: NULL input\n"));
+      error = -EFAULT;
+      goto error;
+   }
+
+   LOG(6, (KERN_DEBUG "VMware hgfs: HgfsLookup: dir ino %lu, i_dev %u\n",
+          dir->i_ino, dir->i_sb->s_dev));
+   LOG(6, (KERN_DEBUG "VMware hgfs: HgfsLookup: entry name is \"%s\"\n",
+           dentry->d_name.name));
+
+   /* Do a getattr on the file to see if it exists on the server. */
+   inode = NULL;
+   attr.fileName = NULL;
+   error = HgfsPrivateGetattr(dentry, &attr);
+   if (!error) {
+      /* File exists on the server. */
+
+      /*
+       * Get the inode with this inode number and the attrs we got from
+       * the server.
+       */
+      inode = HgfsIget(dir->i_sb, 0, &attr);
+      kfree(attr.fileName);
+      if (!inode) {
+         error = -ENOMEM;
+         LOG(4, (KERN_DEBUG "VMware hgfs: HgfsLookup: out of memory getting "
+                 "inode\n"));
+         goto error;
+      }
+   } else if (error != -ENOENT) {
+      /*
+       * Either the file doesn't exist or there was a more serious
+       * error; if it's the former, it's okay, we just do nothing.
+       */
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsLookup: error other "
+              "than ENOENT: %d\n", error));
+      goto error;
+   }
+
+   /*
+    * Set the dentry's time to NOW, set its operations pointer, add it
+    * and the new (possibly NULL) inode to the dcache.
+    */
+   HgfsDentryAgeReset(dentry);
+   dentry->d_op = &HgfsDentryOperations;
+   LOG(6, (KERN_DEBUG "VMware hgfs: HgfsLookup: adding new entry\n"));
+   d_add(dentry, inode);
+
+   return NULL;
+
+error:
+   return ERR_PTR(error);
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * HgfsMkdir --
+ *
+ *    Handle a mkdir request
+ *
+ * Results:
+ *    Returns zero on success, or a negative error on failure.
+ *
+ * Side effects:
+ *    None
+ *
+ *----------------------------------------------------------------------
+ */
+
+static int
+HgfsMkdir(struct inode *dir,     // IN: Inode of parent directory
+          struct dentry *dentry, // IN: Dentry with name to be created
+          int mode)              // IN: Mode of dir to be created
+{
+   HgfsReq *req;
+   HgfsStatus replyStatus;
+   HgfsOp opUsed;
+   int result = 0;
+
+   ASSERT(dir);
+   ASSERT(dir->i_sb);
+   ASSERT(dentry);
+
+   req = HgfsGetNewRequest();
+   if (!req) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsMkdir: out of memory while "
+              "getting new request\n"));
+      result = -ENOMEM;
+      goto out;
+   }
+
+  retry:
+   opUsed = atomic_read(&hgfsVersionCreateDir);
+   result = HgfsPackCreateDirRequest(dentry, mode, opUsed, req);
+   if (result != 0) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsMkdir: error packing request\n"));
+      goto out;
+   }
+
+   /*
+    * Send the request and process the reply. Since HgfsReplyCreateDirV2 and
+    * HgfsReplyCreateDir are identical, we need no special logic here.
+    */
+   result = HgfsSendRequest(req);
+   if (result == 0) {
+      LOG(6, (KERN_DEBUG "VMware hgfs: HgfsMkdir: got reply\n"));
+      replyStatus = HgfsReplyStatus(req);
+      result = HgfsStatusConvertToLinux(replyStatus);
+
+      switch (result) {
+      case 0:
+         LOG(6, (KERN_DEBUG "VMware hgfs: HgfsMkdir: directory created "
+                 "successfully, instantiating dentry\n"));
+         result = HgfsInstantiate(dentry, 0, NULL);
+         if (result == 0) {
+            /*
+             * Attempt to set host directory's uid/gid to that of the
+             * current user.  As with the open(.., O_CREAT) case, this is
+             * only expected to work when the hgfs server is running on
+             * a Linux machine and as root, but we might as well give it
+             * a go.
+             */
+            HgfsSetUidGid(dir, dentry, current->fsuid, current->fsgid);
+         }
+
+         /*
+          * XXX: When we support hard links, this is a good place to
+          * increment link count of parent dir.
+          */
+         break;
+      case -EPROTO:
+         /* Retry with older version(s). Set globally. */
+         if (opUsed == HGFS_OP_CREATE_DIR_V3) {
+            LOG(4, (KERN_DEBUG "VMware hgfs: HgfsMkdir: Version 3 not "
+                    "supported. Falling back to version 2.\n"));
+            atomic_set(&hgfsVersionCreateDir, HGFS_OP_CREATE_DIR_V2);
+            goto retry;
+         } else if (opUsed == HGFS_OP_CREATE_DIR_V2) {
+            LOG(4, (KERN_DEBUG "VMware hgfs: HgfsMkdir: Version 2 not "
+                    "supported. Falling back to version 1.\n"));
+            atomic_set(&hgfsVersionCreateDir, HGFS_OP_CREATE_DIR);
+            goto retry;
+         }
+
+         /* Fallthrough. */
+         default:
+            LOG(6, (KERN_DEBUG "VMware hgfs: HgfsMkdir: directory was not "
+                    "created, error %d\n", result));
+            break;
+         }
+   } else if (result == -EIO) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsMkdir: timed out\n"));
+   } else if (result == -EPROTO) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsMkdir: server "
+              "returned error: %d\n", result));
+   } else {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsMkdir: unknown error: "
+              "%d\n", result));
+   }
+
+out:
+   HgfsFreeRequest(req);
+   return result;
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * HgfsRmdir --
+ *
+ *    Handle an rmdir request. Just calls HgfsDelete with the
+ *    correct opcode.
+ *
+ * Results:
+ *    Returns zero on success, or a negative error on failure.
+ *
+ * Side effects:
+ *    None
+ *
+ *----------------------------------------------------------------------
+ */
+
+static int
+HgfsRmdir(struct inode *dir,      // IN: Parent dir of dir to remove
+          struct dentry *dentry)  // IN: Dentry of dir to remove
+{
+   int result;
+
+   LOG(8, (KERN_DEBUG "VMware hgfs: HgfsRmdir: was called\n"));
+
+   /*
+    * XXX: CIFS also sets the size of the deleted directory to 0. Why? I don't
+    * know...why not?
+    *
+    * XXX: When we support hardlinks, we should decrement the link count of
+    * the parent directory.
+    */
+   result = HgfsDelete(dir, dentry, HGFS_OP_DELETE_DIR);
+   if (!result) {
+      compat_i_size_write(dentry->d_inode, 0);
+   }
+   return result;
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * HgfsUnlink --
+ *
+ *    Handle an unlink request. Just calls HgfsDelete with the
+ *    correct opcode.
+ *
+ * Results:
+ *    Returns zero on success, or a negative error on failure.
+ *
+ * Side effects:
+ *    None
+ *
+ *----------------------------------------------------------------------
+ */
+
+static int
+HgfsUnlink(struct inode *dir,      // IN: Parent dir of file to unlink
+           struct dentry *dentry)  // IN: Dentry of file to unlink
+{
+   LOG(8, (KERN_DEBUG "VMware hgfs: HgfsUnlink: was called\n"));
+
+   return HgfsDelete(dir, dentry, HGFS_OP_DELETE_FILE);
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * HgfsRename --
+ *
+ *    Handle rename requests.
+ *
+ * Results:
+ *    Returns zero on success, or a negative error on failure.
+ *
+ * Side effects:
+ *    None
+ *
+ *----------------------------------------------------------------------
+ */
+
+static int
+HgfsRename(struct inode *oldDir,      // IN: Inode of original directory
+           struct dentry *oldDentry,  // IN: Dentry of file to rename
+           struct inode *newDir,      // IN: Inode of new directory
+           struct dentry *newDentry)  // IN: Dentry containing new name
+{
+   HgfsReq *req = NULL;
+   char *oldName;
+   char *newName;
+   uint32 *oldNameLength;
+   uint32 *newNameLength;
+   int result = 0;
+   uint32 reqSize;
+   HgfsOp opUsed;
+   HgfsStatus replyStatus;
+
+   ASSERT(oldDir);
+   ASSERT(oldDir->i_sb);
+   ASSERT(oldDentry);
+   ASSERT(newDir);
+   ASSERT(newDentry);
+
+   if (!oldDir || !oldDentry || !newDir || !newDentry) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsRename: NULL input\n"));
+      result = -EFAULT;
+      goto out;
+   }
+
+   req = HgfsGetNewRequest();
+   if (!req) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsRename: out of memory while "
+              "getting new request\n"));
+      result = -ENOMEM;
+      goto out;
+   }
+
+retry:
+   opUsed = atomic_read(&hgfsVersionRename);
+   if (opUsed == HGFS_OP_RENAME_V3) {
+      HgfsRequestRenameV3 *request = (HgfsRequestRenameV3 *)HGFS_REQ_PAYLOAD_V3(req);
+      HgfsRequest *header = (HgfsRequest *)HGFS_REQ_PAYLOAD(req);
+
+      header->op = opUsed;
+      header->id = req->id;
+
+      oldName = request->oldName.name;
+      oldNameLength = &request->oldName.length;
+      request->hints = 0;
+      request->oldName.flags = 0;
+      request->oldName.fid = HGFS_INVALID_HANDLE;
+      request->oldName.caseType = HGFS_FILE_NAME_CASE_SENSITIVE;
+      request->reserved = 0;
+      reqSize = HGFS_REQ_PAYLOAD_SIZE_V3(request);
+   } else {
+      HgfsRequestRename *request = (HgfsRequestRename *)HGFS_REQ_PAYLOAD(req);
+
+      request->header.op = opUsed;
+      oldName = request->oldName.name;
+      oldNameLength = &request->oldName.length;
+      reqSize = sizeof *request;
+   }
+
+   /* Build full old name to send to server. */
+   if (HgfsBuildPath(oldName, HGFS_NAME_BUFFER_SIZET(reqSize),
+                     oldDentry) < 0) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsRename: build old path failed\n"));
+      result = -EINVAL;
+      goto out;
+   }
+   LOG(6, (KERN_DEBUG "VMware hgfs: HgfsRename: Old name: \"%s\"\n",
+           oldName));
+
+   /* Convert old name to CP format. */
+   result = CPName_ConvertTo(oldName,
+                             HGFS_NAME_BUFFER_SIZET(reqSize),
+                             oldName);
+   if (result < 0) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsRename: oldName CP "
+              "conversion failed\n"));
+      result = -EINVAL;
+      goto out;
+   }
+
+   /* Unescape the old CP name. */
+   result = HgfsEscape_Undo(oldName, result);
+   *oldNameLength = result;
+   reqSize += result;
+
+   /*
+    * Build full new name to send to server.
+    * Note the different buffer length. This is because HgfsRequestRename
+    * contains two filenames, and once we place the first into the packet we
+    * must account for it when determining the amount of buffer available for
+    * the second.
+    */
+   if (opUsed == HGFS_OP_RENAME_V3) {
+      HgfsRequestRenameV3 *request = (HgfsRequestRenameV3 *)HGFS_REQ_PAYLOAD_V3(req);
+      HgfsFileNameV3 *newNameP;
+      newNameP = (HgfsFileNameV3 *)((char *)&request->oldName +
+                                    sizeof request->oldName + result);
+      newName = newNameP->name;
+      newNameLength = &newNameP->length;
+      newNameP->flags = 0;
+      newNameP->fid = HGFS_INVALID_HANDLE;
+      newNameP->caseType = HGFS_FILE_NAME_CASE_SENSITIVE;
+   } else {
+      HgfsRequestRename *request = (HgfsRequestRename *)HGFS_REQ_PAYLOAD(req);
+      HgfsFileName *newNameP;
+      newNameP = (HgfsFileName *)((char *)&request->oldName +
+                                  sizeof request->oldName + result);
+      newName = newNameP->name;
+      newNameLength = &newNameP->length;
+   }
+
+   if (HgfsBuildPath(newName, HGFS_NAME_BUFFER_SIZET(reqSize) - result,
+                     newDentry) < 0) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsRename: build new path failed\n"));
+      result = -EINVAL;
+      goto out;
+   }
+   LOG(6, (KERN_DEBUG "VMware hgfs: HgfsRename: New name: \"%s\"\n",
+           newName));
+
+   /* Convert new name to CP format. */
+   result = CPName_ConvertTo(newName,
+                             HGFS_NAME_BUFFER_SIZET(reqSize) - result,
+                             newName);
+   if (result < 0) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsRename: newName CP "
+              "conversion failed\n"));
+      result = -EINVAL;
+      goto out;
+   }
+
+   /* Unescape the new CP name. */
+   result = HgfsEscape_Undo(newName, result);
+   *newNameLength = result;
+   reqSize += result;
+   req->payloadSize = reqSize;
+
+   result = HgfsSendRequest(req);
+   if (result == 0) {
+      LOG(6, (KERN_DEBUG "VMware hgfs: HgfsRename: got reply\n"));
+      replyStatus = HgfsReplyStatus(req);
+      result = HgfsStatusConvertToLinux(replyStatus);
+
+      if (result == -EPROTO) {
+         /* Retry with older version(s). Set globally. */
+         if (opUsed == HGFS_OP_RENAME_V3) {
+            atomic_set(&hgfsVersionRename, HGFS_OP_RENAME);
+            goto retry;
+         } else {
+            LOG(4, (KERN_DEBUG "VMware hgfs: HgfsRename: server "
+                    "returned error: %d\n", result));
+            goto out;
+         }
+      }
+   } else if (result == -EIO) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsRename: timed out\n"));
+   } else if (result == -EPROTO) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsRename: server "
+              "returned error: %d\n", result));
+   } else {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsRename: unknown error: "
+              "%d\n", result));
+   }
+
+out:
+   HgfsFreeRequest(req);
+   return result;
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * HgfsPackSymlinkCreateRequest --
+ *
+ *    Setup the create symlink request, depending on the op version.
+ *
+ * Results:
+ *    Returns zero on success, or negative error on failure.
+ *
+ * Side effects:
+ *    None
+ *
+ *----------------------------------------------------------------------
+ */
+
+static int
+HgfsPackSymlinkCreateRequest(struct dentry *dentry,   // IN: File pointer for this open
+                             const char *symname,     // IN: Target name
+                             HgfsOp opUsed,           // IN: Op to be used
+                             HgfsReq *req)            // IN/OUT: Packet to write into
+{
+   HgfsRequestSymlinkCreateV3 *requestV3 = NULL;
+   HgfsRequestSymlinkCreate *request = NULL;
+   char *symlinkName;
+   uint32 *symlinkNameLength;
+   char *targetName;
+   uint32 *targetNameLength;
+   size_t targetNameBytes;
+
+   size_t requestSize;
+   int result;
+
+   ASSERT(dentry);
+   ASSERT(symname);
+   ASSERT(req);
+
+   switch (opUsed) {
+   case HGFS_OP_CREATE_SYMLINK_V3: {
+      HgfsRequest *requestHeader;
+
+      requestHeader = (HgfsRequest *)(HGFS_REQ_PAYLOAD(req));
+      requestHeader->op = opUsed;
+      requestHeader->id = req->id;
+
+      requestV3 = (HgfsRequestSymlinkCreateV3 *)HGFS_REQ_PAYLOAD_V3(req);
+
+      /* We'll use these later. */
+      symlinkName = requestV3->symlinkName.name;
+      symlinkNameLength = &requestV3->symlinkName.length;
+      requestV3->symlinkName.flags = 0;
+      requestV3->symlinkName.fid = HGFS_INVALID_HANDLE;
+      requestV3->symlinkName.caseType = HGFS_FILE_NAME_CASE_SENSITIVE;
+      requestV3->reserved = 0;
+      requestSize = HGFS_REQ_PAYLOAD_SIZE_V3(requestV3);
+      break;
+   }
+   case HGFS_OP_CREATE_SYMLINK: {
+
+      request = (HgfsRequestSymlinkCreate *)(HGFS_REQ_PAYLOAD(req));
+      request->header.op = opUsed;
+      request->header.id = req->id;
+
+      /* We'll use these later. */
+      symlinkName = request->symlinkName.name;
+      symlinkNameLength = &request->symlinkName.length;
+      requestSize = sizeof *request;
+      break;
+   }
+   default:
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsPackSymlinkCreateRequest: unexpected "
+              "OP type encountered\n"));
+      return -EPROTO;
+   }
+
+   if (HgfsBuildPath(symlinkName, HGFS_PACKET_MAX - (requestSize - 1),
+                     dentry) < 0) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsPackSymlinkCreateRequest: build symlink path "
+              "failed\n"));
+      return -EINVAL;
+   }
+
+   LOG(6, (KERN_DEBUG "VMware hgfs: HgfsPackSymlinkCreateRequest: Symlink name: \"%s\"\n",
+           symlinkName));
+
+   /* Convert symlink name to CP format. */
+   result = CPName_ConvertTo(symlinkName,
+                             HGFS_PACKET_MAX - (requestSize - 1),
+                             symlinkName);
+   if (result < 0) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsPackSymlinkCreateRequest: symlinkName CP "
+              "conversion failed\n"));
+      return -EINVAL;
+   }
+
+   /* Unescape the symlink CP name. */
+   result = HgfsEscape_Undo(symlinkName, result);
+   *symlinkNameLength = result;
+   req->payloadSize = requestSize + result;
+
+   /*
+    * Note the different buffer length. This is because HgfsRequestSymlink
+    * contains two filenames, and once we place the first into the packet we
+    * must account for it when determining the amount of buffer available for
+    * the second.
+    *
+    * Also note that targetNameBytes accounts for the NUL character. Once
+    * we've converted it to CP name, it won't be NUL-terminated and the length
+    * of the string in the packet itself won't account for it.
+    */
+   if (opUsed == HGFS_OP_CREATE_SYMLINK_V3) {
+      HgfsFileNameV3 *fileNameP;
+      fileNameP = (HgfsFileNameV3 *)((char *)&requestV3->symlinkName +
+                                     sizeof requestV3->symlinkName + result);
+      targetName = fileNameP->name;
+      targetNameLength = &fileNameP->length;
+      fileNameP->flags = 0;
+      fileNameP->fid = HGFS_INVALID_HANDLE;
+      fileNameP->caseType = HGFS_FILE_NAME_CASE_SENSITIVE;
+   } else {
+      HgfsFileName *fileNameP;
+      fileNameP = (HgfsFileName *)((char *)&request->symlinkName +
+                                   sizeof request->symlinkName + result);
+      targetName = fileNameP->name;
+      targetNameLength = &fileNameP->length;
+   }
+   targetNameBytes = strlen(symname) + 1;
+
+   /* Copy target name into request packet. */
+   if (targetNameBytes > HGFS_PACKET_MAX - (requestSize - 1)) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsPackSymlinkCreateRequest: target name is too "
+              "big\n"));
+      return -EINVAL;
+   }
+   memcpy(targetName, symname, targetNameBytes);
+   LOG(6, (KERN_DEBUG "VMware hgfs: HgfsPackSymlinkCreateRequest: target name: \"%s\"\n",
+           targetName));
+
+   /* Convert target name to CPName-lite format. */
+   CPNameLite_ConvertTo(targetName, targetNameBytes - 1, '/');
+
+   /* Unescape the target CP-lite name. */
+   result = HgfsEscape_Undo(targetName, targetNameBytes - 1);
+   *targetNameLength = result;
+   req->payloadSize += result;
+
+   return 0;
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * HgfsSymlink --
+ *
+ *    Handle a symlink request
+ *
+ * Results:
+ *    Returns zero on success, or a negative error on failure.
+ *
+ * Side effects:
+ *    None
+ *
+ *----------------------------------------------------------------------
+ */
+
+static int
+HgfsSymlink(struct inode *dir,     // IN: Inode of parent directory
+            struct dentry *dentry, // IN: Dentry of new symlink file
+            const char *symname)   // IN: Target name
+{
+   HgfsReq *req;
+   int result = 0;
+   HgfsOp opUsed;
+   HgfsStatus replyStatus;
+
+   ASSERT(dir);
+   ASSERT(dir->i_sb);
+   ASSERT(dentry);
+   ASSERT(symname);
+
+   req = HgfsGetNewRequest();
+   if (!req) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsSymlink: out of memory while "
+              "getting new request\n"));
+      result = -ENOMEM;
+      goto out;
+   }
+
+  retry:
+   opUsed = atomic_read(&hgfsVersionCreateSymlink);
+   result = HgfsPackSymlinkCreateRequest(dentry, symname, opUsed, req);
+   if (result != 0) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsSymlink: error packing request\n"));
+      goto out;
+   }
+
+   result = HgfsSendRequest(req);
+   if (result == 0) {
+      LOG(6, (KERN_DEBUG "VMware hgfs: HgfsSymlink: got reply\n"));
+      replyStatus = HgfsReplyStatus(req);
+      result = HgfsStatusConvertToLinux(replyStatus);
+      if (result == 0) {
+         LOG(6, (KERN_DEBUG "VMware hgfs: HgfsSymlink: symlink created "
+                 "successfully, instantiating dentry\n"));
+         result = HgfsInstantiate(dentry, 0, NULL);
+      } else if (result == -EPROTO) {
+         /* Retry with older version(s). Set globally. */
+         if (opUsed == HGFS_OP_CREATE_SYMLINK_V3) {
+            LOG(4, (KERN_DEBUG "VMware hgfs: HgfsSymlink: Version 3 "
+                    "not supported. Falling back to version 2.\n"));
+            atomic_set(&hgfsVersionCreateSymlink, HGFS_OP_CREATE_SYMLINK);
+            goto retry;
+         } else {
+            LOG(6, (KERN_DEBUG "VMware hgfs: HgfsSymlink: symlink was not "
+                    "created, error %d\n", result));
+         }
+      }
+   } else if (result == -EIO) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsSymlink: timed out\n"));
+   } else if (result == -EPROTO) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsSymlink: server "
+              "returned error: %d\n", result));
+   } else {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsSymlink: unknown error: "
+              "%d\n", result));
+   }
+
+out:
+   HgfsFreeRequest(req);
+
+   return result;
+}
+
+
+#ifdef HGFS_GETATTR_ONLY
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * HgfsGetattr --
+ *
+ *    Hgfs superblock 'getattr' method.
+ *
+ * Results:
+ *    0 on success
+ *    error < 0 on failure
+ *
+ * Side effects:
+ *    None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static int
+HgfsGetattr(struct vfsmount *mnt,  // Unused
+            struct dentry *dentry, // IN
+            struct kstat *stat)    // OUT
+{
+   int err;
+
+   // XXX ASSERT(mnt); ? --hpreg
+   ASSERT(dentry);
+   ASSERT(stat);
+
+   err = HgfsRevalidate(dentry);
+   if (err) {
+      return err;
+   }
+
+   /* Convert stats from the VFS inode format to the kernel format --hpreg */
+   generic_fillattr(dentry->d_inode, stat);
+   // XXX Should we set stat->blocks and stat->blksize? --hpreg
+
+   return 0;
+}
+#endif
+
+/*
+ * Public function implementations.
+ */
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * HgfsSetattr --
+ *
+ *    Handle a setattr request. Call HgfsSetattrCopy to determine
+ *    which fields need updating and convert them to the HgfsAttr
+ *    format, then send the request to the server.
+ *
+ * Results:
+ *    Returns zero on success, or a negative error on failure.
+ *
+ * Side effects:
+ *    None
+ *
+ *----------------------------------------------------------------------
+ */
+
+int
+HgfsSetattr(struct dentry *dentry,  // IN: File to set attributes of
+            struct iattr *iattr)    // IN: Attributes to set
+{
+   HgfsReq *req;
+   HgfsStatus replyStatus;
+   int result = 0;
+   Bool changed = FALSE;
+   Bool allowHandleReuse = TRUE;
+   HgfsOp opUsed;
+
+   ASSERT(dentry);
+   ASSERT(dentry->d_inode);
+   ASSERT(dentry->d_inode->i_mapping);
+   ASSERT(dentry->d_sb);
+   ASSERT(iattr);
+
+   req = HgfsGetNewRequest();
+   if (!req) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsSetattr: out of memory while "
+              "getting new request\n"));
+      result = -ENOMEM;
+      goto out;
+   }
+
+  retry:
+   /* Fill out the request packet. */
+   opUsed = atomic_read(&hgfsVersionSetattr);
+   result = HgfsPackSetattrRequest(iattr, dentry, allowHandleReuse,
+                                   opUsed, req, &changed);
+   if (result != 0 || !changed) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsSetattr: no attrs changed\n"));
+      goto out;
+   }
+
+   /*
+    * Flush all dirty pages prior to sending the request if we're going to
+    * modify the file size.
+    */
+   if (iattr->ia_valid & ATTR_SIZE) {
+      compat_filemap_write_and_wait(dentry->d_inode->i_mapping);
+   }
+
+   /* Send the request and process the reply. */
+   result = HgfsSendRequest(req);
+   if (result == 0) {
+      /* Get the reply. */
+      replyStatus = HgfsReplyStatus(req);
+      result = HgfsStatusConvertToLinux(replyStatus);
+
+      switch (result) {
+      case 0:
+         /*
+          * If we modified the file size, we must truncate our pages from the
+          * page cache.
+          */
+         if (iattr->ia_valid & ATTR_SIZE) {
+            result = HgfsTruncatePages(dentry->d_inode, iattr->ia_size);
+         }
+
+         /* Fallthrough to revalidate. */
+      case -EPERM:
+         /*
+          * Now that the server's attributes are updated, let's update our
+          * local view of them. Unfortunately, we can't trust iattr, because
+          * the server may have chosen to ignore certain attributes that we
+          * asked it to set. For example, a Windows server will have ignored
+          * the mode nearly entirely. Therefore, rather than calling
+          * inode_setattr() to update the inode with the contents of iattr,
+          * just force a revalidate.
+          *
+          * XXX: Note that EPERM gets similar treatment, as the server may
+          * have updated some of the attributes and still sent us an error.
+          */
+         HgfsDentryAgeForce(dentry);
+         HgfsRevalidate(dentry);
+         break;
+
+      case -EBADF:
+         /*
+          * This can happen if we attempted a setattr by handle and the handle
+          * was closed. Because we have no control over the backdoor, it's
+          * possible that an attacker closed our handle, in which case the
+          * driver still thinks the handle is open. So a straight-up
+          * "goto retry" would cause an infinite loop. Instead, let's retry
+          * with a setattr by name.
+          */
+         if (allowHandleReuse) {
+            allowHandleReuse = FALSE;
+            goto retry;
+         }
+
+         /*
+          * There's no reason why the server should have sent us this error
+          * when we haven't used a handle. But to prevent an infinite loop in
+          * the driver, let's make sure that we don't retry again.
+          */
+         break;
+
+      case -EPROTO:
+         /* Retry with older version(s). Set globally. */
+         if (opUsed == HGFS_OP_SETATTR_V3) {
+            LOG(4, (KERN_DEBUG "VMware hgfs: HgfsSetattr: Version 3 "
+                    "not supported. Falling back to version 2.\n"));
+            atomic_set(&hgfsVersionSetattr, HGFS_OP_SETATTR_V2);
+            goto retry;
+         } else if (opUsed == HGFS_OP_SETATTR_V2) {
+            LOG(4, (KERN_DEBUG "VMware hgfs: HgfsSetattr: Version 2 "
+                    "not supported. Falling back to version 1.\n"));
+            atomic_set(&hgfsVersionSetattr, HGFS_OP_SETATTR);
+            goto retry;
+         }
+
+         /* Fallthrough. */
+      default:
+         break;
+      }
+   } else if (result == -EIO) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsSetattr: timed out\n"));
+   } else if (result == -EPROTO) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsSetattr: server "
+              "returned error: %d\n", result));
+   } else {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsSetattr: unknown error: "
+              "%d\n", result));
+   }
+
+out:
+   HgfsFreeRequest(req);
+   return result;
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * HgfsRevalidate --
+ *
+ *    Called when the kernel wants to check that an inode is still
+ *    valid. Called with the dentry that points to the inode we're
+ *    interested in.
+ *
+ *    We call HgfsPrivateGetattr with the inode's remote name, and if
+ *    it succeeds we update the inode's attributes and return zero
+ *    (success). Otherwise, we return an error.
+ *
+ * Results:
+ *    Returns zero if inode is valid, negative error if not.
+ *
+ * Side effects:
+ *    None
+ *
+ *----------------------------------------------------------------------
+ */
+
+int
+HgfsRevalidate(struct dentry *dentry)  // IN: Dentry to revalidate
+{
+   HgfsAttrInfo attr;
+   int error = 0;
+   HgfsSuperInfo *si;
+   unsigned long age;
+
+   ASSERT(dentry);
+   si = HGFS_SB_TO_COMMON(dentry->d_sb);
+
+   if (!dentry->d_inode) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsRevalidate: null input\n"));
+      return -EINVAL;
+   }
+
+   LOG(6, (KERN_DEBUG "VMware hgfs: HgfsRevalidate: name %s, "
+           "inum %lu\n", dentry->d_name.name, dentry->d_inode->i_ino));
+
+   age = jiffies - dentry->d_time;
+   if (age > si->ttl) {
+      LOG(6, (KERN_DEBUG "VMware hgfs: HgfsRevalidate: dentry is too old, "
+              "getting new attributes\n"));
+      /*
+       * Sync unwritten file data so the file size on the server will
+       * be current with our view of the file.
+       */
+      compat_filemap_write_and_wait(dentry->d_inode->i_mapping);
+      attr.fileName = NULL;
+      error = HgfsPrivateGetattr(dentry,
+                                 &attr);
+      if (!error) {
+         /* No error, so update inode's attributes and reset the age. */
+         HgfsChangeFileAttributes(dentry->d_inode, &attr);
+         HgfsDentryAgeReset(dentry);
+         kfree(attr.fileName);
+      }
+   } else {
+      LOG(6, (KERN_DEBUG "VMware hgfs: HgfsRevalidate: using cached dentry "
+              "attributes\n"));
+   }
+
+   return error;
+}
--- kernel/linux-2.6.26.3/fs/vmhgfs/inode.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/inode.h	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,38 @@
+/*********************************************************
+ * Copyright (C) 2006 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * inode.h --
+ *
+ * Inode operations for the filesystem portion of the vmhgfs driver.
+ */
+
+#ifndef _HGFS_DRIVER_INODE_H_
+#define _HGFS_DRIVER_INODE_H_
+
+/* Must come before any kernel header file. */
+#include "driver-config.h"
+
+#include "compat_fs.h"
+
+/* Public functions (with respect to the entire module). */
+int HgfsSetattr(struct dentry *dentry,
+                struct iattr *iattr);
+int HgfsRevalidate(struct dentry *dentry);
+
+#endif // _HGFS_DRIVER_INODE_H_
--- kernel/linux-2.6.26.3/fs/vmhgfs/kernelStubs.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/kernelStubs.h	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,146 @@
+/*********************************************************
+ * Copyright (C) 2006 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * kernelStubs.h
+ *
+ * KernelStubs implements some userspace library functions in terms
+ * of kernel functions to allow library userspace code to be used in a
+ * kernel.
+ */
+
+#ifndef __KERNELSTUBS_H__
+#define __KERNELSTUBS_H__
+
+#ifdef linux
+#   ifndef __KERNEL__
+#      error "__KERNEL__ is not defined"
+#   endif
+#   include "driver-config.h" // Must be included before any other header files
+#   include "vm_basic_types.h"
+#   include <linux/kernel.h>
+#   include <linux/string.h>
+#elif defined(_WIN32)
+#   include "vm_basic_types.h"
+#   include <ntddk.h>   /* kernel memory APIs */
+#   include <stdio.h>   /* for _vsnprintf, vsprintf */
+#   include <stdarg.h>  /* for va_start stuff */
+#   include <stdlib.h>  /* for min macro. */
+#   include "vm_assert.h"  /* Our assert macros */
+#elif defined(__FreeBSD__)
+#   include "vm_basic_types.h"
+#   ifndef _KERNEL
+#      error "_KERNEL is not defined"
+#   endif
+#   include <sys/types.h>
+#   include <sys/malloc.h>
+#   include <sys/param.h>
+#   include <sys/kernel.h>
+#   include <machine/stdarg.h>
+#   include <sys/libkern.h>
+#   include "vm_assert.h"
+#elif defined(__APPLE__)
+#   include "vm_basic_types.h"
+#   ifndef KERNEL
+#      error "KERNEL is not defined"
+#   endif
+#   include <stdarg.h>
+#   include <string.h>
+#endif
+
+/*
+ * Function Prototypes
+ */
+
+#if defined(linux) || defined(__APPLE__)     /* if (linux) || (__APPLE__) { */
+
+#  ifdef linux                               /* if (linux) { */
+char *strdup(const char *source);
+#  endif
+
+/* Shared between Linux and Apple kernel stubs. */
+void *malloc(size_t size);
+void free(void *mem);
+void *calloc(size_t num, size_t len);
+void *realloc(void *ptr, size_t newSize);
+
+#elif defined(_WIN32)                           /* } else if (_WIN32) { */
+
+#if (_WIN32_WINNT == 0x0400)
+/* The following declarations are missing on NT4. */
+typedef unsigned int UINT_PTR;
+typedef unsigned int SIZE_T;
+
+/* No free with tag availaible on NT4 kernel! */
+#define KRNL_STUBS_FREE(P,T)     ExFreePool((P))
+
+#else /* _WIN32_WINNT */
+#define KRNL_STUBS_FREE(P,T)     ExFreePoolWithTag((P),(T))
+/* Win 2K and later useful kernel function, documented but not declared! */
+NTKERNELAPI VOID ExFreePoolWithTag(IN PVOID  P, IN ULONG  Tag);
+#endif /* _WIN32_WINNT */
+
+#elif defined(__FreeBSD__)                      /* } else if (FreeBSD) { */
+
+/* Kernel memory on FreeBSD is tagged for statistics and sanity checking. */
+MALLOC_DECLARE(M_VMWARE_TEMP);
+
+/*
+ * On FreeBSD, the general memory allocator for both userland and the kernel is named
+ * malloc, but the kernel malloc() takes more arguments.  The following alias & macros
+ * work around this, to provide the standard malloc() API for userspace code that is
+ * being used in the kernel.
+ */
+
+#   undef malloc
+
+static INLINE void *
+__compat_malloc(unsigned long size, struct malloc_type *type, int flags) {
+   return malloc(size, type, flags);
+}
+
+#   define malloc(size)         __compat_malloc(size, M_VMWARE_TEMP, M_NOWAIT)
+#   define calloc(count, size)  __compat_malloc((count) * (size),       \
+                                                M_VMWARE_TEMP, M_NOWAIT|M_ZERO)
+#   define realloc(buf, size)   realloc(buf, size, M_VMWARE_TEMP, M_NOWAIT)
+#   define free(buf)            free(buf, M_VMWARE_TEMP)
+#   define strchr(s,c)          index(s,c)
+#   define strrchr(s,c)         rindex(s,c)
+
+#endif                                          /* } */
+
+/*
+ * Stub functions we provide.
+ */
+
+void Panic(const char *fmt, ...);
+
+char *Str_Strcpy(char *buf, const char *src, size_t maxSize);
+int Str_Vsnprintf(char *str, size_t size, const char *format,
+                  va_list arguments);
+char *Str_Vasprintf(size_t *length, const char *format,
+                    va_list arguments);
+char *Str_Asprintf(size_t *length, const char *Format, ...);
+
+/*
+ * Functions the driver must implement for the stubs.
+ */
+EXTERN void Debug(const char *fmt, ...);
+
+
+#endif /* __KERNELSTUBS_H__ */
--- kernel/linux-2.6.26.3/fs/vmhgfs/kernelStubsLinux.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/kernelStubsLinux.c	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,426 @@
+/*********************************************************
+ * Copyright (C) 2006 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * kernelStubsLinux.c
+ *
+ * This file contains implementations of common userspace functions in terms
+ * that the Linux kernel can understand.
+ */
+
+/* Must come before any kernel header file */
+#include "driver-config.h"
+#include "kernelStubs.h"
+#include "compat_kernel.h"
+#include "compat_page.h"
+#include "compat_sched.h"
+#include <linux/slab.h>
+
+#include "vm_assert.h"
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Panic --
+ *
+ *    Prints the debug message and stops the system.
+ *
+ * Results:
+ *    None.
+ *
+ * Side effects:
+ *    None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+void
+Panic(const char *fmt, ...) // IN
+{
+   va_list args;
+   char *result;
+
+   va_start(args, fmt);
+   result = Str_Vasprintf(NULL, fmt, args);
+   va_end(args);
+
+   if (result) {
+      printk(KERN_EMERG "%s", result);
+   }
+
+   BUG();
+
+   while (1); // Avoid compiler warning.
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * Str_Strcpy--
+ *
+ *    Wrapper for strcpy that checks for buffer overruns.
+ *
+ * Results:
+ *    Same as strcpy.
+ *
+ * Side effects:
+ *    None.
+ *
+ *----------------------------------------------------------------------
+ */
+
+char *
+Str_Strcpy(char *buf,       // OUT
+           const char *src, // IN
+           size_t maxSize)  // IN
+{
+   unsigned int *stack = (unsigned int *)&buf;
+   size_t len;
+
+   len = strlen(src);
+   if (len >= maxSize) {
+      Panic("%s:%d Buffer too small 0x%x\n", __FILE__,__LINE__,
+            stack[-1]);
+   }
+   return memcpy(buf, src, len + 1);
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * Str_Vsnprintf --
+ *
+ *	Compatability wrapper b/w different libc versions
+ *
+ * Results:
+ *	int - number of bytes written (not including NULL terminate character),
+ *	      -1 on overflow (insufficient space for NULL terminate is considered
+ *	      overflow)
+ *
+ *	NB: on overflow the buffer WILL be null terminated
+ *
+ * Side effects:
+ *	None
+ *
+ *----------------------------------------------------------------------
+ */
+
+int
+Str_Vsnprintf(char *str,          // OUT
+              size_t size,        // IN
+              const char *format, // IN
+              va_list arguments)  // IN
+{
+   int retval;
+   retval = vsnprintf(str, size, format, arguments);
+
+   /*
+    * Linux glibc 2.0.x returns -1 and null terminates (which we shouldn't
+    * be linking against), but glibc 2.1.x follows c99 and returns
+    * characters that would have been written.
+    */
+   if (retval >= size) {
+      return -1;
+   }
+   return retval;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Str_Vasprintf --
+ *
+ *    Allocate and format a string, using the GNU libc way to specify the
+ *    format (i.e. optionally allow the use of positional parameters)
+ *
+ * Results:
+ *    The allocated string on success (if 'length' is not NULL, *length
+ *       is set to the length of the allocated string)
+ *    NULL on failure
+ *
+ * Side effects:
+ *    None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+char *
+Str_Vasprintf(size_t *length,       // OUT
+              const char *format,   // IN
+              va_list arguments)    // IN
+{
+   /*
+    * Simple implementation of Str_Vasprintf when userlevel libraries are not
+    * available (e.g. for use in drivers). We just fallback to vsnprintf,
+    * doubling if we didn't have enough space.
+    */
+   unsigned int bufSize;
+   char *buf;
+   int retval;
+
+   bufSize = strlen(format);
+   buf = NULL;
+
+   do {
+      /*
+       * Initial allocation of strlen(format) * 2. Should this be tunable?
+       * XXX Yes, this could overflow and spin forever when you get near 2GB
+       *     allocations. I don't care. --rrdharan
+       */
+      va_list args2;
+
+      bufSize *= 2;
+      buf = realloc(buf, bufSize);
+
+      if (!buf) {
+         return NULL;
+      }
+
+      va_copy(args2, arguments);
+      retval = Str_Vsnprintf(buf, bufSize, format, args2);
+      va_end(args2);
+   } while (retval == -1);
+
+   if (length) {
+      *length = retval;
+   }
+
+   /*
+    * Try to trim the buffer here to save memory?
+    */
+   return buf;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Str_Asprintf --
+ *
+ *    Same as Str_Vasprintf(), but parameters are passed inline --hpreg
+ *
+ * Results:
+ *    Same as Str_Vasprintf()
+ *
+ * Side effects:
+ *    Same as Str_Vasprintf()
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+char *
+Str_Asprintf(size_t *length,       // OUT
+             const char *format,   // IN
+             ...)                  // IN
+{
+   va_list arguments;
+   char *result;
+
+   va_start(arguments, format);
+   result = Str_Vasprintf(length, format, arguments);
+   va_end(arguments);
+
+   return result;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * strdup --
+ *
+ *    Duplicates a string.
+ *
+ * Results:
+ *    A pointer to memory containing the duplicated string or NULL if no
+ *    memory was available.
+ *
+ * Side effects:
+ *    None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+char *
+strdup(const char *source) // IN
+{
+   char *target = NULL;
+   if (source) {
+
+      /*
+       * We call our special implementation of malloc() because the users of
+       * strdup() will call free(), and that'll decrement the pointer before
+       * freeing it. Thus, we need to make sure that the allocated block
+       * also stores the block length before the block itself (see malloc()
+       * below).
+       */
+      unsigned int len = strlen(source);
+      target = malloc(len + 1);
+      if (target) {
+         memcpy(target, source, len + 1);
+      }
+   }
+
+   return target;
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * malloc --
+ *
+ *      Allocate memory using kmalloc. There is no realloc
+ *      equivalent, so we roll our own by padding each allocation with
+ *      4 (or 8 for 64 bit guests) extra bytes to store the block length.
+ *
+ * Results:
+ *      Pointer to driver heap memory, offset by 4 (or 8)
+ *      bytes from the real block pointer.
+ *
+ * Side effects:
+ *      None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+void *
+malloc(size_t size) // IN
+{
+   size_t *ptr;
+   ptr = kmalloc(size + sizeof size, GFP_KERNEL);
+
+   if (ptr) {
+      *ptr++ = size;
+   }
+   return ptr;
+}
+
+/*
+ *---------------------------------------------------------------------------
+ *
+ * free --
+ *
+ *     Free memory allocated by a previous call to malloc, calloc or realloc.
+ *
+ * Results:
+ *     None.
+ *
+ * Side effects:
+ *     Calls kfree to free the real (base) pointer.
+ *
+ *---------------------------------------------------------------------------
+ */
+
+void
+free(void *mem) // IN
+{
+   if (mem) {
+      size_t *dataPtr = (size_t *)mem;
+      kfree(--dataPtr);
+   }
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * calloc --
+ *
+ *      Malloc and zero.
+ *
+ * Results:
+ *      Pointer to driver heap memory (see malloc, above).
+ *
+ * Side effects:
+ *      None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+void *
+calloc(size_t num, // IN
+       size_t len) // IN
+{
+   size_t size;
+   void *ptr;
+
+   size = num * len;
+   ptr = malloc(size);
+   if (ptr) {
+      memset(ptr, 0, size);
+   }
+   return ptr;
+}
+
+
+/*
+ *----------------------------------------------------------------------------
+ *
+ * realloc --
+ *
+ *      Since the driver heap has no realloc equivalent, we have to roll our
+ *      own. Fortunately, we can retrieve the block size of every block we
+ *      hand out since we stashed it at allocation time (see malloc above).
+ *
+ * Results:
+ *      Pointer to memory block valid for 'newSize' bytes, or NULL if
+ *      allocation failed.
+ *
+ * Side effects:
+ *      Could copy memory around.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+void *
+realloc(void* ptr,      // IN
+        size_t newSize) // IN
+{
+   void *newPtr;
+   size_t *dataPtr;
+   size_t length, lenUsed;
+
+   dataPtr = (size_t *)ptr;
+   length = ptr ? dataPtr[-1] : 0;
+   if (newSize == 0) {
+      if (ptr) {
+         free(ptr);
+         newPtr = NULL;
+      } else {
+         newPtr = malloc(newSize);
+      }
+   } else if (newSize == length) {
+      newPtr = ptr;
+   } else if ((newPtr = malloc(newSize))) {
+      if (length < newSize) {
+         lenUsed = length;
+      } else {
+         lenUsed = newSize;
+      }
+      memcpy(newPtr, ptr, lenUsed);
+      free(ptr);
+   }
+   return newPtr;
+}
+
+
--- kernel/linux-2.6.26.3/fs/vmhgfs/link.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/link.c	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,184 @@
+/*********************************************************
+ * Copyright (C) 2006 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * link.c --
+ *
+ * Symlink-specific inode operations for the filesystem portion of the
+ * vmhgfs driver.
+ */
+
+/* Must come before any kernel header file. */
+#include "driver-config.h"
+
+#include "compat_fs.h"
+#include "compat_namei.h"
+
+#include "module.h"
+#include "hgfsProto.h"
+#include "fsutil.h"
+#include "vm_assert.h"
+
+/* HGFS symlink operations. */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 13)
+static void *HgfsFollowlink(struct dentry *dentry,
+                            struct nameidata *nd);
+#else
+static int HgfsFollowlink(struct dentry *dentry,
+                          struct nameidata *nd);
+#endif
+static int HgfsReadlink(struct dentry *dentry,
+                        char __user *buffer,
+                        int buflen);
+
+/* HGFS inode operations structure for symlinks. */
+struct inode_operations HgfsLinkInodeOperations = {
+   .follow_link   = HgfsFollowlink,
+   .readlink      = HgfsReadlink,
+};
+
+/*
+ * HGFS symlink operations.
+ */
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * HgfsFollowlink --
+ *
+ *    Modeled after nfs_follow_link from a 2.4 kernel so it'll work
+ *    across all kernel revisions we care about.
+ *
+ * Results:
+ *    Returns zero on success, negative error on failure.
+ *
+ *    On new kernels: The error is returned as void *.
+ *    On older kernels: The error is returned as is.
+ *
+ * Side effects:
+ *    None
+ *
+ *----------------------------------------------------------------------
+ */
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 13)
+static void *
+HgfsFollowlink(struct dentry *dentry, // IN: Dentry containing link
+               struct nameidata *nd)  // OUT: Contains target dentry
+#else
+static int
+HgfsFollowlink(struct dentry *dentry, // IN: Dentry containing link
+               struct nameidata *nd)  // OUT: Contains target dentry
+#endif
+{
+   HgfsAttrInfo attr;
+   int error;
+
+   ASSERT(dentry);
+   ASSERT(nd);
+
+   if (!dentry) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsFollowlink: null input\n"));
+      error = -EINVAL;
+      goto out;
+   }
+
+   LOG(6, (KERN_DEBUG "VMware hgfs: HgfsFollowlink: calling "
+           "HgfsPrivateGetattr\n"));
+   attr.fileName = NULL;
+   error = HgfsPrivateGetattr(dentry, &attr);
+   if (!error) {
+
+      /* Let's make sure we got called on a symlink. */
+      if (attr.type != HGFS_FILE_TYPE_SYMLINK ||
+          attr.fileName == NULL) {
+         LOG(6, (KERN_DEBUG "VMware hgfs: HgfsFollowlink: got called "
+                 "on something that wasn't a symlink\n"));
+         error = -EINVAL;
+      } else {
+         LOG(6, (KERN_DEBUG "VMware hgfs: HgfsFollowlink: calling "
+                 "vfs_follow_link\n"));
+         error = vfs_follow_link(nd, attr.fileName);
+      }
+      kfree(attr.fileName);
+   }
+  out:
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 13)
+   return ERR_PTR(error);
+#else
+   return error;
+#endif
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * HgfsReadlink --
+ *
+ *    Modeled after nfs_read_link from a 2.4 kernel so it'll work
+ *    across all kernel revisions we care about.
+ *
+ * Results:
+ *    Returns zero on success, negative error on failure.
+ *
+ * Side effects:
+ *    None
+ *
+ *----------------------------------------------------------------------
+ */
+
+static int
+HgfsReadlink(struct dentry *dentry,  // IN:  Dentry containing link
+             char __user *buffer,    // OUT: User buffer to copy link into
+             int buflen)             // IN:  Length of user buffer
+
+{
+   HgfsAttrInfo attr;
+   int error;
+
+   ASSERT(dentry);
+   ASSERT(buffer);
+
+   if (!dentry) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsReadlink: null input\n"));
+      return -EINVAL;
+   }
+
+   LOG(6, (KERN_DEBUG "VMware hgfs: HgfsReadlink: calling "
+           "HgfsPrivateGetattr\n"));
+   attr.fileName = NULL;
+   error = HgfsPrivateGetattr(dentry, &attr);
+   if (!error) {
+
+      /* Let's make sure we got called on a symlink. */
+      if (attr.type != HGFS_FILE_TYPE_SYMLINK ||
+          attr.fileName == NULL) {
+         LOG(6, (KERN_DEBUG "VMware hgfs: HgfsReadlink: got called "
+                 "on something that wasn't a symlink\n"));
+         error = -EINVAL;
+      } else {
+         LOG(6, (KERN_DEBUG "VMware hgfs: HgfsReadlink: calling "
+                 "vfs_readlink\n"));
+         error = vfs_readlink(dentry, buffer, buflen, attr.fileName);
+      }
+      kfree(attr.fileName);
+   }
+   return error;
+}
--- kernel/linux-2.6.26.3/fs/vmhgfs/Makefile	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/Makefile	2008-09-03 09:57:35.000000000 -0500
@@ -0,0 +1,43 @@
+#############################################################
+# Copyright 1998 VMware, Inc.  All rights reserved. 
+#############################################################
+####
+#### This program is free software; you can redistribute it and/or modify it
+#### under the terms of the GNU General Public License as published by the
+#### Free Software Foundation version 2 and no later version.
+####
+#### This program is distributed in the hope that it will be useful, but
+#### WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+#### or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+#### for more details.
+####
+#### You should have received a copy of the GNU General Public License along
+#### with this program; if not, write to the Free Software Foundation, Inc.,
+#### 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+
+####
+####  VMware vmhgfs Makefile to be distributed externally
+####
+####
+
+obj-$(CONFIG_VMHGFS) += vmhgfs.o
+
+vmhgfs-objs := backdoor.o bdhandler.o \
+               cpName.o cpNameLinux.o cpNameLite.o dentry.o dir.o file.o \
+               filesystem.o fsutil.o hgfsBd.o hgfsUtil.o inode.o \
+               kernelStubsLinux.o link.o messageBackdoor.o message.o \
+               module.o page.o request.o rpcout.o staticEscape.o stubs.o \
+               super.o hgfsEscapeLinux.o
+
+#
+# On a 32-bit machine, strip out 64-bit backdoor code, and vice versa.
+#
+ifeq ($(CONFIG_X86_64),y)
+vmhgfs-objs += backdoorGcc64.o
+else
+vmhgfs-objs += backdoorGcc32.o
+endif
+
+EXTRA_CFLAGS += -DVMW_USING_KBUILD -DVMW_HAVE_SET_USER_NICE -DVMW_HAVE_EPOLL
+EXTRA_CFLAGS += -DVMW_SB_HAS_MAXBYTES -DVMW_KMEMCR_CTOR_HAS_3_ARGS -DVMW_GETSB_2618
+EXTRA_CFLAGS += -DVMW_STATFS_2618 -DVMW_INODE_2618
--- kernel/linux-2.6.26.3/fs/vmhgfs/messageBackdoor.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/messageBackdoor.c	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,628 @@
+/*********************************************************
+ * Copyright (C) 1999 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * messageBackdoor.c --
+ *
+ *    Second layer of the internal communication channel between guest
+ *    applications and vmware
+ *
+ *    Build a generic messaging system between guest applications and vmware.
+ *
+ *    The protocol is not completely symmetrical, because:
+ *     . basic requests can only be sent by guest applications (when vmware
+ *       wants to post a message to a guest application, the message will be
+ *       really fetched only when the guest application will poll for new
+ *       available messages)
+ *     . several guest applications can talk to vmware, while the contrary is
+ *       not true
+ *
+ *    Operations that are not atomic (in terms of number of backdoor calls)
+ *    can be aborted by vmware if a checkpoint/restore occurs in the middle of
+ *    such an operation. This layer takes care of retrying those operations.
+ */
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+
+#if defined(__KERNEL__) || defined(_KERNEL) || defined(KERNEL)
+#   include "kernelStubs.h"
+#else
+#   include <stdio.h>
+#   include <stdlib.h>
+#   include "debug.h"
+#endif
+
+#ifdef MESSAGE_DEBUG
+#   define MESSAGE_LOG(args) Debug args
+#else /* MESSAGE_DEBUG */
+#   define MESSAGE_LOG(args)
+#endif /* MESSAGE_DEBUG */
+
+
+#include "backdoor_def.h"
+#include "guest_msg_def.h"
+#include "backdoor.h"
+#include "message.h"
+
+
+/* The channel object */
+struct Message_Channel {
+   /* Identifier */
+   uint16 id;
+
+   /* Reception buffer */
+   /*  Data */
+   unsigned char *in;
+   /*  Allocated size */
+   size_t inAlloc;
+
+   /* The cookie */
+   uint32 cookieHigh;
+   uint32 cookieLow;
+};
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * MessageBackdoor_Open --
+ *
+ *    Open a communication channel
+ *
+ * Result:
+ *    An allocated Message_Channel on success
+ *    NULL on failure
+ *
+ * Side-effects:
+ *    None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+Message_Channel *
+MessageBackdoor_Open(uint32 proto) // IN
+{
+   Message_Channel *chan;
+   uint32 flags;
+   Backdoor_proto bp;
+
+   chan = (Message_Channel *)malloc(sizeof(*chan));
+   if (chan == NULL) {
+      MESSAGE_LOG(("Message: Not enough memory\n"));
+      goto error_quit;
+   }
+
+   flags = GUESTMSG_FLAG_COOKIE;
+retry:
+   /* IN: Type */
+   bp.in.cx.halfs.high = MESSAGE_TYPE_OPEN;
+   /* IN: Magic number of the protocol and flags */
+   bp.in.size = proto | flags;
+
+   bp.in.cx.halfs.low = BDOOR_CMD_MESSAGE;
+   Backdoor(&bp);
+
+   /* OUT: Status */
+   if ((bp.in.cx.halfs.high & MESSAGE_STATUS_SUCCESS) == 0) {
+      if (flags) {
+         /* Cookies not supported. Fall back to no cookie. --hpreg */
+         flags = 0;
+         goto retry;
+      }
+
+      MESSAGE_LOG(("Message: Unable to open a communication channel\n"));
+      goto error_quit;
+   }
+
+   /* OUT: Id and cookie */
+   chan->id = bp.in.dx.halfs.high;
+   chan->cookieHigh = bp.out.si.word;
+   chan->cookieLow = bp.out.di.word;
+
+   /* Initialize the channel */
+   chan->in = NULL;
+   chan->inAlloc = 0;
+
+   MESSAGE_LOG(("Message: Communication channel %u opened\n", chan->id));
+   return chan;
+
+error_quit:
+   free(chan);
+   chan = NULL;
+   return NULL;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * MessageBackdoor_GetReadEvent --
+ *
+ *    This allows higher levels of the IPC stack to use an event to detect
+ *    when a message has arrived. This allows an interrupt-model rather than
+ *    continually calling Message_Receive in a busy loop. This may only be supported
+ *    by some transports. The backdoor does not, so the IPC code will still
+ *    have to poll in those cases.
+ *
+ * Result:
+ *    Bool - whether this feature is supported by this transport.
+ *
+ * Side-effects:
+ *    None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+Bool 
+MessageBackdoor_GetReadEvent(Message_Channel *chan,  // IN
+                             int64 *event)           // OUT
+{
+   return FALSE;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * MessageBackdoor_Send --
+ *
+ *    Send a message over a communication channel
+ *
+ * Result:
+ *    TRUE on success
+ *    FALSE on failure (the message is discarded by vmware)
+ *
+ * Side-effects:
+ *    None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+Bool
+MessageBackdoor_Send(Message_Channel *chan,    // IN/OUT
+                     const unsigned char *buf, // IN
+                     size_t bufSize)           // IN
+{
+   const unsigned char *myBuf;
+   size_t myBufSize;
+   Backdoor_proto bp;
+
+retry:
+   myBuf = buf;
+   myBufSize = bufSize;
+
+   /*
+    * Send the size.
+    */
+
+   /* IN: Type */
+   bp.in.cx.halfs.high = MESSAGE_TYPE_SENDSIZE;
+   /* IN: Id and cookie */
+   bp.in.dx.halfs.high = chan->id;
+   bp.in.si.word = chan->cookieHigh;
+   bp.in.di.word = chan->cookieLow;
+   /* IN: Size */
+   bp.in.size = myBufSize;
+
+   bp.in.cx.halfs.low = BDOOR_CMD_MESSAGE;
+   Backdoor(&bp);
+
+   /* OUT: Status */
+   if ((bp.in.cx.halfs.high & MESSAGE_STATUS_SUCCESS) == 0) {
+      MESSAGE_LOG(("Message: Unable to send a message over the communication "
+                   "channel %u\n", chan->id));
+      return FALSE;
+   }
+
+   if (bp.in.cx.halfs.high & MESSAGE_STATUS_HB) {
+      /*
+       * High-bandwidth backdoor port supported. Send the message in one
+       * backdoor operation. --hpreg
+       */
+
+      if (myBufSize) {
+         Backdoor_proto_hb bphb;
+
+         bphb.in.bx.halfs.low = BDOORHB_CMD_MESSAGE;
+         bphb.in.bx.halfs.high = MESSAGE_STATUS_SUCCESS;
+         bphb.in.dx.halfs.high = chan->id;
+         bphb.in.bp.word = chan->cookieHigh;
+         bphb.in.dstAddr = chan->cookieLow;
+         bphb.in.size = myBufSize;
+         bphb.in.srcAddr = (uintptr_t) myBuf;
+         Backdoor_HbOut(&bphb);
+         if ((bphb.in.bx.halfs.high & MESSAGE_STATUS_SUCCESS) == 0) {
+            if ((bphb.in.bx.halfs.high & MESSAGE_STATUS_CPT) != 0) {
+               /* A checkpoint occurred. Retry the operation. --hpreg */
+               goto retry;
+            }
+
+            MESSAGE_LOG(("Message: Unable to send a message over the "
+                         "communication channel %u\n", chan->id));
+            return FALSE;
+         }
+      }
+   } else {
+      /*
+       * High-bandwidth backdoor port not supported. Send the message, 4 bytes
+       * at a time. --hpreg
+       */
+
+      for (;;) {
+         if (myBufSize == 0) {
+            /* We are done */
+	    break;
+         }
+
+         /* IN: Type */
+         bp.in.cx.halfs.high = MESSAGE_TYPE_SENDPAYLOAD;
+         /* IN: Id and cookie */
+         bp.in.dx.halfs.high = chan->id;
+         bp.in.si.word = chan->cookieHigh;
+         bp.in.di.word = chan->cookieLow;
+         /* IN: Piece of message */
+         /*
+          * Beware in case we are not allowed to read extra bytes beyond the
+          * end of the buffer.
+          */
+         switch (myBufSize) {
+         case 1:
+            bp.in.size = myBuf[0];
+            myBufSize -= 1;
+            break;
+         case 2:
+            bp.in.size = myBuf[0] | myBuf[1] << 8;
+            myBufSize -= 2;
+            break;
+         case 3:
+            bp.in.size = myBuf[0] | myBuf[1] << 8 | myBuf[2] << 16;
+            myBufSize -= 3;
+            break;
+         default:
+            bp.in.size = *(const uint32 *)myBuf;
+            myBufSize -= 4;
+            break;
+         }
+
+         bp.in.cx.halfs.low = BDOOR_CMD_MESSAGE;
+         Backdoor(&bp);
+
+         /* OUT: Status */
+         if ((bp.in.cx.halfs.high & MESSAGE_STATUS_SUCCESS) == 0) {
+            if ((bp.in.cx.halfs.high & MESSAGE_STATUS_CPT) != 0) {
+               /* A checkpoint occurred. Retry the operation. --hpreg */
+               goto retry;
+            }
+
+            MESSAGE_LOG(("Message: Unable to send a message over the "
+                         "communication channel %u\n", chan->id));
+            return FALSE;
+         }
+
+         myBuf += 4;
+      }
+   }
+
+   MESSAGE_LOG(("Message: Sent a message over the communication channel %u\n",
+                chan->id));
+
+   return TRUE;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * MessageBackdoor_Receive --
+ *
+ *    If vmware has posted a message for this channel, retrieve it
+ *
+ * Result:
+ *    TRUE on success (bufSize is 0 if there is no message)
+ *    FALSE on failure
+ *
+ * Side-effects:
+ *    None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+Bool
+MessageBackdoor_Receive(Message_Channel *chan, // IN/OUT
+                        unsigned char **buf,   // OUT
+                        size_t *bufSize)       // OUT
+{
+   Backdoor_proto bp;
+   size_t myBufSize;
+   unsigned char *myBuf;
+
+retry:
+   /*
+    * Is there a message waiting for our retrieval?
+    */
+
+   /* IN: Type */
+   bp.in.cx.halfs.high = MESSAGE_TYPE_RECVSIZE;
+   /* IN: Id and cookie */
+   bp.in.dx.halfs.high = chan->id;
+   bp.in.si.word = chan->cookieHigh;
+   bp.in.di.word = chan->cookieLow;
+
+   bp.in.cx.halfs.low = BDOOR_CMD_MESSAGE;
+   Backdoor(&bp);
+
+   /* OUT: Status */
+   if ((bp.in.cx.halfs.high & MESSAGE_STATUS_SUCCESS) == 0) {
+      MESSAGE_LOG(("Message: Unable to poll for messages over the "
+                   "communication channel %u\n", chan->id));
+      return FALSE;
+   }
+
+   if ((bp.in.cx.halfs.high & MESSAGE_STATUS_DORECV) == 0) {
+      /* No message to retrieve */
+      *bufSize = 0;
+      return TRUE;
+   }
+
+   /*
+    * Receive the size.
+    */
+
+   /* OUT: Type */
+   if (bp.in.dx.halfs.high != MESSAGE_TYPE_SENDSIZE) {
+      MESSAGE_LOG(("Message: Protocol error. Expected a "
+                   "MESSAGE_TYPE_SENDSIZE request from vmware\n"));
+      return FALSE;
+   }
+
+   /* OUT: Size */
+   myBufSize = bp.out.bx.word;
+
+   /*
+    * Allocate an extra byte for a trailing NUL character. The code that will
+    * deal with this message may not know about binary strings, and may expect
+    * a C string instead. --hpreg
+    */
+   if (myBufSize + 1 > chan->inAlloc) {
+      myBuf = (unsigned char *)realloc(chan->in, myBufSize + 1);
+      if (myBuf == NULL) {
+	 MESSAGE_LOG(("Message: Not enough memory to receive a message over "
+                      "the communication channel %u\n", chan->id));
+	 goto error_quit;
+      }
+
+      chan->in = myBuf;
+      chan->inAlloc = myBufSize + 1;
+   }
+   *bufSize = myBufSize;
+   myBuf = *buf = chan->in;
+
+   if (bp.in.cx.halfs.high & MESSAGE_STATUS_HB) {
+      /*
+       * High-bandwidth backdoor port supported. Receive the message in one
+       * backdoor operation. --hpreg
+       */
+
+      if (myBufSize) {
+         Backdoor_proto_hb bphb;
+
+         bphb.in.bx.halfs.low = BDOORHB_CMD_MESSAGE;
+         bphb.in.bx.halfs.high = MESSAGE_STATUS_SUCCESS;
+         bphb.in.dx.halfs.high = chan->id;
+         bphb.in.srcAddr = chan->cookieHigh;
+         bphb.in.bp.word = chan->cookieLow;
+         bphb.in.size = myBufSize;
+         bphb.in.dstAddr = (uintptr_t) myBuf;
+         Backdoor_HbIn(&bphb);
+         if ((bphb.in.bx.halfs.high & MESSAGE_STATUS_SUCCESS) == 0) {
+            if ((bphb.in.bx.halfs.high & MESSAGE_STATUS_CPT) != 0) {
+               /* A checkpoint occurred. Retry the operation. --hpreg */
+               goto retry;
+            }
+
+            MESSAGE_LOG(("Message: Unable to receive a message over the "
+                         "communication channel %u\n", chan->id));
+            goto error_quit;
+         }
+      }
+   } else {
+      /*
+       * High-bandwidth backdoor port not supported. Receive the message, 4
+       * bytes at a time. --hpreg
+       */
+
+      for (;;) {
+         if (myBufSize == 0) {
+            /* We are done */
+            break;
+         }
+
+         /* IN: Type */
+         bp.in.cx.halfs.high = MESSAGE_TYPE_RECVPAYLOAD;
+         /* IN: Id and cookie */
+         bp.in.dx.halfs.high = chan->id;
+         bp.in.si.word = chan->cookieHigh;
+         bp.in.di.word = chan->cookieLow;
+         /* IN: Status for the previous request (that succeeded) */
+         bp.in.size = MESSAGE_STATUS_SUCCESS;
+
+         bp.in.cx.halfs.low = BDOOR_CMD_MESSAGE;
+         Backdoor(&bp);
+
+         /* OUT: Status */
+         if ((bp.in.cx.halfs.high & MESSAGE_STATUS_SUCCESS) == 0) {
+            if ((bp.in.cx.halfs.high & MESSAGE_STATUS_CPT) != 0) {
+               /* A checkpoint occurred. Retry the operation. --hpreg */
+               goto retry;
+            }
+
+            MESSAGE_LOG(("Message: Unable to receive a message over the "
+                         "communication channel %u\n", chan->id));
+            goto error_quit;
+         }
+
+         /* OUT: Type */
+         if (bp.in.dx.halfs.high != MESSAGE_TYPE_SENDPAYLOAD) {
+            MESSAGE_LOG(("Message: Protocol error. Expected a "
+                         "MESSAGE_TYPE_SENDPAYLOAD from vmware\n"));
+            goto error_quit;
+         }
+
+         /* OUT: Piece of message */
+         /*
+          * Beware in case we are not allowed to write extra bytes beyond the
+          * end of the buffer. --hpreg
+          */
+         switch (myBufSize) {
+         case 1:
+            myBuf[0] = bp.out.bx.word & 0xff;
+            myBufSize -= 1;
+            break;
+         case 2:
+            myBuf[0] = bp.out.bx.word & 0xff;
+            myBuf[1] = (bp.out.bx.word >> 8) & 0xff;
+            myBufSize -= 2;
+            break;
+         case 3:
+            myBuf[0] = bp.out.bx.word & 0xff;
+            myBuf[1] = (bp.out.bx.word >> 8) & 0xff;
+            myBuf[2] = (bp.out.bx.word >> 16) & 0xff;
+            myBufSize -= 3;
+            break;
+         default:
+            *(uint32 *)myBuf = bp.out.bx.word;
+            myBufSize -= 4;
+            break;
+         }
+
+         myBuf += 4;
+      }
+   }
+
+   /* Write a trailing NUL just after the message. --hpreg */
+   chan->in[*bufSize] = '\0';
+
+   /* IN: Type */
+   bp.in.cx.halfs.high = MESSAGE_TYPE_RECVSTATUS;
+   /* IN: Id and cookie */
+   bp.in.dx.halfs.high = chan->id;
+   bp.in.si.word = chan->cookieHigh;
+   bp.in.di.word = chan->cookieLow;
+   /* IN: Status for the previous request (that succeeded) */
+   bp.in.size = MESSAGE_STATUS_SUCCESS;
+
+   bp.in.cx.halfs.low = BDOOR_CMD_MESSAGE;
+   Backdoor(&bp);
+
+   /* OUT: Status */
+   if ((bp.in.cx.halfs.high & MESSAGE_STATUS_SUCCESS) == 0) {
+      if ((bp.in.cx.halfs.high & MESSAGE_STATUS_CPT) != 0) {
+	 /* A checkpoint occurred. Retry the operation. --hpreg */
+	 goto retry;
+      }
+
+      MESSAGE_LOG(("Message: Unable to receive a message over the "
+                   "communication channel %u\n", chan->id));
+      goto error_quit;
+   }
+
+   return TRUE;
+
+error_quit:
+   /* IN: Type */
+   if (myBufSize == 0) {
+      bp.in.cx.halfs.high = MESSAGE_TYPE_RECVSTATUS;
+   } else {
+      bp.in.cx.halfs.high = MESSAGE_TYPE_RECVPAYLOAD;
+   }
+   /* IN: Id and cookie */
+   bp.in.dx.halfs.high = chan->id;
+   bp.in.si.word = chan->cookieHigh;
+   bp.in.di.word = chan->cookieLow;
+   /* IN: Status for the previous request (that failed) */
+   bp.in.size = 0;
+
+   bp.in.cx.halfs.low = BDOOR_CMD_MESSAGE;
+   Backdoor(&bp);
+
+   /* OUT: Status */
+   if ((bp.in.cx.halfs.high & MESSAGE_STATUS_SUCCESS) == 0) {
+      MESSAGE_LOG(("Message: Unable to signal an error of reception over the "
+                   "communication channel %u\n", chan->id));
+      return FALSE;
+   }
+
+   return FALSE;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * MessageBackdoor_Close --
+ *
+ *    Close a communication channel
+ *
+ * Result:
+ *    TRUE on success, the channel is destroyed
+ *    FALSE on failure
+ *
+ * Side-effects:
+ *    None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+Bool
+MessageBackdoor_Close(Message_Channel *chan) // IN/OUT
+{
+   Backdoor_proto bp;
+   Bool ret = TRUE;
+
+   /* IN: Type */
+   bp.in.cx.halfs.high = MESSAGE_TYPE_CLOSE;
+   /* IN: Id and cookie */
+   bp.in.dx.halfs.high = chan->id;
+   bp.in.si.word = chan->cookieHigh;
+   bp.in.di.word = chan->cookieLow;
+
+   bp.in.cx.halfs.low = BDOOR_CMD_MESSAGE;
+   Backdoor(&bp);
+
+   /* OUT: Status */
+   if ((bp.in.cx.halfs.high & MESSAGE_STATUS_SUCCESS) == 0) {
+      MESSAGE_LOG(("Message: Unable to close the communication channel %u\n",
+                  chan->id));
+      ret = FALSE;
+   } else {
+      MESSAGE_LOG(("Message: Communication channel %u closed\n", chan->id));
+   }
+
+   free(chan->in);
+   chan->in = NULL;
+
+   free(chan);
+   return ret;
+}
+
+#ifdef __cplusplus
+}
+#endif
--- kernel/linux-2.6.26.3/fs/vmhgfs/message.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/message.c	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,298 @@
+/*********************************************************
+ * Copyright (C) 1999 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * message.c --
+ *
+ *    Second layer of the internal communication channel between guest
+ *    applications and vmware
+ *
+ *    Build a generic messaging system between guest applications and vmware.
+ *
+ *    The protocol is not completely symmetrical, because:
+ *     . basic requests can only be sent by guest applications (when vmware
+ *       wants to post a message to a guest application, the message will be
+ *       really fetched only when the guest application will poll for new
+ *       available messages)
+ *     . several guest applications can talk to vmware, while the contrary is
+ *       not true
+ *
+ *    Operations that are not atomic (in terms of number of backdoor calls)
+ *    can be aborted by vmware if a checkpoint/restore occurs in the middle of
+ *    such an operation. This layer takes care of retrying those operations.
+ */
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+#if defined(__KERNEL__) || defined(_KERNEL) || defined(KERNEL)
+#   include "kernelStubs.h"
+#else
+#   include <stdio.h>
+#   include <stdlib.h>
+#   include "debug.h"
+#endif
+
+#include "backdoor_def.h"
+#include "guest_msg_def.h"
+#include "backdoor.h"
+#include "message.h"
+
+static MessageOpenProcType externalOpenProc = NULL;
+static MessageGetReadEventProcType externalGetReadEventProc = NULL;
+static MessageSendProcType externalSendProc = NULL;
+static MessageReceiveProcType externalReceiveProc = NULL;
+static MessageCloseProcType externalCloseProc = NULL;
+
+/*
+ * Currently, the default implementation is to use the backdoor. Soon,
+ * this will not be the default, as we will explicitly set it when we
+ * decide to use the backdoor.
+ */
+EXTERN Message_Channel *MessageBackdoor_Open(uint32 proto);
+
+EXTERN Bool MessageBackdoor_GetReadEvent(Message_Channel *chan,
+                                         int64 *event);
+
+EXTERN Bool MessageBackdoor_Send(Message_Channel *chan,
+                                 const unsigned char *buf,
+                                 size_t bufSize);
+
+EXTERN Bool MessageBackdoor_Receive(Message_Channel *chan,
+                                    unsigned char **buf,
+                                    size_t *bufSize);
+
+EXTERN Bool MessageBackdoor_Close(Message_Channel *chan);
+
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Message_SetTransport --
+ *
+ *    This tells the message layer to use an alternate transport
+ *    for messages. By default, we use the backdoor, so this function
+ *    overrides that default at runtime and switches everything over to
+ *    an alternate transport.
+ *
+ * Result:
+ *    None
+ *
+ * Side-effects:
+ *    None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+void 
+Message_SetTransport(MessageOpenProcType openProc,                   // IN
+                     MessageGetReadEventProcType getReadEeventProc,  // IN
+                     MessageSendProcType sendProc,                   // IN
+                     MessageReceiveProcType receiveProc,             // IN
+                     MessageCloseProcType closeProc)                 // IN
+{
+   externalOpenProc = openProc;
+   externalGetReadEventProc = getReadEeventProc;
+   externalSendProc = sendProc;
+   externalReceiveProc = receiveProc;
+   externalCloseProc = closeProc;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Message_Open --
+ *
+ *    Open a communication channel
+ *
+ * Result:
+ *    An allocated Message_Channel on success
+ *    NULL on failure
+ *
+ * Side-effects:
+ *    None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+Message_Channel *
+Message_Open(uint32 proto) // IN
+{
+   /*
+    * If there is an alterate backdoor implementation, then call that.
+    */
+   if (NULL != externalOpenProc) {
+      return((*externalOpenProc)(proto));
+   }
+
+   /*
+    * Otherwise, we default to the backdoor.
+    */
+   return(MessageBackdoor_Open(proto));
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Message_GetReadEvent --
+ *
+ *    This allows higher levels of the IPC stack to use an event to detect
+ *    when a message has arrived. This allows an asynchronous, event-based-model 
+ *    rather than continually calling Message_Receive in a busy loop. This may 
+ *    only be supported by some transports. The backdoor does not, so the IPC
+ *    code will still have to poll in those cases.
+ *
+ * Result:
+ *    Bool - whether this feature is supported by this transport.
+ *
+ * Side-effects:
+ *    None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+Bool 
+Message_GetReadEvent(Message_Channel *chan,  // IN
+                     int64 *event)           // OUT
+{
+   /*
+    * If there is an alterate backdoor implementation, then call that.
+    */
+   if (NULL != externalGetReadEventProc) {
+      return((*externalGetReadEventProc)(chan, event));
+   }
+
+   /*
+    * Otherwise, we default to the backdoor.
+    */
+   return(MessageBackdoor_GetReadEvent(chan, event));
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Message_Send --
+ *
+ *    Send a message over a communication channel
+ *
+ * Result:
+ *    TRUE on success
+ *    FALSE on failure (the message is discarded by vmware)
+ *
+ * Side-effects:
+ *    None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+Bool
+Message_Send(Message_Channel *chan,    // IN/OUT
+             const unsigned char *buf, // IN
+             size_t bufSize)           // IN
+{
+   /*
+    * If there is an alterate backdoor implementation, then call that.
+    */
+   if (NULL != externalSendProc) {
+      return((*externalSendProc)(chan, buf, bufSize));
+   }
+
+   /*
+    * Otherwise, we default to the backdoor.
+    */
+   return(MessageBackdoor_Send(chan, buf, bufSize));
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Message_Receive --
+ *
+ *    If vmware has posted a message for this channel, retrieve it
+ *
+ * Result:
+ *    TRUE on success (bufSize is 0 if there is no message)
+ *    FALSE on failure
+ *
+ * Side-effects:
+ *    None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+Bool
+Message_Receive(Message_Channel *chan, // IN/OUT
+                unsigned char **buf,   // OUT
+                size_t *bufSize)       // OUT
+{
+   /*
+    * If there is an alterate backdoor implementation, then call that.
+    */
+   if (NULL != externalReceiveProc) {
+      return((*externalReceiveProc)(chan, buf, bufSize));
+   }
+
+   /*
+    * Otherwise, we default to the backdoor.
+    */
+   return(MessageBackdoor_Receive(chan, buf, bufSize));
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Message_Close --
+ *
+ *    Close a communication channel
+ *
+ * Result:
+ *    TRUE on success, the channel is destroyed
+ *    FALSE on failure
+ *
+ * Side-effects:
+ *    None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+Bool
+Message_Close(Message_Channel *chan) // IN/OUT
+{
+   /*
+    * If there is an alterate backdoor implementation, then call that.
+    */
+   if (NULL != externalCloseProc) {
+      return((*externalCloseProc)(chan));
+   }
+
+   /*
+    * Otherwise, we default to the backdoor.
+    */
+   return(MessageBackdoor_Close(chan));
+}
+
+#ifdef __cplusplus
+}
+#endif
--- kernel/linux-2.6.26.3/fs/vmhgfs/message.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/message.h	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,106 @@
+/*********************************************************
+ * Copyright (C) 1999 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * message.h --
+ *
+ *    Second layer of the internal communication channel between guest
+ *    applications and vmware
+ */
+
+#ifndef __MESSAGE_H__
+#   define __MESSAGE_H__
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+#include "vm_basic_types.h"
+
+
+typedef struct Message_Channel Message_Channel;
+
+
+/*
+ * These functions must be implemented by any external Message
+ * transport implementation. Some examples include crossTalk,
+ * a network socket, or a Microsoft Hypervisor backdoor.
+ *
+ * These external functions mirror the same corresponding Message_* 
+ * functions below.
+ */
+typedef Message_Channel *(*MessageOpenProcType)(uint32 proto);
+
+typedef Bool (*MessageGetReadEventProcType)(Message_Channel *chan,
+                                            int64 *readEvent);
+
+typedef Bool (*MessageSendProcType)(Message_Channel *chan,
+                                    const unsigned char *buf,
+                                    size_t bufSize);
+typedef Bool (*MessageReceiveProcType)(Message_Channel *chan,
+                                       unsigned char **buf,
+                                       size_t *bufSize);
+typedef Bool (*MessageCloseProcType)(Message_Channel *chan);
+
+
+/*
+ * This tells the message layer to use an alternate transport
+ * for messages. By default, we use the backdoor, so this function
+ * overrides that default at runtime and switches everything over to
+ * an alternate transport.
+ */
+void Message_SetTransport(MessageOpenProcType openProc,
+                          MessageGetReadEventProcType getReadEeventProc,
+                          MessageSendProcType sendProc,
+                          MessageReceiveProcType receiveProc,
+                          MessageCloseProcType closeProc);
+
+void MessageStub_RegisterTransport(void);
+
+Message_Channel *
+Message_Open(uint32 proto); // IN
+
+/*
+ * This allows higher levels of the IPC stack to use an event to detect
+ * when a message has arrived. This allows an interrupt-model rather than
+ * continually calling Message_Receive in a busy loop. This may only be supported
+ * by some transports. The backdoor does not, so the IPC code will still
+ * have to poll in those cases.
+ */
+Bool
+Message_GetReadEvent(Message_Channel *chan,    // IN
+                     int64 *event);            // OUT
+
+Bool
+Message_Send(Message_Channel *chan,    // IN/OUT
+             const unsigned char *buf, // IN
+             size_t bufSize);          // IN
+
+Bool
+Message_Receive(Message_Channel *chan, // IN/OUT
+                unsigned char **buf,   // OUT
+                size_t *bufSize);      // OUT
+
+Bool
+Message_Close(Message_Channel *chan); // IN/OUT
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif /* __MESSAGE_H__ */
--- kernel/linux-2.6.26.3/fs/vmhgfs/module.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/module.c	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,107 @@
+/*********************************************************
+ * Copyright (C) 2006 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * module.c --
+ *
+ * Module-specific components of the vmhgfs driver.
+ */
+
+/* Must come before any kernel header file. */
+#include "driver-config.h"
+
+#include <linux/errno.h>
+#include "compat_module.h"
+
+#include "filesystem.h"
+#include "module.h"
+#include "vmhgfs_version.h"
+
+#ifdef VMX86_DEVEL
+/*
+ * Logging is available only in devel build.
+ */
+
+int LOGLEVEL_THRESHOLD = 4;
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 9)
+module_param(LOGLEVEL_THRESHOLD, int, 0444);
+#else
+MODULE_PARM(LOGLEVEL_THRESHOLD, "i");
+#endif
+
+MODULE_PARM_DESC(LOGLEVEL_THRESHOLD, "Set verbosity (0 means no log, 10 means very verbose, 4 is default)");
+#endif
+
+/* Module information. */
+MODULE_AUTHOR("VMware, Inc.");
+MODULE_DESCRIPTION("VMware Host/Guest File System");
+MODULE_VERSION(VMHGFS_DRIVER_VERSION_STRING);
+MODULE_LICENSE("GPL v2");
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * init_module --
+ *
+ *    linux module entry point. Called by /sbin/insmod command.
+ *    Sets up internal state and registers the hgfs filesystem
+ *    with the kernel.
+ *
+ * Results:
+ *    Returns 0 on success, an error on failure.
+ *
+ * Side effects:
+ *    None
+ *
+ *----------------------------------------------------------------------
+ */
+
+int
+init_module(void)
+{
+   return HgfsInitFileSystem() ? 0 : -EBUSY;
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * cleanup_module --
+ *
+ *    Called by /sbin/rmmod. Unregisters filesystem with kernel,
+ *    cleans up internal state, and unloads module.
+ *
+ *    Note: for true kernel 2.4 compliance, this should be
+ *    "module_exit".
+ *
+ * Results:
+ *    None
+ *
+ * Side effects:
+ *    None
+ *
+ *----------------------------------------------------------------------
+ */
+
+void
+cleanup_module(void)
+{
+   HgfsCleanupFileSystem();
+}
--- kernel/linux-2.6.26.3/fs/vmhgfs/module.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/module.h	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,262 @@
+/*********************************************************
+ * Copyright (C) 2006 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * module.h --
+ *
+ * Global module definitions for the entire vmhgfs driver.
+ */
+
+#ifndef _HGFS_DRIVER_MODULE_H_
+#define _HGFS_DRIVER_MODULE_H_
+
+/* Must come before any kernel header file. */
+#include "driver-config.h"
+
+#include <asm/atomic.h>
+#include "compat_completion.h"
+#include "compat_fs.h"
+#include "compat_kthread.h"
+#include "compat_semaphore.h"
+#include "compat_slab.h"
+#include "compat_spinlock.h"
+#include "compat_version.h"
+
+#include "rpcout.h"
+#include "hgfsProto.h"
+
+#ifndef __user
+#define __user
+#endif
+
+/* Logging stuff. */
+#ifdef VMX86_DEVEL
+extern int LOGLEVEL_THRESHOLD;
+
+#define LOG(level, args) ((void) (LOGLEVEL_THRESHOLD >= (level) ? (printk args) : 0))
+#else
+#define LOG(level, args)
+#endif
+
+/* Blocksize to be set in superblock. (XXX how is this used?) */
+#define HGFS_BLOCKSIZE 1024
+
+/* The amount of time we'll wait for the backdoor to process our request. */
+#define HGFS_REQUEST_TIMEOUT (30 * HZ)
+
+/*
+ * Inode number of the root inode. We set this to be non-zero because,
+ * according to glibc source, when the returned inode number in a dirent
+ * is zero, that entry has been deleted. This is presumably when you've done
+ * an opendir, the file is deleted, and then you do a readdir. The point is
+ * that if the root inode is zero, aliases to it (such as '.' and "..") won't
+ * appear in a directory listing.
+ */
+#define HGFS_ROOT_INO 1
+
+/* Leave HGFS_ROOT_INO and below out of inode number generation. */
+#define HGFS_RESERVED_INO HGFS_ROOT_INO + 1
+
+/*
+ * Macros for accessing members that are private to this code in
+ * sb/inode/file structs.
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 42)
+#define HGFS_SET_SB_TO_COMMON(sb, common) do { (sb)->u.generic_sbp = (common); } while (0)
+#define HGFS_SB_TO_COMMON(sb)             ((HgfsSuperInfo *)(sb)->u.generic_sbp)
+#else
+#define HGFS_SET_SB_TO_COMMON(sb, common) do { (sb)->s_fs_info = (common); } while (0)
+#define HGFS_SB_TO_COMMON(sb)             ((HgfsSuperInfo *)(sb)->s_fs_info)
+#endif
+
+#ifdef VMW_EMBED_INODE
+#define INODE_GET_II_P(_inode) container_of(_inode, HgfsInodeInfo, inode)
+#elif defined(VMW_INODE_2618)
+#define INODE_GET_II_P(inode) ((HgfsInodeInfo *)(inode)->i_private)
+#else
+#define INODE_GET_II_P(inode) ((HgfsInodeInfo *)(inode)->u.generic_ip)
+#endif
+
+#if defined(VMW_INODE_2618)
+#define INODE_SET_II_P(inode, info) do { (inode)->i_private = (info); } while (0)
+#else
+#define INODE_SET_II_P(inode, info) do { (inode)->u.generic_ip = (info); } while (0)
+#endif
+
+/* 2.5.x kernels support nanoseconds timestamps. */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 48)
+#define HGFS_DECLARE_TIME(unixtm) time_t unixtm
+#define HGFS_EQUAL_TIME(unixtm1, unixtm2) (unixtm1 == unixtm2)
+#define HGFS_SET_TIME(unixtm,nttime) HgfsConvertFromNtTime(&unixtm, nttime)
+#define HGFS_GET_TIME(unixtm) HgfsConvertToNtTime(unixtm, 0L)
+#define HGFS_GET_CURRENT_TIME() HgfsConvertToNtTime(CURRENT_TIME, 0L)
+/*
+ * Beware! This macro returns list of two elements. Do not add braces around.
+ */
+#define HGFS_PRINT_TIME(unixtm) unixtm, 0L
+#else
+#define HGFS_DECLARE_TIME(unixtm) struct timespec unixtm
+#define HGFS_EQUAL_TIME(unixtm1, unixtm2) timespec_equal(&unixtm1, &unixtm2)
+#define HGFS_SET_TIME(unixtm,nttime) HgfsConvertFromNtTimeNsec(&unixtm, nttime)
+#define HGFS_GET_TIME(unixtm) HgfsConvertTimeSpecToNtTime(&unixtm)
+#define HGFS_GET_CURRENT_TIME() ({                                     \
+                                    struct timespec ct = CURRENT_TIME; \
+                                    HGFS_GET_TIME(ct);                 \
+                                 })
+
+/*
+ * Beware! This macro returns list of two elements. Do not add braces around.
+ */
+#define HGFS_PRINT_TIME(unixtm) unixtm.tv_sec, unixtm.tv_nsec
+#endif
+
+/*
+ * The writeback support we're using (set_page_dirty()) was added in
+ * 2.5.12, so we only support writeback from then on.
+ */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 5, 12)
+#define HGFS_ENABLE_WRITEBACK
+#endif
+
+/*
+ * For files opened in our actual Host/Guest filesystem, the
+ * file->private_data field is used for storing the HgfsFileInfo of the
+ * opened file. This macro is for accessing the file information from the
+ * file *.
+ */
+#define FILE_SET_FI_P(file, info) do { (file)->private_data = info; } while (0)
+#define FILE_GET_FI_P(file)         ((HgfsFileInfo *)(file)->private_data)
+
+/*
+ * When waking up the request handler thread, these are the possible operations
+ * one can ask it to perform.
+ */
+#define HGFS_REQ_THREAD_SEND  (1 << 0)
+#define HGFS_REQ_THREAD_EXIT  (1 << 1)
+
+/* Data kept in each superblock in sb->u. */
+typedef struct HgfsSuperInfo {
+   uid_t uid;                       /* UID of user who mounted this fs. */
+   Bool uidSet;                     /* Was the UID specified at mount-time? */
+   gid_t gid;                       /* GID of user who mounted this fs. */
+   Bool gidSet;                     /* Was the GID specified at mount-time? */
+   mode_t fmask;                    /* File permission mask. */
+   mode_t dmask;                    /* Directory permission mask. */
+   uint32 ttl;                      /* Maximum dentry age (in ticks). */
+   char *shareName;                 /* Mounted share name. */
+   size_t shareNameLen;             /* To avoid repeated strlen() calls. */
+} HgfsSuperInfo;
+
+/*
+ * HGFS specific per-inode data.
+ */
+typedef struct HgfsInodeInfo {
+#ifdef VMW_EMBED_INODE
+   /* Embedded inode. */
+   struct inode inode;
+#endif
+
+   /* Was the inode number for this inode generated via iunique()? */
+   Bool isFakeInodeNumber;
+
+   /* Is this a fake inode created in HgfsCreate that has yet to be opened? */
+   Bool createdAndUnopened;
+
+   /* Is this inode referenced by HGFS? (needed by HgfsInodeLookup()) */
+   Bool isReferencedInode;
+
+   /* List of open files for this inode. */
+   struct list_head files;
+} HgfsInodeInfo;
+
+/*
+ * HGFS specific per-file data.
+ */
+typedef struct HgfsFileInfo {
+
+   /* Links to place this object on the inode's list of open files. */
+   struct list_head list;
+
+   /* Handle to be sent to the server. Needed for writepage(). */
+   HgfsHandle handle;
+
+   /*
+    * Mode with which handle was opened. When we reuse a handle, we need to
+    * choose one with appropriate permissions.
+    */
+   HgfsOpenMode mode;
+} HgfsFileInfo;
+
+
+/*
+ * Global synchronization primitives.
+ */
+
+/*
+ * We use hgfsBigLock to protect certain global structures that are locked for
+ * a very short amount of time.
+ */
+extern spinlock_t hgfsBigLock;
+
+/*
+ * The request handler thread uses hgfsReqThreadWait to wake up and handle
+ * IO. Possible operations include:
+ *   -Sending outgoing HGFS requests.
+ *   -Shutting down the request handler thread.
+ *
+ * Finally, we use hgfsReqThread to synchronize the stopping of the
+ * backdoor handler thread.
+ */
+extern long hgfsReqThreadFlags;
+extern wait_queue_head_t hgfsReqThreadWait;
+extern struct task_struct *hgfsReqThread;
+
+/* Hgfs filesystem structs. */
+extern struct super_operations HgfsSuperOperations;
+extern struct dentry_operations HgfsDentryOperations;
+extern struct inode_operations HgfsFileInodeOperations;
+extern struct inode_operations HgfsDirInodeOperations;
+extern struct inode_operations HgfsLinkInodeOperations;
+extern struct file_operations HgfsFileFileOperations;
+extern struct file_operations HgfsDirFileOperations;
+extern struct address_space_operations HgfsAddressSpaceOperations;
+
+/* Other global state. */
+extern compat_kmem_cache *hgfsReqCache;
+extern compat_kmem_cache *hgfsInodeCache;
+extern RpcOut *hgfsRpcOut;
+extern unsigned int hgfsIdCounter;
+extern struct list_head hgfsReqsUnsent;
+
+extern atomic_t hgfsVersionOpen;
+extern atomic_t hgfsVersionRead;
+extern atomic_t hgfsVersionWrite;
+extern atomic_t hgfsVersionClose;
+extern atomic_t hgfsVersionSearchOpen;
+extern atomic_t hgfsVersionSearchRead;
+extern atomic_t hgfsVersionSearchClose;
+extern atomic_t hgfsVersionGetattr;
+extern atomic_t hgfsVersionSetattr;
+extern atomic_t hgfsVersionCreateDir;
+extern atomic_t hgfsVersionDeleteFile;
+extern atomic_t hgfsVersionDeleteDir;
+extern atomic_t hgfsVersionRename;
+extern atomic_t hgfsVersionQueryVolumeInfo;
+extern atomic_t hgfsVersionCreateSymlink;
+
+#endif // _HGFS_DRIVER_MODULE_H_
--- kernel/linux-2.6.26.3/fs/vmhgfs/page.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/page.c	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,847 @@
+/*********************************************************
+ * Copyright (C) 2006 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * page.c --
+ *
+ * Address space operations for the filesystem portion of the vmhgfs driver.
+ */
+
+/* Must come before any kernel header file. */
+#include "driver-config.h"
+
+#include <linux/pagemap.h>
+
+#include "compat_mm.h"
+#include "compat_page-flags.h"
+#include "compat_fs.h"
+#include "compat_kernel.h"
+#ifdef HGFS_ENABLE_WRITEBACK
+#include <linux/writeback.h>
+#endif
+
+#include "cpName.h"
+#include "hgfsProto.h"
+#include "module.h"
+#include "request.h"
+#include "hgfsUtil.h"
+#include "fsutil.h"
+#include "inode.h"
+#include "vm_assert.h"
+#include "vm_basic_types.h"
+
+/* Private functions. */
+static int HgfsDoWrite(HgfsHandle handle,
+                       const char *buf,
+                       size_t count,
+                       loff_t offset);
+static int HgfsDoRead(HgfsHandle handle,
+                      char *buf,
+                      size_t count,
+                      loff_t offset);
+static int HgfsDoReadpage(HgfsHandle handle,
+                          struct page *page,
+                          unsigned pageFrom,
+                          unsigned pageTo);
+static int HgfsDoWritepage(HgfsHandle handle,
+                           struct page *page,
+                           unsigned pageFrom,
+                           unsigned pageTo);
+
+/* HGFS address space operations. */
+static int HgfsReadpage(struct file *file,
+                        struct page *page);
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 5, 52)
+static int HgfsWritepage(struct page *page,
+                         struct writeback_control *wbc);
+#else
+static int HgfsWritepage(struct page *page);
+#endif
+static int HgfsPrepareWrite(struct file *file,
+                            struct page *page,
+                            unsigned pageFrom,
+                            unsigned pageTo);
+static int HgfsCommitWrite(struct file *file,
+                           struct page *page,
+                           unsigned pageFrom,
+                           unsigned pageTo);
+
+/* HGFS address space operations structure. */
+struct address_space_operations HgfsAddressSpaceOperations = {
+   .readpage      = HgfsReadpage,
+   .writepage     = HgfsWritepage,
+   .prepare_write = HgfsPrepareWrite,
+   .commit_write  = HgfsCommitWrite,
+#ifdef HGFS_ENABLE_WRITEBACK
+   .set_page_dirty = __set_page_dirty_nobuffers,
+#endif
+};
+
+
+/*
+ * Private functions.
+ */
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * HgfsDoRead --
+ *
+ *    Do one read request. Called by HgfsReadpage, possibly multiple times
+ *    if the size of the read is too big to be handled by one server request.
+ *
+ *    We send a "Read" request to the server with the given handle.
+ *
+ *    It is assumed that this function is never called with a larger read than
+ *    what can be sent in one request.
+ *
+ * Results:
+ *    Returns the number of bytes read on success, or an error on failure.
+ *
+ * Side effects:
+ *    None.
+ *
+ *----------------------------------------------------------------------------
+ */
+
+static int
+HgfsDoRead(HgfsHandle handle,  // IN:  Handle for this file
+           char *buf,          // OUT: Buffer to copy data into
+           size_t count,       // IN:  Number of bytes to read
+           loff_t offset)      // IN:  Offset at which to read
+{
+   HgfsReq *req;
+   HgfsOp opUsed;
+   int result = 0;
+   uint32 actualSize = 0;
+   char *payload = NULL;
+   HgfsStatus replyStatus;
+
+   ASSERT(buf);
+
+   req = HgfsGetNewRequest();
+   if (!req) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsDoRead: out of memory while "
+              "getting new request\n"));
+      result = -ENOMEM;
+      goto out;
+   }
+
+ retry:
+   opUsed = atomic_read(&hgfsVersionRead);
+   if (opUsed == HGFS_OP_READ_V3) {
+      HgfsRequest *header;
+      HgfsRequestReadV3 *request;
+
+      header = (HgfsRequest *)(HGFS_REQ_PAYLOAD(req));
+      header->id = req->id;
+      header->op = opUsed;
+
+      request = (HgfsRequestReadV3 *)(HGFS_REQ_PAYLOAD_V3(req));
+      request->file = handle;
+      request->offset = offset;
+      request->requiredSize = count;
+      request->reserved = 0;
+      req->payloadSize = HGFS_REQ_PAYLOAD_SIZE_V3(request);
+   } else {
+      HgfsRequestRead *request;
+
+      request = (HgfsRequestRead *)(HGFS_REQ_PAYLOAD(req));
+      request->header.id = req->id;
+      request->header.op = opUsed;
+      request->file = handle;
+      request->offset = offset;
+      request->requiredSize = count;
+      req->payloadSize = sizeof *request;
+   }
+
+
+   /* Send the request and process the reply. */
+   result = HgfsSendRequest(req);
+   if (result == 0) {
+      /* Get the reply. */
+      replyStatus = HgfsReplyStatus(req);
+      result = HgfsStatusConvertToLinux(replyStatus);
+
+      switch (result) {
+      case 0:
+         if (opUsed == HGFS_OP_READ_V3) {
+            actualSize = ((HgfsReplyReadV3 *)HGFS_REP_PAYLOAD_V3(req))->actualSize;
+            payload = ((HgfsReplyReadV3 *)HGFS_REP_PAYLOAD_V3(req))->payload;
+         } else {
+            actualSize = ((HgfsReplyRead *)HGFS_REQ_PAYLOAD(req))->actualSize;
+            payload = ((HgfsReplyRead *)HGFS_REQ_PAYLOAD(req))->payload;
+         }
+
+         /* Sanity check on read size. */
+         if (actualSize > count) {
+            LOG(4, (KERN_DEBUG "VMware hgfs: HgfsDoRead: read too big!\n"));
+            result = -EPROTO;
+            goto out;
+         }
+
+         if (!actualSize) {
+            /* We got no bytes, so don't need to copy to user. */
+            LOG(6, (KERN_DEBUG "VMware hgfs: HgfsDoRead: server returned "
+                   "zero\n"));
+            result = actualSize;
+            goto out;
+         }
+
+         /* Return result. */
+         memcpy(buf, payload, actualSize);
+         LOG(6, (KERN_DEBUG "VMware hgfs: HgfsDoRead: copied %u\n",
+                 actualSize));
+         result = actualSize;
+	 break;
+
+      case -EPROTO:
+         /* Retry with older version(s). Set globally. */
+         if (opUsed == HGFS_OP_READ_V3) {
+            LOG(4, (KERN_DEBUG "VMware hgfs: HgfsDoRead: Version 3 not "
+                    "supported. Falling back to version 1.\n"));
+            atomic_set(&hgfsVersionRead, HGFS_OP_READ);
+            goto retry;
+         }
+	 break;
+
+      default:
+         break;
+      }
+   } else if (result == -EIO) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsDoRead: timed out\n"));
+   } else if (result == -EPROTO) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsDoRead: server "
+              "returned error: %d\n", result));
+   } else {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsDoRead: unknown error: "
+              "%d\n", result));
+   }
+
+out:
+   HgfsFreeRequest(req);
+   return result;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * HgfsDoWrite --
+ *
+ *    Do one write request. Called by HgfsDoWritepage, possibly multiple
+ *    times if the size of the write is too big to be handled by one server
+ *    request.
+ *
+ *    We send a "Write" request to the server with the given handle.
+ *
+ *    It is assumed that this function is never called with a larger write
+ *    than what can be sent in one request.
+ *
+ * Results:
+ *    Returns the number of bytes written on success, or an error on failure.
+ *
+ * Side effects:
+ *    None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static int
+HgfsDoWrite(HgfsHandle handle,       // IN: Handle for this file
+            const char *buf,         // IN: Buffer containing data
+            size_t count,            // IN: Number of bytes to write
+            loff_t offset)           // IN: Offset to begin writing at
+{
+   HgfsReq *req;
+   int result = 0;
+   HgfsOp opUsed;
+   uint32 requiredSize = 0;
+   uint32 actualSize = 0;
+   char *payload = NULL;
+   uint32 reqSize;
+   HgfsStatus replyStatus;
+
+   ASSERT(buf);
+
+   req = HgfsGetNewRequest();
+   if (!req) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsDoWrite: out of memory while "
+              "getting new request\n"));
+      result = -ENOMEM;
+      goto out;
+   }
+
+ retry:
+   opUsed = atomic_read(&hgfsVersionWrite);
+   if (opUsed == HGFS_OP_WRITE_V3) {
+      HgfsRequest *header;
+      HgfsRequestWriteV3 *request;
+
+      header = (HgfsRequest *)(HGFS_REQ_PAYLOAD(req));
+      header->id = req->id;
+      header->op = opUsed;
+
+      request = (HgfsRequestWriteV3 *)(HGFS_REQ_PAYLOAD_V3(req));
+      request->file = handle;
+      request->flags = 0;
+      request->offset = offset;
+      request->requiredSize = count;
+      request->reserved = 0;
+      payload = request->payload;
+      requiredSize = request->requiredSize;
+      reqSize = HGFS_REQ_PAYLOAD_SIZE_V3(request);
+   } else {
+      HgfsRequestWrite *request;
+
+      request = (HgfsRequestWrite *)(HGFS_REQ_PAYLOAD(req));
+      request->header.id = req->id;
+      request->header.op = opUsed;
+      request->file = handle;
+      request->flags = 0;
+      request->offset = offset;
+      request->requiredSize = count;
+      payload = request->payload;
+      requiredSize = request->requiredSize;
+      reqSize = sizeof *request;
+   }
+
+   memcpy(payload, buf, requiredSize);
+   req->payloadSize = reqSize + requiredSize - 1;
+
+   /* Send the request and process the reply. */
+   result = HgfsSendRequest(req);
+   if (result == 0) {
+      /* Get the reply. */
+      replyStatus = HgfsReplyStatus(req);
+      result = HgfsStatusConvertToLinux(replyStatus);
+
+      switch (result) {
+      case 0:
+         if (opUsed == HGFS_OP_WRITE_V3) {
+            actualSize = ((HgfsReplyWriteV3 *)HGFS_REP_PAYLOAD_V3(req))->actualSize;
+         } else {
+            actualSize = ((HgfsReplyWrite *)HGFS_REQ_PAYLOAD(req))->actualSize;
+         }
+
+         /* Return result. */
+         LOG(6, (KERN_DEBUG "VMware hgfs: HgfsDoWrite: wrote %u bytes\n",
+                 actualSize));
+         result = actualSize;
+         break;
+
+      case -EPROTO:
+         /* Retry with older version(s). Set globally. */
+         if (opUsed == HGFS_OP_WRITE_V3) {
+            LOG(4, (KERN_DEBUG "VMware hgfs: HgfsDoWrite: Version 3 not "
+                    "supported. Falling back to version 1.\n"));
+            atomic_set(&hgfsVersionWrite, HGFS_OP_WRITE);
+            goto retry;
+         }
+         break;
+
+      default:
+         LOG(4, (KERN_DEBUG "VMware hgfs: HgfsDoWrite: server "
+                 "returned error: %d\n", result));
+         break;
+      }
+   } else if (result == -EIO) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsDoWrite: timed out\n"));
+   } else if (result == -EPROTO) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsDoWrite: server "
+              "returned error: %d\n", result));
+   } else {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsDoWrite: unknown error: "
+              "%d\n", result));
+   }
+
+out:
+   HgfsFreeRequest(req);
+   return result;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * HgfsDoReadpage --
+ *
+ *    Reads in a single page, using the specified handle and page offsets.
+ *    At the time of writing, HGFS_IO_MAX == PAGE_CACHE_SIZE, so we could
+ *    avoid the do {} while() and just read the page as is, but in case the
+ *    above assumption is ever broken, it's nice that this will continue to
+ *    "just work".
+ *
+ * Results:
+ *    Zero on success, non-zero on error.
+ *
+ * Side effects:
+ *    None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static int
+HgfsDoReadpage(HgfsHandle handle,  // IN:     Handle to use for reading
+               struct page *page,  // IN/OUT: Page to read into
+               unsigned pageFrom,  // IN:     Where to start reading to
+               unsigned pageTo)    // IN:     Where to stop reading
+{
+   int result = 0;
+   char *buffer = kmap(page) + pageFrom;
+   loff_t curOffset = ((loff_t)page->index << PAGE_CACHE_SHIFT) + pageFrom;
+   size_t nextCount, remainingCount = pageTo - pageFrom;
+
+   LOG(6, (KERN_DEBUG "VMware hgfs: HgfsDoReadpage: read %Zu bytes from fh %u "
+           "at offset %Lu\n", remainingCount, handle, curOffset));
+
+   /*
+    * Call HgfsDoRead repeatedly until either
+    * - HgfsDoRead returns an error, or
+    * - HgfsDoRead returns 0 (end of file), or
+    * - We have read the requested number of bytes.
+    */
+   do {
+      nextCount = (remainingCount > HGFS_IO_MAX) ?
+         HGFS_IO_MAX : remainingCount;
+      result = HgfsDoRead(handle, buffer, nextCount, curOffset);
+      if (result < 0) {
+         LOG(4, (KERN_DEBUG "VMware hgfs: HgfsDoReadpage: read error %d\n",
+                 result));
+         goto out;
+      }
+      remainingCount -= result;
+      curOffset += result;
+      buffer += result;
+   } while ((result > 0) && (remainingCount > 0));
+
+   /*
+    * It's possible that despite being asked to read a full page, there is less
+    * than a page in the file from this offset, so we should zero the rest of
+    * the page's memory.
+    */
+   memset(buffer, 0, remainingCount);
+
+   /*
+    * We read a full page (or all of the page that actually belongs to the
+    * file), so mark it up to date. Also, flush the old page data from the data
+    * cache.
+    */
+   flush_dcache_page(page);
+   SetPageUptodate(page);
+   result = 0;
+
+  out:
+   kunmap(page);
+   return result;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * HgfsDoWritepage --
+ *
+ *    Writes out a single page, using the specified handle and page offsets.
+ *    At the time of writing, HGFS_IO_MAX == PAGE_CACHE_SIZE, so we could
+ *    avoid the do {} while() and just write the page as is, but in case the
+ *    above assumption is ever broken, it's nice that this will continue to
+ *    "just work".
+ *
+ *    A quick note about appending to files. Before HGFS used the page cache,
+ *    an HgfsWrite examined a file's f_flags and added HGFS_WRITE_APPEND to
+ *    the write packet if the file was opened with O_APPEND. This causes the
+ *    server to reopen the fd with O_APPEND so that writes will append to the
+ *    end.
+ *
+ *    In the page cache world, this won't work because we may have arrived at
+ *    this function via writepage(), which doesn't give us a particular file
+ *    and thus we don't know if we should be appending or not. In fact, the
+ *    generic write path employed by the page cache handles files with O_APPEND
+ *    set by moving the file offset to the result of i_size_read(). So we
+ *    shouldn't ever need to set HGFS_WRITE_APPEND, as now we will handle all
+ *    write appends, instead of telling the server to do it for us.
+ *
+ * Results:
+ *    Zero on success, non-zero on error.
+ *
+ * Side effects:
+ *    None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static int
+HgfsDoWritepage(HgfsHandle handle,  // IN: Handle to use for writing
+                struct page *page,  // IN: Page containing data to write
+                unsigned pageFrom,  // IN: Beginning page offset
+                unsigned pageTo)    // IN: Ending page offset
+{
+   int result = 0;
+   char *buffer = kmap(page) + pageFrom;
+   loff_t curOffset = ((loff_t)page->index << PAGE_CACHE_SHIFT) + pageFrom;
+   size_t nextCount;
+   size_t remainingCount = pageTo - pageFrom;
+   struct inode *inode;
+
+   ASSERT(page->mapping);
+   ASSERT(page->mapping->host);
+   inode = page->mapping->host;
+
+   /*
+    * Call HgfsDoWrite repeatedly until either
+    * - HgfsDoWrite returns an error, or
+    * - HgfsDoWrite returns 0 (XXX this probably rarely happens), or
+    * - We have written the requested number of bytes.
+    */
+   do {
+      nextCount = (remainingCount > HGFS_IO_MAX) ?
+         HGFS_IO_MAX : remainingCount;
+      result = HgfsDoWrite(handle, buffer, nextCount, curOffset);
+      if (result < 0) {
+         LOG(4, (KERN_DEBUG "VMware hgfs: HgfsDoWritepage: write error %d\n",
+                 result));
+         goto out;
+      }
+      remainingCount -= result;
+      curOffset += result;
+      buffer += result;
+
+      /* Update the inode's size now rather than waiting for a revalidate. */
+      if (curOffset > compat_i_size_read(inode)) {
+         compat_i_size_write(inode, curOffset);
+      }
+   } while ((result > 0) && (remainingCount > 0));
+
+   result = 0;
+
+  out:
+   kunmap(page);
+   return result;
+}
+
+
+/*
+ * HGFS address space operations.
+ */
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * HgfsReadpage --
+ *
+ *    Read a page from an open file. Like HgfsWritepage, there are some
+ *    complicated locking rules governing this function. The page arrives from
+ *    the VFS locked, and we must unlock it before exiting. In addition, we
+ *    must acquire a reference to the page before mapping it, and we must
+ *    flush the page's data from the data cache (not to be confused with
+ *    dcache i.e. the dentry cache).
+ *
+ * Results:
+ *    Zero on success, non-zero on error.
+ *
+ * Side effects:
+ *    None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static int
+HgfsReadpage(struct file *file, // IN:     File to read from
+             struct page *page) // IN/OUT: Page to write to
+{
+   int result = 0;
+   HgfsHandle handle;
+
+   ASSERT(file);
+   ASSERT(file->f_dentry);
+   ASSERT(file->f_dentry->d_inode);
+   ASSERT(page);
+
+   handle = FILE_GET_FI_P(file)->handle;
+   LOG(6, (KERN_DEBUG "VMware hgfs: HgfsReadPage: reading from handle %u\n",
+           handle));
+
+   page_cache_get(page);
+   result = HgfsDoReadpage(handle, page, 0, PAGE_CACHE_SIZE);
+   page_cache_release(page);
+   compat_unlock_page(page);
+   return result;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * HgfsWritepage --
+ *
+ *    The "spontaneous" way to write a page, called when the kernel is under
+ *    memory pressure or is asked to sync a memory mapped file. Because
+ *    writepage() can be called from so many different places, we don't get a
+ *    filp with which to write, and we have to be very careful about races and
+ *    locking.
+ *
+ * Results:
+ *    Zero on success, non-zero on error.
+ *
+ * Side effects:
+ *    None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 5, 52)
+static int
+HgfsWritepage(struct page *page,             // IN: Page to write from
+              struct writeback_control *wbc) // IN: Ignored
+#else
+static int
+HgfsWritepage(struct page *page)             // IN: Page to write from
+#endif
+{
+   struct inode *inode;
+   HgfsHandle handle;
+   int result;
+   pgoff_t lastPageIndex;
+   loff_t currentFileSize;
+   unsigned to = PAGE_CACHE_SIZE;
+
+   ASSERT(page);
+   ASSERT(page->mapping);
+   ASSERT(page->mapping->host);
+   inode = page->mapping->host;
+
+   /* We need a writable file handle. */
+   result = HgfsGetHandle(inode,
+                          HGFS_OPEN_MODE_WRITE_ONLY + 1,
+                          &handle);
+   if (result) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsWritepage: could not get writable "
+              "file handle\n"));
+      goto exit;
+   }
+
+   /*
+    * We were given an entire page to write. In most cases this means "start
+    * writing from the beginning of the page (byte 0) to the very end (byte
+    * PAGE_CACHE_SIZE). But what if this is the last page of the file? Then
+    * we don't want to write a full PAGE_CACHE_SIZE bytes, but just however
+    * many bytes may remain in the page.
+    *
+    * XXX: Other filesystems check the page index to make sure that the page
+    * we're being asked to write is within the size of the file. I guess
+    * that's because writepage() can race with truncate(), and if we find
+    * ourselves here after a truncate(), we can drop the write.
+    */
+   currentFileSize = compat_i_size_read(inode);
+   lastPageIndex = currentFileSize >> PAGE_CACHE_SHIFT;
+   if (page->index > lastPageIndex) {
+      goto exit;
+   } else if (page->index == lastPageIndex) {
+      to = currentFileSize & (PAGE_CACHE_SIZE - 1);
+      if (to == 0) {
+         goto exit;
+      }
+   }
+
+   /*
+    * This part is fairly intricate, so it deserves some explanation. We're
+    * really interested in calling HgfsDoWritepage with our page and
+    * handle, without having to then worry about locks or references. See
+    * Documentation/filesystems/Locking in the kernel to see what rules we
+    * must obey.
+    *
+    * Firstly, we acquire a reference to the page via page_cache_get() and call
+    * compat_set_page_writeback(). The latter does a number of things: it sets
+    * the writeback bit on the page, and if it wasn't already set, it sets the
+    * writeback bit in the radix tree. Then, if the page isn't dirty, it clears
+    * the dirty bit in the radix tree. The end result is that the radix tree's
+    * notion of dirty and writeback is fully synced with the page itself.
+    *
+    * Secondly, we write the page itself.
+    *
+    * Thirdly, we end writeback of the page via compat_end_page_writeback(),
+    * and release our reference on the page.
+    *
+    * Finally, we unlock the page, waking up its waiters and making it
+    * available to anyone else. Note that this step must be performed
+    * regardless of whether we wrote anything, as the VFS locked the page for
+    * us.
+    */
+   page_cache_get(page);
+   compat_set_page_writeback(page);
+   result = HgfsDoWritepage(handle, page, 0, to);
+   compat_end_page_writeback(page);
+   page_cache_release(page);
+
+  exit:
+   compat_unlock_page(page);
+   return result;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * HgfsPrepareWrite --
+ *
+ *      Called by the generic write path to set up a write request for a page.
+ *      We're expected to do any pre-allocation and housekeeping prior to
+ *      receiving the write.
+ *
+ * Results:
+ *      Always zero.
+ *
+ * Side effects:
+ *      None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static int
+HgfsPrepareWrite(struct file *file,  // IN: Ignored
+                 struct page *page,  // IN: Page to prepare
+                 unsigned pageFrom,  // IN: Beginning page offset
+                 unsigned pageTo)    // IN: Ending page offset
+{
+#ifdef HGFS_ENABLE_WRITEBACK
+   loff_t offset = (loff_t)page->index << PAGE_CACHE_SHIFT;
+   loff_t currentFileSize = compat_i_size_read(page->mapping->host);
+
+   /*
+    * If we are doing a partial write into a new page (beyond end of
+    * file), then intialize it. This allows other writes to this page
+    * to accumulate before we need to write it to the server.
+    */
+   if ((offset >= currentFileSize) ||
+       ((pageFrom == 0) && (offset + pageTo) >= currentFileSize)) {
+      void *kaddr = kmap_atomic(page, KM_USER0);
+
+      if (pageFrom) {
+         memset(kaddr, 0, pageFrom);
+      }
+      if (pageTo < PAGE_CACHE_SIZE) {
+         memset(kaddr + pageTo, 0, PAGE_CACHE_SIZE - pageTo);
+      }
+      kunmap_atomic(kaddr, KM_USER0);
+      flush_dcache_page(page);
+   }
+#endif
+
+   /*
+    * Prior to 2.4.10, our caller expected to call page_address(page) between
+    * the calls to prepare_write() and commit_write(). This meant filesystems
+    * had to kmap() the page in prepare_write() and kunmap() it in
+    * commit_write(). In 2.4.10, the call to page_address() was replaced with
+    * __copy_to_user(), and while its not clear to me why this is safer,
+    * nfs_prepare_write() dropped the kmap()/kunmap() calls in the same patch,
+    * so the two events must be related.
+    */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 10)
+   kmap(page);
+#endif
+   return 0;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * HgfsCommitWrite --
+ *
+ *    This function is the more common write path for HGFS, called from
+ *    generic_file_buffered_write. It is much simpler for us than
+ *    HgfsWritepage above: the caller has obtained a reference to the page
+ *    and will unlock it when we're done. And we don't need to worry about
+ *    properly marking the writeback bit, either. See mm/filemap.c in the
+ *    kernel for details about how we are called.
+ *
+ * Results:
+ *    Zero on succes, non-zero on error.
+ *
+ * Side effects:
+ *    None.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static int
+HgfsCommitWrite(struct file *file, // IN: File we're writing to
+                struct page *page, // IN: Page we're writing from
+                unsigned pageFrom, // IN: Beginning page offset
+                unsigned pageTo)   // IN: Ending page offset
+{
+   HgfsHandle handle;
+   struct inode *inode;
+   loff_t currentFileSize;
+   loff_t offset;
+   loff_t writeTo;
+
+   ASSERT(file);
+   ASSERT(page);
+   inode = page->mapping->host;
+   currentFileSize = compat_i_size_read(inode);
+   offset = (loff_t)page->index << PAGE_CACHE_SHIFT;
+   writeTo = offset + pageTo;
+
+   /* See coment in HgfsPrepareWrite. */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 10)
+   kunmap(page);
+#endif
+
+   if (writeTo > currentFileSize) {
+      compat_i_size_write(inode, writeTo);
+   }
+
+   /* We wrote a complete page, so it is up to date. */
+   if ((pageTo - pageFrom) == PAGE_CACHE_SIZE) {
+      SetPageUptodate(page);
+   }
+
+#ifdef HGFS_ENABLE_WRITEBACK
+   /*
+    * Check if this is a partial write to a new page, which was
+    * initialized in HgfsPrepareWrite.
+    */
+   if ((offset >= currentFileSize) ||
+       ((pageFrom == 0) && (writeTo >= currentFileSize))) {
+      SetPageUptodate(page);
+   }
+
+   /*
+    * If the page is uptodate, then just mark it dirty and let
+    * the page cache write it when it wants to.
+    */
+   if (PageUptodate(page)) {
+      set_page_dirty(page);
+      return 0;
+   }
+#endif
+   /*
+    * We've recieved a partial write to page that is not uptodate, so
+    * do the write now while the page is still locked.  Another
+    * alternative would be to read the page in HgfsPrepareWrite, which
+    * would make it uptodate (ie a complete cached page).
+    */
+   handle = FILE_GET_FI_P(file)->handle;
+   LOG(6, (KERN_DEBUG "VMware hgfs: HgfsCommitWrite: writing to handle %u\n",
+           handle));
+   return HgfsDoWritepage(handle, page, pageFrom, pageTo);
+}
+
+
--- kernel/linux-2.6.26.3/fs/vmhgfs/request.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/request.c	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,275 @@
+/*********************************************************
+ * Copyright (C) 2006 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * request.c --
+ *
+ * Functions dealing with the creation, deletion, and sending of HGFS
+ * requests are defined here.
+ */
+
+/* Must come before any kernel header file. */
+#include "driver-config.h"
+
+#include <asm/atomic.h>
+#include <linux/list.h>
+#include <linux/signal.h>
+#include "compat_kernel.h"
+#include "compat_sched.h"
+#include "compat_semaphore.h"
+#include "compat_slab.h"
+#include "compat_spinlock.h"
+
+#include "module.h"
+#include "request.h"
+#include "fsutil.h"
+#include "vm_assert.h"
+
+static int HgfsWaitRequestReply(HgfsReq *req);
+
+/*
+ * Private function implementations.
+ */
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * HgfsWaitRequestReply --
+ *
+ *    Wait for the reply to a request that we sent.
+ *
+ * Results:
+ *    Returns zero when the answer has been received, -ERESTARTSYS if
+ *    interrupted, or -EPROTO if there was a backdoor error. It is important
+ *    that -ERESTARTSYS be returned in the event of a signal getting caught,
+ *    because calling functions test the return value to determine
+ *    whether or not to free the request object.
+ *
+ * Side effects:
+ *    None
+ *
+ *----------------------------------------------------------------------
+ */
+
+static int
+HgfsWaitRequestReply(HgfsReq *req)  // IN/OUT: Request object
+{
+   int err = 0;
+   long timeleft;
+
+   ASSERT(req);
+
+   if (!req) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsWaitRequestReply: null req\n"));
+      return -EINVAL;
+   }
+
+   timeleft = wait_event_timeout(req->queue,
+                                 (req->state == HGFS_REQ_STATE_COMPLETED ||
+                                  req->state == HGFS_REQ_STATE_ERROR),
+                                 HGFS_REQUEST_TIMEOUT);
+   /*
+    * Did we time out? If so, abandon the request. We have to be careful,
+    * because a timeout means that the request is still on a list somewhere.
+    */
+   if (timeleft == 0) {
+      spin_lock(&hgfsBigLock);
+      if (!list_empty(&req->list)) {
+         list_del_init(&req->list);
+      }
+      spin_unlock(&hgfsBigLock);
+
+      /*
+       * Notice that we're completely ignoring any pending signals. That's
+       * because the request timed out; it was not interrupted. There's no
+       * point in having the client retry the syscall (through -ERESTARTSYS) if
+       * it wasn't actually interrupted.
+       */
+      err = -EIO;
+   } else if (req->state == HGFS_REQ_STATE_ERROR) {
+      /*
+       * If the backdoor exploded, let's modify the return value so the client
+       * knows about it. We only care about this if we didn't timeout.
+       */
+      err = -EPROTO;
+   }
+
+   LOG(8, (KERN_DEBUG "VMware hgfs: HgfsWaitRequestReply: request finished, "
+           "code %d\n", err));
+   return err;
+}
+
+
+/*
+ * Public function implementations.
+ */
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * HgfsGetNewRequest --
+ *
+ *    Get a new request structure off the free list and initialize it.
+ *
+ * Results:
+ *    On success the new struct is returned with all fields
+ *    initialized. Returns NULL on failure.
+ *
+ * Side effects:
+ *    None
+ *
+ *----------------------------------------------------------------------
+ */
+
+HgfsReq *
+HgfsGetNewRequest(void)
+{
+   HgfsReq *req = NULL;
+
+   req = kmem_cache_alloc(hgfsReqCache, GFP_KERNEL);
+   if (req == NULL) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsGetNewRequest: "
+              "can't allocate memory\n"));
+      return NULL;
+   }
+   init_waitqueue_head(&req->queue);
+   req->payloadSize = 0;
+   req->state = HGFS_REQ_STATE_ALLOCATED;
+
+   /* Setup the packet prefix. */
+   memcpy(req->packet, HGFS_SYNC_REQREP_CLIENT_CMD,
+          HGFS_SYNC_REQREP_CLIENT_CMD_LEN);
+
+   /* Atomically increment counter and set ID. */
+   spin_lock(&hgfsBigLock);
+   req->id = hgfsIdCounter++;
+   spin_unlock(&hgfsBigLock);
+
+   return req;
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * HgfsSendRequest --
+ *
+ *    Add an HGFS request to the request queue, wake up the backdoor
+ *    handler, and wait for the reply.
+ *
+ * Results:
+ *    Returns zero on success, -ERESTARTSYS if interrupted (this value will
+ *    be returned by HgfsWaitRequestReply), negative error
+ *    otherwise. Callers use the -ERESTARTSYS return value to determine
+ *    whether they should free the request object before exiting.
+ *
+ * Side effects:
+ *    None
+ *
+ *----------------------------------------------------------------------
+ */
+
+int
+HgfsSendRequest(HgfsReq *req)       // IN/OUT: Outgoing request
+{
+   int error;
+
+   ASSERT(req);
+   ASSERT(req->payloadSize <= HGFS_PACKET_MAX);
+
+   req->state = HGFS_REQ_STATE_UNSENT;
+
+   LOG(8, (KERN_DEBUG "VMware hgfs: HgfsSendRequest: Sending request id %d\n",
+           req->id));
+
+   /*
+    * Add the request to the queue, wake up the backdoor handler thread, and
+    * wait for a reply.
+    */
+   spin_lock(&hgfsBigLock);
+   list_add_tail(&req->list, &hgfsReqsUnsent);
+   spin_unlock(&hgfsBigLock);
+
+   set_bit(HGFS_REQ_THREAD_SEND, &hgfsReqThreadFlags);
+   wake_up_interruptible(&hgfsReqThreadWait);
+   error = HgfsWaitRequestReply(req);
+
+   return error;
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * HgfsFreeRequest --
+ *
+ *    Free an HGFS request.
+ *
+ * Results:
+ *    None
+ *
+ * Side effects:
+ *    None
+ *
+ *----------------------------------------------------------------------
+ */
+
+void
+HgfsFreeRequest(HgfsReq *req) // IN: Request to free
+{
+   ASSERT(hgfsReqCache);
+
+   /* Atomically decrement counter. */
+   spin_lock(&hgfsBigLock);
+   hgfsIdCounter--;
+   spin_unlock(&hgfsBigLock);
+
+   if (req != NULL) {
+      kmem_cache_free(hgfsReqCache, req);
+   }
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * HgfsReplyStatus --
+ *
+ *    Return reply status.
+ *
+ * Results:
+ *    Returns reply status as per the protocol.
+ *    XXX: Needs changes when vmci headers are added.
+ *
+ * Side effects:
+ *    None
+ *
+ *----------------------------------------------------------------------
+ */
+
+HgfsStatus
+HgfsReplyStatus(HgfsReq *req)  // IN
+{
+   HgfsReply *rep;
+
+   rep = (HgfsReply *)(HGFS_REQ_PAYLOAD(req));
+
+   return rep->status;
+}
+
--- kernel/linux-2.6.26.3/fs/vmhgfs/request.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/request.h	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,118 @@
+/*********************************************************
+ * Copyright (C) 2006 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * request.h --
+ *
+ * Functions dealing with the creation, deletion, and sending of HGFS
+ * requests are defined here.
+ */
+
+#ifndef _HGFS_DRIVER_REQUEST_H_
+#define _HGFS_DRIVER_REQUEST_H_
+
+/* Must come before any kernel header file. */
+#include "driver-config.h"
+
+#include <linux/list.h>
+#include "compat_sched.h"
+#include "compat_spinlock.h"
+#include "compat_wait.h"
+
+#include "hgfs.h" /* For common HGFS definitions. */
+#include "vm_basic_types.h"
+
+/* Macros for accessing the payload portion of the HGFS request packet. */
+#define HGFS_REQ_PAYLOAD(hgfsReq) ((hgfsReq)->packet + HGFS_CLIENT_CMD_LEN)
+
+/* XXX: Needs change when VMCI is supported. */
+#define HGFS_REQ_PAYLOAD_V3(hgfsReq) (HGFS_REQ_PAYLOAD(hgfsReq) + sizeof(HgfsRequest))
+#define HGFS_REP_PAYLOAD_V3(hgfsRep) (HGFS_REQ_PAYLOAD(hgfsRep) + sizeof(HgfsReply))
+
+/*
+ * HGFS_REQ_STATE_ALLOCATED:
+ *    The filesystem half has allocated the request from the slab
+ *    allocator. The request is not on any list.
+ *
+ * HGFS_REQ_STATE_UNSENT:
+ *    The filesystem half of the driver has filled in the request fields
+ *    and placed the request in the global unsent list. It is now the
+ *    backdoor handler's responsibility to submit this request to
+ *    the backdoor. Requests in this state are on the global unsent list.
+ *
+ * HGFS_REQ_STATE_SENT:
+ *    The backdoor handler has sent the packet, but the reply will arrive
+ *    asynchronously. The request is now on the sent list, and whenever
+ *    the reply arrives, the backdoor handler will remove the request from
+ *    the sent list and stuff the reply into the request's packet buffer.
+ *
+ * HGFS_REQ_STATE_ERROR:
+ *    The backdoor handler encountered an error while sending the request
+ *    or getting the reply. The filesystem half of the driver should
+ *    free the request. Requests in this state are not on any list.
+ *
+ * HGFS_REQ_STATE_COMPLETED:
+ *    The backdoor handler sent the request and received a reply. The reply
+ *    is stuffed in the request's packet buffer. Requests in this state
+ *    are not on any list.
+ */
+typedef enum {
+   HGFS_REQ_STATE_ALLOCATED,
+   HGFS_REQ_STATE_UNSENT,
+   HGFS_REQ_STATE_SENT,
+   HGFS_REQ_STATE_ERROR,
+   HGFS_REQ_STATE_COMPLETED,
+} HgfsState;
+
+/*
+ * A request to be sent to the user process.
+ */
+typedef struct HgfsReq {
+
+   /* Links to place the object on various lists. */
+   struct list_head list;
+
+   /*
+    * When clients wait for the reply to a request, they'll wait on this
+    * wait queue.
+    */
+   wait_queue_head_t queue;
+
+   /* Current state of the request. */
+   HgfsState state;
+
+   /* ID of this request */
+   uint32 id;
+
+   /* Total size of the payload.*/
+   size_t payloadSize;
+
+   /*
+    * Packet of data, for both incoming and outgoing messages.
+    * Include room for the command.
+    */
+   char packet[HGFS_PACKET_MAX + HGFS_CLIENT_CMD_LEN];
+} HgfsReq;
+
+/* Public functions (with respect to the entire module). */
+HgfsReq *HgfsGetNewRequest(void);
+int HgfsSendRequest(HgfsReq *req);
+void HgfsFreeRequest(HgfsReq *req);
+HgfsStatus HgfsReplyStatus(HgfsReq *req); // IN
+
+#endif // _HGFS_DRIVER_REQUEST_H_
--- kernel/linux-2.6.26.3/fs/vmhgfs/rpcout.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/rpcout.c	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,466 @@
+/*********************************************************
+ * Copyright (C) 2004 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * rpcout.c --
+ *
+ *    Remote Procedure Call between VMware and guest applications
+ *    C implementation.
+ *
+ *    This module contains implements the out (guest=>host) direction only.
+ *    The in and out modules are separate since some applications (e.g.
+ *    drivers that want to do RPC-based logging) only want/need/can have the
+ *    out direction.
+ */
+
+
+#if defined(__KERNEL__) || defined(_KERNEL) || defined(KERNEL)
+#   include "kernelStubs.h"
+#else
+#   include <stdio.h>
+#   include <string.h>
+#   include <stdlib.h>
+#   include <stdarg.h>
+#   include "str.h"
+#   include "debug.h"
+#endif
+
+#include "vmware.h"
+#include "rpcout.h"
+#include "message.h"
+
+
+/*
+ * The RpcOut object
+ */
+
+struct RpcOut {
+   Message_Channel *channel;
+};
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * RpcOut_Construct --
+ *
+ *      Constructor for the RpcOut object
+ *
+ * Results:
+ *      New RpcOut object.
+ *
+ * Side effects:
+ *      Allocates memory.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+RpcOut *
+RpcOut_Construct(void)
+{
+   return (RpcOut *)calloc(1, sizeof(RpcOut));
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * RpcOut_Destruct --
+ *
+ *      Destructor for the RpcOut object.
+ *
+ * Results:
+ *      None.
+ *
+ * Side effects:
+ *      Frees RpcOut object memory.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+void
+RpcOut_Destruct(RpcOut *out) // IN
+{
+   ASSERT(out);
+   ASSERT(out->channel == NULL);
+
+   free(out);
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * RpcOut_start --
+ *
+ *      Open the channel
+ *
+ * Result:
+ *      TRUE on success
+ *      FALSE on failure
+ *
+ * Side-effects:
+ *      None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+Bool
+RpcOut_start(RpcOut *out) // IN
+{
+   ASSERT(out);
+   ASSERT(out->channel == NULL);
+   out->channel = Message_Open(RPCI_PROTOCOL_NUM);
+   if (out->channel == NULL) {
+      Debug("RpcOut: couldn't open channel with RPCI protocol\n");
+      return FALSE;
+   }
+
+   return TRUE;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * RpcOut_send --
+ *
+ *    Make VMware synchroneously execute a TCLO command
+ *
+ *    Unlike the other send varieties, RpcOut_send requires that the
+ *    caller pass non-NULL reply and repLen arguments.
+ *
+ * Result
+ *    TRUE on success. 'reply' contains the result of the rpc
+ *    FALSE on error. 'reply' will contain a description of the error
+ *
+ *    In both cases, the caller should not free the reply.
+ *
+ * Side-effects
+ *    None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+Bool
+RpcOut_send(RpcOut *out,         // IN
+            char const *request, // IN
+            size_t reqLen,       // IN
+            char const **reply,  // OUT
+            size_t *repLen)      // OUT
+{
+   unsigned char *myReply;
+   size_t myRepLen;
+   Bool success;
+
+   ASSERT(out);
+
+   ASSERT(out->channel);
+   if (Message_Send(out->channel, (const unsigned char *)request, reqLen) == FALSE) {
+      *reply = "RpcOut: Unable to send the RPCI command";
+      *repLen = strlen(*reply);
+
+      return FALSE;
+   }
+
+   if (Message_Receive(out->channel, &myReply, &myRepLen) == FALSE) {
+      *reply = "RpcOut: Unable to receive the result of the RPCI command";
+      *repLen = strlen(*reply);
+
+      return FALSE;
+   }
+
+   if (myRepLen < 2
+       || (   (success = strncmp((const char *)myReply, "1 ", 2) == 0) == FALSE
+              && strncmp((const char *)myReply, "0 ", 2))) {
+      *reply = "RpcOut: Invalid format for the result of the RPCI command";
+      *repLen = strlen(*reply);
+
+      return FALSE;
+   }
+
+   *reply = ((const char *)myReply) + 2;
+   *repLen = myRepLen - 2;
+
+   return success;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * RpcOut_stop --
+ *
+ *    Close the channel
+ *
+ * Result
+ *    TRUE on success
+ *    FALSE on failure
+ *
+ * Side-effects
+ *    Frees the result of the last command.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+Bool
+RpcOut_stop(RpcOut *out) // IN
+{
+   Bool status;
+
+   ASSERT(out);
+
+   status = TRUE;
+
+   if (out->channel) {
+      /* Try to close the channel */
+      if (Message_Close(out->channel) == FALSE) {
+         Debug("RpcOut: couldn't close channel\n");
+         status = FALSE;
+      }
+
+      out->channel = NULL;
+   }
+
+   return status;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * RpcOut_sendOne --
+ *
+ *    Make VMware execute a RPCI command
+ *
+ *    VMware closes a channel when it detects that there has been no activity
+ *    on it for a while. Because we do not know how often this program will
+ *    make VMware execute a RPCI, we open/close one channel per RPCI command
+ *
+ * Return value:
+ *    TRUE on success. '*reply' contains an allocated result of the rpc
+ *    FALSE on error. '*reply' contains an allocated description of the error 
+ *                    or NULL.
+ *
+ * Side effects:
+ *    None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+Bool
+RpcOut_sendOne(char **reply,        // OUT: Result
+               size_t *repLen,      // OUT: Length of the result
+               char const *reqFmt,  // IN: RPCI command
+               ...)                 // Unspecified
+{
+   va_list args;
+   Bool status;
+   char *request;
+   size_t reqLen = 0;
+
+   status = FALSE;
+
+   /* Format the request string */
+   va_start(args, reqFmt);
+   request = Str_Vasprintf(&reqLen, reqFmt, args);
+   va_end(args);
+
+   /* 
+    * If Str_Vasprintf failed, write NULL into the reply if the caller wanted
+    * a reply back.
+    */
+   if (request == NULL) {
+      if (reply) {
+         *reply = NULL;
+      }
+      return FALSE;
+   }
+
+   /*
+    * If the command doesn't contain a space, add one to the end to maintain
+    * compatibility with old VMXs.
+    *
+    * For a long time, the GuestRpc logic in the VMX was wired to expect a
+    * trailing space in every command, even commands without arguments. That is
+    * no longer true, but we must continue to add a trailing space because we
+    * don't know whether we're talking to an old or new VMX.
+    */
+   if (strchr(request, ' ') == NULL) {
+      char *tmp;
+
+      tmp = Str_Asprintf(NULL, "%s ", request);
+      free(request);
+      request = tmp;
+
+      /* 
+       * If Str_Asprintf failed, write NULL into reply if the caller wanted 
+       * a reply back. 
+       */
+      if (request == NULL) {
+         if (reply != NULL) {
+            *reply = NULL;
+         }
+         return FALSE;
+      }
+   }
+
+   status = RpcOut_SendOneRaw(request, reqLen, reply, repLen);
+
+   free(request);
+
+   return status;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * RpcOut_SendOneRaw --
+ *
+ *    Make VMware execute a RPCI command
+ *
+ *    VMware closes a channel when it detects that there has been no activity
+ *    on it for a while. Because we do not know how often this program will
+ *    make VMware execute a RPCI, we open/close one channel per RPCI command.
+ *
+ *    This function sends a message over the backdoor without using
+ *    any of the Str_ functions on the request buffer; Str_Asprintf() in
+ *    particular uses FormatMessage on Win32, which corrupts some UTF-8
+ *    strings. Using this function directly instead of using RpcOut_SendOne()
+ *    avoids these problems.
+ *
+ *    If this is not an issue, you can use RpcOut_sendOne(), which has
+ *    varargs.
+ *
+ *    Note: It is the caller's responsibility to ensure that the RPCI command
+ *          followed by a space appear at the start of the request buffer. See
+ *          the command in RpcOut_sendOne for details.
+ *
+ * Return value:
+ *    TRUE on success. '*reply' contains an allocated result of the rpc
+ *    FALSE on error. '*reply' contains an allocated description of the 
+ *                    error or NULL.
+ *                    
+ *
+ * Side effects:
+ *    None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+Bool
+RpcOut_SendOneRaw(void *request,       // IN: RPCI command
+                  size_t reqLen,       // IN: Size of request buffer
+                  char **reply,        // OUT: Result
+                  size_t *repLen)      // OUT: Length of the result
+{
+   Bool status;
+   RpcOut *out = NULL;
+   char const *myReply;
+   size_t myRepLen;
+
+   status = FALSE;
+
+   Debug("Rpci: Sending request='%s'\n", (char *)request);
+   out = RpcOut_Construct();
+   if (out == NULL) {
+      myReply = "RpcOut: Unable to create the RpcOut object";
+      myRepLen = strlen(myReply);
+
+      goto sent;
+   } else if (RpcOut_start(out) == FALSE) {
+      myReply = "RpcOut: Unable to open the communication channel";
+      myRepLen = strlen(myReply);
+
+      goto sent;
+   } else if (RpcOut_send(out, request, reqLen, &myReply, &myRepLen)
+              == FALSE) {
+      /* We already have the description of the error */
+      goto sent;
+   }
+
+   status = TRUE;
+
+sent:
+   Debug("Rpci: Sent request='%s', reply='%s', len=%"FMTSZ"u, status=%d\n",
+         (char *)request, myReply, myRepLen, status);
+
+   if (reply != NULL) {
+      /* 
+       * If we got a non-NULL reply, make a copy of it, because the reply
+       * we got back is inside the channel buffer, which will get destroyed
+       * at the end of this function.
+       */
+      if (myReply != NULL) {
+         /*
+          * We previously used strdup to duplicate myReply, but that
+          * breaks if you are sending binary (not string) data over the
+          * backdoor. Don't assume the data is a string.
+          *
+          * myRepLen is strlen(myReply), so we need an extra byte to
+          * cover the NUL terminator.
+          */
+         *reply = malloc(myRepLen + 1);
+         if (*reply != NULL) {
+            memcpy(*reply, myReply, myRepLen);
+            /*
+             * The message layer already writes a trailing NUL but we might
+             * change that someday, so do it again here.
+             */
+            (*reply)[myRepLen] = 0;
+         }
+      } else {
+         /* 
+          * Our reply was NULL, so just pass the NULL back up to the caller.
+          */ 
+         *reply = NULL;
+      }
+      
+      /* 
+       * Only set the length if the caller wanted it and if we got a good 
+       * reply. 
+       */
+      if (repLen != NULL && *reply != NULL) {
+         *repLen = myRepLen;
+      }
+   }
+
+   if (out) {
+      if (RpcOut_stop(out) == FALSE) {
+         /* 
+          * We couldn't stop the channel. Free anything we allocated, give our
+          * client a reply of NULL, and return FALSE.
+          */
+
+         if (reply != NULL) {
+            free(*reply);
+            *reply = NULL;
+         }
+         Debug("Rpci: unable to close the communication channel\n");
+         status = FALSE;
+      }
+
+      RpcOut_Destruct(out);
+      out = NULL;
+   }
+
+   return status;
+}
+
+
--- kernel/linux-2.6.26.3/fs/vmhgfs/rpcout.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/rpcout.h	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,59 @@
+/*********************************************************
+ * Copyright (C) 2007 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * rpcout.h --
+ *
+ *    Remote Procedure Call between VMware and guest applications
+ *    C declarations
+ */
+
+
+#ifndef __RPCOUT_H__
+#   define __RPCOUT_H__
+
+#include "vm_basic_types.h"
+
+#define RPCI_PROTOCOL_NUM       0x49435052 /* 'RPCI' ;-) */
+
+typedef struct RpcOut RpcOut;
+
+RpcOut *RpcOut_Construct(void);
+void RpcOut_Destruct(RpcOut *out);
+Bool RpcOut_start(RpcOut *out);
+Bool RpcOut_send(RpcOut *out, char const *request, size_t reqLen,
+                 char const **reply, size_t *repLen);
+Bool RpcOut_stop(RpcOut *out);
+
+
+/*
+ * This is the only method needed to send a message to vmware for
+ * 99% of uses. I'm leaving the others defined here so people know
+ * they can be exported again if the need arises. [greg]
+ */
+Bool RpcOut_sendOne(char **reply, size_t *repLen, char const *reqFmt, ...);
+
+/* 
+ * A new version of the above function that works with UTF-8 strings
+ * and other data that would be corrupted by Win32's FormatMessage
+ * function (which is used by RpcOut_sendOne()).
+ */
+
+Bool RpcOut_SendOneRaw(void *request, size_t reqLen, char **reply, size_t *repLen);
+
+#endif /* __RPCOUT_H__ */
--- kernel/linux-2.6.26.3/fs/vmhgfs/staticEscape.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/staticEscape.c	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,278 @@
+/*********************************************************
+ * Copyright (C) 1998 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * staticEscape.c --
+ *
+ *    Buffer escaping, stolen from hpreg's buffer escaping 
+ *    in lib/string, but modified to use bit vectors instead
+ *    of arrays, and static buffers instead of dynbufs. [bac]
+ *
+ */
+
+#if defined(sun)
+#   include <string.h>
+#elif defined(__FreeBSD__)
+#   if defined(_KERNEL)
+#      include <sys/libkern.h>
+#      define memmove(dst0, src0, len)  bcopy(src0, dst0, len)
+#   else
+#      include <string.h>
+#   endif
+#endif
+
+#include "staticEscape.h"
+#include "vm_assert.h"
+
+
+/*
+ * Table to use to quickly convert an ASCII hexadecimal digit character into a
+ * decimal number. If the input is not an hexadecimal digit character, the
+ * output is -1 --hpreg
+ */
+static int const Hex2Dec[] = {
+   -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
+   -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
+   -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
+    0,  1,  2,  3,  4,  5,  6,  7,  8,  9, -1, -1, -1, -1, -1, -1,
+   -1, 10, 11, 12, 13, 14, 15, -1, -1, -1, -1, -1, -1, -1, -1, -1,
+   -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
+   -1, 10, 11, 12, 13, 14, 15, -1, -1, -1, -1, -1, -1, -1, -1, -1,
+   -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
+   -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
+   -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
+   -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
+   -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
+   -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
+   -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
+   -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
+   -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
+};
+
+
+/*
+ * Table to use to quickly convert a decimal number into an ASCII hexadecimal
+ * digit character --hpreg
+ */
+static char const Dec2Hex[] = {
+   '0', '1', '2', '3', '4', '5', '6', '7',
+   '8', '9', 'A', 'B', 'C', 'D', 'E', 'F',
+};
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * StaticEscape_Do --
+ *
+ *    Escape a buffer. Expects sizeBufOut to account for the NUL terminator.
+ *
+ *    You can calculate the required size of the output buffer as follows:    
+ *    sizeBufOut >= (((sizeIn - # of chars to be escaped) * sizeof *sizeIn) +
+ *                   (sizeof escSeq * # of chars to be escaped) +
+ *                    sizeof '\0')
+ *
+ *    Or, in English, "the number of non-escaped characters times each
+ *    non-escaped character's size, plus the number of escaped characters times
+ *    each escaped character's size, plus the size of the NUL terminator" (not
+ *    that this is very useful, since most callers won't take the time to
+ *    determine the number of characters to be escaped up front).
+ *
+ *    Note that this function assumes one to one mapping between characters
+ *    and bytes. This works for any ASCII-transparent encodings (such as UTF8).
+ *
+ *    XXX: An interface with an input size in characters and an output size in
+ *    bytes is broken (especially when the the return value is in bytes, but
+ *    _without_ the NUL terminator). We do it to maintain consistency with
+ *    the StaticEscapeW interface, where the distinction between characters
+ *    and bytes is actually important.
+ *
+ * Results: 
+ *    On success, the size (excluding the NUL terminator) of the
+ *    escaped, NUL terminated buffer.
+ *    On failure (bufOut not big enough to hold result), negative value.
+ *
+ * Side effects:
+ *    None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+int
+StaticEscape_Do(char escByte,                   // IN: The escape character
+                EscBitVector const *bytesToEsc, // IN: Chars we must escape
+                void const *bufIn,              // IN: Input buffer
+                uint32 sizeIn,                  // IN: Size of bufIn (chars)
+                uint32 sizeBufOut,              // IN: Size of bufOut (bytes)
+                char *bufOut)                   // OUT: Output buffer
+{
+   char const *buf;
+   unsigned int startUnescaped;
+   unsigned int index;
+   char escSeq[3];
+   int copySize;
+   int outPos;
+
+   /* Make sure we won't obviously overflow the bufOut [bac] */
+   if (sizeIn > sizeBufOut) {
+      return -1;
+   }
+
+   ASSERT(bytesToEsc);
+   /* Unsigned does matter --hpreg */
+   ASSERT(EscBitVector_Test(bytesToEsc, (unsigned char)escByte));
+   buf = (char const *)bufIn;
+   ASSERT(buf);
+
+   escSeq[0] = escByte;
+   startUnescaped = 0;
+   outPos = 0;
+
+   for (index = 0; index < sizeIn; index++) {
+      /* Unsigned does matter --hpreg */
+      unsigned char ubyte;
+
+      ubyte = buf[index];
+      if (EscBitVector_Test(bytesToEsc, ubyte)) {
+         /* We must escape that byte --hpreg */
+
+         escSeq[1] = Dec2Hex[ubyte >> 4];
+	 escSeq[2] = Dec2Hex[ubyte & 0xF];
+         copySize = index - startUnescaped;
+         if (outPos + copySize + sizeof(escSeq) > sizeBufOut) {
+            /*
+             * Make sure that both the first chunk and the
+             * escape sequence will fit in the bufOut. [bac]
+             */
+            return -1;
+         }
+         memcpy(&bufOut[outPos], &buf[startUnescaped], copySize);
+         outPos += copySize;
+         copySize = sizeof(escSeq);
+         memcpy(&bufOut[outPos], escSeq, copySize);
+         outPos += copySize;
+         startUnescaped = index + 1;
+      }
+   }
+
+   copySize = index - startUnescaped;
+   if (outPos + copySize + 1 > sizeBufOut) {
+      /* 
+       * Make sure the terminating NUL will fit too, so we don't have
+       * to check again below. [bac]
+       */
+      return -1;
+   }
+   memcpy(&bufOut[outPos], &buf[startUnescaped], copySize);
+   outPos += copySize;
+   memcpy(&bufOut[outPos], "", 1);
+
+   return outPos; /* Size of the output buf, not counting NUL terminator */
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * StaticEscape_Undo --
+ *
+ *    Unescape a buffer --hpreg
+ *
+ *    The unescaping is done in place in the input buffer, and
+ *    thus can not fail.
+ * 
+ * Results:
+ *    The size (excluding the NUL terminator) of the unescaped, NUL
+ *    terminated buffer.
+ *    
+ * Side effects:
+ *    None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+int
+StaticEscape_Undo(char escByte,  // IN
+                  void *bufIn,   // IN
+                  uint32 sizeIn) // IN
+{
+   char *buf;
+   unsigned int state;
+   unsigned int startUnescaped;
+   unsigned int index;
+   int outPos;
+   int copySize;
+   int h = 0; /* Compiler warning --hpreg */
+   int l;
+
+   buf = (char *)bufIn;
+   ASSERT(buf);
+
+   outPos = 0;
+   startUnescaped = 0;
+   state = 0;
+
+   for (index = 0; index < sizeIn; index++) {
+      /* Unsigned does matter --hpreg */
+      unsigned char ubyte;
+
+      ubyte = buf[index];
+      switch (state) {
+      case 0: /* Found <byte> --hpreg */
+         if (ubyte == escByte) {
+            state = 1;
+         }
+         break;
+
+      case 1: /* Found <escByte><byte> --hpreg */
+         h = Hex2Dec[ubyte];
+         state = h >= 0 ? 2 : 0;
+         break;
+
+      case 2: /* Found <escByte><hexa digit><byte> --hpreg */
+         l = Hex2Dec[ubyte];
+         if (l >= 0) {
+            char escaped;
+
+            escaped = h << 4 | l;
+
+            copySize = index - 2 - startUnescaped;
+            memmove(&buf[outPos], &buf[startUnescaped], copySize);
+            outPos += copySize;
+            memcpy(&buf[outPos], &escaped, 1);
+            outPos++;
+
+            startUnescaped = index + 1;
+         }
+         state = 0;
+         break;
+
+      default:
+         NOT_IMPLEMENTED();
+         break;
+      }
+   }
+
+   /* Last unescaped chunk (if any) --hpreg */
+   copySize = index - startUnescaped;
+   memmove(&buf[outPos], &buf[startUnescaped], copySize);
+   outPos += copySize;
+   memcpy(&buf[outPos], "", 1);
+
+   return outPos;
+}
--- kernel/linux-2.6.26.3/fs/vmhgfs/staticEscape.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/staticEscape.h	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,68 @@
+/*********************************************************
+ * Copyright (C) 1998 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * staticEscape.h --
+ *
+ *    Buffer escaping using bit vectors instead of arrays
+ *    and static buffers instead of dynbufs. [bac]
+ *
+ *    - Unescaping is done in place and cannot fail. 
+ *    - Escaping's results are put into the caller-provided static
+ *    buffer, and it fails if the buffer is too small.
+ */
+
+#ifndef __STATIC_ESCAPE_H__
+#define __STATIC_ESCAPE_H__
+
+#include "escBitvector.h"
+int
+StaticEscape_Do(char escByte,                   // IN
+                EscBitVector const *bytesToEsc, // IN
+                void const *bufIn,              // IN
+                unsigned int sizeIn,            // IN
+                unsigned int sizeBufout,        // IN
+                char *bufOut);                  // OUT
+
+int
+StaticEscape_Undo(char escByte,          // IN
+                  void *bufIn,           // IN
+                  unsigned int sizeIn);  // IN
+
+#if defined(_WIN32)
+/* Wide character versions of the escape routines. */
+
+int
+StaticEscape_DoW(wchar_t escByte,                // IN
+                 wchar_t const *bytesToEsc,      // IN
+                 void const *bufIn,              // IN
+                 unsigned int sizeIn,            // IN
+                 unsigned int sizeBufout,        // IN
+                 void *bufOut);                  // OUT
+
+int
+StaticEscape_UndoW(wchar_t escByte,          // IN
+                   wchar_t *bufIn,           // IN
+                   unsigned int sizeIn);     // IN
+
+int
+StaticEscape_UndoWToA(char escChar,     // IN
+                      char *bufIn,      // IN
+                      uint32 sizeIn);   // IN
+#endif
+#endif /* __STATIC_ESCAPE_H__ */
--- kernel/linux-2.6.26.3/fs/vmhgfs/stubs.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/stubs.c	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,85 @@
+/*********************************************************
+ * Copyright (C) 2006 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * stubs.c
+ *
+ * Contains stubs and helper functions.
+ */
+
+/* Must come before any kernel header file. */
+#include "driver-config.h"
+
+#include "kernelStubs.h"
+#include "module.h"
+#include "vm_assert.h"
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * Debug --
+ *
+ *    If debugging is enabled, output debug information.
+ *
+ * Result
+ *    None
+ *
+ * Side-effects
+ *    None
+ *
+ *----------------------------------------------------------------------
+ */
+
+void
+Debug(char const *fmt, // IN: Format string
+      ...)             // IN: Arguments
+{
+   va_list args;
+   int numBytes;
+   static char out[128];
+
+   va_start(args, fmt);
+   numBytes = Str_Vsnprintf(out, sizeof out, fmt, args);
+   va_end(args);
+
+   if (numBytes > 0) {
+      LOG(6, (KERN_DEBUG "VMware hgfs: %s", out));
+   }
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * Log --
+ *
+ *    Needs to be defined.
+ *
+ * Result
+ *    None
+ *
+ * Side-effects
+ *    None
+ *
+ *----------------------------------------------------------------------
+ */
+void
+Log(const char *string, ...)
+{
+   // do nothing.
+}
--- kernel/linux-2.6.26.3/fs/vmhgfs/super.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/super.c	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,464 @@
+/*********************************************************
+ * Copyright (C) 2006 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * super.c --
+ *
+ * Superblock operations for the filesystem portion of the vmhgfs driver.
+ */
+
+/* Must come before any kernel header file. */
+#include "driver-config.h"
+
+#include <linux/vfs.h>
+#include "compat_fs.h"
+#include "compat_statfs.h"
+#include "compat_kernel.h"
+#include "compat_slab.h"
+#include "compat_sched.h"
+#include "compat_version.h"
+
+#include "hgfsProto.h"
+#include "escBitvector.h"
+#include "hgfsEscape.h"
+#include "cpName.h"
+#include "hgfsUtil.h"
+#include "request.h"
+#include "fsutil.h"
+#include "hgfsDevLinux.h"
+#include "module.h"
+#include "vm_assert.h"
+
+
+/* Hgfs filesystem superblock operations */
+#ifdef VMW_EMBED_INODE
+static struct inode *HgfsAllocInode(struct super_block *sb);
+static void HgfsDestroyInode(struct inode *inode);
+#endif
+#ifndef VMW_USE_IGET_LOCKED
+static void HgfsReadInode(struct inode *inode);
+#endif
+static void HgfsClearInode(struct inode *inode);
+static void HgfsPutSuper(struct super_block *sb);
+#if defined(VMW_STATFS_2618)
+static int HgfsStatfs(struct dentry *dentry,
+                      struct compat_kstatfs *stat);
+#else
+static int HgfsStatfs(struct super_block *sb,
+                      struct compat_kstatfs *stat);
+#endif
+
+struct super_operations HgfsSuperOperations = {
+#ifdef VMW_EMBED_INODE
+   .alloc_inode   = HgfsAllocInode,
+   .destroy_inode = HgfsDestroyInode,
+#endif
+#ifndef VMW_USE_IGET_LOCKED
+   .read_inode    = HgfsReadInode,
+#endif
+   .clear_inode   = HgfsClearInode,
+   .put_super     = HgfsPutSuper,
+   .statfs        = HgfsStatfs,
+};
+
+
+#ifdef VMW_EMBED_INODE
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * HgfsAllocInode --
+ *
+ *    Hgfs superblock 'alloc_inode' method. Called by the kernel to allocate
+ *    a new inode struct. We use this VFS method instead of read_inode because
+ *    we want to control both how we allocate and how we fill in the inode.
+ *
+ * Results:
+ *    Non-null: A valid inode.
+ *    null: Error in inode allocation.
+ *
+ * Side effects:
+ *    Allocates memory.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static struct inode *
+HgfsAllocInode(struct super_block *sb) // IN: Superblock for the inode
+{
+   HgfsInodeInfo *iinfo;
+
+   iinfo = kmem_cache_alloc(hgfsInodeCache, GFP_KERNEL);
+   if (!iinfo) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsAllocInode: "
+              "can't allocate memory\n"));
+      return NULL;
+   }
+
+   return &iinfo->inode;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * HgfsDestroyInode --
+ *
+ *    Hgfs superblock 'destroy_inode' method. Called by the kernel when it
+ *    deallocates an inode. We use this method instead of clear_inode because
+ *    we want to control both how we deallocate and how we clear the inode.
+ *
+ * Results:
+ *    None
+ *
+ * Side effects:
+ *    Frees memory associated with inode.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static void
+HgfsDestroyInode(struct inode *inode) // IN: The VFS inode
+{
+   kmem_cache_free(hgfsInodeCache, INODE_GET_II_P(inode));
+}
+
+#endif
+
+
+#ifndef VMW_USE_IGET_LOCKED
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * HgfsReadInode --
+ *
+ *    Hgfs superblock 'read_inode' method. Called by the kernel to fill in a
+ *    VFS inode, given its hgfs inode number. Needed by iget().
+ *
+ * Results:
+ *    None
+ *
+ * Side effects:
+ *    None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static void
+HgfsReadInode(struct inode *inode) // IN/OUT: VFS inode to fill in
+{
+   HgfsDoReadInode(inode);
+}
+#endif
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * HgfsClearInode --
+ *
+ *    Hgfs superblock 'clear_inode' method. Called by the kernel when it is
+ *    about to destroy a VFS inode.
+ *
+ * Results:
+ *    None
+ *
+ * Side effects:
+ *    None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static void
+HgfsClearInode(struct inode *inode) // IN: The VFS inode
+{
+#ifdef VMW_EMBED_INODE
+   /* Do nothing. HgfsDestroyInode will do the dirty work. */
+#else
+   HgfsInodeInfo *iinfo;
+
+   ASSERT(inode);
+
+   /* The HGFS inode information may be partially constructed --hpreg */
+   iinfo = INODE_GET_II_P(inode);
+   if (iinfo) {
+      kmem_cache_free(hgfsInodeCache, iinfo);
+   }
+#endif
+}
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * HgfsPutSuper --
+ *
+ *    Hgfs superblock 'put_super' method. Called after a umount(2) of the
+ *    filesystem succeeds.
+ *
+ * Results:
+ *    None
+ *
+ * Side effects:
+ *    None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static void
+HgfsPutSuper(struct super_block *sb) // IN: The superblock
+{
+   HgfsSuperInfo *si;
+
+   ASSERT(sb);
+
+   LOG(6, (KERN_DEBUG "VMware hgfs: HgfsPutSuper: was called\n"));
+
+   si = HGFS_SB_TO_COMMON(sb);
+
+   kfree(si->shareName);
+   kfree(si);
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * HgfsPackQueryVolumeRequest --
+ *
+ *    Setup the query volume request, depending on the op version.
+ *
+ * Results:
+ *    Returns zero on success, or negative error on failure.
+ *
+ * Side effects:
+ *    None
+ *
+ *----------------------------------------------------------------------
+ */
+
+static int
+HgfsPackQueryVolumeRequest(struct dentry *dentry,   // IN: File pointer for this open
+                           HgfsOp opUsed,           // IN: Op to be used.
+                           HgfsReq *req)            // IN/OUT: Packet to write into
+{
+   char *name;
+   uint32 *nameLength;
+   size_t requestSize;
+   int result;
+
+   ASSERT(dentry);
+   ASSERT(req);
+
+   switch (opUsed) {
+   case HGFS_OP_QUERY_VOLUME_INFO_V3: {
+      HgfsRequest *requestHeader;
+      HgfsRequestQueryVolumeV3 *requestV3;
+
+      requestHeader = (HgfsRequest *)(HGFS_REQ_PAYLOAD(req));
+      requestHeader->op = opUsed;
+      requestHeader->id = req->id;
+
+      requestV3 = (HgfsRequestQueryVolumeV3 *)HGFS_REQ_PAYLOAD_V3(req);
+
+      /* We'll use these later. */
+      name = requestV3->fileName.name;
+      nameLength = &requestV3->fileName.length;
+      requestV3->fileName.flags = 0;
+      requestV3->fileName.fid = HGFS_INVALID_HANDLE;
+      requestV3->fileName.caseType = HGFS_FILE_NAME_CASE_SENSITIVE;
+      requestV3->reserved = 0;
+      requestSize = HGFS_REQ_PAYLOAD_SIZE_V3(requestV3);
+      break;
+   }
+   case HGFS_OP_QUERY_VOLUME_INFO: {
+      HgfsRequestQueryVolume *request;
+
+      request = (HgfsRequestQueryVolume *)(HGFS_REQ_PAYLOAD(req));
+      request->header.op = opUsed;
+      request->header.id = req->id;
+
+      /* We'll use these later. */
+      name = request->fileName.name;
+      nameLength = &request->fileName.length;
+      requestSize = sizeof *request;
+      break;
+   }
+   default:
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsPackQueryVolumeRequest: unexpected "
+              "OP type encountered\n"));
+      return -EPROTO;
+   }
+
+   /* Build full name to send to server. */
+   if (HgfsBuildPath(name, HGFS_PACKET_MAX - (requestSize - 1),
+                     dentry) < 0) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsPackQueryVolumeRequest: build path failed\n"));
+      return -EINVAL;
+   }
+   LOG(6, (KERN_DEBUG "VMware hgfs: HgfsPackQueryVolumeRequest: opening \"%s\"\n",
+           name));
+
+   /* Convert to CP name. */
+   result = CPName_ConvertTo(name,
+                             HGFS_PACKET_MAX - (requestSize - 1),
+                             name);
+   if (result < 0) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsPackQueryVolumeRequest: CP conversion failed\n"));
+      return -EINVAL;
+   }
+
+   /* Unescape the CP name. */
+   result = HgfsEscape_Undo(name, result);
+   *nameLength = (uint32) result;
+   req->payloadSize = requestSize + result;
+
+   return 0;
+}
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * HgfsStatfs --
+ *
+ *    Hgfs superblock 'statfs' method. Called when statfs(2) is invoked on the
+ *    filesystem.
+ *
+ * Results:
+ *    0 on success
+ *    error < 0 on failure
+ *
+ * Side effects:
+ *    None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+#if defined(VMW_STATFS_2618)
+static int
+HgfsStatfs(struct dentry *dentry,	// IN : The directory entry
+           struct compat_kstatfs *stat) // OUT: Stat to fill in
+#else
+static int
+HgfsStatfs(struct super_block *sb,	// IN : The superblock
+           struct compat_kstatfs *stat) // OUT: Stat to fill in
+#endif
+{
+   HgfsReq *req;
+   int result = 0;
+   struct dentry *dentryToUse;
+   struct super_block *sbToUse;
+   HgfsOp opUsed;
+   HgfsStatus replyStatus;
+   uint64 freeBytes;
+   uint64 totalBytes;
+
+   ASSERT(stat);
+#if defined(VMW_STATFS_2618)
+   ASSERT(dentry);
+   ASSERT(dentry->d_sb);
+   dentryToUse = dentry;
+   sbToUse = dentry->d_sb;
+#else
+   ASSERT(sb);
+   ASSERT(sb->s_root);
+   dentryToUse = sb->s_root;
+   sbToUse = sb;
+#endif
+   LOG(6, (KERN_DEBUG "VMware hgfs: HgfsStatfs: was called\n"));
+   memset(stat, 0, sizeof *stat);
+
+   req = HgfsGetNewRequest();
+   if (!req) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsStatfs: out of memory while "
+              "getting new request\n"));
+      result = -ENOMEM;
+      goto out;
+   }
+
+  retry:
+   opUsed = atomic_read(&hgfsVersionQueryVolumeInfo);
+   result = HgfsPackQueryVolumeRequest(dentryToUse, opUsed, req);
+   if (result != 0) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsStatfs: error packing request\n"));
+      goto out;
+   }
+
+   result = HgfsSendRequest(req);
+   if (result == 0) {
+      LOG(6, (KERN_DEBUG "VMware hgfs: HgfsStatfs: got reply\n"));
+      replyStatus = HgfsReplyStatus(req);
+      result = HgfsStatusConvertToLinux(replyStatus);
+
+      /*
+       * If the statfs succeeded on the server, copy the stats
+       * into the kstatfs struct, otherwise return an error.
+       */
+      switch (result) {
+      case 0:
+         stat->f_type = HGFS_SUPER_MAGIC;
+         stat->f_bsize = sbToUse->s_blocksize;
+         stat->f_namelen = PATH_MAX;
+         if (opUsed == HGFS_OP_QUERY_VOLUME_INFO_V3) {
+            totalBytes = ((HgfsReplyQueryVolumeV3 *)HGFS_REP_PAYLOAD_V3(req))->totalBytes;
+            freeBytes = ((HgfsReplyQueryVolumeV3 *)HGFS_REP_PAYLOAD_V3(req))->freeBytes;
+         } else {
+            totalBytes = ((HgfsReplyQueryVolume *)HGFS_REQ_PAYLOAD(req))->totalBytes;
+            freeBytes = ((HgfsReplyQueryVolume *)HGFS_REQ_PAYLOAD(req))->freeBytes;
+         }
+         stat->f_blocks = totalBytes >> sbToUse->s_blocksize_bits;
+         stat->f_bfree = freeBytes >> sbToUse->s_blocksize_bits;
+         stat->f_bavail = stat->f_bfree;
+         break;
+
+      case -EPERM:
+         /*
+          * We're cheating! This will cause statfs will return success.
+          * We're doing this because an old server will complain when it gets
+          * a statfs on a per-share mount. Rather than have 'df' spit an
+          * error, let's just return all zeroes.
+          */
+         result = 0;
+         break;
+
+      case -EPROTO:
+         /* Retry with older version(s). Set globally. */
+         if (opUsed == HGFS_OP_QUERY_VOLUME_INFO_V3) {
+            LOG(4, (KERN_DEBUG "VMware hgfs: HgfsStatfs: Version 3 not "
+                    "supported. Falling back to version 1.\n"));
+            atomic_set(&hgfsVersionQueryVolumeInfo, HGFS_OP_QUERY_VOLUME_INFO);
+            goto retry;
+         }
+         break;
+
+      default:
+         break;
+      }
+   } else if (result == -EIO) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsStatfs: timed out\n"));
+   } else if (result == -EPROTO) {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsStatfs: server returned error: "
+              "%d\n", result));
+   } else {
+      LOG(4, (KERN_DEBUG "VMware hgfs: HgfsStatfs: unknown error: %d\n",
+              result));
+   }
+
+out:
+   HgfsFreeRequest(req);
+   return result;
+}
--- kernel/linux-2.6.26.3/fs/vmhgfs/vm_assert.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/vm_assert.h	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,317 @@
+/*********************************************************
+ * Copyright (C) 1998-2004 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * vm_assert.h --
+ *
+ *	The basic assertion facility for all VMware code.
+ *
+ *	For proper use, see
+ *	http://vmweb.vmware.com/~mts/WebSite/guide/programming/asserts.html
+ */
+
+#ifndef _VM_ASSERT_H_
+#define _VM_ASSERT_H_
+
+#define INCLUDE_ALLOW_USERLEVEL
+#define INCLUDE_ALLOW_VMMEXT
+#define INCLUDE_ALLOW_MODULE
+#define INCLUDE_ALLOW_VMMON
+#define INCLUDE_ALLOW_VMNIXMOD
+#define INCLUDE_ALLOW_VMKERNEL
+#define INCLUDE_ALLOW_VMKDRIVERS
+#define INCLUDE_ALLOW_VMK_MODULE
+#define INCLUDE_ALLOW_DISTRIBUTE
+#define INCLUDE_ALLOW_VMCORE
+#define INCLUDE_ALLOW_VMIROM
+#include "includeCheck.h"
+
+// XXX not necessary except some places include vm_assert.h improperly
+#include "vm_basic_types.h"
+#include "vm_basic_defs.h"
+
+
+/*
+ * XXX old file code
+ */
+
+#ifdef FILECODEINT
+#error "Don't define FILECODEINT.  It is obsolete."
+#endif
+#ifdef FILECODE
+#error "Don't define FILECODE.  It is obsolete."
+#endif
+
+
+/*
+ * Panic and log functions
+ */
+
+EXTERN void Log(const char *fmt, ...) PRINTF_DECL(1, 2);
+EXTERN void Warning(const char *fmt, ...) PRINTF_DECL(1, 2);
+EXTERN NORETURN void Panic(const char *fmt, ...) PRINTF_DECL(1, 2);
+
+EXTERN void LogThrottled(uint32 *count, const char *fmt, ...)
+            PRINTF_DECL(2, 3);
+EXTERN void WarningThrottled(uint32 *count, const char *fmt, ...)
+            PRINTF_DECL(2, 3);
+
+/* DB family:  messages which are parsed by logfile database system */
+#define WarningDB Warning
+#define LogDB Log
+#define WarningThrottledDB WarningThrottled
+#define LogThrottledDB LogThrottled
+
+
+/*
+ * Stress testing: redefine ASSERT_IFNOT() to taste
+ */
+
+#ifndef ASSERT_IFNOT
+   #ifdef __cplusplus
+      #define ASSERT_IFNOT(cond, panic) (UNLIKELY(!(cond)) ? (panic) : (void)0)
+   #else
+      #define ASSERT_IFNOT(cond, panic) (UNLIKELY(!(cond)) ? (panic) : 0)
+   #endif
+#endif
+
+
+/*
+ * Assert, panic, and log macros
+ *
+ * Some of these are redefined below undef !VMX86_DEBUG.
+ * ASSERT() is special cased because of interaction with Windows DDK.
+ */
+
+#if defined VMX86_DEBUG || defined ASSERT_ALWAYS_AVAILABLE
+#undef ASSERT
+#define ASSERT(cond) \
+           ASSERT_IFNOT(cond, _ASSERT_PANIC(AssertAssert))
+#endif
+#define ASSERT_BUG(bug, cond) \
+           ASSERT_IFNOT(cond, _ASSERT_PANIC_BUG(bug, AssertAssert))
+#define ASSERT_BUG_DEBUGONLY(bug, cond) ASSERT_BUG(bug, cond)
+
+#define PANIC()        _ASSERT_PANIC(AssertPanic)
+#define PANIC_BUG(bug) _ASSERT_PANIC_BUG(bug, AssertPanic)
+
+#define ASSERT_NOT_IMPLEMENTED(cond) \
+           ASSERT_IFNOT(cond, NOT_IMPLEMENTED())
+#define ASSERT_NOT_IMPLEMENTED_BUG(bug, cond) \
+           ASSERT_IFNOT(cond, NOT_IMPLEMENTED_BUG(bug))
+
+#define NOT_IMPLEMENTED()        _ASSERT_PANIC(AssertNotImplemented)
+#define NOT_IMPLEMENTED_BUG(bug) _ASSERT_PANIC_BUG(bug, AssertNotImplemented)
+
+#define NOT_REACHED()            _ASSERT_PANIC(AssertNotReached)
+#define NOT_REACHED_BUG(bug)     _ASSERT_PANIC_BUG(bug, AssertNotReached)
+
+#define ASSERT_MEM_ALLOC(cond) \
+           ASSERT_IFNOT(cond, _ASSERT_PANIC(AssertMemAlloc))
+
+#ifdef VMX86_DEVEL
+   #define ASSERT_LENGTH(real, expected) \
+              ASSERT_IFNOT((real) == (expected), \
+                 Panic(AssertLengthFmt, __FILE__, __LINE__, real, expected))
+#else
+   #define ASSERT_LENGTH(real, expected) ASSERT((real) == (expected))
+#endif
+
+#ifdef VMX86_DEVEL
+   #define ASSERT_DEVEL(cond) ASSERT(cond)
+#else
+   #define ASSERT_DEVEL(cond) ((void) 0)
+#endif
+
+#define ASSERT_NO_INTERRUPTS()  ASSERT(!INTERRUPTS_ENABLED())
+#define ASSERT_HAS_INTERRUPTS() ASSERT(INTERRUPTS_ENABLED())
+
+#define ASSERT_LOG_UNEXPECTED(bug, cond) \
+           (UNLIKELY(!(cond)) ? LOG_UNEXPECTED(bug) : 0)
+#ifdef VMX86_DEVEL
+   #define LOG_UNEXPECTED(bug) \
+              Warning(AssertUnexpectedFmt, __FILE__, __LINE__, bug)
+#else
+   #define LOG_UNEXPECTED(bug) \
+              Log(AssertUnexpectedFmt, __FILE__, __LINE__, bug)
+#endif
+
+#define ASSERT_NOT_TESTED(cond) (UNLIKELY(!(cond)) ? NOT_TESTED() : 0)
+#ifdef VMX86_DEVEL
+   #define NOT_TESTED() Warning(AssertNotTestedFmt, __FILE__, __LINE__)
+#else
+   #define NOT_TESTED() Log(AssertNotTestedFmt, __FILE__, __LINE__)
+#endif
+
+#define NOT_TESTED_ONCE()                                               \
+   do {                                                                 \
+      static Bool alreadyPrinted = FALSE;                               \
+      if (UNLIKELY(!alreadyPrinted)) {                                  \
+	 alreadyPrinted = TRUE;                                         \
+	 NOT_TESTED();                                                  \
+      }                                                                 \
+   } while (0)
+
+#define NOT_TESTED_1024()                                               \
+   do {                                                                 \
+      static uint16 count = 0;                                          \
+      if (UNLIKELY(count == 0)) { NOT_TESTED(); }                       \
+      count = (count + 1) & 1023;                                       \
+   } while (0)
+
+#define LOG_ONCE(_s)                                                    \
+   do {                                                                 \
+      static Bool logged = FALSE;                                       \
+      if (!logged) {                                                    \
+	 Log _s;                                                        \
+         logged = TRUE;                                                 \
+      }                                                                 \
+   } while (0)
+
+
+/*
+ * Redefine macros that are only in debug versions
+ */
+
+#if !defined VMX86_DEBUG && !defined ASSERT_ALWAYS_AVAILABLE // {
+
+#undef  ASSERT
+#define ASSERT(cond) ((void) 0)
+
+#undef  ASSERT_BUG_DEBUGONLY
+#define ASSERT_BUG_DEBUGONLY(bug, cond) ((void) 0)
+
+#undef  ASSERT_LENGTH
+#define ASSERT_LENGTH(real, expected) ((void) 0)
+
+/*
+ * Expand NOT_REACHED() as appropriate for each situation.
+ *
+ * Mainly, we want the compiler to infer the same control-flow
+ * information as it would from Panic().  Otherwise, different
+ * compilation options will lead to different control-flow-derived
+ * errors, causing some make targets to fail while others succeed.
+ *
+ * VC++ has the __assume() built-in function which we don't trust
+ * (see bug 43485); gcc has no such construct; we just panic in
+ * userlevel code.  The monitor doesn't want to pay the size penalty
+ * (measured at 212 bytes for the release vmm for a minimal infinite
+ * loop; panic would cost even more) so it does without and lives
+ * with the inconsistency.
+ */
+
+#ifdef VMM
+#undef  NOT_REACHED
+#define NOT_REACHED() ((void) 0)
+#else
+// keep debug definition
+#endif
+
+#undef  ASSERT_LOG_UNEXPECTED
+#define ASSERT_LOG_UNEXPECTED(bug, cond) ((void) 0)
+
+#undef LOG_UNEXPECTED
+#define LOG_UNEXPECTED(bug) ((void) 0)
+
+#undef  ASSERT_NOT_TESTED
+#define ASSERT_NOT_TESTED(cond) ((void) 0)
+#undef  NOT_TESTED
+#define NOT_TESTED() ((void) 0)
+#undef  NOT_TESTED_ONCE
+#define NOT_TESTED_ONCE() ((void) 0)
+#undef  NOT_TESTED_1024
+#define NOT_TESTED_1024() ((void) 0)
+
+#endif // !VMX86_DEBUG }
+
+
+/*
+ * Compile-time assertions.
+ *
+ * ASSERT_ON_COMPILE does not use the common
+ * switch (0) { case 0: case (e): ; } trick because some compilers (e.g. MSVC)
+ * generate code for it.
+ *
+ * The implementation uses both enum and typedef because the typedef alone is
+ * insufficient; gcc allows arrays to be declared with non-constant expressions
+ * (even in typedefs, where it makes no sense).
+ */
+
+#define ASSERT_ON_COMPILE(e) \
+   do { \
+      enum { AssertOnCompileMisused = ((e) ? 1 : -1) }; \
+      typedef char AssertOnCompileFailed[AssertOnCompileMisused]; \
+   } while (0)
+
+
+/*
+ * To put an ASSERT_ON_COMPILE() outside a function, wrap it
+ * in MY_ASSERTS().  The first parameter must be unique in
+ * each .c file where it appears.  For example,
+ *
+ * MY_ASSERTS(FS3_INT,
+ *    ASSERT_ON_COMPILE(sizeof(FS3_DiskLock) == 128);
+ *    ASSERT_ON_COMPILE(sizeof(FS3_DiskLockReserved) == DISK_BLOCK_SIZE);
+ *    ASSERT_ON_COMPILE(sizeof(FS3_DiskBlock) == DISK_BLOCK_SIZE);
+ *    ASSERT_ON_COMPILE(sizeof(Hardware_DMIUUID) == 16);
+ * )
+ *
+ * Caution: ASSERT() within MY_ASSERTS() is silently ignored.
+ * The same goes for anything else not evaluated at compile time.
+ */
+
+#define MY_ASSERTS(name, assertions) \
+   static INLINE void name(void) { \
+      assertions \
+   }
+
+
+/*
+ * Internal macros, functions, and strings
+ *
+ * The monitor wants to save space at call sites, so it has specialized
+ * functions for each situation.  User level wants to save on implementation
+ * so it uses generic functions.
+ */
+
+#if !defined VMM || defined MONITOR_APP // {
+
+#define _ASSERT_PANIC(name) \
+           Panic(_##name##Fmt "\n", __FILE__, __LINE__)
+#define _ASSERT_PANIC_BUG(bug, name) \
+           Panic(_##name##Fmt " bugNr=%d\n", __FILE__, __LINE__, bug)
+
+#define AssertLengthFmt     _AssertLengthFmt
+#define AssertUnexpectedFmt _AssertUnexpectedFmt
+#define AssertNotTestedFmt  _AssertNotTestedFmt
+
+#endif // }
+
+// these don't have newline so a bug can be tacked on
+#define _AssertPanicFmt            "PANIC %s:%d"
+#define _AssertAssertFmt           "ASSERT %s:%d"
+#define _AssertNotImplementedFmt   "NOT_IMPLEMENTED %s:%d"
+#define _AssertNotReachedFmt       "NOT_REACHED %s:%d"
+#define _AssertMemAllocFmt         "MEM_ALLOC %s:%d"
+
+// these are complete formats with newline
+#define _AssertLengthFmt           "LENGTH %s:%d r=%#x e=%#x\n"
+#define _AssertUnexpectedFmt       "UNEXPECTED %s:%d bugNr=%d\n"
+#define _AssertNotTestedFmt        "NOT_TESTED %s:%d\n"
+
+#endif /* ifndef _VM_ASSERT_H_ */
--- kernel/linux-2.6.26.3/fs/vmhgfs/vm_basic_asm.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/vm_basic_asm.h	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,832 @@
+/*********************************************************
+ * Copyright (C) 2003 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * vm_basic_asm.h
+ *
+ *	Basic asm macros
+ */
+
+#ifndef _VM_BASIC_ASM_H_
+#define _VM_BASIC_ASM_H_
+
+#define INCLUDE_ALLOW_USERLEVEL
+#define INCLUDE_ALLOW_VMMEXT
+#define INCLUDE_ALLOW_MODULE
+#define INCLUDE_ALLOW_VMMON
+#define INCLUDE_ALLOW_VMNIXMOD
+#define INCLUDE_ALLOW_VMK_MODULE
+#define INCLUDE_ALLOW_VMKERNEL
+#define INCLUDE_ALLOW_DISTRIBUTE
+#define INCLUDE_ALLOW_VMCORE
+#define INCLUDE_ALLOW_VMIROM
+#include "includeCheck.h"
+
+#include "vm_basic_types.h"
+#include "x86cpuid.h"
+
+#ifdef VM_X86_64
+#include "vm_basic_asm_x86_64.h"
+#else
+#include "vm_basic_asm_x86.h"
+#endif
+
+
+/*
+ * x86-64 windows doesn't support inline asm so we have to use these
+ * intrinsic functions defined in the compiler.  Not all of these are well
+ * documented.  There is an array in the compiler dll (c1.dll) which has
+ * an array of the names of all the intrinsics minus the leading
+ * underscore.  Searching around in the ntddk.h file can also be helpful.
+ *
+ * The declarations for the intrinsic functions were taken from the DDK. 
+ * Our declarations must match the ddk's otherwise the 64-bit c++ compiler
+ * will complain about second linkage of the intrinsic functions.
+ * We define the intrinsic using the basic types corresponding to the 
+ * Windows typedefs. This avoids having to include windows header files
+ * to get to the windows types.
+ */
+#ifdef _MSC_VER
+#ifdef __cplusplus
+extern "C" {
+#endif
+/*
+ * It seems x86 & x86-64 windows still implements these intrinsic
+ * functions.  The documentation for the x86-64 suggest the
+ * __inbyte/__outbyte intrinsics eventhough the _in/_out work fine and
+ * __inbyte/__outbyte aren't supported on x86.
+ */
+int            _inp(unsigned short);
+unsigned short _inpw(unsigned short);
+unsigned long  _inpd(unsigned short);
+
+int            _outp(unsigned short, int);
+unsigned short _outpw(unsigned short, unsigned short);
+unsigned long  _outpd(uint16, unsigned long);
+#pragma intrinsic(_inp, _inpw, _inpd, _outp, _outpw, _outpw, _outpd)
+void _ReadWriteBarrier(void);
+#pragma intrinsic(_ReadWriteBarrier)
+
+#ifdef VM_X86_64
+/*
+ * intrinsic functions only supported by x86-64 windows as of 2k3sp1
+ */
+void             __cpuid(unsigned int*, unsigned int);
+unsigned __int64 __rdtsc(void);
+void             __stosw(unsigned short*, unsigned short, size_t);
+void             __stosd(unsigned long*, unsigned long, size_t);
+#pragma intrinsic(__cpuid, __rdtsc, __stosw, __stosd)
+
+/*
+ * intrinsic functions supported by x86-64 windows and newer x86
+ * compilers (13.01.2035 for _BitScanForward).
+ */
+unsigned char  _BitScanForward(unsigned long*, unsigned long);
+void           _mm_pause(void);
+#pragma intrinsic(_BitScanForward, _mm_pause)
+#endif /* VM_X86_64 */
+
+#ifdef __cplusplus
+}
+#endif
+#endif /* _MSC_VER */
+
+
+#ifdef __GNUC__ // {
+
+/*
+ * Checked against the Intel manual and GCC --hpreg
+ *
+ * volatile because reading from port can modify the state of the underlying
+ * hardware.
+ *
+ * Note: The undocumented %z construct doesn't work (internal compiler error)
+ *       with gcc-2.95.1
+ */
+
+#define __GCC_IN(s, type, name) \
+static INLINE type              \
+name(uint16 port)               \
+{                               \
+   type val;                    \
+                                \
+   __asm__ __volatile__(        \
+      "in" #s " %w1, %0"        \
+      : "=a" (val)              \
+      : "Nd" (port)             \
+   );                           \
+                                \
+   return val;                  \
+}
+
+__GCC_IN(b, uint8, INB)
+__GCC_IN(w, uint16, INW)
+__GCC_IN(l, uint32, IN32)
+
+
+/*
+ * Checked against the Intel manual and GCC --hpreg
+ *
+ * Note: The undocumented %z construct doesn't work (internal compiler error)
+ *       with gcc-2.95.1
+ */
+
+#define __GCC_OUT(s, s2, port, val) do { \
+   __asm__(                              \
+      "out" #s " %" #s2 "1, %w0"         \
+      :                                  \
+      : "Nd" (port), "a" (val)           \
+   );                                    \
+} while (0)
+
+#define OUTB(port, val) __GCC_OUT(b, b, port, val)
+#define OUTW(port, val) __GCC_OUT(w, w, port, val)
+#define OUT32(port, val) __GCC_OUT(l, , port, val)
+
+
+#define GET_CURRENT_EIP(_eip) \
+      __asm__ __volatile("call 0\n\tpopl %0" : "=r" (_eip): );
+
+
+/*
+ * Checked against the Intel manual and GCC --hpreg
+ * 
+ * Need __volatile__ and "memory" since CPUID has a synchronizing effect.
+ * The CPUID may also change at runtime (APIC flag, etc).
+ *
+ */
+
+static INLINE void
+__GET_CPUID(int eax,         // IN
+            CPUIDRegs *regs) // OUT
+{
+   __asm__ __volatile__(
+#if defined __PIC__ && !vm_x86_64 // %ebx is reserved by the compiler.
+      "movl %%ebx, %1"  "\n\t"
+      "cpuid"           "\n\t"
+      "xchgl %%ebx, %1"
+      : "=a" (regs->eax), "=&rm" (regs->ebx), "=c" (regs->ecx), "=d" (regs->edx)
+#else
+      "cpuid"
+      : "=a" (regs->eax), "=b" (regs->ebx), "=c" (regs->ecx), "=d" (regs->edx)
+#endif
+      : "a" (eax)
+      : "memory"
+   );
+}
+
+static INLINE void
+__GET_CPUID2(int eax,         // IN
+             int ecx,         // IN
+             CPUIDRegs *regs) // OUT
+{
+   __asm__ __volatile__(
+#if defined __PIC__ && !vm_x86_64 // %ebx is reserved by the compiler.
+      "movl %%ebx, %1"  "\n\t"
+      "cpuid"           "\n\t"
+      "xchgl %%ebx, %1"
+      : "=a" (regs->eax), "=&rm" (regs->ebx), "=c" (regs->ecx), "=d" (regs->edx)
+#else
+      "cpuid"
+      : "=a" (regs->eax), "=b" (regs->ebx), "=c" (regs->ecx), "=d" (regs->edx)
+#endif
+      : "a" (eax), "c" (ecx)
+      : "memory"
+   );
+}
+
+static INLINE uint32
+__GET_EAX_FROM_CPUID(int eax) // IN
+{
+#if defined __PIC__ && !vm_x86_64 // %ebx is reserved by the compiler.
+   uint32 ebx;
+
+   __asm__ __volatile__(
+      "movl %%ebx, %1"  "\n\t"
+      "cpuid"           "\n\t"
+      "xchgl %%ebx, %1"
+      : "=a" (eax), "=&rm" (ebx)
+      : "a" (eax)
+      : "memory", "%ecx", "%edx"
+   );
+#else
+   __asm__ __volatile__(
+      "cpuid"
+      : "=a" (eax)
+      : "a" (eax)
+      : "memory", "%ebx", "%ecx", "%edx"
+   );
+#endif
+
+   return eax;
+}
+
+static INLINE uint32
+__GET_EBX_FROM_CPUID(int eax) // IN
+{
+   uint32 ebx;
+
+   __asm__ __volatile__(
+#if defined __PIC__ && !vm_x86_64 // %ebx is reserved by the compiler.
+      "movl %%ebx, %1"  "\n\t"
+      "cpuid"           "\n\t"
+      "xchgl %%ebx, %1"
+      : "=a" (eax), "=&rm" (ebx)
+#else
+      "cpuid"
+      : "=a" (eax), "=b" (ebx)
+#endif
+      : "a" (eax)
+      : "memory", "%ecx", "%edx"
+   );
+
+   return ebx;
+}
+
+static INLINE uint32
+__GET_ECX_FROM_CPUID(int eax) // IN
+{
+   uint32 ecx;
+#if defined __PIC__ && !vm_x86_64 // %ebx is reserved by the compiler.
+   uint32 ebx;
+
+   __asm__ __volatile__(
+      "movl %%ebx, %1"  "\n\t"
+      "cpuid"           "\n\t"
+      "xchgl %%ebx, %1"
+      : "=a" (eax), "=&rm" (ebx), "=c" (ecx)
+      : "a" (eax)
+      : "memory", "%edx"
+   );
+#else
+
+   __asm__ __volatile__(
+      "cpuid"
+      : "=a" (eax), "=c" (ecx)
+      : "a" (eax)
+      : "memory", "%ebx", "%edx"
+   );
+#endif
+
+   return ecx;
+}
+
+static INLINE uint32
+__GET_EDX_FROM_CPUID(int eax) // IN
+{
+   uint32 edx;
+#if defined __PIC__ && !vm_x86_64 // %ebx is reserved by the compiler.
+   uint32 ebx;
+
+   __asm__ __volatile__(
+      "movl %%ebx, %1"  "\n\t"
+      "cpuid"           "\n\t"
+      "xchgl %%ebx, %1"
+      : "=a" (eax), "=&rm" (ebx), "=d" (edx)
+      : "a" (eax)
+      : "memory", "%ecx"
+   );
+#else
+
+   __asm__ __volatile__(
+      "cpuid"
+      : "=a" (eax), "=d" (edx)
+      : "a" (eax)
+      : "memory", "%ebx", "%ecx"
+   );
+#endif
+
+   return edx;
+}
+
+
+static INLINE uint32
+__GET_EAX_FROM_CPUID4(int ecx) // IN
+{
+   uint32 eax;
+#if defined __PIC__ && !vm_x86_64 // %ebx is reserved by the compiler.
+   uint32 ebx;
+
+   __asm__ __volatile__(
+      "movl %%ebx, %1"  "\n\t"
+      "cpuid"           "\n\t"
+      "xchgl %%ebx, %1"
+      : "=a" (eax), "=&rm" (ebx), "=c" (ecx)
+      : "a" (4), "c" (ecx)
+      : "memory", "%edx"
+   );
+#else
+
+   __asm__ __volatile__(
+      "cpuid"
+      : "=a" (eax), "=c" (ecx)
+      : "a" (4), "c" (ecx)
+      : "memory", "%ebx", "%edx"
+   );
+#endif
+
+   return eax;
+}
+
+#elif defined(_MSC_VER) // } {
+static INLINE  uint8
+INB(uint16 port) 
+{
+   return (uint8)_inp(port);
+}
+static INLINE void
+OUTB(uint16 port, uint8 value)
+{
+   _outp(port, value);
+}
+static INLINE uint16
+INW(uint16 port)
+{
+   return _inpw(port);
+}
+static INLINE void
+OUTW(uint16 port, uint16 value)
+{
+   _outpw(port, value);
+}
+static INLINE  uint32
+IN32(uint16 port) 
+{
+   return _inpd(port);
+}
+static INLINE void 
+OUT32(uint16 port, uint32 value)
+{
+   _outpd(port, value);
+}
+
+#ifndef VM_X86_64
+#ifdef NEAR
+#undef NEAR
+#endif
+
+#define GET_CURRENT_EIP(_eip) do { \
+   __asm call NEAR PTR $+5 \
+   __asm pop eax \
+   __asm mov _eip, eax \
+} while (0)
+#endif
+
+static INLINE void
+__GET_CPUID(int input, CPUIDRegs *regs)
+{
+#ifdef VM_X86_64
+   __cpuid((unsigned int *)regs, input);
+#else
+   __asm push esi
+   __asm push ebx
+   __asm push ecx
+   __asm push edx
+
+   __asm mov  eax, input
+   __asm mov  esi, regs
+   __asm _emit 0x0f __asm _emit 0xa2
+   __asm mov 0x0[esi], eax
+   __asm mov 0x4[esi], ebx
+   __asm mov 0x8[esi], ecx
+   __asm mov 0xC[esi], edx
+
+   __asm pop edx
+   __asm pop ecx
+   __asm pop ebx
+   __asm pop esi
+#endif
+}
+
+#ifdef VM_X86_64
+
+/*
+ * No inline assembly in Win64. Implemented in bora/lib/user in
+ * cpuidMasm64.asm.
+ */
+
+extern void
+__GET_CPUID2(int inputEax, int inputEcx, CPUIDRegs *regs);
+
+#else // VM_X86_64
+
+static INLINE void
+__GET_CPUID2(int inputEax, int inputEcx, CPUIDRegs *regs)
+{
+   __asm push esi
+   __asm push ebx
+   __asm push ecx
+   __asm push edx
+
+   __asm mov  eax, inputEax
+   __asm mov  ecx, inputEcx
+   __asm mov  esi, regs
+   __asm _emit 0x0f __asm _emit 0xa2
+   __asm mov 0x0[esi], eax
+   __asm mov 0x4[esi], ebx
+   __asm mov 0x8[esi], ecx
+   __asm mov 0xC[esi], edx
+
+   __asm pop edx
+   __asm pop ecx
+   __asm pop ebx
+   __asm pop esi
+}
+#endif
+
+static INLINE uint32
+__GET_EAX_FROM_CPUID(int input)
+{
+#ifdef VM_X86_64
+   CPUIDRegs regs;
+   __cpuid((unsigned int *)&regs, input);
+   return regs.eax;
+#else
+   uint32 output;
+
+   //NOT_TESTED();
+   __asm push ebx
+   __asm push ecx
+   __asm push edx
+
+   __asm mov  eax, input
+   __asm _emit 0x0f __asm _emit 0xa2
+   __asm mov  output, eax
+
+   __asm pop edx
+   __asm pop ecx
+   __asm pop ebx
+
+   return output;
+#endif
+}
+
+static INLINE uint32
+__GET_EBX_FROM_CPUID(int input)
+{
+#ifdef VM_X86_64
+   CPUIDRegs regs;
+   __cpuid((unsigned int *)&regs, input);
+   return regs.ebx;
+#else
+   uint32 output;
+
+   //NOT_TESTED();
+   __asm push ebx
+   __asm push ecx
+   __asm push edx
+
+   __asm mov  eax, input
+   __asm _emit 0x0f __asm _emit 0xa2
+   __asm mov  output, ebx
+
+   __asm pop edx
+   __asm pop ecx
+   __asm pop ebx
+
+   return output;
+#endif
+}
+
+static INLINE uint32
+__GET_ECX_FROM_CPUID(int input)
+{
+#ifdef VM_X86_64
+   CPUIDRegs regs;
+   __cpuid((unsigned int *)&regs, input);
+   return regs.ecx;
+#else
+   uint32 output;
+
+   //NOT_TESTED();
+   __asm push ebx
+   __asm push ecx
+   __asm push edx
+
+   __asm mov  eax, input
+   __asm _emit 0x0f __asm _emit 0xa2
+   __asm mov  output, ecx
+
+   __asm pop edx
+   __asm pop ecx
+   __asm pop ebx
+
+   return output;
+#endif
+}
+
+static INLINE uint32
+__GET_EDX_FROM_CPUID(int input)
+{
+#ifdef VM_X86_64
+   CPUIDRegs regs;
+   __cpuid((unsigned int *)&regs, input);
+   return regs.edx;
+#else
+   uint32 output;
+
+   //NOT_TESTED();
+   __asm push ebx
+   __asm push ecx
+   __asm push edx
+
+   __asm mov  eax, input
+   __asm _emit 0x0f __asm _emit 0xa2
+   __asm mov  output, edx
+
+   __asm pop edx
+   __asm pop ecx
+   __asm pop ebx
+
+   return output;
+#endif
+}
+
+#ifdef VM_X86_64
+
+/*
+ * No inline assembly in Win64. Implemented in bora/lib/user in
+ * cpuidMasm64.asm.
+ */
+
+extern uint32
+__GET_EAX_FROM_CPUID4(int inputEcx);
+
+#else // VM_X86_64
+
+static INLINE uint32
+__GET_EAX_FROM_CPUID4(int inputEcx)
+{
+   uint32 output;
+
+   //NOT_TESTED();
+   __asm push ebx
+   __asm push ecx
+   __asm push edx
+
+   __asm mov  eax, 4
+   __asm mov  ecx, inputEcx
+   __asm _emit 0x0f __asm _emit 0xa2
+   __asm mov  output, eax
+
+   __asm pop edx
+   __asm pop ecx
+   __asm pop ebx
+
+   return output;
+}
+
+#endif // VM_X86_64
+
+#else // }
+#error 
+#endif
+
+#define CPUID_FOR_SIDE_EFFECTS() ((void)__GET_EAX_FROM_CPUID(0))
+
+static INLINE void
+__GET_CPUID4(int inputEcx, CPUIDRegs *regs)
+{
+   __GET_CPUID2(4, inputEcx, regs);
+}
+
+/* The first parameter is used as an rvalue and then as an lvalue. */
+#define GET_CPUID(_ax, _bx, _cx, _dx) { \
+   CPUIDRegs regs;                      \
+   __GET_CPUID(_ax, &regs);             \
+   _ax = regs.eax;                      \
+   _bx = regs.ebx;                      \
+   _cx = regs.ecx;                      \
+   _dx = regs.edx;                      \
+}
+
+
+/* Sequence recommended by Intel for the Pentium 4. */
+#define INTEL_MICROCODE_VERSION() (             \
+   __SET_MSR(MSR_BIOS_SIGN_ID, 0),              \
+   __GET_EAX_FROM_CPUID(1),                     \
+   __GET_MSR(MSR_BIOS_SIGN_ID))
+
+
+#ifdef _MSC_VER   
+static INLINE int
+ffs(uint32 bitVector)
+{
+   int idx;
+   if (!bitVector) {
+      return 0;
+   }
+#ifdef VM_X86_64
+   _BitScanForward((unsigned long*)&idx, (unsigned long)bitVector);
+#else
+   __asm bsf eax, bitVector
+   __asm mov idx, eax
+#endif
+   return idx+1;
+}
+#endif
+
+#ifdef __GNUC__
+static INLINE void *
+uint16set(void *dst, uint16 val, size_t count)
+{
+   int dummy0;
+   int dummy1;
+
+   __asm__ __volatile__("\t"
+                        "cld"            "\n\t"
+                        "rep ; stosw"    "\n"
+                        : "=c" (dummy0), "=D" (dummy1)
+                        : "0" (count), "1" (dst), "a" (val)
+                        : "memory", "cc"
+      );
+
+   return dst;
+}
+
+static INLINE void *
+uint32set(void *dst, uint32 val, size_t count)
+{
+   int dummy0;
+   int dummy1;
+
+   __asm__ __volatile__("\t"
+                        "cld"            "\n\t"
+                        "rep ; stosl"    "\n"
+                        : "=c" (dummy0), "=D" (dummy1)
+                        : "0" (count), "1" (dst), "a" (val)
+                        : "memory", "cc"
+      );
+
+   return dst;
+}
+
+#elif defined(_MSC_VER)
+
+static INLINE void *
+uint16set(void *dst, uint16 val, size_t count)
+{
+#ifdef VM_X86_64
+   __stosw((uint16*)dst, val, count);
+#else
+   __asm { pushf;
+           mov ax, val;
+           mov ecx, count;
+           mov edi, dst;
+           cld;
+           rep stosw;
+           popf;
+   }
+#endif
+   return dst;
+}
+
+static INLINE void *
+uint32set(void *dst, uint32 val, size_t count)
+{
+#ifdef VM_X86_64
+   __stosd((unsigned long*)dst, (unsigned long)val, count);
+#else
+   __asm { pushf;
+           mov eax, val;
+           mov ecx, count;
+           mov edi, dst;
+           cld;
+           rep stosd;
+           popf;
+   }
+#endif
+   return dst;
+}
+
+#else
+#error "No compiler defined for uint*set"
+#endif
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Bswap --
+ *
+ *    Swap the 4 bytes of "v" as follows: 3210 -> 0123.
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+#ifdef __GNUC__ // {
+static INLINE uint32
+Bswap(uint32 v)
+{
+   /* Checked against the Intel manual and GCC --hpreg */
+   __asm__(
+      "bswap %0" 
+      : "=r" (v)
+      : "0" (v)
+   );
+   return v;
+}
+#endif // }
+
+#ifdef __GNUC__ // {
+/*
+ * COMPILER_MEM_BARRIER prevents the compiler from re-ordering memory
+ * references accross the barrier.  NOTE: It does not generate any
+ * instruction, so the CPU is free to do whatever it wants to...
+ */
+#define COMPILER_MEM_BARRIER() __asm__ __volatile__ ("": : :"memory")
+#elif defined(_MSC_VER) // } {
+#define COMPILER_MEM_BARRIER() _ReadWriteBarrier()
+#endif // }
+
+
+/*
+ * PAUSE is a P4 instruction that improves spinlock power+performance;
+ * on non-P4 IA32 systems, the encoding is interpreted as a REPZ-NOP.
+ * Use volatile to avoid NOP removal.
+ */
+static INLINE void
+PAUSE(void)
+#ifdef __GNUC__
+{
+   __asm__ __volatile__( "pause" :);
+}
+#elif defined(_MSC_VER)
+#ifdef VM_X86_64
+{
+   _mm_pause();
+}
+#else /* VM_X86_64 */
+#pragma warning( disable : 4035)
+{
+   __asm _emit 0xf3 __asm _emit 0x90
+}
+#pragma warning (default: 4035)
+#endif /* VM_X86_64 */
+#else  /* __GNUC__  */
+#error No compiler defined for PAUSE
+#endif
+
+
+/*
+ * Checked against the Intel manual and GCC --hpreg
+ *
+ * volatile because the tsc always changes without the compiler knowing it.
+ */
+static INLINE uint64
+RDTSC(void)
+#ifdef __GNUC__
+{
+#ifdef VM_X86_64
+   uint64 tscLow;
+   uint64 tscHigh;
+
+   __asm__ __volatile__(
+      "rdtsc"
+      : "=a" (tscLow), "=d" (tscHigh)
+   );
+
+   return tscHigh << 32 | tscLow;
+#else
+   uint64 tim;
+
+   __asm__ __volatile__(
+      "rdtsc"
+      : "=A" (tim)
+   );
+
+   return tim;
+#endif
+}
+#elif defined(_MSC_VER)
+#ifdef VM_X86_64
+{
+   return __rdtsc();
+}
+#else
+#pragma warning( disable : 4035)
+{
+   __asm _emit 0x0f __asm _emit 0x31
+}
+#pragma warning (default: 4035)
+#endif /* VM_X86_64 */
+#else  /* __GNUC__  */
+#error No compiler defined for RDTSC
+#endif /* __GNUC__  */
+
+#endif
--- kernel/linux-2.6.26.3/fs/vmhgfs/vm_basic_asm_x86_64.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/vm_basic_asm_x86_64.h	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,336 @@
+/*********************************************************
+ * Copyright (C) 1998-2004 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * vm_basic_asm_x86_64.h
+ *
+ *	Basic x86_64 asm macros.
+ */
+
+#ifndef _VM_BASIC_ASM_X86_64_H_
+#define _VM_BASIC_ASM_X86_64_H_
+
+#define INCLUDE_ALLOW_USERLEVEL
+#define INCLUDE_ALLOW_VMMEXT
+#define INCLUDE_ALLOW_MODULE
+#define INCLUDE_ALLOW_VMMON
+#define INCLUDE_ALLOW_VMK_MODULE
+#define INCLUDE_ALLOW_VMKERNEL
+#define INCLUDE_ALLOW_DISTRIBUTE
+#define INCLUDE_ALLOW_VMCORE
+#define INCLUDE_ALLOW_VMNIXMOD
+#include "includeCheck.h"
+
+#ifndef VM_X86_64
+#error "This file is x86-64 only!"
+#endif
+
+#ifdef _MSC_VER
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+uint64 _umul128(uint64 multiplier, uint64 multiplicand, 
+                uint64 *highProduct);
+int64 _mul128(int64 multiplier, int64 multiplicand, 
+              int64 *highProduct);
+uint64 __shiftright128(uint64 lowPart, uint64 highPart, uint8 shift);
+#ifdef __cplusplus
+}
+#endif
+
+#pragma intrinsic(_umul128, _mul128, __shiftright128)
+
+#endif // _MSC_VER
+
+/*
+ * FXSAVE/FXRSTOR
+ *     save/restore SIMD/MMX fpu state
+ *
+ * The pointer passed in must be 16-byte aligned.
+ *
+ * Intel and AMD processors behave differently w.r.t. fxsave/fxrstor. Intel
+ * processors unconditionally save the exception pointer state (instruction
+ * ptr., data ptr., and error instruction opcode). FXSAVE_ES1 and FXRSTOR_ES1
+ * work correctly for Intel processors.
+ *
+ * AMD processors only save the exception pointer state if ES=1. This leads to a
+ * security hole whereby one process/VM can inspect the state of another process
+ * VM. The AMD recommended workaround involves clobbering the exception pointer
+ * state unconditionally, and this is implemented in FXRSTOR_AMD_ES0. Note that
+ * FXSAVE_ES1 will only save the exception pointer state for AMD processors if
+ * ES=1.
+ *
+ * The workaround (FXRSTOR_AMD_ES0) only costs 1 cycle more than just doing an
+ * fxrstor, on both AMD Opteron and Intel Core CPUs.
+ */
+#if defined(__GNUC__)
+
+static INLINE void 
+FXSAVE_ES1(uint8 *save)
+{
+   __asm__ __volatile__ ("fxsaveq %0  \n" : "=m" (*save) : : "memory");
+}
+
+static INLINE void 
+FXSAVE_COMPAT_ES1(uint8 *save)
+{
+   __asm__ __volatile__ ("fxsave %0  \n" : "=m" (*save) : : "memory");
+}
+
+static INLINE void 
+FXRSTOR_ES1(const uint8 *load)
+{
+   __asm__ __volatile__ ("fxrstorq %0 \n" : : "m" (*load) : "memory");
+}
+
+static INLINE void 
+FXRSTOR_COMPAT_ES1(const uint8 *load)
+{
+   __asm__ __volatile__ ("fxrstor %0 \n" : : "m" (*load) : "memory");
+}
+
+static INLINE void 
+FXRSTOR_AMD_ES0(const uint8 *load)
+{
+   uint64 dummy = 0;
+      
+   __asm__ __volatile__ 
+       ("fnstsw  %%ax    \n"     // Grab x87 ES bit
+        "bt      $7,%%ax \n"     // Test ES bit
+        "jnc     1f      \n"     // Jump if ES=0
+        "fnclex          \n"     // ES=1. Clear it so fild doesn't trap
+        "1:              \n"
+        "ffree   %%st(7) \n"     // Clear tag bit - avoid poss. stack overflow
+        "fildl   %0      \n"     // Dummy Load from "safe address" changes all
+                                 // x87 exception pointers.
+        "fxrstorq %1 \n"
+        :
+        : "m" (dummy), "m" (*load)
+        : "ax", "memory");
+}
+
+#endif /* __GNUC__ */
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Mul64x3264 --
+ *
+ *    Unsigned integer by fixed point multiplication:
+ *       result = multiplicand * multiplier >> shift
+ * 
+ *       Unsigned 64-bit integer multiplicand.
+ *       Unsigned 32-bit fixed point multiplier, represented as
+ *         multiplier >> shift, where shift < 64.
+ *       Unsigned 64-bit integer product.
+ *
+ * Implementation:
+ *    Multiply 64x64 bits to yield a full 128-bit product.
+ *    Shift result in RDX:RAX right by "shift".
+ *    Return the low-order 64 bits of the above.
+ *
+ * Result:
+ *    Product
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+#if defined(__GNUC__)
+
+static INLINE uint64
+Mul64x3264(uint64 multiplicand,
+           uint32 multiplier,
+           uint32 shift)
+{
+   uint64 result, dummy;
+   const uint64 multiplier64 = multiplier;
+
+   __asm__("mulq    %3      \n\t"
+           "shrdq   %1, %0  \n\t"
+           : "=a" (result),
+             "=d" (dummy)
+           : "0"  (multiplier64),
+             "rm" (multiplicand),
+         "c"  (shift)
+           : "cc");
+   return result;
+}
+
+#elif defined(_MSC_VER)
+
+static INLINE uint64
+Mul64x3264(uint64 multiplicand, uint32 multiplier, uint32 shift)
+{
+   uint64 tmplo, tmphi;
+   tmplo = _umul128(multiplicand, multiplier, &tmphi);
+   return __shiftright128(tmplo, tmphi, (uint8) shift);
+}
+
+#endif
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Muls64x32s64 --
+ *
+ *    Signed integer by fixed point multiplication:
+ *       result = multiplicand * multiplier >> shift
+ * 
+ *       Signed 64-bit integer multiplicand.
+ *       Unsigned 32-bit fixed point multiplier, represented as
+ *         multiplier >> shift, where shift < 64.
+ *       Signed 64-bit integer product.
+ *
+ * Implementation:
+ *    Multiply 64x64 bits to yield a full 128-bit product.
+ *    Shift result in RDX:RAX right by "shift".
+ *    Return the low-order 64 bits of the above.
+ *
+ *    Note: using an unsigned shift instruction is correct because
+ *    shift < 64 and we return only the low 64 bits of the shifted
+ *    result.
+ *
+ * Result:
+ *    Product
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+#if defined(__GNUC__)
+
+static inline int64
+Muls64x32s64(int64 multiplicand, uint32 multiplier, uint32 shift)
+{
+   int64 result, dummy;
+   const int64 multiplier64 = multiplier;
+
+   __asm__("imulq   %3      \n\t"
+       "shrdq   %1, %0  \n\t"
+       : "=a" (result),
+         "=d" (dummy)
+       : "0"  (multiplier64),
+         "rm" (multiplicand),
+         "c"  (shift)
+       : "cc");
+   return result;
+}
+
+#elif defined(_MSC_VER)
+
+static INLINE int64
+Muls64x32s64(int64 multiplicand, uint32 multiplier, uint32 shift)
+{
+   int64 tmplo, tmphi;
+   tmplo = _mul128(multiplicand, multiplier, &tmphi);
+   return __shiftright128(tmplo, tmphi, (uint8) shift);
+}
+
+#endif
+
+
+#if defined(__GNUC__)
+
+static INLINE void *
+uint64set(void *dst, uint64 val, uint64 count)
+{
+   int dummy0;
+   int dummy1;
+   __asm__ __volatile__("\t"
+                        "cld"            "\n\t"
+                        "rep ; stosq"    "\n"
+                        : "=c" (dummy0), "=D" (dummy1)
+                        : "0" (count), "1" (dst), "a" (val)
+                        : "memory", "cc");
+   return dst;
+}
+
+#endif
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Div643232 --
+ *
+ *    Unsigned integer division:
+ *       The dividend is 64-bit wide
+ *       The divisor  is 32-bit wide
+ *       The quotient is 32-bit wide
+ *
+ *    Use this function if you are certain that the quotient will fit in 32 bits,
+ *    If that is not the case, a #DE exception was generated in 32-bit version,
+ *    but not in this 64-bit version. So please be careful.
+ *
+ * Results:
+ *    Quotient and remainder
+ *
+ * Side effects:
+ *    None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+#if defined(__GNUC__) || defined(_MSC_VER)
+
+static INLINE void
+Div643232(uint64 dividend,   // IN
+          uint32 divisor,    // IN
+          uint32 *quotient,  // OUT
+          uint32 *remainder) // OUT
+{
+   *quotient = (uint32)(dividend / divisor);
+   *remainder = (uint32)(dividend % divisor);
+}
+
+#endif
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Div643264 --
+ *
+ *    Unsigned integer division:
+ *       The dividend is 64-bit wide
+ *       The divisor  is 32-bit wide
+ *       The quotient is 64-bit wide
+ *
+ * Results:
+ *    Quotient and remainder
+ *
+ * Side effects:
+ *    None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+#if defined(__GNUC__)
+
+static INLINE void
+Div643264(uint64 dividend,   // IN
+          uint32 divisor,    // IN
+          uint64 *quotient,  // OUT
+          uint32 *remainder) // OUT
+{
+   *quotient = dividend / divisor;
+   *remainder = dividend % divisor;
+}
+
+#endif
+
+#endif // _VM_BASIC_ASM_X86_64_H_
--- kernel/linux-2.6.26.3/fs/vmhgfs/vm_basic_asm_x86.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/vm_basic_asm_x86.h	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,500 @@
+/*********************************************************
+ * Copyright (C) 1998-2003 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * vm_basic_asm_x86.h
+ *
+ *	Basic IA32 asm macros
+ */
+
+#ifndef _VM_BASIC_ASM_X86_H_
+#define _VM_BASIC_ASM_X86_H_
+
+#define INCLUDE_ALLOW_USERLEVEL
+#define INCLUDE_ALLOW_VMMEXT
+#define INCLUDE_ALLOW_MODULE
+#define INCLUDE_ALLOW_VMMON
+#define INCLUDE_ALLOW_VMNIXMOD
+#define INCLUDE_ALLOW_VMK_MODULE
+#define INCLUDE_ALLOW_VMKERNEL
+#define INCLUDE_ALLOW_DISTRIBUTE
+#define INCLUDE_ALLOW_VMCORE
+#define INCLUDE_ALLOW_VMIROM
+#include "includeCheck.h"
+
+#ifdef VM_X86_64
+/*
+ * The gcc inline asm uses the "A" constraint which differs in 32 & 64
+ * bit mode.  32 bit means eax and edx, 64 means rax or rdx.
+ */
+#error "x86-64 not supported"
+#endif
+
+
+
+
+/*
+ * from linux: usr/include/asm/io.h
+ */
+#ifdef __GNUC__
+#ifndef __SLOW_DOWN_IO
+#ifdef SLOW_IO_BY_JUMPING
+#define __SLOW_DOWN_IO __asm__ __volatile__("jmp 1f\n1:\tjmp 1f\n1:")
+#else
+#define __SLOW_DOWN_IO __asm__ __volatile__("outb %al,$0x80")
+#endif
+#endif
+#elif _MSC_VER
+#ifdef SLOW_IO_BY_JUMPING
+#define __SLOW_DOWN_IO __asm jmp SHORT $+2 __asm  jmp SHORT $+2
+#else
+#define __SLOW_DOWN_IO __asm out 80h,al
+#endif
+#else
+#error
+#endif
+
+#ifdef REALLY_SLOW_IO
+#define SLOW_DOWN_IO { __SLOW_DOWN_IO; __SLOW_DOWN_IO; __SLOW_DOWN_IO; __SLOW_DOWN_IO; }
+#else
+#define SLOW_DOWN_IO __SLOW_DOWN_IO
+#endif
+
+/*
+ * FXSAVE/FXRSTOR
+ *     save/restore SIMD/MMX fpu state
+ *
+ * The pointer passed in must be 16-byte aligned.
+ *
+ * Intel and AMD processors behave differently w.r.t. fxsave/fxrstor. Intel
+ * processors unconditionally save the exception pointer state (instruction
+ * ptr., data ptr., and error instruction opcode). FXSAVE_ES1 and FXRSTOR_ES1
+ * work correctly for Intel processors.
+ *
+ * AMD processors only save the exception pointer state if ES=1. This leads to a
+ * security hole whereby one process/VM can inspect the state of another process
+ * VM. The AMD recommended workaround involves clobbering the exception pointer
+ * state unconditionally, and this is implemented in FXRSTOR_AMD_ES0. Note that
+ * FXSAVE_ES1 will only save the exception pointer state for AMD processors if
+ * ES=1.
+ *
+ * The workaround (FXRSTOR_AMD_ES0) only costs 1 cycle more than just doing an
+ * fxrstor, on both AMD Opteron and Intel Core CPUs.
+ */
+#if defined(__GNUC__)
+static INLINE void 
+FXSAVE_ES1(uint8 *save)
+{
+   __asm__ __volatile__ ("fxsave %0\n" : "=m" (*save) : : "memory");
+}
+
+static INLINE void 
+FXRSTOR_ES1(const uint8 *load)
+{
+   __asm__ __volatile__ ("fxrstor %0\n" : : "m" (*load) : "memory");
+}
+
+static INLINE void 
+FXRSTOR_AMD_ES0(const uint8 *load)
+{
+   uint64 dummy = 0;
+      
+   __asm__ __volatile__ 
+       ("fnstsw  %%ax    \n"     // Grab x87 ES bit
+        "bt      $7,%%ax \n"     // Test ES bit
+        "jnc     1f      \n"     // Jump if ES=0
+        "fnclex          \n"     // ES=1. Clear it so fild doesn't trap
+        "1:              \n"
+        "ffree   %%st(7) \n"     // Clear tag bit - avoid poss. stack overflow
+        "fildl   %0      \n"     // Dummy Load from "safe address" changes all
+                                 // x87 exception pointers.
+        "fxrstor %1      \n"
+        :  
+        : "m" (dummy), "m" (*load)
+        : "ax", "memory");
+}
+#endif /* __GNUC__ */
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Div643232 --
+ *
+ *    Unsigned integer division:
+ *       The dividend is 64-bit wide
+ *       The divisor  is 32-bit wide
+ *       The quotient is 32-bit wide
+ *
+ *    Use this function if you are certain that:
+ *    o Either the quotient will fit in 32 bits,
+ *    o Or your code is ready to handle a #DE exception indicating overflow.
+ *    If that is not the case, then use Div643264(). --hpreg
+ *
+ * Results:
+ *    Quotient and remainder
+ *
+ * Side effects:
+ *    None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+#if defined(__GNUC__)
+
+static INLINE void
+Div643232(uint64 dividend,   // IN
+          uint32 divisor,    // IN
+          uint32 *quotient,  // OUT
+          uint32 *remainder) // OUT
+{
+   /* Checked against the Intel manual and GCC --hpreg */
+   __asm__(
+      "divl %4"
+      : "=a" (*quotient),
+        "=d" (*remainder)
+      : "0" ((uint32)dividend),
+        "1" ((uint32)(dividend >> 32)),
+        "rm" (divisor)
+      : "cc"
+   );
+}
+
+#elif _MSC_VER
+
+static INLINE void
+Div643232(uint64 dividend,   // IN
+          uint32 divisor,    // IN
+          uint32 *quotient,  // OUT
+          uint32 *remainder) // OUT
+{
+   /* Written and tested by mann, checked by dbudko and hpreg */
+   __asm {
+      mov  eax, DWORD PTR [dividend]
+      mov  edx, DWORD PTR [dividend+4]
+      div  DWORD PTR [divisor]
+      mov  edi, DWORD PTR [quotient]
+      mov  [edi], eax
+      mov  edi, DWORD PTR [remainder]
+      mov  [edi], edx
+   }
+}
+
+#else
+#error No compiler defined for Div643232
+#endif
+
+
+#if defined(__GNUC__)
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Div643264 --
+ *
+ *    Unsigned integer division:
+ *       The dividend is 64-bit wide
+ *       The divisor  is 32-bit wide
+ *       The quotient is 64-bit wide --hpreg
+ *
+ * Results:
+ *    Quotient and remainder
+ *
+ * Side effects:
+ *    None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+static INLINE void
+Div643264(uint64 dividend,   // IN
+          uint32 divisor,    // IN
+          uint64 *quotient,  // OUT
+          uint32 *remainder) // OUT
+{
+   uint32 hQuotient;
+   uint32 lQuotient;
+
+   /* Checked against the Intel manual and GCC --hpreg */
+   __asm__(
+      "divl %5"        "\n\t"
+      "movl %%eax, %0" "\n\t"
+      "movl %4, %%eax" "\n\t"
+      "divl %5"
+      : "=&rm" (hQuotient),
+        "=a" (lQuotient),
+        "=d" (*remainder)
+      : "1" ((uint32)(dividend >> 32)),
+        "g" ((uint32)dividend),
+        "rm" (divisor),
+        "2" (0)
+      : "cc"
+   );
+   *quotient = (uint64)hQuotient << 32 | lQuotient;
+}
+#endif
+
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Mul64x3264 --
+ *
+ *    Unsigned integer by fixed point multiplication:
+ *       Unsigned 64-bit integer multiplicand.
+ *       Unsigned 32-bit fixed point multiplier, represented as
+ *         multiplier >> shift, where shift < 64.
+ *       Unsigned 64-bit integer product.
+ *
+ * Implementation:
+ *    Multiply 64x32 bits to yield a full 96-bit product.
+ *    Shift right by shift.
+ *    Return the low-order 64 bits of the result.
+ *
+ * Result:
+ *    Product
+ *
+ * Side effects:
+ *    None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+#if defined(__GNUC__)
+
+static INLINE uint64
+Mul64x3264(uint64 multiplicand, uint32 multiplier, uint32 shift)
+{
+   uint64 result;
+   uint32 tmp1, tmp2;
+   // ASSERT(shift >= 0 && shift < 64);
+  
+   /*
+    * Written and tested by mann, improved with suggestions by hpreg.
+    *
+    * The main improvement over the previous version is that the test
+    * of shift against 32 is moved out of the asm and into C code.
+    * This lets the compiler delete the test and one of the
+    * alternative code sequences in the case where shift is a
+    * constant.  It also lets us use the best code sequence in each
+    * alternative, rather than a compromise.  The downside is that in
+    * the non-constant case, this version takes slightly more code
+    * space.
+    *
+    * Note on the constraints: We don't really want multiplicand to
+    * start in %edx:%eax as the =A constraint dictates; in fact, we'd
+    * prefer any *other* two registers.  But gcc doesn't have
+    * constraint syntax for any other register pair, and trying to
+    * constrain ((uint32) multiplicand) to one place and (multiplicand
+    * >> 32) to another generates *really* bad code -- gcc is just not
+    * smart enough, at least in the version we are currently using.
+    */
+   if (shift < 32) {
+      __asm__("mov   %%eax, %2     \n\t" // Save lo(multiplicand) in tmp2
+              "mov   %%edx, %%eax  \n\t" // Get hi(multiplicand)
+              "mull  %4            \n\t" // p2 = hi(multiplicand) * multiplier
+              "xchg  %%eax, %2     \n\t" // Save lo(p2) in tmp2, get lo(multiplicand)
+              "mov   %%edx, %1     \n\t" // Save hi(p2) in tmp1
+              "mull  %4            \n\t" // p1 = lo(multiplicand) * multiplier
+              "addl  %2, %%edx     \n\t" // hi(p1) += lo(p2)
+              "adcl  $0, %1        \n\t" // hi(p2) += carry from previous step
+              "shrdl %%edx, %%eax  \n\t" // result = hi(p2):hi(p1):lo(p1) >> shift
+              "shrdl %1, %%edx"
+              : "=A"  (result),
+                "=&r" (tmp1),            // use in shrdl requires it to be a register
+                "=&r" (tmp2)             // could be "=&rm" but "m" is slower
+              : "0"   (multiplicand),
+                "rm"  (multiplier),
+                "c"   (shift)
+              : "cc"
+         );
+   } else {
+      __asm__("mov   %%edx, %2     \n\t" // Save hi(multiplicand) in tmp2
+              "mull  %4            \n\t" // p1 = lo(multiplicand) * multiplier
+              "mov   %%edx, %1     \n\t" // Save hi(p1) in tmp1
+              "mov   %2, %%eax     \n\t" // Discard lo(p1), get hi(multiplicand)
+              "mull  %4            \n\t" // p2 = hi(multiplicand) * multiplier
+              "addl  %1, %%eax     \n\t" // lo(p2) += hi(p1)
+              "adcl  $0, %%edx     \n\t" // hi(p2) += carry from previous step
+              "shrdl %%edx, %%eax  \n\t" // result = p2 >> (shift & 31)
+              "shrl  %%cl, %%edx"
+              : "=A"  (result),
+                "=&r" (tmp1),            // could be "=&rm" but "m" is slower
+                "=&r" (tmp2)             // could be "=&rm" but "m" is slower
+              : "0"   (multiplicand),
+                "rm"  (multiplier),
+                "c"   (shift)
+              : "cc"
+         );
+   }
+   return result;
+}
+
+#elif _MSC_VER
+#pragma warning(disable: 4035)
+
+static INLINE uint64
+Mul64x3264(uint64 multiplicand, uint32 multiplier, uint32 shift)
+{
+   // ASSERT(shift >= 0 && shift < 64);
+
+   /* Written and tested by mann, checked by dbudko and hpreg */
+   __asm {
+      mov  eax, DWORD PTR [multiplicand+4]  // Get hi(multiplicand)
+      mul  DWORD PTR [multiplier]           // p2 = hi(multiplicand) * multiplier
+      mov  ecx, eax                         // Save lo(p2)
+      mov  ebx, edx                         // Save hi(p2)
+      mov  eax, DWORD PTR [multiplicand]    // Get lo(multiplicand)
+      mul  DWORD PTR [multiplier+0]         // p1 = lo(multiplicand) * multiplier
+      add  edx, ecx                         // hi(p1) += lo(p2)
+      adc  ebx, 0                           // hi(p2) += carry from previous step
+      mov  ecx, DWORD PTR [shift]           // Get shift
+      cmp  ecx, 32                          // shift < 32?
+      jl   SHORT l2                         // Go if so
+      mov  eax, edx                         // result = hi(p2):hi(p1) >> (shift & 31)
+      mov  edx, ebx
+      shrd eax, edx, cl
+      shr  edx, cl
+      jmp  SHORT l3
+   l2:
+      shrd eax, edx, cl                     // result = hi(p2):hi(p1):lo(p1) >> shift
+      shrd edx, ebx, cl
+   l3:
+   }
+   // return with result in edx:eax
+}
+
+#pragma warning(default: 4035)
+#else
+#error No compiler defined for Mul64x3264
+#endif
+
+/*
+ *-----------------------------------------------------------------------------
+ *
+ * Muls64x32s64 --
+ *
+ *    Signed integer by fixed point multiplication:
+ *       Signed 64-bit integer multiplicand.
+ *       Unsigned 32-bit fixed point multiplier, represented as
+ *         multiplier >> shift, where shift < 64.
+ *       Signed 64-bit integer product.
+ *
+ * Implementation:
+ *    Multiply 64x32 bits to yield a full 96-bit product.
+ *    Shift right by the location of the binary point.
+ *    Return the low-order 64 bits of the result.
+ *
+ * Result:
+ *    Product
+ *
+ * Side effects:
+ *    None
+ *
+ *-----------------------------------------------------------------------------
+ */
+
+#if defined(__GNUC__)
+
+static INLINE int64
+Muls64x32s64(int64 multiplicand, uint32 multiplier, uint32 shift)
+{
+   int64 result;
+   uint32 tmp1, tmp2;
+   // ASSERT(shift >= 0 && shift < 64);
+
+   /* Written and tested by mann, checked by dbudko and hpreg */
+   /* XXX hpreg suggested some improvements that we haven't converged on yet */
+   __asm__("mov   %%eax, %2\n\t"      // Save lo(multiplicand)
+           "mov   %%edx, %%eax\n\t"   // Get hi(multiplicand)
+           "test  %%eax, %%eax\n\t"   // Check sign of multiplicand
+           "jl    0f\n\t"             // Go if negative
+           "mull  %4\n\t"             // p2 = hi(multiplicand) * multiplier
+           "jmp   1f\n"
+        "0:\n\t"
+           "mull  %4\n\t"             // p2 = hi(multiplicand) * multiplier
+           "sub   %4, %%edx\n"        // hi(p2) += -1 * multiplier
+        "1:\n\t"
+           "xchg  %%eax, %2\n\t"      // Save lo(p2), get lo(multiplicand)
+           "mov   %%edx, %1\n\t"      // Save hi(p2)
+           "mull  %4\n\t"             // p1 = lo(multiplicand) * multiplier
+           "addl  %2, %%edx\n\t"      // hi(p1) += lo(p2)
+           "adcl  $0, %1\n\t"         // hi(p2) += carry from previous step
+           "cmpl  $32, %%ecx\n\t"     // shift < 32?
+           "jl    2f\n\t"             // Go if so
+           "mov   %%edx, %%eax\n\t"   // result = hi(p2):hi(p1) >> (shift & 31)
+           "mov   %1, %%edx\n\t"
+           "shrdl %%edx, %%eax\n\t"
+           "sarl  %%cl, %%edx\n\t"
+           "jmp   3f\n"
+        "2:\n\t"
+           "shrdl %%edx, %%eax\n\t"   // result = hi(p2):hi(p1):lo(p1) >> shift
+           "shrdl %1, %%edx\n"
+        "3:\n\t"
+           : "=A" (result), "=&r" (tmp1), "=&r" (tmp2)
+           : "0" (multiplicand), "rm" (multiplier), "c" (shift)
+           : "cc");
+   return result;
+}
+
+#elif _MSC_VER
+#pragma warning(disable: 4035)
+
+static INLINE int64
+Muls64x32s64(int64 multiplicand, uint32 multiplier, uint32 shift)
+{
+   //ASSERT(shift >= 0 && shift < 64);
+  
+   /* Written and tested by mann, checked by dbudko and hpreg */
+   __asm {
+      mov  eax, DWORD PTR [multiplicand+4]  // Get hi(multiplicand)
+      test eax, eax                         // Check sign of multiplicand
+      jl   SHORT l0                         // Go if negative
+      mul  DWORD PTR [multiplier]           // p2 = hi(multiplicand) * multiplier
+      jmp  SHORT l1
+   l0:
+      mul  DWORD PTR [multiplier]           // p2 = hi(multiplicand) * multiplier
+      sub  edx, DWORD PTR [multiplier]      // hi(p2) += -1 * multiplier
+   l1:
+      mov  ecx, eax                         // Save lo(p2)
+      mov  ebx, edx                         // Save hi(p2)
+      mov  eax, DWORD PTR [multiplicand]    // Get lo(multiplicand)
+      mul  DWORD PTR [multiplier]           // p1 = lo(multiplicand) * multiplier
+      add  edx, ecx                         // hi(p1) += lo(p2)
+      adc  ebx, 0                           // hi(p2) += carry from previous step
+      mov  ecx, DWORD PTR [shift]           // Get shift
+      cmp  ecx, 32                          // shift < 32?
+      jl   SHORT l2                         // Go if so
+      mov  eax, edx                         // result = hi(p2):hi(p1) >> (shift & 31)
+      mov  edx, ebx
+      shrd eax, edx, cl
+      sar  edx, cl
+      jmp  SHORT l3
+   l2:
+      shrd eax, edx, cl                     // result = hi(p2):hi(p1):lo(p1) << shift
+      shrd edx, ebx, cl
+   l3:
+   }
+   // return with result in edx:eax
+}
+
+#pragma warning(default: 4035)
+#else
+#error No compiler defined for Muls64x32s64
+#endif
+
+
+#endif
--- kernel/linux-2.6.26.3/fs/vmhgfs/vm_basic_defs.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/vm_basic_defs.h	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,606 @@
+/*********************************************************
+ * Copyright (C) 2003 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * vm_basic_defs.h --
+ *
+ *	Standard macros for VMware source code.
+ */
+
+#ifndef _VM_BASIC_DEFS_H_
+#define _VM_BASIC_DEFS_H_
+
+#define INCLUDE_ALLOW_USERLEVEL
+#define INCLUDE_ALLOW_VMMEXT
+#define INCLUDE_ALLOW_MODULE
+#define INCLUDE_ALLOW_VMMON
+#define INCLUDE_ALLOW_VMNIXMOD
+#define INCLUDE_ALLOW_VMKERNEL
+#define INCLUDE_ALLOW_VMKDRIVERS
+#define INCLUDE_ALLOW_VMK_MODULE
+#define INCLUDE_ALLOW_DISTRIBUTE
+#define INCLUDE_ALLOW_VMCORE
+#define INCLUDE_ALLOW_VMIROM
+#include "includeCheck.h"
+#include "vm_basic_types.h" // For INLINE.
+
+/* Checks for FreeBSD, filtering out VMKERNEL. */
+#define __IS_FREEBSD__ (!defined(VMKERNEL) && defined(__FreeBSD__))
+#define __IS_FREEBSD_VER__(ver) (__IS_FREEBSD__ && __FreeBSD_version >= (ver))
+
+#if defined _WIN32 && defined USERLEVEL
+   #include <stddef.h>  /*
+                         * We re-define offsetof macro from stddef, make 
+                         * sure that its already defined before we do it
+                         */
+   #include <windows.h>	// for Sleep() and LOWORD() etc.
+#endif
+
+
+/*
+ * Simple macros
+ */
+
+#if (defined __APPLE__ || defined __FreeBSD__) && \
+    (!defined KERNEL && !defined _KERNEL && !defined VMKERNEL && !defined __KERNEL__)
+#   include <stddef.h>
+#else
+// XXX the __cplusplus one matches that of VC++, to prevent redefinition warning
+// XXX the other one matches that of gcc3.3.3/glibc2.2.4 to prevent redefinition warnings
+#ifndef offsetof
+#ifdef __cplusplus
+#define offsetof(s,m)   (size_t)&(((s *)0)->m)
+#else
+#define offsetof(TYPE, MEMBER) ((size_t) &((TYPE *)0)->MEMBER)
+#endif
+#endif
+#endif // __APPLE__
+
+#ifndef ARRAYSIZE
+#define ARRAYSIZE(a) (sizeof (a) / sizeof *(a))
+#endif
+
+#ifndef MIN
+#define MIN(_a, _b)   (((_a) < (_b)) ? (_a) : (_b))
+#endif
+
+/* The Solaris 9 cross-compiler complains about these not being used */
+#ifndef sun
+static INLINE int 
+Min(int a, int b)
+{
+   return a < b ? a : b;
+}
+#endif
+
+#ifndef MAX
+#define MAX(_a, _b)   (((_a) > (_b)) ? (_a) : (_b))
+#endif
+
+#ifndef sun
+static INLINE int 
+Max(int a, int b)
+{
+   return a > b ? a : b;
+}
+#endif
+
+#define ROUNDUP(x,y)		(((x) + (y) - 1) / (y) * (y))
+#define ROUNDDOWN(x,y)		((x) / (y) * (y))
+#define ROUNDUPBITS(x, bits)	(((uintptr_t) (x) + MASK(bits)) & ~MASK(bits))
+#define ROUNDDOWNBITS(x, bits)	((uintptr_t) (x) & ~MASK(bits))
+#define CEILING(x, y)		(((x) + (y) - 1) / (y))
+#if defined __APPLE__
+#include <machine/param.h>
+#undef MASK
+#endif
+#define MASK(n)			((1 << (n)) - 1)	/* make an n-bit mask */
+#define DWORD_ALIGN(x)          ((((x)+3) >> 2) << 2)
+#define QWORD_ALIGN(x)          ((((x)+4) >> 3) << 3)
+
+#define IMPLIES(a,b) (!(a) || (b))
+
+/*
+ * Not everybody (e.g., the monitor) has NULL
+ */
+
+#ifndef NULL
+#ifdef  __cplusplus
+#define NULL    0
+#else
+#define NULL    ((void *)0)
+#endif
+#endif
+
+
+/* 
+ * Token concatenation
+ *
+ * The C preprocessor doesn't prescan arguments when they are
+ * concatenated or stringified.  So we need extra levels of
+ * indirection to convince the preprocessor to expand its
+ * arguments.
+ */
+
+#define CONC(x, y)              x##y
+#define XCONC(x, y)             CONC(x, y)
+#define XXCONC(x, y)            XCONC(x, y)
+#define MAKESTR(x)              #x
+#define XSTR(x)                 MAKESTR(x)
+
+
+/*
+ * Page operations
+ *
+ * It has been suggested that these definitions belong elsewhere
+ * (like x86types.h).  However, I deem them common enough
+ * (since even regular user-level programs may want to do
+ * page-based memory manipulation) to be here.
+ * -- edward
+ */
+
+#ifndef PAGE_SHIFT // {
+#if defined VM_I386
+   #define PAGE_SHIFT    12
+#elif defined __APPLE__
+   #define PAGE_SHIFT    12
+#else
+   #error
+#endif
+#endif // }
+
+#ifndef PAGE_SIZE
+#define PAGE_SIZE     (1<<PAGE_SHIFT)
+#endif
+
+#ifndef PAGE_MASK
+#define PAGE_MASK     (PAGE_SIZE - 1)
+#endif
+
+#ifndef PAGE_OFFSET
+#define PAGE_OFFSET(_addr)  ((uintptr_t)(_addr)&(PAGE_SIZE-1))
+#endif
+
+#ifndef VM_PAGE_BASE
+#define VM_PAGE_BASE(_addr)  ((_addr)&~(PAGE_SIZE-1))
+#endif
+
+#ifndef VM_PAGES_SPANNED
+#define VM_PAGES_SPANNED(_addr, _size) \
+   ((((_addr) & (PAGE_SIZE - 1)) + (_size) + (PAGE_SIZE - 1)) >> PAGE_SHIFT)
+#endif
+
+#ifndef BYTES_2_PAGES
+#define BYTES_2_PAGES(_nbytes) ((_nbytes) >> PAGE_SHIFT)
+#endif
+
+#ifndef PAGES_2_BYTES
+#define PAGES_2_BYTES(_npages) (((uint64)(_npages)) << PAGE_SHIFT)
+#endif
+
+#ifndef MBYTES_2_PAGES
+#define MBYTES_2_PAGES(_nbytes) ((_nbytes) << (20 - PAGE_SHIFT))
+#endif
+
+#ifndef PAGES_2_MBYTES
+#define PAGES_2_MBYTES(_npages) ((_npages) >> (20 - PAGE_SHIFT))
+#endif
+
+#ifndef VM_PAE_LARGE_PAGE_SHIFT
+#define VM_PAE_LARGE_PAGE_SHIFT 21
+#endif 
+
+#ifndef VM_PAE_LARGE_PAGE_SIZE
+#define VM_PAE_LARGE_PAGE_SIZE (1 << VM_PAE_LARGE_PAGE_SHIFT)
+#endif
+
+#ifndef VM_PAE_LARGE_PAGE_MASK
+#define VM_PAE_LARGE_PAGE_MASK (VM_PAE_LARGE_PAGE_SIZE - 1)
+#endif
+
+#ifndef VM_PAE_LARGE_2_SMALL_PAGES
+#define VM_PAE_LARGE_2_SMALL_PAGES (BYTES_2_PAGES(VM_PAE_LARGE_PAGE_SIZE))
+#endif
+
+/*
+ * Word operations
+ */
+
+#ifndef LOWORD
+#define LOWORD(_dw)   ((_dw) & 0xffff)
+#endif
+#ifndef HIWORD
+#define HIWORD(_dw)   (((_dw) >> 16) & 0xffff)
+#endif
+
+#ifndef LOBYTE
+#define LOBYTE(_w)    ((_w) & 0xff)
+#endif
+#ifndef HIBYTE
+#define HIBYTE(_w)    (((_w) >> 8) & 0xff)
+#endif
+
+#define HIDWORD(_qw)   ((uint32)((_qw) >> 32))
+#define LODWORD(_qw)   ((uint32)(_qw))
+#define QWORD(_hi, _lo)   ((((uint64)(_hi)) << 32) | ((uint32)(_lo)))
+
+
+/*
+ * Deposit a field _src at _pos bits from the right,
+ * with a length of _len, into the integer _target.
+ */
+
+#define DEPOSIT_BITS(_src,_pos,_len,_target) { \
+	unsigned mask = ((1 << _len) - 1); \
+	unsigned shiftedmask = ((1 << _len) - 1) << _pos; \
+	_target = (_target & ~shiftedmask) | ((_src & mask) << _pos); \
+}
+
+
+/*
+ * Get return address.
+ */
+
+#ifdef _MSC_VER
+#ifdef __cplusplus
+extern "C"
+#endif 
+void *_ReturnAddress(void);
+#pragma intrinsic(_ReturnAddress)
+#define GetReturnAddress() _ReturnAddress()
+#elif __GNUC__
+#define GetReturnAddress() __builtin_return_address(0)
+#endif
+
+
+#ifdef __GNUC__
+#ifndef sun
+
+/*
+ * Get the frame pointer. We use this assembly hack instead of
+ * __builtin_frame_address() due to a bug introduced in gcc 4.1.1
+ */
+static INLINE_SINGLE_CALLER uintptr_t
+GetFrameAddr(void)
+{
+   uintptr_t bp;
+#if (__GNUC__ < 4 || (__GNUC__ == 4 && __GNUC_MINOR__ == 0))
+   bp = (uintptr_t)__builtin_frame_address(0);
+#elif (__GNUC__ == 4 && __GNUC_MINOR__ == 1 && __GNUC_PATCHLEVEL__ <= 3)
+#  if defined(VMM64) || defined(VM_X86_64)
+     __asm__ __volatile__("movq %%rbp, %0\n" : "=g" (bp));
+#  else
+     __asm__ __volatile__("movl %%ebp, %0\n" : "=g" (bp));
+#  endif
+#else
+   __asm__ __volatile__(
+#ifdef __linux__
+      ".print \"This newer version of GCC may or may not have the "
+               "__builtin_frame_address bug.  Need to update this. "
+               "See bug 147638.\"\n"
+      ".abort"
+#else /* MacOS */
+      ".abort \"This newer version of GCC may or may not have the "
+               "__builtin_frame_address bug.  Need to update this. "
+               "See bug 147638.\"\n"
+#endif
+      : "=g" (bp)
+   );
+#endif
+   return bp;
+}
+
+
+/*
+ * Returns the frame pointer of the calling function.
+ * Equivalent to __builtin_frame_address(1).
+ */
+static INLINE_SINGLE_CALLER uintptr_t
+GetCallerFrameAddr(void)
+{
+   return *(uintptr_t*)GetFrameAddr();
+}
+
+#endif // sun
+#endif // __GNUC__
+
+/*
+ * Data prefetch was added in gcc 3.1.1
+ * http://www.gnu.org/software/gcc/gcc-3.1/changes.html
+ */
+#ifdef __GNUC__
+#  if ((__GNUC__ > 3) || (__GNUC__ == 3 && __GNUC_MINOR__ > 1) || \
+       (__GNUC__ == 3 && __GNUC_MINOR__ == 1 && __GNUC_PATCHLEVEL__ >= 1))
+#     define PREFETCH_R(var) __builtin_prefetch((var), 0 /* read */, \
+                                                3 /* high temporal locality */)
+#     define PREFETCH_W(var) __builtin_prefetch((var), 1 /* write */, \
+                                                3 /* high temporal locality */)
+#  else
+#     define PREFETCH_R(var) ((void)(var))
+#     define PREFETCH_W(var) ((void)(var))
+#  endif
+#endif /* __GNUC__ */
+
+
+#ifdef USERLEVEL // {
+
+/*
+ * Note this might be a problem on NT b/c while sched_yield guarantees it
+ * moves you to the end of your priority list, Sleep(0) offers no such
+ * guarantee.  Bummer.  --Jeremy.
+ */
+
+#if defined(N_PLAT_NLM)
+/* We do not have YIELD() as we do not need it yet... */
+#elif defined(_WIN32)
+#      define YIELD()		Sleep(0)
+#else
+#      include <sched.h>        // For sched_yield.  Don't ask.  --Jeremy.
+#      define YIELD()		sched_yield()
+#endif 
+
+
+/*
+ * Standardize some Posix names on Windows.
+ */
+
+#ifdef _WIN32 // {
+
+#define  snprintf  _snprintf
+#define	vsnprintf _vsnprintf
+
+static INLINE void
+sleep(unsigned int sec)
+{
+   Sleep(sec * 1000);
+}
+
+static INLINE void
+usleep(unsigned long usec)
+{
+   Sleep(CEILING(usec, 1000));
+}
+
+typedef int pid_t;
+#define       F_OK          0
+#define       X_OK          1
+#define       W_OK          2
+#define       R_OK          4
+
+#endif // }
+
+/*
+ * Macro for username comparison.
+ */
+
+#ifdef _WIN32 // {
+#define USERCMP(x,y)  Str_Strcasecmp(x,y)
+#else
+#define USERCMP(x,y)  strcmp(x,y)
+#endif // }
+
+
+#endif // }
+
+#ifndef va_copy
+
+#ifdef _WIN32
+
+/*
+ * Windows needs va_copy. This works for both 32 and 64-bit Windows
+ * based on inspection of how varags.h from the Visual C CRTL is
+ * implemented. (Future versions of the RTL may break this).
+ */
+
+#define va_copy(dest, src) ((dest) = (src))
+
+#elif defined(__APPLE__) && defined(KERNEL)
+
+/*
+ * MacOS kernel-mode needs va_copy. Based on inspection of stdarg.h
+ * from the MacOSX10.4u.sdk kernel framework, this should work.
+ * (Future versions of the SDK may break this).
+ */
+
+#define va_copy(dest, src) ((dest) = (src))
+
+#elif defined(__GNUC__) && (__GNUC__ < 3)
+
+/*
+ * Old versions of gcc recognize __va_copy, but not va_copy.
+ */
+
+#define va_copy(dest, src) __va_copy(dest, src)
+
+#endif // _WIN32
+
+#endif // va_copy
+
+/*
+ * This one is outside USERLEVEL because it's used by
+ * files compiled into the Windows hgfs driver or the display
+ * driver.
+ */
+
+#ifdef _WIN32
+#define PATH_MAX 256
+#ifndef strcasecmp
+#define strcasecmp(_s1,_s2)   _stricmp((_s1),(_s2))
+#endif
+#ifndef strncasecmp
+#define strncasecmp(_s1,_s2,_n)   _strnicmp((_s1),(_s2),(_n))
+#endif
+#endif
+
+/* 
+ * Convenience macro for COMMUNITY_SOURCE
+ */
+#undef EXCLUDE_COMMUNITY_SOURCE
+#ifdef COMMUNITY_SOURCE
+   #define EXCLUDE_COMMUNITY_SOURCE(x) 
+#else
+   #define EXCLUDE_COMMUNITY_SOURCE(x) x
+#endif
+
+#undef COMMUNITY_SOURCE_INTEL_SECRET
+#if !defined(COMMUNITY_SOURCE) || defined(INTEL_SOURCE)
+/*
+ * It's ok to include INTEL_SECRET source code for non-commsrc,
+ * or for drops directed at Intel.
+ */
+   #define COMMUNITY_SOURCE_INTEL_SECRET
+#endif
+
+/*
+ * Convenience macros and definitions. Can often be used instead of #ifdef.
+ */
+
+#undef DEBUG_ONLY
+#undef SL_DEBUG_ONLY
+#undef VMX86_SL_DEBUG
+#ifdef VMX86_DEBUG
+#define vmx86_debug      1
+#define DEBUG_ONLY(x)    x
+/*
+ * Be very, very, very careful with SL_DEBUG. Pls ask ganesh or min before 
+ * using it.
+ */
+#define VMX86_SL_DEBUG
+#define vmx86_sl_debug   1
+#define SL_DEBUG_ONLY(x) x
+#else
+#define vmx86_debug      0
+#define DEBUG_ONLY(x)
+#define vmx86_sl_debug   0
+#define SL_DEBUG_ONLY(x)
+#endif
+
+#ifdef VMX86_STATS
+#define vmx86_stats   1
+#define STATS_ONLY(x) x
+#else
+#define vmx86_stats   0
+#define STATS_ONLY(x)
+#endif
+
+#ifdef VMX86_DEVEL
+#define vmx86_devel   1
+#define DEVEL_ONLY(x) x
+#else
+#define vmx86_devel   0
+#define DEVEL_ONLY(x)
+#endif
+
+#ifdef VMX86_LOG
+#define vmx86_log     1
+#define LOG_ONLY(x)   x
+#else
+#define vmx86_log     0
+#define LOG_ONLY(x)
+#endif
+
+#ifdef VMX86_VMM_SERIAL_LOGGING
+#define vmx86_vmm_serial_log     1
+#define VMM_SERIAL_LOG_ONLY(x)   x
+#else
+#define vmx86_vmm_serial_log     0
+#define VMM_SERIAL_LOG_ONLY(x)
+#endif
+
+#ifdef VMX86_SERVER
+#define vmx86_server 1
+#define SERVER_ONLY(x) x
+#define HOSTED_ONLY(x)
+#else
+#define vmx86_server 0
+#define SERVER_ONLY(x)
+#define HOSTED_ONLY(x) x
+#endif
+
+#ifdef VMX86_WGS
+#define vmx86_wgs 1
+#define WGS_ONLY(x) x
+#else
+#define vmx86_wgs 0
+#define WGS_ONLY(x) 
+#endif
+
+#ifdef VMKERNEL
+#define vmkernel 1
+#define VMKERNEL_ONLY(x) x
+#else
+#define vmkernel 0
+#define VMKERNEL_ONLY(x)
+#endif
+
+#ifdef _WIN32
+#define WIN32_ONLY(x) x
+#define POSIX_ONLY(x)
+#else
+#define WIN32_ONLY(x)
+#define POSIX_ONLY(x) x
+#endif
+
+#ifdef VMM
+#define VMM_ONLY(x) x
+#define USER_ONLY(x)
+#else
+#define VMM_ONLY(x)
+#define USER_ONLY(x) x
+#endif
+
+/* VMVISOR ifdef only allowed in the vmkernel */
+#ifdef VMKERNEL
+#ifdef VMVISOR
+#define vmvisor 1
+#define VMVISOR_ONLY(x) x
+#else
+#define vmvisor 0
+#define VMVISOR_ONLY(x)
+#endif
+#endif
+
+#ifdef _WIN32
+#define VMW_INVALID_HANDLE INVALID_HANDLE_VALUE
+#else
+#define VMW_INVALID_HANDLE (-1)
+#endif
+
+#ifdef _WIN32
+#define fsync(fd) _commit(fd)
+#define fileno(f) _fileno(f)
+#else
+#endif
+
+/*
+ * Debug output macros for Windows drivers (the Eng variant is for
+ * display/printer drivers only.
+ */
+#ifdef _WIN32
+#ifndef USES_OLD_WINDDK
+#if defined(VMX86_DEBUG) || defined(ASSERT_ALWAYS_AVAILABLE)
+#define WinDrvPrint(arg, ...) DbgPrint(arg, __VA_ARGS__)
+#define WinDrvEngPrint(arg, ...) EngDbgPrint(arg, __VA_ARGS__)
+#else
+#define WinDrvPrint(arg, ...)
+#define WinDrvEngPrint(arg, ...)
+#endif
+#endif
+#endif // _WIN32
+
+#endif // ifndef _VM_BASIC_DEFS_H_
--- kernel/linux-2.6.26.3/fs/vmhgfs/vm_basic_types.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/vm_basic_types.h	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,866 @@
+/*********************************************************
+ * Copyright (C) 1998-2008 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ *
+ * vm_basic_types.h --
+ *
+ *    basic data types.
+ */
+
+
+#ifndef _VM_BASIC_TYPES_H_
+#define _VM_BASIC_TYPES_H_
+
+#define INCLUDE_ALLOW_USERLEVEL
+#define INCLUDE_ALLOW_VMMEXT
+#define INCLUDE_ALLOW_MODULE
+#define INCLUDE_ALLOW_VMMON
+#define INCLUDE_ALLOW_VMNIXMOD
+#define INCLUDE_ALLOW_VMKERNEL
+#define INCLUDE_ALLOW_VMKDRIVERS
+#define INCLUDE_ALLOW_VMK_MODULE
+#define INCLUDE_ALLOW_DISTRIBUTE
+#define INCLUDE_ALLOW_VMCORE
+#define INCLUDE_ALLOW_VMIROM
+#include "includeCheck.h"
+
+/* STRICT ANSI means the Xserver build and X defines Bool differently. */
+#if !defined(__STRICT_ANSI__) || defined(__FreeBSD__)
+typedef char           Bool;
+#endif
+
+#ifndef FALSE
+#define FALSE          0
+#endif
+
+#ifndef TRUE
+#define TRUE           1
+#endif
+
+#define IsBool(x)      (((x) & ~1) == 0)
+#define IsBool2(x, y)  ((((x) | (y)) & ~1) == 0)
+
+/*
+ * Macros __i386__ and __ia64 are intrinsically defined by GCC
+ */
+#ifdef __i386__
+#define VM_I386
+#endif
+
+#ifdef _WIN64
+#define __x86_64__
+#endif
+
+#ifdef __x86_64__
+#define VM_X86_64
+#define VM_I386
+#define vm_x86_64 (1)
+#else
+#define vm_x86_64 (0)
+#endif
+
+
+
+#ifdef _WIN32
+/* safe assumption for a while */
+#define VM_I386
+#endif
+
+#ifdef _MSC_VER
+typedef unsigned __int64 uint64;
+typedef signed __int64 int64;
+
+#pragma warning (3 :4505) // unreferenced local function
+#pragma warning (disable :4018) // signed/unsigned mismatch
+#pragma warning (disable :4761) // integral size mismatch in argument; conversion supplied
+#pragma warning (disable :4305) // truncation from 'const int' to 'short'
+#pragma warning (disable :4244) // conversion from 'unsigned short' to 'unsigned char'
+#pragma warning (disable :4267) // truncation of 'size_t'
+#pragma warning (disable :4146) // unary minus operator applied to unsigned type, result still unsigned
+#pragma warning (disable :4142) // benign redefinition of type
+
+#elif __GNUC__
+/* The Xserver source compiles with -ansi -pendantic */
+#ifndef __STRICT_ANSI__
+#if defined(VM_X86_64)
+typedef unsigned long uint64;
+typedef long int64;
+#else
+typedef unsigned long long uint64;
+typedef long long int64;
+#endif
+#elif __FreeBSD__
+typedef unsigned long long uint64;
+typedef long long int64;
+#endif
+#else
+#error - Need compiler define for int64/uint64
+#endif
+
+typedef unsigned int       uint32;
+typedef unsigned short     uint16;
+typedef unsigned char      uint8;
+
+typedef int       int32;
+typedef short     int16;
+typedef char      int8;
+
+/*
+ * FreeBSD (for the tools build) unconditionally defines these in
+ * sys/inttypes.h so don't redefine them if this file has already
+ * been included. [greg]
+ *
+ * This applies to Solaris as well.
+ */
+
+/*
+ * Before trying to do the includes based on OS defines, see if we can use
+ * feature-based defines to get as much functionality as possible
+ */
+
+#ifdef HAVE_INTTYPES_H
+#include <inttypes.h>
+#endif
+#ifdef HAVE_SYS_TYPES_H
+#include <sys/types.h>
+#endif
+#ifdef HAVE_SYS_INTTYPES_H
+#include <sys/inttypes.h>
+#endif
+#ifdef HAVE_STDINT_H
+#include <stdint.h>
+#endif
+#ifdef HAVE_STDLIB_H
+#include <stdlib.h>
+#endif
+
+#ifdef __FreeBSD__
+#include <sys/param.h> /* For __FreeBSD_version */         
+#endif
+
+#if !defined(USING_AUTOCONF)
+#   if defined(__FreeBSD__) || defined(sun)
+#      ifdef KLD_MODULE
+#         include <sys/types.h>
+#      else
+#         if !defined(VMKERNEL) && (__FreeBSD_version >= 500043)
+#            include <inttypes.h>
+#            include <sys/types.h>
+#         else
+#            include <sys/inttypes.h>
+#         endif
+#      endif
+#   elif defined __APPLE__
+#      if KERNEL
+#         include <sys/unistd.h>
+#         include <sys/types.h> /* mostly for size_t */
+#         include <stdint.h>
+#      else
+#         include <unistd.h>
+#         include <inttypes.h>
+#         include <stdlib.h>
+#         include <stdint.h>
+#      endif
+#   else
+#      if !defined(__intptr_t_defined) && !defined(intptr_t)
+#         define __intptr_t_defined
+#         define intptr_t  intptr_t
+#         ifdef VM_I386
+#            ifdef VM_X86_64
+typedef int64     intptr_t;
+#            else
+typedef int32     intptr_t;
+#            endif
+#         endif
+#      endif
+
+#      ifndef _STDINT_H
+#         ifdef VM_I386
+#            ifdef VM_X86_64
+typedef uint64    uintptr_t;
+#            else
+typedef uint32    uintptr_t;
+#            endif
+#         endif
+#      endif
+#   endif
+#endif
+
+
+/*
+ * Time
+ * XXX These should be cleaned up.  -- edward
+ */
+
+typedef int64 VmTimeType;          /* Time in microseconds */
+typedef int64 VmTimeRealClock;     /* Real clock kept in microseconds */
+typedef int64 VmTimeVirtualClock;  /* Virtual Clock kept in CPU cycles */
+
+/*
+ * Printf format specifiers for size_t and 64-bit number.
+ * Use them like this:
+ *    printf("%"FMT64"d\n", big);
+ *
+ * FMTH is for handles/fds.
+ */
+
+#ifdef _MSC_VER
+   #define FMT64      "I64"
+   #ifdef VM_X86_64
+      #define FMTSZ      "I64"
+      #define FMTPD      "I64"
+      #define FMTH       "I64"
+   #else
+      #define FMTSZ      "I"
+      #define FMTPD      "I"
+      #define FMTH       "I"
+   #endif
+#elif __GNUC__
+   #define FMTH ""
+   #if defined(N_PLAT_NLM) || defined(sun) || \
+       (defined(__FreeBSD__) && (__FreeBSD__ + 0) && ((__FreeBSD__ + 0) < 5))
+      /*
+       * Why (__FreeBSD__ + 0)?  See bug 141008.
+       * Yes, we really need to test both (__FreeBSD__ + 0) and
+       * ((__FreeBSD__ + 0) < 5).  No, we can't remove "+ 0" from
+       * ((__FreeBSD__ + 0) < 5).
+       */
+      #ifdef VM_X86_64
+         #define FMTSZ  "l"
+         #define FMTPD  "l"
+      #else
+         #define FMTSZ  ""
+         #define FMTPD  ""
+      #endif
+   #elif defined(__linux__) \
+      || (defined(_POSIX_C_SOURCE) && _POSIX_C_SOURCE >= 200112L) \
+      || (defined(_POSIX_VERSION) && _POSIX_VERSION >= 200112L) \
+      || (defined(_POSIX2_VERSION) && _POSIX2_VERSION >= 200112L)
+      /* BSD/Darwin, Linux */
+      #define FMTSZ     "z"
+
+      #ifdef VM_X86_64
+         #define FMTPD  "l"
+      #else
+         #define FMTPD  ""
+      #endif
+   #else
+      /* Systems with a pre-C99 libc */
+      #define FMTSZ     "Z"
+      #ifdef VM_X86_64
+         #define FMTPD  "l"
+      #else
+         #define FMTPD  ""
+      #endif
+   #endif
+   #ifdef VM_X86_64
+      #define FMT64     "l"
+   #elif defined(sun) || defined(__APPLE__) || defined(__FreeBSD__)
+      #define FMT64     "ll"
+   #else
+      #define FMT64     "L"
+   #endif
+#else
+   #error - Need compiler define for FMT64 and FMTSZ
+#endif
+
+/*
+ * Suffix for 64-bit constants.  Use it like this:
+ *    CONST64(0x7fffffffffffffff) for signed or
+ *    CONST64U(0x7fffffffffffffff) for unsigned.
+ *
+ * 2004.08.30(thutt):
+ *   The vmcore/asm64/gen* programs are compiled as 32-bit
+ *   applications, but must handle 64 bit constants.  If the
+ *   64-bit-constant defining macros are already defined, the
+ *   definition will not be overwritten.
+ */
+
+#if !defined(CONST64) || !defined(CONST64U)
+#ifdef _MSC_VER
+#define CONST64(c) c##I64
+#define CONST64U(c) c##uI64
+#elif __GNUC__
+#ifdef VM_X86_64
+#define CONST64(c) c##L
+#define CONST64U(c) c##uL
+#else
+#define CONST64(c) c##LL
+#define CONST64U(c) c##uLL
+#endif
+#else
+#error - Need compiler define for CONST64
+#endif
+#endif
+
+/*
+ * Use CONST3264/CONST3264U if you want a constant to be
+ * treated as a 32-bit number on 32-bit compiles and
+ * a 64-bit number on 64-bit compiles. Useful in the case
+ * of shifts, like (CONST3264U(1) << x), where x could be
+ * more than 31 on a 64-bit compile.
+ */
+
+#ifdef VM_X86_64
+    #define CONST3264(a) CONST64(a)
+    #define CONST3264U(a) CONST64U(a)
+#else
+    #define CONST3264(a) (a)
+    #define CONST3264U(a) (a)
+#endif
+
+#define MIN_INT32  ((int32)0x80000000)
+#define MAX_INT32  ((int32)0x7fffffff)
+
+#define MIN_UINT32 ((uint32)0)
+#define MAX_UINT32 ((uint32)0xffffffff)
+
+#define MIN_INT64  (CONST64(0x8000000000000000))
+#define MAX_INT64  (CONST64(0x7fffffffffffffff))
+
+#define MIN_UINT64 (CONST64U(0))
+#define MAX_UINT64 (CONST64U(0xffffffffffffffff))
+
+typedef uint8 *TCA;  /* Pointer into TC (usually). */
+
+/*
+ * Type big enough to hold an integer between 0..100
+ */
+typedef uint8 Percent;
+#define AsPercent(v)	((Percent)(v))
+#define CHOOSE_PERCENT  AsPercent(101)
+
+
+typedef uintptr_t VA;
+typedef uintptr_t VPN;
+
+typedef uint64    PA;
+typedef uint32    PPN;
+
+typedef uint64    PhysMemOff;
+typedef uint64    PhysMemSize;
+
+/* The Xserver source compiles with -ansi -pendantic */
+#ifndef __STRICT_ANSI__
+typedef uint64    BA;
+#endif
+typedef uint32    BPN;
+typedef uint32    PageNum;
+typedef unsigned  MemHandle;
+typedef int32     World_ID;
+
+#define INVALID_WORLD_ID ((World_ID)0)
+
+typedef World_ID User_CartelID;
+#define INVALID_CARTEL_ID INVALID_WORLD_ID
+
+typedef User_CartelID User_SessionID;
+#define INVALID_SESSION_ID INVALID_CARTEL_ID
+
+typedef User_CartelID User_CartelGroupID;
+#define INVALID_CARTELGROUP_ID INVALID_CARTEL_ID
+
+typedef uint32 Worldlet_ID;
+#define INVALID_WORLDLET_ID ((Worldlet_ID)0)
+
+/* world page number */
+typedef uint32    WPN;
+
+/* The Xserver source compiles with -ansi -pendantic */
+#ifndef __STRICT_ANSI__
+typedef uint64     MA;
+typedef uint32     MPN;
+#endif
+
+/*
+ * This type should be used for variables that contain sector
+ * position/quantity.
+ */
+typedef uint64 SectorType;
+
+/*
+ * Linear address
+ */
+
+typedef uintptr_t LA;
+typedef uintptr_t LPN;
+#define LA_2_LPN(_la)     ((_la) >> PAGE_SHIFT)
+#define LPN_2_LA(_lpn)    ((_lpn) << PAGE_SHIFT)
+
+#define LAST_LPN   ((((LA)  1) << (8 * sizeof(LA)   - PAGE_SHIFT)) - 1)
+#define LAST_LPN32 ((((LA32)1) << (8 * sizeof(LA32) - PAGE_SHIFT)) - 1)
+#define LAST_LPN64 ((((LA64)1) << (8 * sizeof(LA64) - PAGE_SHIFT)) - 1)
+
+/* Valid bits in a LPN. */
+#define LPN_MASK   LAST_LPN
+#define LPN_MASK32 LAST_LPN32
+#define LPN_MASK64 LAST_LPN64
+
+/*
+ * On 64 bit platform, address and page number types default
+ * to 64 bit. When we need to represent a 32 bit address, we use
+ * types defined below.
+ *
+ * On 32 bit platform, the following types are the same as the
+ * default types.
+ */
+typedef uint32 VA32;
+typedef uint32 VPN32;
+typedef uint32 LA32;
+typedef uint32 LPN32;
+typedef uint32 PA32;
+typedef uint32 PPN32;
+typedef uint32 MA32;
+typedef uint32 MPN32;
+
+/*
+ * On 64 bit platform, the following types are the same as the
+ * default types.
+ */
+typedef uint64 VA64;
+typedef uint64 VPN64;
+typedef uint64 LA64;
+typedef uint64 LPN64;
+typedef uint64 PA64;
+typedef uint64 PPN64;
+typedef uint64 MA64;
+typedef uint64 MPN64;
+
+/*
+ * VA typedefs for user world apps.
+ */
+typedef VA32 UserVA32;
+typedef VA64 UserVA64;
+typedef UserVA32 UserVAConst; /* Userspace ptr to data that we may only read. */
+typedef UserVA64 UserVA64Const; /* Used by 64-bit syscalls until conversion is finished. */
+#ifdef VMKERNEL
+typedef UserVA32 UserVA;
+#else
+typedef void * UserVA;
+#endif
+
+
+/*
+ * Maximal possible PPN value (errors too) that PhysMem can handle.
+ * Must be at least as large as MAX_PPN which is the maximum PPN
+ * for any region other than buserror.
+ */
+#define PHYSMEM_MAX_PPN ((PPN)0xffffffff)
+#define MAX_PPN         ((PPN)0x1fffffff)   /* Maximal observable PPN value. */
+#define INVALID_PPN     ((PPN)0xffffffff)
+
+#define INVALID_BPN  ((BPN) 0x1fffffff)
+
+#define INVALID_MPN  ((MPN)-1)
+#define MEMREF_MPN   ((MPN)-2)
+#define RESERVED_MPN ((MPN) 0)
+/* Support 39 bits of address space, minus one page. */
+#define MAX_MPN      ((MPN) 0x07ffffff)
+
+#define INVALID_LPN ((LPN)-1)
+#define INVALID_VPN ((VPN)-1)
+#define INVALID_LPN64 ((LPN64)-1)
+#define INVALID_PAGENUM ((PageNum)-1)
+#define INVALID_WPN ((WPN) -1)
+
+
+/*
+ * Format modifier for printing VA, LA, and VPN.
+ * Use them like this: Log("%#"FMTLA"x\n", laddr)
+ */
+
+#if defined(VMM64) || defined(FROBOS64) || vm_x86_64 || defined __APPLE__
+#   define FMTLA "l"
+#   define FMTVA "l"
+#   define FMTVPN "l"
+#else
+#   define FMTLA ""
+#   define FMTVA ""
+#   define FMTVPN ""
+#endif
+
+#ifndef EXTERN
+#define EXTERN        extern
+#endif
+#define CONST         const
+
+
+#ifndef INLINE
+#   ifdef _MSC_VER
+#      define INLINE        __inline
+#   else
+#      define INLINE        inline
+#   endif
+#endif
+
+
+/*
+ * Annotation for data that may be exported into a DLL and used by other
+ * apps that load that DLL and import the data.
+ */
+#if defined(_WIN32) && defined(VMX86_IMPORT_DLLDATA)
+#  define VMX86_EXTERN_DATA       extern __declspec(dllimport)
+#else // !_WIN32
+#  define VMX86_EXTERN_DATA       extern
+#endif
+
+#if defined(_WIN32) && !defined(VMX86_NO_THREADS)
+#define THREADSPECIFIC __declspec(thread)
+#else
+#define THREADSPECIFIC
+#endif
+
+/*
+ * Due to the wonderful "registry redirection" feature introduced in
+ * 64-bit Windows, if you access any key under HKLM\Software in 64-bit
+ * code, you need to open/create/delete that key with
+ * VMKEY_WOW64_32KEY if you want a consistent view with 32-bit code.
+ */
+
+#ifdef _WIN32
+#ifdef _WIN64
+#define VMW_KEY_WOW64_32KEY KEY_WOW64_32KEY
+#else
+#define VMW_KEY_WOW64_32KEY 0x0
+#endif
+#endif
+
+
+/*
+ * Consider the following reasons functions are inlined:
+ *
+ *  1) inlined for performance reasons
+ *  2) inlined because it's a single-use function
+ *
+ * Functions which meet only condition 2 should be marked with this
+ * inline macro; It is not critical to be inlined (but there is a
+ * code-space & runtime savings by doing so), so when other callers
+ * are added the inline-ness should be removed.
+ */
+
+#if __GNUC__ > 3 || (__GNUC__ == 3 && __GNUC_MINOR__ >= 3)
+/*
+ * Starting at version 3.3, gcc does not always inline functions marked
+ * 'inline' (it depends on their size). To force gcc to do so, one must use the
+ * extra __always_inline__ attribute.
+ */
+#   define INLINE_SINGLE_CALLER INLINE __attribute__((__always_inline__))
+#   if    defined(VMM) \
+       && (__GNUC__ > 4 || (__GNUC__ == 4 && __GNUC_MINOR__ > 1))
+#      warning Verify INLINE_SINGLE_CALLER '__always_inline__' attribute (did \
+             monitor size change?)
+#   endif
+#else
+#   define INLINE_SINGLE_CALLER INLINE
+#endif
+
+/*
+ * Used when a hard guaranteed of no inlining is needed. Very few
+ * instances need this since the absence of INLINE is a good hint
+ * that gcc will not do inlining.
+ */
+
+#if defined(__GNUC__) && defined(VMM)
+#define ABSOLUTELY_NOINLINE __attribute__((__noinline__))
+#endif
+
+/*
+ * Attributes placed on function declarations to tell the compiler
+ * that the function never returns.
+ */
+
+#ifdef _MSC_VER
+#define NORETURN __declspec(noreturn)
+#elif __GNUC__ > 2 || (__GNUC__ == 2 && __GNUC_MINOR__ >= 9)
+#define NORETURN __attribute__((__noreturn__))
+#else
+#define NORETURN
+#endif
+
+/*
+ * GCC 3.2 inline asm needs the + constraint for input/ouput memory operands.
+ * Older GCCs don't know about it --hpreg
+ */
+
+#if __GNUC__ > 3 || (__GNUC__ == 3 && __GNUC_MINOR__ >= 2)
+#   define VM_ASM_PLUS 1
+#else
+#   define VM_ASM_PLUS 0
+#endif
+
+/*
+ * Branch prediction hints:
+ *     LIKELY(exp)   - Expression exp is likely TRUE.
+ *     UNLIKELY(exp) - Expression exp is likely FALSE.
+ *   Usage example:
+ *        if (LIKELY(excCode == EXC_NONE)) {
+ *               or
+ *        if (UNLIKELY(REAL_MODE(vc))) {
+ *
+ * We know how to predict branches on gcc3 and later (hopefully),
+ * all others we don't so we do nothing.
+ */
+
+#if (__GNUC__ >= 3)
+/*
+ * gcc3 uses __builtin_expect() to inform the compiler of an expected value.
+ * We use this to inform the static branch predictor. The '!!' in LIKELY
+ * will convert any !=0 to a 1.
+ */
+#define LIKELY(_exp)     __builtin_expect(!!(_exp), 1)
+#define UNLIKELY(_exp)   __builtin_expect((_exp), 0)
+#else
+#define LIKELY(_exp)      (_exp)
+#define UNLIKELY(_exp)    (_exp)
+#endif
+
+/*
+ * GCC's argument checking for printf-like functions
+ * This is conditional until we have replaced all `"%x", void *'
+ * with `"0x%08x", (uint32) void *'. Note that %p prints different things
+ * on different platforms.  Argument checking is enabled for the
+ * vmkernel, which has already been cleansed.
+ *
+ * fmtPos is the position of the format string argument, beginning at 1
+ * varPos is the position of the variable argument, beginning at 1
+ */
+
+#if defined(__GNUC__)
+# define PRINTF_DECL(fmtPos, varPos) __attribute__((__format__(__printf__, fmtPos, varPos)))
+#else
+# define PRINTF_DECL(fmtPos, varPos)
+#endif
+
+#if defined(__GNUC__)
+# define SCANF_DECL(fmtPos, varPos) __attribute__((__format__(__scanf__, fmtPos, varPos)))
+#else
+# define SCANF_DECL(fmtPos, varPos)
+#endif
+
+/*
+ * UNUSED_PARAM should surround the parameter name and type declaration,
+ * e.g. "int MyFunction(int var1, UNUSED_PARAM(int var2))"
+ *
+ */
+
+#ifndef UNUSED_PARAM
+# if defined(__GNUC__)
+#  define UNUSED_PARAM(_parm) _parm  __attribute__((__unused__))
+# else
+#  define UNUSED_PARAM(_parm) _parm
+# endif
+#endif
+
+/*
+ * REGPARM defaults to REGPARM3, i.e., a requent that gcc
+ * puts the first three arguments in registers.  (It is fine
+ * if the function has fewer than three args.)  Gcc only.
+ * Syntactically, put REGPARM where you'd put INLINE or NORETURN.
+ */
+
+#if defined(__GNUC__)
+# define REGPARM0 __attribute__((regparm(0)))
+# define REGPARM1 __attribute__((regparm(1)))
+# define REGPARM2 __attribute__((regparm(2)))
+# define REGPARM3 __attribute__((regparm(3)))
+# define REGPARM REGPARM3
+#else
+# define REGPARM0
+# define REGPARM1
+# define REGPARM2
+# define REGPARM3
+# define REGPARM
+#endif
+
+/*
+ * ALIGNED specifies minimum alignment in "n" bytes.
+ */
+
+#ifdef __GNUC__
+#define ALIGNED(n) __attribute__((__aligned__(n)))
+#else
+#define ALIGNED(n)
+#endif
+
+/*
+ * __func__ is a stringified function name that is part of the C99 standard. The block
+ * below defines __func__ on older systems where the compiler does not support that
+ * macro.
+ */
+#if defined(__GNUC__) \
+   && ((__GNUC__ == 2 && __GNUC_MINOR < 96) \
+       || (__GNUC__ < 2))
+#   define __func__ __FUNCTION__
+#endif
+
+/*
+ * Once upon a time, this was used to silence compiler warnings that
+ * get generated when the compiler thinks that a function returns
+ * when it is marked noreturn.  Don't do it.  Use NOT_REACHED().
+ */
+
+#define INFINITE_LOOP()           do { } while (1)
+
+/*
+ * On FreeBSD (for the tools build), size_t is typedef'd if _BSD_SIZE_T_
+ * is defined. Use the same logic here so we don't define it twice. [greg]
+ */
+#ifdef __FreeBSD__
+#   ifdef _BSD_SIZE_T_
+#      undef _BSD_SIZE_T_
+#      ifdef VM_I386
+#         ifdef VM_X86_64
+             typedef uint64 size_t;
+#         else
+             typedef uint32 size_t;
+#         endif
+#      endif /* VM_I386 */
+#   endif
+
+#   ifdef _BSD_SSIZE_T_
+#      undef _BSD_SSIZE_T_
+#      define _SSIZE_T
+#      define __ssize_t_defined
+#      define _SSIZE_T_DECLARED
+#      ifdef VM_I386
+#         ifdef VM_X86_64
+             typedef int64 ssize_t;
+#         else
+             typedef int32 ssize_t;
+#         endif
+#      endif /* VM_I386 */
+#   endif
+
+#else
+#   ifndef _SIZE_T
+#      define _SIZE_T
+#      ifdef VM_I386
+#         ifdef VM_X86_64
+             typedef uint64 size_t;
+#         else
+             typedef uint32 size_t;
+#         endif
+#      endif /* VM_I386 */
+#   endif
+
+#   if !defined(FROBOS) && !defined(_SSIZE_T) && !defined(ssize_t) && \
+       !defined(__ssize_t_defined) && !defined(_SSIZE_T_DECLARED)
+#      define _SSIZE_T
+#      define __ssize_t_defined
+#      define _SSIZE_T_DECLARED
+#      ifdef VM_I386
+#         ifdef VM_X86_64
+             typedef int64 ssize_t;
+#         else
+             typedef int32 ssize_t;
+#         endif
+#      endif /* VM_I386 */
+#   endif
+
+#endif
+
+/*
+ * Format modifier for printing pid_t.  On sun the pid_t is a ulong, but on
+ * Linux it's an int.
+ * Use this like this: printf("The pid is %"FMTPID".\n", pid);
+ */
+#ifdef sun
+#   ifdef VM_X86_64
+#      define FMTPID "d"
+#   else
+#      define FMTPID "lu"
+#   endif
+#else
+# define FMTPID "d"
+#endif
+
+/*
+ * Format modifier for printing uid_t.  On sun the uid_t is a ulong, but on
+ * Linux it's an int.
+ * Use this like this: printf("The uid is %"FMTUID".\n", uid);
+ */
+#ifdef sun
+#   ifdef VM_X86_64
+#      define FMTUID "u"
+#   else
+#      define FMTUID "lu"
+#   endif
+#else
+# define FMTUID "u"
+#endif
+
+/*
+ * Format modifier for printing mode_t.  On sun the mode_t is a ulong, but on
+ * Linux it's an int.
+ * Use this like this: printf("The mode is %"FMTMODE".\n", mode);
+ */
+#ifdef sun
+#   ifdef VM_X86_64
+#      define FMTMODE "o"
+#   else
+#      define FMTMODE "lo"
+#   endif
+#else
+# define FMTMODE "o"
+#endif
+
+/*
+ * Format modifier for printing time_t. Most platforms define a time_t to be
+ * a long int, but on FreeBSD (as of 5.0, it seems), the time_t is a signed
+ * size quantity. Refer to the definition of FMTSZ to see why we need silly
+ * preprocessor arithmetic.
+ * Use this like this: printf("The mode is %"FMTTIME".\n", time);
+ */
+#if defined(__FreeBSD__) && (__FreeBSD__ + 0) && ((__FreeBSD__ + 0) >= 5)
+#   define FMTTIME FMTSZ"d"
+#else
+#   define FMTTIME "ld"
+#endif
+
+/*
+ * Define MXSemaHandle here so both vmmon and vmx see this definition.
+ */
+
+#ifdef _WIN32
+typedef uintptr_t MXSemaHandle;
+#else
+typedef int MXSemaHandle;
+#endif
+
+/*
+ * Define type for poll device handles.
+ */
+
+#ifdef _WIN32
+typedef uintptr_t PollDevHandle;
+#else
+typedef int PollDevHandle;
+#endif
+
+/*
+ * Define the utf16_t type.
+ */
+
+#if defined(_WIN32) && defined(_NATIVE_WCHAR_T_DEFINED)
+typedef wchar_t utf16_t;
+#else
+typedef uint16 utf16_t;
+#endif
+
+#endif  /* _VM_BASIC_TYPES_H_ */
--- kernel/linux-2.6.26.3/fs/vmhgfs/vmhgfs_version.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/vmhgfs_version.h	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,32 @@
+/*********************************************************
+ * Copyright (C) 2007 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * vmhgfs_version.h --
+ *
+ * Version definitions for the Linux vmhgfs driver.
+ */
+
+#ifndef _VMHGFS_VERSION_H_
+#define _VMHGFS_VERSION_H_
+
+#define VMHGFS_DRIVER_VERSION          1.4.1.1
+#define VMHGFS_DRIVER_VERSION_COMMAS   1,4,1,1
+#define VMHGFS_DRIVER_VERSION_STRING   "1.4.1.1"
+
+#endif /* _VMHGFS_VERSION_H_ */
--- kernel/linux-2.6.26.3/fs/vmhgfs/vmware.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/vmware.h	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,58 @@
+/*********************************************************
+ * Copyright (C) 2003 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * vmware.h --
+ *
+ *	Standard include file for VMware source code.
+ */
+
+#ifndef _VMWARE_H_
+#define _VMWARE_H_
+
+#define INCLUDE_ALLOW_USERLEVEL
+#define INCLUDE_ALLOW_VMCORE
+#define INCLUDE_ALLOW_MODULE
+#define INCLUDE_ALLOW_VMMON
+#define INCLUDE_ALLOW_VMNIXMOD
+#define INCLUDE_ALLOW_VMKERNEL
+#define INCLUDE_ALLOW_VMK_MODULE
+#define INCLUDE_ALLOW_DISTRIBUTE
+#include "includeCheck.h"
+
+#include "vm_basic_types.h"
+#include "vm_basic_defs.h"
+#include "vm_assert.h"
+
+/*
+ * Global error codes. Currently used internally, but may be exported
+ * to customers one day, like VM_E_XXX in vmcontrol_constants.h
+ */
+
+typedef enum VMwareStatus {
+   VMWARE_STATUS_SUCCESS,  /* success */
+   VMWARE_STATUS_ERROR,    /* generic error */
+   VMWARE_STATUS_NOMEM,    /* generic memory allocation error */
+   VMWARE_STATUS_INSUFFICIENT_RESOURCES, /* internal or system resource limit exceeded */
+   VMWARE_STATUS_INVALID_ARGS  /* invalid arguments */
+} VMwareStatus;
+
+#define VMWARE_SUCCESS(s) ((s) == VMWARE_STATUS_SUCCESS)
+
+
+#endif // ifndef _VMWARE_H_
--- kernel/linux-2.6.26.3/fs/vmhgfs/vmware_pack_begin.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/vmware_pack_begin.h	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,43 @@
+/*********************************************************
+ * Copyright (C) 2002 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * vmware_pack_begin.h --
+ *
+ *    Begin of structure packing. See vmware_pack_init.h for details.
+ *
+ *    Note that we do not use the following construct in this include file,
+ *    because we want to emit the code every time the file is included --hpreg
+ *
+ *    #ifndef foo
+ *    #   define foo
+ *    ...
+ *    #endif
+ *
+ */
+
+
+#include "vmware_pack_init.h"
+
+
+#ifdef _MSC_VER
+#   pragma pack(push, 1)
+#elif __GNUC__
+#else
+#   error Compiler packing...
+#endif
--- kernel/linux-2.6.26.3/fs/vmhgfs/vmware_pack_end.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/vmware_pack_end.h	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,44 @@
+/*********************************************************
+ * Copyright (C) 2002 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+/*
+ * vmware_pack_end.h --
+ *
+ *    End of structure packing. See vmware_pack_init.h for details.
+ *
+ *    Note that we do not use the following construct in this include file,
+ *    because we want to emit the code every time the file is included --hpreg
+ *
+ *    #ifndef foo
+ *    #   define foo
+ *    ...
+ *    #endif
+ *
+ */
+
+
+#include "vmware_pack_init.h"
+
+
+#ifdef _MSC_VER
+#   pragma pack(pop)
+#elif __GNUC__
+__attribute__((__packed__))
+#else
+#   error Compiler packing...
+#endif
--- kernel/linux-2.6.26.3/fs/vmhgfs/vmware_pack_init.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/vmware_pack_init.h	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,65 @@
+/*********************************************************
+ * Copyright (C) 2002 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef __VMWARE_PACK_INIT_H__
+#   define __VMWARE_PACK_INIT_H__
+
+
+/*
+ * vmware_pack_init.h --
+ *
+ *    Platform-independent code to make the compiler pack (i.e. have them
+ *    occupy the smallest possible space) structure definitions. The following
+ *    constructs are known to work --hpreg
+ *
+ *    #include "vmware_pack_begin.h"
+ *    struct foo {
+ *       ...
+ *    }
+ *    #include "vmware_pack_end.h"
+ *    ;
+ *
+ *    typedef
+ *    #include "vmware_pack_begin.h"
+ *    struct foo {
+ *       ...
+ *    }
+ *    #include "vmware_pack_end.h"
+ *    foo;
+ */
+
+
+#ifdef _MSC_VER
+/*
+ * MSVC 6.0 emits warning 4103 when the pack push and pop pragma pairing is
+ * not balanced within 1 included file. That is annoying because our scheme
+ * is based on the pairing being balanced between 2 included files.
+ *
+ * So we disable this warning, but this is safe because the compiler will also
+ * emit warning 4161 when there is more pops than pushes within 1 main
+ * file --hpreg
+ */
+
+#   pragma warning(disable:4103)
+#elif __GNUC__
+#else
+#   error Compiler packing...
+#endif
+
+
+#endif /* __VMWARE_PACK_INIT_H__ */
--- kernel/linux-2.6.26.3/fs/vmhgfs/x86cpuid.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-2.6.26.3.vmtools/fs/vmhgfs/x86cpuid.h	2008-09-03 10:01:01.000000000 -0500
@@ -0,0 +1,967 @@
+/*********************************************************
+ * Copyright (C) 1998-2008 VMware, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation version 2 and no later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
+ *
+ *********************************************************/
+
+#ifndef _X86CPUID_H_
+#define _X86CPUID_H_
+
+/* http://www.sandpile.org/ia32/cpuid.htm */
+
+#define INCLUDE_ALLOW_USERLEVEL
+#define INCLUDE_ALLOW_VMX
+#define INCLUDE_ALLOW_VMMEXT
+#define INCLUDE_ALLOW_VMKERNEL
+#define INCLUDE_ALLOW_MODULE
+#define INCLUDE_ALLOW_VMNIXMOD
+#define INCLUDE_ALLOW_DISTRIBUTE
+#define INCLUDE_ALLOW_VMK_MODULE
+#define INCLUDE_ALLOW_VMCORE
+#define INCLUDE_ALLOW_VMMON
+#include "includeCheck.h"
+
+#include "vm_basic_types.h"
+
+/*
+ * The linux kernel's ptrace.h stupidly defines the bare
+ * EAX/EBX/ECX/EDX, which wrecks havoc with our preprocessor tricks.
+ */
+#undef EAX
+#undef EBX
+#undef ECX
+#undef EDX
+
+typedef struct CPUIDRegs {
+   uint32 eax, ebx, ecx, edx;
+} CPUIDRegs;
+
+typedef union CPUIDRegsUnion {
+   uint32 array[4];
+   CPUIDRegs regs;
+} CPUIDRegsUnion;
+
+/*
+ * Results of calling cpuid(eax, ecx) on all host logical CPU.
+ */
+#ifdef _MSC_VER
+#pragma warning (disable :4200) // non-std extension: zero-sized array in struct
+#endif
+
+typedef
+#include "vmware_pack_begin.h"
+struct CPUIDReply {
+   /*
+    * Unique host logical CPU identifier. It does not change across queries, so
+    * we use it to correlate the replies of multiple queries.
+    */
+   uint64 tag;                // OUT
+
+   CPUIDRegs regs;            // OUT
+}
+#include "vmware_pack_end.h"
+CPUIDReply;
+
+typedef
+#include "vmware_pack_begin.h"
+struct CPUIDQuery {
+   uint32 eax;                // IN
+   uint32 ecx;                // IN
+   uint32 numLogicalCPUs;     // IN/OUT
+   CPUIDReply logicalCPUs[0]; // OUT
+}
+#include "vmware_pack_end.h"
+CPUIDQuery;
+
+/*
+ * CPUID levels the monitor caches and ones that are not cached, but
+ * have fields defined below (short name and actual value).
+ * 
+ * The first parameter defines whether the level is masked/tested
+ * during power-on/migration.  Any level which is marked as FALSE here
+ * *must* have all field masks defined as IGNORE in CPUID_FIELD_DATA.
+ * A static assert in lib/cpuidcompat/cpuidcompat.c will check this.
+ *
+ * IMPORTANT: WHEN ADDING A NEW FIELD TO THE CACHED LEVELS, make sure
+ * you update vmcore/vmm/cpu/priv.c:Priv_CPUID() and vmcore/vmm64/bt/
+ * cpuid_shared.S (and geninfo) to include the new level.
+ */
+
+#define CPUID_CACHED_LEVELS                     \
+   CPUIDLEVEL(TRUE,  0,  0)                     \
+   CPUIDLEVEL(TRUE,  1,  1)                     \
+   CPUIDLEVEL(FALSE,400, 0x40000000)            \
+   CPUIDLEVEL(FALSE,410, 0x40000010)            \
+   CPUIDLEVEL(FALSE, 80, 0x80000000)            \
+   CPUIDLEVEL(TRUE,  81, 0x80000001)            \
+   CPUIDLEVEL(FALSE, 88, 0x80000008)            \
+   CPUIDLEVEL(TRUE,  8A, 0x8000000A)
+
+#define CPUID_UNCACHED_LEVELS                   \
+   CPUIDLEVEL(FALSE, 4, 4)                      \
+   CPUIDLEVEL(FALSE, 5, 5)                      \
+   CPUIDLEVEL(FALSE, 6, 6)                      \
+   CPUIDLEVEL(FALSE, A, 0xA)                    \
+   CPUIDLEVEL(FALSE, 86, 0x80000006)            \
+   CPUIDLEVEL(FALSE, 87, 0x80000007)            \
+
+#define CPUID_ALL_LEVELS                        \
+   CPUID_CACHED_LEVELS                          \
+   CPUID_UNCACHED_LEVELS
+
+/* Define cached CPUID levels in the form: CPUID_LEVEL_<ShortName> */
+typedef enum {
+#define CPUIDLEVEL(t, s, v) CPUID_LEVEL_##s,
+   CPUID_CACHED_LEVELS
+#undef CPUIDLEVEL
+   CPUID_NUM_LEVELS
+} CpuidLevels;
+
+/*
+ * CPUID result registers
+ */
+
+#define CPUID_REGS                              \
+   CPUIDREG(EAX, eax)                           \
+   CPUIDREG(EBX, ebx)                           \
+   CPUIDREG(ECX, ecx)                           \
+   CPUIDREG(EDX, edx)
+
+typedef enum {
+#define CPUIDREG(uc, lc) CPUID_REG_##uc,
+   CPUID_REGS
+#undef CPUIDREG
+   CPUID_NUM_REGS
+} CpuidRegs;
+
+/*
+ * CPU vendors
+ */
+
+typedef enum {
+   CPUID_VENDOR_UNKNOWN,
+   CPUID_VENDOR_COMMON,
+   CPUID_VENDOR_INTEL,
+   CPUID_VENDOR_AMD,
+   CPUID_VENDOR_CYRIX,
+   CPUID_NUM_VENDORS
+} CpuidVendors;
+
+#define CPUID_INTEL_VENDOR_STRING       "GenuntelineI"
+#define CPUID_AMD_VENDOR_STRING         "AuthcAMDenti"
+#define CPUID_CYRIX_VENDOR_STRING       "CyriteadxIns"
+#define CPUID_HYPERV_HYPERVISOR_VENDOR_STRING  "Microsoft Hv"
+#define CPUID_INTEL_VENDOR_STRING_FIXED "GenuineIntel"
+#define CPUID_AMD_VENDOR_STRING_FIXED   "AuthenticAMD"
+#define CPUID_CYRIX_VENDOR_STRING_FIXED "CyrixInstead"
+
+#define CPUID_HYPERV_HYPERVISOR_VENDOR_STRING  "Microsoft Hv"
+
+/*
+ * FIELDDEF can be defined to process the CPUID information provided
+ * in the following CPUID_FIELD_DATA macro.  The first parameter is
+ * the CPUID level of the feature (must be defined in CPUID_*_LEVELS.
+ * The second parameter is the register the field is contained in
+ * (defined in CPUID_REGS).  The third field is the vendor this
+ * feature applies to.  "COMMON" means all vendors apply.  UNKNOWN may
+ * not be used here.  The fourth and fifth parameters are the bit
+ * position of the field and the width, respectively.  The sixth is
+ * the text name of the field.
+ *
+ * The seventh and eighth parameters specify the default CPUID
+ * behavior for power-on, guest view, and migration tests (cpt/rsm &
+ * vmotion).  The eighth parameter is ignored for types other than
+ * MASK & TEST, and must be zero in this case.
+ *
+ * When adding a new field, be sure to consider its purpose.  The
+ * following list of types is provided in order of likely use.
+ *
+ * NOTE: this form of representation is separate from the masking
+ * system specified via the config file.  That is because this
+ * representation must take into account multi-bit fields.
+ *
+ * HOST    - Passthrough host value and cannot change during migration.
+ * MASK, 0 - Hide from the guest, because we don't support it or we
+ *           don't want the guest to know that it exists.
+ * IGNORE  - Ignore this field for all tests
+ *
+ *    (Think twice before using the below mask types/combinations)
+ *
+ * MASK, x - Force the guest to always see x, and don't compare for
+ *           migration -- only APIC as of today; it is controlled by
+ *           software and we know how to toggle it
+ * TEST, x - Require host CPUID field to be x for power-on
+ * RSVD    - Hidden from the guest, but compared during migration
+ *
+ *
+ * Table to explain mask type meanings:
+ *
+ *                         IGNR   MASK   TEST   HOST   RSVD
+ * --------------------------------------------------------
+ * Req'd val for power-on   -      -      x      -      -
+ * Value guest sees         *      x      *      *      0
+ * Checked on migration?    N      N      Y      Y      Y
+ *
+ * * - initial host's power-on CPUID value
+ *
+ * FIELDDEFA takes a ninth parameter, the name used when creating
+ * accessor functions in lib/public/cpuidInfoFuncs.h.
+ *
+ * FLAGDEF/FLAGDEFA is defined identically to fields, but their
+ * accessors are more appropriate for 1-bit flags.
+ */
+
+typedef enum {
+   CPUID_FIELD_MASK_IGNORE,
+   CPUID_FIELD_MASK_MASK,
+   CPUID_FIELD_MASK_TEST,
+   CPUID_FIELD_MASK_HOST,
+   CPUID_FIELD_MASK_RSVD,
+   CPUID_NUM_FIELD_MASKS
+} CpuidFieldMasks;
+
+
+typedef enum {
+   CPUID_FIELD_SUPPORTED_NO,
+   CPUID_FIELD_SUPPORTED_YES,
+   CPUID_FIELD_SUPPORTED_ANY,
+   CPUID_FIELD_SUPPORTED_NA,
+   CPUID_NUM_FIELD_SUPPORTEDS
+} CpuidFieldSupported;
+
+
+/*    LEVEL, REG, VENDOR, POS, SIZE, NAME,       MON SUPP, MASK TYPE, SET TO, CPL3, [FUNC] */
+#define CPUID_FIELD_DATA_LEVEL_0                                               \
+FIELDDEF(  0, EAX, COMMON,  0, 32, NUMLEVELS,           ANY, IGNORE, 0, FALSE)     \
+FIELDDEF(  0, EBX, COMMON,  0, 32, VENDOR1,             YES, HOST,   0, TRUE)      \
+FIELDDEF(  0, ECX, COMMON,  0, 32, VENDOR3,             YES, HOST,   0, TRUE)      \
+FIELDDEF(  0, EDX, COMMON,  0, 32, VENDOR2,             YES, HOST,   0, TRUE)
+                                                        
+/*    LEVEL, REG, VENDOR, POS, SIZE, NAME,       MON SUPP, MASK TYPE, SET TO, CPL3, [FUNC] */
+#define CPUID_FIELD_DATA_LEVEL_1                                               \
+FIELDDEFA( 1, EAX, COMMON,  0,  4, STEPPING,            ANY, IGNORE, 0, FALSE, STEPPING)  \
+FIELDDEFA( 1, EAX, COMMON,  4,  4, MODEL,               ANY, IGNORE, 0, FALSE, MODEL)     \
+FIELDDEFA( 1, EAX, COMMON,  8,  4, FAMILY,              YES, HOST,   0, FALSE, FAMILY)    \
+FIELDDEF(  1, EAX, COMMON, 12,  2, TYPE,                ANY, IGNORE, 0, FALSE)            \
+FIELDDEFA( 1, EAX, COMMON, 16,  4, EXTMODEL,            ANY, IGNORE, 0, FALSE, EXT_MODEL) \
+FIELDDEFA( 1, EAX, COMMON, 20,  8, EXTFAMILY,           YES, HOST,   0, FALSE, EXT_FAMILY) \
+FIELDDEF(  1, EBX, COMMON,  0,  8, BRAND_ID,            ANY, IGNORE, 0, FALSE)            \
+FIELDDEF(  1, EBX, COMMON,  8,  8, CLFL_SIZE,           ANY, IGNORE, 0, FALSE)            \
+FIELDDEFA( 1, EBX, COMMON, 16,  8, LCPU_COUNT,          ANY, IGNORE, 0, FALSE, LCPU_COUNT) \
+FIELDDEFA( 1, EBX, COMMON, 24,  8, APICID,              ANY, IGNORE, 0, FALSE, APICID)    \
+FLAGDEFA(  1, ECX, COMMON, 0,   1, SSE3,                YES, HOST,   0, TRUE,  SSE3)      \
+FLAGDEF(   1, ECX, INTEL,  2,   1, NDA2,                NO,  MASK,   0, FALSE)            \
+FLAGDEFA(  1, ECX, COMMON, 3,   1, MWAIT,               NO,  MASK,   0, FALSE, MWAIT)     \
+FLAGDEFA(  1, ECX, INTEL,  4,   1, DSCPL,               NO,  MASK,   0, FALSE, DSCPL)     \
+FLAGDEFA(  1, ECX, INTEL,  5,   1, VMX,                 NO,  MASK,   0, FALSE, VMX)       \
+FLAGDEF(   1, ECX, INTEL,  6,   1, SMX,                 NO,  MASK,   0, FALSE)            \
+FLAGDEF(   1, ECX, INTEL,  7,   1, EST,                 NO,  MASK,   0, FALSE)            \
+FLAGDEF(   1, ECX, INTEL,  8,   1, TM2,                 NO,  MASK,   0, FALSE)            \
+FLAGDEFA(  1, ECX, COMMON, 9,   1, SSSE3,               YES, HOST,   0, TRUE,  SSSE3)     \
+FLAGDEF(   1, ECX, INTEL,  10,  1, HTCACHE,             NO,  MASK,   0, FALSE)            \
+FLAGDEFA(  1, ECX, COMMON, 13,  1, CMPX16,              YES, HOST,   0, TRUE,  CMPX16)    \
+FLAGDEF(   1, ECX, INTEL,  14,  1, xPPR,                NO,  MASK,   0, FALSE)            \
+FLAGDEF(   1, ECX, INTEL,  15,  1, PERF_MSR,            NO,  MASK,   0, FALSE)            \
+FLAGDEF(   1, ECX, INTEL,  18,  1, DCA,                 NO,  MASK,   0, FALSE)            \
+FLAGDEFA(  1, ECX, INTEL,  19,  1, SSE41,               YES, HOST,   0, TRUE,  SSE41)     \
+FLAGDEFA(  1, ECX, INTEL,  20,  1, SSE42,               YES, HOST,   0, TRUE,  SSE42)     \
+FLAGDEF(   1, ECX, INTEL,  21,  1, X2APIC,              NO,  MASK,   0, FALSE)            \
+FLAGDEF(   1, ECX, INTEL,  22,  1, MOVBE,               NO,  RSVD,   0, TRUE)             \
+FLAGDEFA(  1, ECX, COMMON, 23,  1, POPCNT,              YES, HOST,   0, TRUE,  POPCNT)    \
+FLAGDEF(   1, ECX, INTEL,  24,  1, ULE,                 NO,  RSVD,   0, TRUE)             \
+FLAGDEF(   1, ECX, INTEL,  26,  1, XSAVE,               NO,  MASK,   0, FALSE)            \
+FLAGDEF(   1, ECX, INTEL,  27,  1, OSXSAVE,             NO,  RSVD,   0, TRUE)             \
+FLAGDEFA(  1, ECX, COMMON, 31,  1, HYPERVISOR,          ANY, IGNORE, 0, FALSE, HYPERVISOR)\
+FLAGDEFA(  1, EDX, COMMON, 0,   1, FPU,                 YES, HOST,   0, TRUE, FPU)        \
+FLAGDEFA(  1, EDX, COMMON, 1,   1, VME,                 YES, HOST,   0, FALSE, VME)       \
+FLAGDEF(   1, EDX, COMMON, 2,   1, DBGE,                YES, HOST,   0, FALSE)            \
+FLAGDEF(   1, EDX, COMMON, 3,   1, PGSZE,               YES, HOST,   0, FALSE)            \
+FLAGDEFA(  1, EDX, COMMON, 4,   1, TSC,                 YES, HOST,   0, TRUE, TSC)        \
+FLAGDEF(   1, EDX, COMMON, 5,   1, MSR,                 YES, HOST,   0, FALSE)            \
+FLAGDEFA(  1, EDX, COMMON, 6,   1, PAE,                 YES, HOST,   0, FALSE, PAE)       \
+FLAGDEF(   1, EDX, COMMON, 7,   1, MCK,                 YES, HOST,   0, FALSE)            \
+FLAGDEF(   1, EDX, COMMON, 8,   1, CPMX,                YES, HOST,   0, TRUE)             \
+FLAGDEFA(  1, EDX, COMMON, 9,   1, APIC,                ANY, MASK,   1, FALSE, APIC)      \
+FLAGDEFA(  1, EDX, COMMON, 11,  1, SEP,                 YES, HOST,   0, TRUE,  SEP)       \
+FLAGDEFA(  1, EDX, COMMON, 12,  1, MTRR,                YES, HOST,   0, FALSE, MTRR)      \
+FLAGDEFA(  1, EDX, COMMON, 13,  1, PGE,                 YES, HOST,   0, FALSE, PGE)       \
+FLAGDEFA(  1, EDX, COMMON, 14,  1, MCA,                 YES, HOST,   0, FALSE, MCA)       \
+FLAGDEFA(  1, EDX, COMMON, 15,  1, CMOV,                YES, HOST,   0, TRUE,  CMOV)      \
+FLAGDEFA(  1, EDX, COMMON, 16,  1, PAT,                 YES, HOST,   0, FALSE, PAT)       \
+FLAGDEF(   1, EDX, COMMON, 17,  1, 36PG,                YES, HOST,   0, FALSE)            \
+FLAGDEF(   1, EDX, INTEL,  18,  1, PSN,                 YES, HOST,   0, FALSE)            \
+FLAGDEFA(  1, EDX, COMMON, 19,  1, CLFL,                YES, HOST,   0, TRUE,  CLFL)      \
+FLAGDEF(   1, EDX, INTEL,  21,  1, DTES,                YES, HOST,   0, FALSE)            \
+FLAGDEF(   1, EDX, INTEL,  22,  1, ACPI,                YES, HOST,   0, FALSE)            \
+FLAGDEFA(  1, EDX, COMMON, 23,  1, MMX,                 YES, HOST,   0, TRUE,  MMX)       \
+FLAGDEFA(  1, EDX, COMMON, 24,  1, FXSAVE,              YES, HOST,   0, TRUE,  FXSAVE)    \
+FLAGDEFA(  1, EDX, COMMON, 25,  1, SSE,                 YES, HOST,   0, TRUE,  SSE)       \
+FLAGDEFA(  1, EDX, COMMON, 26,  1, SSE2,                YES, HOST,   0, TRUE,  SSE2)      \
+FLAGDEF(   1, EDX, INTEL,  27,  1, SS,                  YES, HOST,   0, FALSE)            \
+FLAGDEFA(  1, EDX, COMMON, 28,  1, HT,                  NO,  MASK,   0, FALSE, HT)        \
+FLAGDEF(   1, EDX, INTEL,  29,  1, TM,                  NO,  MASK,   0, FALSE)            \
+FLAGDEF(   1, EDX, INTEL,  30,  1, IA64,                NO,  MASK,   0, FALSE)            \
+FLAGDEF(   1, EDX, INTEL,  31,  1, PBE,                 NO,  MASK,   0, FALSE)
+
+/*    LEVEL, REG, VENDOR, POS, SIZE, NAME,       MON SUPP, MASK TYPE, SET TO, CPL3, [FUNC] */
+#define CPUID_FIELD_DATA_LEVEL_4                                               \
+FIELDDEF(  4, EAX, INTEL,   0,  5, CACHE_TYPE,          NA,  IGNORE, 0, FALSE)            \
+FIELDDEF(  4, EAX, INTEL,   5,  3, CACHE_LEVEL,         NA,  IGNORE, 0, FALSE)            \
+FIELDDEF(  4, EAX, INTEL,  14, 12, CACHE_NUMHT_SHARING, NA,  IGNORE, 0, FALSE)            \
+FIELDDEFA( 4, EAX, INTEL,  26,  6, CORE_COUNT,          NA,  IGNORE, 0, FALSE, INTEL_CORE_COUNT)  \
+FIELDDEF(  4, EBX, INTEL,   0, 12, CACHE_LINE,          NA,  IGNORE, 0, FALSE)            \
+FIELDDEF(  4, EBX, INTEL,  12, 10, CACHE_PART,          NA,  IGNORE, 0, FALSE)            \
+FIELDDEF(  4, EBX, INTEL,  22, 10, CACHE_WAYS,          NA,  IGNORE, 0, FALSE)
+
+/*     LEVEL, REG, VENDOR, POS, SIZE, NAME,       MON SUPP, MASK TYPE, SET TO, CPL3, [FUNC] */
+#define CPUID_FIELD_DATA_LEVEL_5                                           \
+FIELDDEF(  5, EAX, COMMON,  0, 16, MWAIT_MIN_SIZE,      NA,  IGNORE, 0, FALSE) \
+FIELDDEF(  5, EBX, COMMON,  0, 16, MWAIT_MAX_SIZE,      NA,  IGNORE, 0, FALSE) \
+FLAGDEF(   5, ECX, COMMON,  0,  1, MWAIT_EXTENSIONS,    NA,  IGNORE, 0, FALSE) \
+FLAGDEF(   5, ECX, COMMON,  1,  1, MWAIT_INTR_BREAK,    NA,  IGNORE, 0, FALSE) \
+FIELDDEF(  5, EDX, INTEL,   0,  4, MWAIT_C0_SUBSTATE,   NA,  IGNORE, 0, FALSE) \
+FIELDDEF(  5, EDX, INTEL,   4,  4, MWAIT_C1_SUBSTATE,   NA,  IGNORE, 0, FALSE) \
+FIELDDEF(  5, EDX, INTEL,   8,  4, MWAIT_C2_SUBSTATE,   NA,  IGNORE, 0, FALSE) \
+FIELDDEF(  5, EDX, INTEL,  12,  4, MWAIT_C3_SUBSTATE,   NA,  IGNORE, 0, FALSE) \
+FIELDDEF(  5, EDX, INTEL,  16,  4, MWAIT_C4_SUBSTATE,   NA,  IGNORE, 0, FALSE)
+
+/*    LEVEL, REG, VENDOR, POS, SIZE, NAME,       MON SUPP, MASK TYPE, SET TO, CPL3, [FUNC] */
+#define CPUID_FIELD_DATA_LEVEL_6                                               \
+FLAGDEF(   6, EAX, INTEL,   0,  1, THERMAL_SENSOR,      NA,  IGNORE, 0, FALSE)     \
+FLAGDEF(   6, EAX, INTEL,   1,  1, TURBO_MODE,          NA,  IGNORE, 0, FALSE)     \
+FIELDDEF(  6, EBX, INTEL,   0,  4, NUM_INTR_THRESHOLDS, NA,  IGNORE, 0, FALSE)     \
+FLAGDEF(   6, ECX, INTEL,   0,  1, HW_COORD_FEEDBACK,   NA,  IGNORE, 0, FALSE)
+
+/*    LEVEL, REG, VENDOR, POS, SIZE, NAME,       MON SUPP, MASK TYPE, SET TO, CPL3, [FUNC] */
+#define CPUID_FIELD_DATA_LEVEL_A                                               \
+FIELDDEFA( A, EAX, INTEL,   0,  8, PMC_VERSION,         NA,  IGNORE, 0, FALSE, PMC_VERSION) \
+FIELDDEFA( A, EAX, INTEL,   8,  8, NUM_PMCS,            NA,  IGNORE, 0, FALSE, NUM_PMCS)  \
+FIELDDEF(  A, EAX, INTEL,  16,  8, PMC_BIT_WIDTH,       NA,  IGNORE, 0, FALSE)            \
+FIELDDEFA( A, EAX, INTEL,  24,  8, PMC_EBX_LENGTH,      NA,  IGNORE, 0, FALSE, PMC_EBX_LENGTH) \
+FLAGDEF(   A, EBX, INTEL,   0,  1, PMC_CORE_CYCLE,      NA,  IGNORE, 0, FALSE)            \
+FLAGDEF(   A, EBX, INTEL,   1,  1, PMC_INSTR_RETIRED,   NA,  IGNORE, 0, FALSE)            \
+FLAGDEF(   A, EBX, INTEL,   2,  1, PMC_REF_CYCLES,      NA,  IGNORE, 0, FALSE)            \
+FLAGDEF(   A, EBX, INTEL,   3,  1, PMC_LAST_LVL_CREF,   NA,  IGNORE, 0, FALSE)            \
+FLAGDEF(   A, EBX, INTEL,   4,  1, PMC_LAST_LVL_CMISS,  NA,  IGNORE, 0, FALSE)            \
+FLAGDEF(   A, EBX, INTEL,   5,  1, PMC_BR_INST_RETIRED, NA,  IGNORE, 0, FALSE)            \
+FLAGDEF(   A, EBX, INTEL,   6,  1, PMC_BR_MISS_RETIRED, NA,  IGNORE, 0, FALSE)
+
+/*    LEVEL, REG, VENDOR, POS, SIZE, NAME,       MON SUPP, MASK TYPE, SET TO, CPL3, [FUNC] */
+#define CPUID_FIELD_DATA_LEVEL_80                                              \
+FIELDDEF( 80, EAX, COMMON,  0, 32, NUM_EXT_LEVELS,      NA,  IGNORE, 0, FALSE)            \
+FIELDDEF( 80, EBX, AMD,     0, 32, AMD_VENDOR1,         NA,  IGNORE, 0, FALSE)            \
+FIELDDEF( 80, ECX, AMD,     0, 32, AMD_VENDOR3,         NA,  IGNORE, 0, FALSE)            \
+FIELDDEF( 80, EDX, AMD,     0, 32, AMD_VENDOR2,         NA,  IGNORE, 0, FALSE)
+                                                        
+/*    LEVEL, REG, VENDOR, POS, SIZE, NAME,       MON SUPP, MASK TYPE, SET TO, CPL3, [FUNC] */
+#define CPUID_FIELD_DATA_LEVEL_81                                              \
+FIELDDEF( 81, EAX, INTEL,   0, 32, UNKNOWN81EAX,        ANY, IGNORE, 0, FALSE)            \
+FIELDDEF( 81, EAX, AMD,     0,  4, STEPPING,            ANY, IGNORE, 0, FALSE)            \
+FIELDDEF( 81, EAX, AMD,     4,  4, MODEL,               ANY, IGNORE, 0, FALSE)            \
+FIELDDEF( 81, EAX, AMD,     8,  4, FAMILY,              ANY, IGNORE, 0, FALSE)            \
+FIELDDEF( 81, EAX, AMD,    12,  2, TYPE,                ANY, IGNORE, 0, FALSE)            \
+FIELDDEF( 81, EAX, AMD,    16,  4, EXTMODEL,            ANY, IGNORE, 0, FALSE)            \
+FIELDDEF( 81, EAX, AMD,    20,  8, EXTFAMILY,           ANY, IGNORE, 0, FALSE)            \
+FIELDDEF( 81, EBX, INTEL,   0, 32, UNKNOWN81EBX,        ANY, IGNORE, 0, FALSE)            \
+FIELDDEF( 81, EBX, AMD,     0, 16, BRAND_ID,            ANY, IGNORE, 0, FALSE)            \
+FIELDDEF( 81, EBX, AMD,    16, 16, UNDEF,               ANY, IGNORE, 0, FALSE)            \
+FLAGDEFA( 81, ECX, COMMON,  0,  1, LAHF,                YES, HOST,   0, TRUE,  LAHF64)    \
+FLAGDEFA( 81, ECX, AMD,     1,  1, CMPLEGACY,           NO,  MASK,   0, FALSE, CMPLEGACY) \
+FLAGDEFA( 81, ECX, AMD,     2,  1, SVM,                 NO,  MASK,   0, FALSE, SVM)       \
+FLAGDEFA( 81, ECX, AMD,     3,  1, EXTAPICSPC,          YES, HOST,   0, FALSE, EXTAPICSPC) \
+FLAGDEFA( 81, ECX, AMD,     4,  1, CR8AVAIL,            NO,  MASK,   0, FALSE, CR8AVAIL)  \
+FLAGDEFA( 81, ECX, AMD,     5,  1, ABM,                 YES, HOST,   0, TRUE,  ABM)       \
+FLAGDEFA( 81, ECX, AMD,     6,  1, SSE4A,               YES, HOST,   0, TRUE,  SSE4A)     \
+FLAGDEF(  81, ECX, AMD,     7,  1, MISALIGNED_SSE,      YES, HOST,   0, TRUE)             \
+FLAGDEFA( 81, ECX, AMD,     8,  1, 3DNPREFETCH,         YES, HOST,   0, TRUE, 3DNPREFETCH) \
+FLAGDEF(  81, ECX, AMD,     9,  1, OSVW,                NO,  MASK,   0, FALSE)            \
+FLAGDEF(  81, ECX, AMD,    10,  1, IBS,                 NO,  MASK,   0, FALSE)            \
+FLAGDEF(  81, ECX, AMD,    11,  1, SSE5,                NO,  RSVD,   0, TRUE)             \
+FLAGDEF(  81, ECX, AMD,    12,  1, SKINIT,              NO,  MASK,   0, FALSE)            \
+FLAGDEF(  81, ECX, AMD,    13,  1, WATCHDOG,            NO,  MASK,   0, FALSE)            \
+FLAGDEF(  81, EDX, AMD,     0,  1, FPU,                 YES, HOST,   0, TRUE)             \
+FLAGDEF(  81, EDX, AMD,     1,  1, VME,                 YES, HOST,   0, FALSE)            \
+FLAGDEF(  81, EDX, AMD,     2,  1, DBGE,                YES, HOST,   0, FALSE)            \
+FLAGDEF(  81, EDX, AMD,     3,  1, PGSZE,               YES, HOST,   0, FALSE)            \
+FLAGDEF(  81, EDX, AMD,     4,  1, TSC,                 YES, HOST,   0, TRUE)             \
+FLAGDEF(  81, EDX, AMD,     5,  1, MSR,                 YES, HOST,   0, FALSE)            \
+FLAGDEF(  81, EDX, AMD,     6,  1, PAE,                 YES, HOST,   0, FALSE)            \
+FLAGDEF(  81, EDX, AMD,     7,  1, MCK,                 YES, HOST,   0, FALSE)            \
+FLAGDEF(  81, EDX, AMD,     8,  1, CPMX,                YES, HOST,   0, TRUE)             \
+FLAGDEF(  81, EDX, AMD,     9,  1, APIC,                ANY, MASK,   1, FALSE)            \
+FLAGDEFA( 81, EDX, COMMON, 11,  1, SYSC,                ANY, IGNORE, 0, TRUE, SYSC)       \
+FLAGDEF(  81, EDX, AMD,    12,  1, MTRR,                YES, HOST,   0, FALSE)            \
+FLAGDEF(  81, EDX, AMD,    13,  1, PGE,                 YES, HOST,   0, FALSE)            \
+FLAGDEF(  81, EDX, AMD,    14,  1, MCA,                 YES, HOST,   0, FALSE)            \
+FLAGDEF(  81, EDX, AMD,    15,  1, CMOV,                YES, HOST,   0, TRUE)             \
+FLAGDEF(  81, EDX, AMD,    16,  1, PAT,                 YES, HOST,   0, FALSE)            \
+FLAGDEF(  81, EDX, AMD,    17,  1, 36PG,                YES, HOST,   0, FALSE)            \
+FLAGDEFA( 81, EDX, COMMON, 20,  1, NX,                  YES, HOST,   0, FALSE, NX)        \
+FLAGDEFA( 81, EDX, AMD,    22,  1, MMXEXT,              YES, HOST,   0, TRUE,  MMXEXT)    \
+FLAGDEF(  81, EDX, AMD,    23,  1, MMX,                 YES, HOST,   0, TRUE)             \
+FLAGDEF(  81, EDX, AMD,    24,  1, FXSAVE,              YES, HOST,   0, TRUE)             \
+FLAGDEFA( 81, EDX, AMD,    25,  1, FFXSR,               YES, HOST,   0, FALSE, FFXSR)     \
+FLAGDEF(  81, EDX, AMD,    26,  1, PDPE1GB,             NO,  MASK,   0, FALSE)            \
+FLAGDEFA( 81, EDX, COMMON, 27,  1, RDTSCP,              YES, HOST,   0, TRUE,  RDTSCP)    \
+FLAGDEFA( 81, EDX, COMMON, 29,  1, LM,                  YES, TEST,   1, FALSE, LM) \
+FLAGDEFA( 81, EDX, AMD,    30,  1, 3DNOWPLUS,           YES, HOST,   0, TRUE,  3DNOWPLUS) \
+FLAGDEFA( 81, EDX, AMD,    31,  1, 3DNOW,               YES, HOST,   0, TRUE,  3DNOW)
+
+/*    LEVEL, REG, VENDOR, POS, SIZE, NAME,       MON SUPP, MASK TYPE, SET TO, CPL3, [FUNC] */
+#define CPUID_FIELD_DATA_LEVEL_8x                                              \
+FIELDDEF( 86, ECX, AMD,     0,  8, L2CACHE_LINE,        NA,  IGNORE, 0, FALSE)            \
+FIELDDEF( 86, ECX, AMD,     8,  4, L2CACHE_LINE_PER_TAG, NA, IGNORE, 0, FALSE)            \
+FIELDDEF( 86, ECX, AMD,    12,  4, L2CACHE_WAYS,        NA,  IGNORE, 0, FALSE)            \
+FIELDDEF( 86, ECX, AMD,    16, 16, L2CACHE_SIZE,        NA,  IGNORE, 0, FALSE)            \
+FIELDDEF( 86, EDX, AMD,     0,  8, L3CACHE_LINE,        NA,  IGNORE, 0, FALSE)            \
+FIELDDEF( 86, EDX, AMD,     8,  4, L3CACHE_LINE_PER_TAG,NA,  IGNORE, 0, FALSE)            \
+FIELDDEF( 86, EDX, AMD,    12,  4, L3CACHE_WAYS,        NA,  IGNORE, 0, FALSE)            \
+FIELDDEF( 86, EDX, AMD,    18, 14, L3CACHE_SIZE,        NA,  IGNORE, 0, FALSE)            \
+FLAGDEF(  87, EDX, AMD,     0,  1, TS,                  NA,  IGNORE, 0, FALSE)            \
+FLAGDEF(  87, EDX, AMD,     1,  1, FID,                 NA,  IGNORE, 0, FALSE)            \
+FLAGDEF(  87, EDX, AMD,     2,  1, VID,                 NA,  IGNORE, 0, FALSE)            \
+FLAGDEF(  87, EDX, AMD,     3,  1, TTP,                 NA,  IGNORE, 0, FALSE)            \
+FLAGDEF(  87, EDX, AMD,     4,  1, TM,                  NA,  IGNORE, 0, FALSE)            \
+FLAGDEF(  87, EDX, AMD,     5,  1, STC,                 NA,  IGNORE, 0, FALSE)            \
+FLAGDEF(  87, EDX, AMD,     6,  1, 100MHZSTEPS,         NA,  IGNORE, 0, FALSE)            \
+FLAGDEF(  87, EDX, AMD,     7,  1, HWPSTATE,            NA,  IGNORE, 0, FALSE)            \
+FLAGDEF(  87, EDX, AMD,     8,  1, TSC_INVARIANT,       NA,  IGNORE, 0, FALSE)            \
+FIELDDEFA(88, EAX, COMMON,  0,  8, PHYSBITS,            NA,  IGNORE, 0, FALSE, PHYS_BITS) \
+FIELDDEFA(88, EAX, COMMON,  8,  8, VIRTBITS,            NA,  IGNORE, 0, FALSE, VIRT_BITS) \
+FIELDDEFA(88, ECX, AMD,     0,  8, CORE_COUNT,          NA,  IGNORE, 0, FALSE, AMD_CORE_COUNT) \
+FIELDDEF( 88, ECX, AMD,    12,  4, APICID_COREID_SIZE,  NA,  IGNORE, 0, FALSE)            \
+FIELDDEFA(8A, EAX, AMD,     0,  8, SVM_REVISION,        NO,  MASK,   0, FALSE, SVM_REVISION) \
+FLAGDEF(  8A, EAX, AMD,     8,  1, SVM_HYPERVISOR,      NO,  MASK,   0, FALSE)            \
+FIELDDEF( 8A, EAX, AMD,     9, 23, SVMEAX_RSVD,         NO,  MASK,   0, FALSE)            \
+FIELDDEF( 8A, EBX, AMD,     0, 32, SVM_N_ASIDS,         NO,  MASK,   0, FALSE)            \
+FIELDDEF( 8A, ECX, AMD,     0, 32, SVMECX_RSVD,         NO,  MASK,   0, FALSE)            \
+FLAGDEFA( 8A, EDX, AMD,     0,  1, SVM_NP,              NO,  MASK,   0, FALSE, NPT)       \
+FLAGDEF(  8A, EDX, AMD,     1,  1, SVM_LBR,             NO,  MASK,   0, FALSE)            \
+FLAGDEF(  8A, EDX, AMD,     2,  1, SVM_LOCK,            NO,  MASK,   0, FALSE)            \
+FLAGDEF(  8A, EDX, AMD,     3,  1, SVM_NRIP,            NO,  MASK,   0, FALSE)            \
+FIELDDEF( 8A, EDX, AMD,     4, 28, SVMEDX_RSVD,         NO,  MASK,   0, FALSE)
+
+#define CPUID_FIELD_DATA                                              \
+   CPUID_FIELD_DATA_LEVEL_0                                           \
+   CPUID_FIELD_DATA_LEVEL_1                                           \
+   CPUID_FIELD_DATA_LEVEL_4                                           \
+   CPUID_FIELD_DATA_LEVEL_5                                           \
+   CPUID_FIELD_DATA_LEVEL_6                                           \
+   CPUID_FIELD_DATA_LEVEL_A                                           \
+   CPUID_FIELD_DATA_LEVEL_80                                          \
+   CPUID_FIELD_DATA_LEVEL_81                                          \
+   CPUID_FIELD_DATA_LEVEL_8x
+
+/*
+ * Define all field and flag values as an enum.  The result is a full
+ * set of values taken from the table above in the form:
+ *
+ * CPUID_FEATURE_<vendor>_ID<level><reg>_<name> == mask for feature
+ * CPUID_<vendor>_ID<level><reg>_<name>_MASK    == mask for field
+ * CPUID_<vendor>_ID<level><reg>_<name>_SHIFT   == offset of field
+ *
+ * e.g. - CPUID_FEATURE_COMMON_ID1EDX_FPU     = 0x1
+ *      - CPUID_COMMON_ID88EAX_VIRTBITS_MASK  = 0xff00
+ *      - CPUID_COMMON_ID88EAX_VIRTBITS_SHIFT = 8
+ *
+ * Note: The FEATURE/MASK definitions must use some gymnastics to get
+ * around a warning when shifting left by 32.
+ */
+#define VMW_BIT_MASK(shift)  (((1 << (shift - 1)) << 1) - 1)
+
+#define FIELDDEF(lvl, reg, vend, bitpos, size, name, s, m, v, c3)       \
+   CPUID_##vend##_ID##lvl##reg##_##name##_SHIFT = bitpos,               \
+   CPUID_##vend##_ID##lvl##reg##_##name##_MASK  =                       \
+                      VMW_BIT_MASK(size) << bitpos,                     \
+   CPUID_FEATURE_##vend##_ID##lvl##reg##_##name =                       \
+                      CPUID_##vend##_ID##lvl##reg##_##name##_MASK,
+
+/* Before simplifying this take a look at bug 293638... */
+#define FIELDDEFA(lvl, reg, vend, bitpos, size, name, s, m, v, c3, f)   \
+   CPUID_##vend##_ID##lvl##reg##_##name##_SHIFT = bitpos,               \
+   CPUID_##vend##_ID##lvl##reg##_##name##_MASK  =                       \
+                      VMW_BIT_MASK(size) << bitpos,                     \
+   CPUID_FEATURE_##vend##_ID##lvl##reg##_##name =                       \
+                      CPUID_##vend##_ID##lvl##reg##_##name##_MASK,
+
+#define FLAGDEFA FIELDDEFA
+#define FLAGDEF FIELDDEF
+
+enum {
+   /* Define data for every CPUID field we have */
+   CPUID_FIELD_DATA
+};
+#undef VMW_BIT_MASK
+#undef FIELDDEF
+#undef FLAGDEF
+#undef FIELDDEFA
+#undef FLAGDEFA
+
+/*
+ * Legal CPUID config file mask characters.  For a description of the
+ * cpuid masking system, please see:
+ *
+ * http://vmweb.vmware.com/~mts/cgi-bin/view.cgi/Apps/CpuMigrationChecks
+ */
+
+#define CPUID_MASK_HIDE_CHR    '0'
+#define CPUID_MASK_HIDE_STR    "0"
+#define CPUID_MASK_FORCE_CHR   '1'
+#define CPUID_MASK_FORCE_STR   "1"
+#define CPUID_MASK_PASS_CHR    '-'
+#define CPUID_MASK_PASS_STR    "-"
+#define CPUID_MASK_TRUE_CHR    'T'
+#define CPUID_MASK_TRUE_STR    "T"
+#define CPUID_MASK_FALSE_CHR   'F'
+#define CPUID_MASK_FALSE_STR   "F"
+#define CPUID_MASK_IGNORE_CHR  'X'
+#define CPUID_MASK_IGNORE_STR  "X"
+#define CPUID_MASK_HOST_CHR    'H'
+#define CPUID_MASK_HOST_STR    "H"
+#define CPUID_MASK_RSVD_CHR    'R'
+#define CPUID_MASK_RSVD_STR    "R"
+#define CPUID_MASK_INSTALL_CHR 'I'
+#define CPUID_MASK_INSTALL_STR "I"
+
+/*
+ * If a level is listed as not masked/tested in CPUID_LEVELS above,
+ * use all "don't care" values for its mask.
+ */
+
+#define CPT_DFLT_UNDEFINED_MASK "XXXX:XXXX:XXXX:XXXX:XXXX:XXXX:XXXX:XXXX"
+
+/*
+ * When LM is disabled, we overlay the following masks onto the
+ * guest's default masks.  Any level that is not defined below should
+ * be treated as all "-"s
+ */
+
+#define CPT_ID1ECX_LM_DISABLED  "----:----:----:----:--0-:----:----:----"
+#define CPT_ID81EDX_LM_DISABLED "--0-:----:----:----:----:----:----:----"
+#define CPT_ID81ECX_LM_DISABLED "----:----:----:----:----:----:----:---0"
+
+#define CPT_GET_LM_DISABLED_MASK(lvl, reg)                                  \
+   ((lvl == 1 && reg == CPUID_REG_ECX) ? CPT_ID1ECX_LM_DISABLED :           \
+    (lvl == 0x80000001 && reg == CPUID_REG_ECX) ? CPT_ID81ECX_LM_DISABLED : \
+    (lvl == 0x80000001 && reg == CPUID_REG_EDX) ? CPT_ID81EDX_LM_DISABLED : \
+    NULL)
+
+/*
+ * Macro to define GET and SET functions for various common CPUID
+ * fields.  To create function for a new field, simply name it (CPUID_
+ * and CPUID_SET_ are automatically prepended), and list the field
+ * name that it needs to use.
+ */
+
+#define FIELD_FUNC(name, field)                                 \
+   static INLINE uint32 CPUID_##name(uint32 reg)                \
+   {                                                            \
+      return (reg & field##_MASK) >> field##_SHIFT;             \
+   }                                                            \
+   static INLINE void CPUID_SET_##name(uint32 *reg, uint32 val) \
+   {                                                            \
+      *reg = (*reg & ~field##_MASK) | (val << field##_SHIFT);   \
+   }
+
+FIELD_FUNC(STEPPING,         CPUID_COMMON_ID1EAX_STEPPING)
+FIELD_FUNC(MODEL,            CPUID_COMMON_ID1EAX_MODEL)
+FIELD_FUNC(FAMILY,           CPUID_COMMON_ID1EAX_FAMILY)
+FIELD_FUNC(TYPE,             CPUID_COMMON_ID1EAX_TYPE)
+FIELD_FUNC(EXTENDED_MODEL,   CPUID_COMMON_ID1EAX_EXTMODEL)
+FIELD_FUNC(EXTENDED_FAMILY,  CPUID_COMMON_ID1EAX_EXTFAMILY)
+FIELD_FUNC(LCPU_COUNT,       CPUID_COMMON_ID1EBX_LCPU_COUNT)
+FIELD_FUNC(APICID,           CPUID_COMMON_ID1EBX_APICID)
+FIELD_FUNC(PA_BITS,          CPUID_COMMON_ID88EAX_PHYSBITS)
+FIELD_FUNC(VIRT_BITS,        CPUID_COMMON_ID88EAX_VIRTBITS)
+FIELD_FUNC(SVM_REVISION,     CPUID_AMD_ID8AEAX_SVM_REVISION)
+FIELD_FUNC(SVM_N_ASIDS,      CPUID_AMD_ID8AEBX_SVM_N_ASIDS)
+FIELD_FUNC(INTEL_CORE_COUNT, CPUID_INTEL_ID4EAX_CORE_COUNT)
+FIELD_FUNC(AMD_CORE_COUNT,   CPUID_AMD_ID88ECX_CORE_COUNT)
+FIELD_FUNC(AMD_APICID_COREID_SIZE, CPUID_AMD_ID88ECX_APICID_COREID_SIZE)
+FIELD_FUNC(AMD_EXTAPICSPC,   CPUID_AMD_ID81ECX_EXTAPICSPC)
+FIELD_FUNC(NUM_PMCS,         CPUID_INTEL_IDAEAX_NUM_PMCS)
+FIELD_FUNC(MWAIT_MIN_SIZE,   CPUID_COMMON_ID5EAX_MWAIT_MIN_SIZE)
+FIELD_FUNC(MWAIT_MAX_SIZE,   CPUID_COMMON_ID5EBX_MWAIT_MAX_SIZE)
+FIELD_FUNC(MWAIT_C0_SUBSTATE, CPUID_INTEL_ID5EDX_MWAIT_C0_SUBSTATE)
+FIELD_FUNC(MWAIT_C1_SUBSTATE, CPUID_INTEL_ID5EDX_MWAIT_C1_SUBSTATE)
+FIELD_FUNC(MWAIT_C2_SUBSTATE, CPUID_INTEL_ID5EDX_MWAIT_C2_SUBSTATE)
+FIELD_FUNC(MWAIT_C3_SUBSTATE, CPUID_INTEL_ID5EDX_MWAIT_C3_SUBSTATE)
+FIELD_FUNC(MWAIT_C4_SUBSTATE, CPUID_INTEL_ID5EDX_MWAIT_C4_SUBSTATE)
+#undef FIELD_FUNC
+
+
+/*
+ * Definitions of various fields' values and more complicated
+ * macros/functions for reading cpuid fields.
+ */
+
+/* Effective Intel CPU Families */
+#define CPUID_FAMILY_486      4
+#define CPUID_FAMILY_P5       5
+#define CPUID_FAMILY_P6       6
+#define CPUID_FAMILY_P4       15
+
+/* Effective AMD CPU Families */
+#define CPUID_FAMILY_5x86     4
+#define CPUID_FAMILY_K5       5
+#define CPUID_FAMILY_K6       5
+#define CPUID_FAMILY_K7       6
+#define CPUID_FAMILY_K8       15
+#define CPUID_FAMILY_K8L      16
+#define CPUID_FAMILY_K8MOBILE 17
+#define CPUID_FAMILY_EXTENDED 15
+
+/* Intel model information */
+#define CPUID_MODEL_PPRO       1
+#define CPUID_MODEL_PII_03     3
+#define CPUID_MODEL_PII_05     5
+#define CPUID_MODEL_CELERON_06 6
+#define CPUID_MODEL_PM_09      9
+#define CPUID_MODEL_PM_0D      13
+#define CPUID_MODEL_PM_0E      14    // Yonah / Sossaman
+#define CPUID_MODEL_CORE_0F    15    // Conroe / Merom
+#define CPUID_MODEL_CORE_17    0x17  // Penryn
+#define CPUID_MODEL_NEHALEM_1A 0x1a  // Nehalem / Gainestown
+#define CPUID_MODEL_ATOM_1C    0x1c  // Silverthorne / Diamondville
+#define CPUID_MODEL_CORE_1D    0x1d  // Dunnington
+
+#define CPUID_MODEL_PIII_07    7
+#define CPUID_MODEL_PIII_08    8
+#define CPUID_MODEL_PIII_0A    10
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * CPUID_IsVendor{AMD,Intel} --
+ *
+ *      Determines if the vendor string in cpuid id0 is from {AMD,Intel}.
+ *
+ * Results:
+ *      True iff vendor string is CPUID_{AMD,INTEL}_VENDOR_STRING
+ *
+ * Side effects:
+ *      None.
+ *
+ *----------------------------------------------------------------------
+ */
+static INLINE Bool
+CPUID_IsRawVendor(CPUIDRegs *id0, const char* vendor)
+{
+   // hard to get strcmp() in some environments, so do it in the raw
+   return (id0->ebx == *(const uint32 *) (vendor + 0) &&
+           id0->ecx == *(const uint32 *) (vendor + 4) &&
+           id0->edx == *(const uint32 *) (vendor + 8));   
+}
+
+static INLINE Bool
+CPUID_IsVendorAMD(CPUIDRegs *id0)
+{
+   return CPUID_IsRawVendor(id0, CPUID_AMD_VENDOR_STRING);
+}
+
+static INLINE Bool
+CPUID_IsVendorIntel(CPUIDRegs *id0)
+{
+   return CPUID_IsRawVendor(id0, CPUID_INTEL_VENDOR_STRING);
+}
+
+
+static INLINE uint32
+CPUID_EFFECTIVE_FAMILY(uint32 v) /* %eax from CPUID with %eax=1. */
+{
+   return CPUID_FAMILY(v) +
+      (CPUID_FAMILY(v) == CPUID_FAMILY_EXTENDED ? CPUID_EXTENDED_FAMILY(v) : 0);
+}
+
+/* Normally only used when FAMILY==CPUID_FAMILY_EXTENDED, but Intel is
+ * now using the extended model field for FAMILY==CPUID_FAMILY_P6 to
+ * refer to the newer Core2 CPUs
+ */
+static INLINE uint32
+CPUID_EFFECTIVE_MODEL(uint32 v) /* %eax from CPUID with %eax=1. */
+{
+   return CPUID_MODEL(v) + (CPUID_EXTENDED_MODEL(v) << 4); 
+}
+
+/*
+ * Notice that CPUID families for Intel and AMD overlap. The following macros
+ * should only be used AFTER the manufacturer has been established (through
+ * the use of CPUID standard function 0).
+ */
+static INLINE Bool
+CPUID_FAMILY_IS_486(uint32 _eax)
+{
+   return CPUID_EFFECTIVE_FAMILY(_eax) == CPUID_FAMILY_486;
+}
+
+static INLINE Bool
+CPUID_FAMILY_IS_P5(uint32 _eax)
+{
+   return CPUID_EFFECTIVE_FAMILY(_eax) == CPUID_FAMILY_P5;
+}
+
+static INLINE Bool
+CPUID_FAMILY_IS_P6(uint32 _eax)
+{
+   return CPUID_EFFECTIVE_FAMILY(_eax) == CPUID_FAMILY_P6;
+}
+
+static INLINE Bool
+CPUID_FAMILY_IS_PENTIUM4(uint32 _eax)
+{
+   return CPUID_EFFECTIVE_FAMILY(_eax) == CPUID_FAMILY_P4;
+}
+
+/*
+ * Intel Pentium M processors are Yonah/Sossaman or an older P-M
+ */
+static INLINE Bool
+CPUID_UARCH_IS_PENTIUM_M(uint32 v) // IN: %eax from CPUID with %eax=1.
+{
+   /* Assumes the CPU manufacturer is Intel. */
+   return CPUID_FAMILY_IS_P6(v) &&
+          (CPUID_EFFECTIVE_MODEL(v) == CPUID_MODEL_PM_09 ||
+           CPUID_EFFECTIVE_MODEL(v) == CPUID_MODEL_PM_0D ||
+           CPUID_EFFECTIVE_MODEL(v) == CPUID_MODEL_PM_0E);
+}
+
+/*
+ * Intel Core processors are Merom, Conroe, Woodcrest, Clovertown,
+ * Penryn, Dunnington, Kentsfield, Yorktown, Harpertown, ........
+ */
+static INLINE Bool
+CPUID_UARCH_IS_CORE(uint32 v) // IN: %eax from CPUID with %eax=1.
+{
+   uint32 model = CPUID_EFFECTIVE_MODEL(v);
+   /* Assumes the CPU manufacturer is Intel. */
+   return CPUID_FAMILY_IS_P6(v) &&
+          model >= CPUID_MODEL_CORE_0F &&
+          (model < CPUID_MODEL_NEHALEM_1A ||
+           model == CPUID_MODEL_CORE_1D);
+}
+
+
+/*
+ * Intel Nehalem processors are: Nehalem, Gainestown.
+ */
+static INLINE Bool
+CPUID_UARCH_IS_NEHALEM(uint32 v) // IN: %eax from CPUID with %eax=1.
+{
+   /* Assumes the CPU manufacturer is Intel. */
+   return CPUID_FAMILY_IS_P6(v) &&
+          CPUID_EFFECTIVE_MODEL(v) == CPUID_MODEL_NEHALEM_1A;
+}
+
+
+static INLINE Bool
+CPUID_FAMILY_IS_K7(uint32 _eax)
+{
+   return CPUID_EFFECTIVE_FAMILY(_eax) == CPUID_FAMILY_K7;
+}
+
+static INLINE Bool
+CPUID_FAMILY_IS_K8(uint32 _eax)
+{
+   return CPUID_EFFECTIVE_FAMILY(_eax) == CPUID_FAMILY_K8;
+}
+
+static INLINE Bool
+CPUID_FAMILY_IS_K8EXT(uint32 _eax)
+{
+   /*
+    * We check for this pattern often enough that it's
+    * worth a separate function, for syntactic sugar.
+    */
+   return CPUID_FAMILY_IS_K8(_eax) &&
+          CPUID_EXTENDED_MODEL(_eax) != 0;
+}
+
+static INLINE Bool
+CPUID_FAMILY_IS_K8L(uint32 _eax)
+{
+   return CPUID_EFFECTIVE_FAMILY(_eax) == CPUID_FAMILY_K8L;
+}
+
+static INLINE Bool
+CPUID_FAMILY_IS_K8MOBILE(uint32 _eax)
+{
+   /* Essentially a K8 (not K8L) part, but with mobile features. */
+   return CPUID_EFFECTIVE_FAMILY(_eax) == CPUID_FAMILY_K8MOBILE;
+}
+
+static INLINE Bool
+CPUID_FAMILY_IS_K8STAR(uint32 _eax)
+{
+   /*
+    * Read function name as "K8*", as in wildcard.
+    * Matches K8 or K8L or K8MOBILE
+    */
+   return CPUID_FAMILY_IS_K8(_eax) || CPUID_FAMILY_IS_K8L(_eax) ||
+          CPUID_FAMILY_IS_K8MOBILE(_eax);
+}
+
+
+#define CPUID_TYPE_PRIMARY     0
+#define CPUID_TYPE_OVERDRIVE   1
+#define CPUID_TYPE_SECONDARY   2
+
+#define CPUID_INTEL_ID4EAX_CACHE_TYPE_NULL      0
+#define CPUID_INTEL_ID4EAX_CACHE_TYPE_DATA      1
+#define CPUID_INTEL_ID4EAX_CACHE_TYPE_INST      2
+#define CPUID_INTEL_ID4EAX_CACHE_TYPE_UNIF      3
+
+#define CPUID_INTEL_ID4EAX_CACHE_SELF_INIT      0x00000100
+#define CPUID_INTEL_ID4EAX_CACHE_FULLY_ASSOC    0x00000200
+
+
+/*
+ * On AMD chips before Opteron and Intel chips before P4 model 3,
+ * WRMSR(TSC) clears the upper half of the TSC instead of using %edx.
+ */
+static INLINE Bool
+CPUID_FullyWritableTSC(Bool isIntel, // IN
+                       uint32 v)     // IN: %eax from CPUID with %eax=1.
+{
+   /*
+    * Returns FALSE if:
+    *   - Intel && P6 (pre-core) or
+    *   - Intel && P4 (model < 3) or
+    *   - !Intel && pre-K8 Opteron
+    * Otherwise, returns TRUE.
+    */
+   return !((isIntel &&
+             ((CPUID_FAMILY_IS_P6(v) &&
+               CPUID_EFFECTIVE_MODEL(v) < CPUID_MODEL_PM_0E) ||
+              (CPUID_FAMILY_IS_PENTIUM4(v) &&
+               CPUID_EFFECTIVE_MODEL(v) < 3))) ||
+            (!isIntel &&
+             CPUID_FAMILY(v) < CPUID_FAMILY_K8));
+}
+
+
+/*
+ * For certain AMD processors, an lfence instruction is necessary at various
+ * places to ensure ordering.
+ */
+
+static INLINE Bool
+CPUID_VendorRequiresFence(CpuidVendors vendor)
+{
+   return vendor == CPUID_VENDOR_AMD;
+}
+
+static INLINE Bool
+CPUID_VersionRequiresFence(uint32 version)
+{
+   return CPUID_EFFECTIVE_FAMILY(version) == CPUID_FAMILY_K8 &&
+          CPUID_EFFECTIVE_MODEL(version) < 0x40;
+}
+
+static INLINE Bool
+CPUID_ID0RequiresFence(CPUIDRegs *id0)
+{
+   if (id0->eax == 0) {
+      return FALSE;
+   }
+   return CPUID_IsVendorAMD(id0);
+}
+
+static INLINE Bool
+CPUID_ID1RequiresFence(CPUIDRegs *id1)
+{
+   return CPUID_VersionRequiresFence(id1->eax);
+}
+
+static INLINE Bool
+CPUID_RequiresFence(CpuidVendors vendor, // IN
+                    uint32 version)      // IN: %eax from CPUID with %eax=1.
+{
+   return CPUID_VendorRequiresFence(vendor) &&
+	  CPUID_VersionRequiresFence(version);
+}
+
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * CPUID_CountsCPUIDAsBranch --
+ *
+ *      Returns TRUE iff the cpuid given counts CPUID as a branch
+ *      (i.e. is a pre-Merom E CPU).
+ *
+ *----------------------------------------------------------------------
+ */
+
+static INLINE Bool
+CPUID_CountsCPUIDAsBranch(uint32 v) /* %eax from CPUID with %eax=1 */
+{
+   /* 
+    * CPUID no longer a branch starting with Merom E. Bug 148411.
+    * Penryn (Extended Model: 1) also has this fixed.
+    *
+    * Merom E is: CPUID.1.eax & 0xfff = 0x6f9
+    */
+   return !(CPUID_FAMILY_IS_P6(v) &&
+            (CPUID_EFFECTIVE_MODEL(v) > CPUID_MODEL_CORE_0F ||
+             (CPUID_EFFECTIVE_MODEL(v) == CPUID_MODEL_CORE_0F &&
+              CPUID_STEPPING(v) >= 9)));
+}
+
+/*
+ * On Merom and later Intel chips, not present PDPTEs with reserved bits
+ * set do not fault with a #GP. See PR# 109120.
+ */
+static INLINE Bool
+CPUID_FaultOnNPReservedPDPTE(uint32 v) // IN: %eax from CPUID with %eax=1.
+{
+   return !(CPUID_FAMILY_IS_P6(v) &&
+            (CPUID_EFFECTIVE_MODEL(v) >= CPUID_MODEL_CORE_0F));
+}
+
+
+/* 
+ * The following low-level functions compute the number of
+ * cores per cpu.  They should be used cautiously because
+ * they do not necessarily work on all types of CPUs.
+ * High-level functions that are correct for all CPUs are
+ * available elsewhere: see lib/cpuidInfo/cpuidInfo.c.
+ */
+
+static INLINE uint32
+CPUID_IntelCoresPerPackage(uint32 v) /* %eax from CPUID with %eax=4 and %ecx=0. */
+{
+   // Note: This is not guaranteed to work on older Intel CPUs.
+   return 1 + CPUID_INTEL_CORE_COUNT(v);
+}
+
+static INLINE uint32
+CPUID_AMDCoresPerPackage(uint32 v) /* %ecx from CPUID with %eax=0x80000008. */
+{
+   // Note: This is not guaranteed to work on older AMD CPUs.
+   return 1 + CPUID_AMD_CORE_COUNT(v);
+}
+
+/*
+ * Hypervisor CPUID space is 0x400000XX.
+ */
+static INLINE Bool
+CPUID_IsHypervisorLevel(uint32 level, uint32 *offset)
+{
+   *offset = level & 0xff;
+   return (level & 0xffffff00) == 0x40000000;
+}
+
+
+#endif
