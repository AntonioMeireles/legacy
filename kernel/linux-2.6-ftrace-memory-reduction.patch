diff -up linux-2.6.28.noarch/kernel/trace/trace.c.orig linux-2.6.28.noarch/kernel/trace/trace.c
--- linux-2.6.28.noarch/kernel/trace/trace.c.orig	2009-03-17 09:55:55.000000000 -0400
+++ linux-2.6.28.noarch/kernel/trace/trace.c	2009-03-18 06:42:11.000000000 -0400
@@ -44,6 +44,12 @@ unsigned long __read_mostly	tracing_max_
 unsigned long __read_mostly	tracing_thresh;
 
 /*
+ * On boot up, the ring buffer is set to the minimum size, so that
+ * we do not waste memory on systems that are not using tracing.
+ */
+static int ring_buffer_expanded;
+
+/*
  * We need to change this state when a selftest is running.
  * A selftest will lurk into the ring-buffer to count the
  * entries inserted during the selftest although some concurrent
@@ -2985,12 +2991,53 @@ tracing_set_trace_read(struct file *filp
 	return simple_read_from_buffer(ubuf, cnt, ppos, buf, r);
 }
 
+static int tracing_resize_ring_buffer(unsigned long size)
+{
+	int ret;
+
+	/*
+	 * If kernel or user changes the size of the ring buffer
+	 * it get completed.
+	 */
+	ring_buffer_expanded = 1;
+
+	ret = ring_buffer_resize(global_trace.buffer, size);
+	if (ret < 0)
+		 return ret;
+
+	ret = ring_buffer_resize(max_tr.buffer, size);
+	if (ret < 0) {
+		 int r;
+
+		 r = ring_buffer_resize(global_trace.buffer,
+					   global_trace.entries);
+		 if (r < 0) {
+			  /* AARGH! We are left with different
+			   * size max buffer!!!! */
+			  WARN_ON(1);
+			  tracing_disabled = 1;
+		 }
+		 return ret;
+	}
+
+	global_trace.entries = size;
+
+	return ret;
+}
+
 static int tracing_set_tracer(char *buf)
 {
 	struct trace_array *tr = &global_trace;
 	struct tracer *t;
 	int ret = 0;
 
+	if (!ring_buffer_expanded) {
+		ret = tracing_resize_ring_buffer(trace_buf_size);
+		if (ret < 0)
+			return ret;
+		ret = 0;
+	}
+
 	mutex_lock(&trace_types_lock);
 	for (t = trace_types; t; t = t->next) {
 		if (strcmp(t->name, buf) == 0)
@@ -3344,28 +3391,11 @@ tracing_entries_write(struct file *filp,
 	val <<= 10;
 
 	if (val != global_trace.entries) {
-		ret = ring_buffer_resize(global_trace.buffer, val);
-		if (ret < 0) {
-			cnt = ret;
-			goto out;
-		}
-
-		ret = ring_buffer_resize(max_tr.buffer, val);
+		ret = tracing_resize_ring_buffer(val);
 		if (ret < 0) {
-			int r;
 			cnt = ret;
-			r = ring_buffer_resize(global_trace.buffer,
-					       global_trace.entries);
-			if (r < 0) {
-				/* AARGH! We are left with different
-				 * size max buffer!!!! */
-				WARN_ON(1);
-				tracing_disabled = 1;
-			}
 			goto out;
 		}
-
-		global_trace.entries = val;
 	}
 
 	filp->f_pos += cnt;
@@ -3826,6 +3856,7 @@ void ftrace_dump(void)
 __init static int tracer_alloc_buffers(void)
 {
 	struct trace_array_cpu *data;
+	int ring_buf_size;
 	int i;
 	int ret = -ENOMEM;
 
@@ -3838,8 +3869,14 @@ __init static int tracer_alloc_buffers(v
 	cpumask_copy(tracing_buffer_mask, cpu_possible_mask);
 	cpumask_copy(tracing_cpumask, cpu_all_mask);
 
+	/* To save memory, keep the ring buffer size to its minimum */
+	if (ring_buffer_expanded)
+		ring_buf_size = trace_buf_size;
+	else
+		ring_buf_size = 1;
+
 	/* TODO: make the number of buffers hot pluggable with CPUS */
-	global_trace.buffer = ring_buffer_alloc(trace_buf_size,
+	global_trace.buffer = ring_buffer_alloc(ring_buf_size,
 						   TRACE_BUFFER_FLAGS);
 	if (!global_trace.buffer) {
 		printk(KERN_ERR "tracer: failed to allocate ring buffer!\n");
@@ -3850,7 +3887,7 @@ __init static int tracer_alloc_buffers(v
 
 
 #ifdef CONFIG_TRACER_MAX_TRACE
-	max_tr.buffer = ring_buffer_alloc(trace_buf_size,
+	max_tr.buffer = ring_buffer_alloc(ring_buf_size,
 					     TRACE_BUFFER_FLAGS);
 	if (!max_tr.buffer) {
 		printk(KERN_ERR "tracer: failed to allocate max ring buffer!\n");
